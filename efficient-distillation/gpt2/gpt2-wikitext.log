WARNING: A conda environment already exists at '/home/tli104/.conda/envs/myenv'
Remove existing environment (y/[n])? 

CondaSystemExit: Exiting.

Collecting git+https://github.com/huggingface/transformers
  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-n8mwh7bl
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-n8mwh7bl
  Resolved https://github.com/huggingface/transformers to commit 656e869a4523f6a0ce90b3aacbb05cc8fb5794bb
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: numpy>=1.17 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (1.21.6)
Requirement already satisfied: regex!=2019.12.17 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (2022.10.31)
Requirement already satisfied: packaging>=20.0 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (23.0)
Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (0.13.3)
Requirement already satisfied: importlib-metadata in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (6.1.0)
Requirement already satisfied: pyyaml>=5.1 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (6.0)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (0.13.3)
Requirement already satisfied: requests in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (2.28.2)
Requirement already satisfied: tqdm>=4.27 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (4.65.0)
Requirement already satisfied: filelock in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from transformers==4.28.0.dev0) (3.10.7)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.0.dev0) (4.5.0)
Requirement already satisfied: zipp>=0.5 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from importlib-metadata->transformers==4.28.0.dev0) (3.15.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from requests->transformers==4.28.0.dev0) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from requests->transformers==4.28.0.dev0) (3.4)
Requirement already satisfied: certifi>=2017.4.17 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from requests->transformers==4.28.0.dev0) (2022.12.7)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tli104/.conda/envs/myenv/lib/python3.7/site-packages (from requests->transformers==4.28.0.dev0) (1.26.15)
04/09/2023 01:17:40 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: fp16

04/09/2023 01:17:40 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: fp16

04/09/2023 01:17:40 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: fp16

04/09/2023 01:17:40 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

04/09/2023 01:17:47 - WARNING - datasets.builder - Found cached dataset text (/home/tli104/.cache/huggingface/datasets/text/default-3efe75d0ffff50d9/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)
  0%|          | 0/2 [00:00<?, ?it/s]  0%|          | 0/2 [00:00<?, ?it/s]  0%|          | 0/2 [00:00<?, ?it/s]  0%|          | 0/2 [00:00<?, ?it/s] 50%|█████     | 1/2 [00:00<00:00,  1.28it/s] 50%|█████     | 1/2 [00:00<00:00,  1.47it/s] 50%|█████     | 1/2 [00:00<00:00,  1.50it/s] 50%|█████     | 1/2 [00:00<00:00,  1.36it/s]100%|██████████| 2/2 [00:00<00:00,  2.92it/s]
100%|██████████| 2/2 [00:00<00:00,  2.89it/s]
100%|██████████| 2/2 [00:00<00:00,  2.52it/s]
100%|██████████| 2/2 [00:00<00:00,  2.70it/s]
loading configuration file config.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/config.json
Model config GPT2Config {
  "_name_or_path": "gpt2-large",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1280,
  "n_head": 20,
  "n_inner": null,
  "n_layer": 36,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.28.0.dev0",
  "use_cache": true,
  "vocab_size": 50257
}

Could not locate the tokenizer configuration file, will try to use the model config instead.
loading configuration file config.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/config.json
Model config GPT2Config {
  "_name_or_path": "gpt2-large",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1280,
  "n_head": 20,
  "n_inner": null,
  "n_layer": 36,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.28.0.dev0",
  "use_cache": true,
  "vocab_size": 50257
}

loading file vocab.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/vocab.json
loading file merges.txt from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/merges.txt
loading file tokenizer.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/tokenizer.json
loading file added_tokens.json from cache at None
loading file special_tokens_map.json from cache at None
loading file tokenizer_config.json from cache at None
loading configuration file config.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/config.json
Model config GPT2Config {
  "_name_or_path": "gpt2-large",
  "activation_function": "gelu_new",
  "architectures": [
    "GPT2LMHeadModel"
  ],
  "attn_pdrop": 0.1,
  "bos_token_id": 50256,
  "embd_pdrop": 0.1,
  "eos_token_id": 50256,
  "initializer_range": 0.02,
  "layer_norm_epsilon": 1e-05,
  "model_type": "gpt2",
  "n_ctx": 1024,
  "n_embd": 1280,
  "n_head": 20,
  "n_inner": null,
  "n_layer": 36,
  "n_positions": 1024,
  "reorder_and_upcast_attn": false,
  "resid_pdrop": 0.1,
  "scale_attn_by_inverse_layer_idx": false,
  "scale_attn_weights": true,
  "summary_activation": null,
  "summary_first_dropout": 0.1,
  "summary_proj_to_labels": true,
  "summary_type": "cls_index",
  "summary_use_proj": true,
  "task_specific_params": {
    "text-generation": {
      "do_sample": true,
      "max_length": 50
    }
  },
  "transformers_version": "4.28.0.dev0",
  "use_cache": true,
  "vocab_size": 50257
}

loading weights file pytorch_model.bin from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/pytorch_model.bin
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 50256,
  "eos_token_id": 50256,
  "transformers_version": "4.28.0.dev0"
}

All model checkpoint weights were used when initializing GPT2LMHeadModel.

All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-large.
If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.
loading configuration file generation_config.json from cache at /home/tli104/.cache/huggingface/hub/models--gpt2-large/snapshots/212095d5832abbf9926672e1c1e8d14312a3be20/generation_config.json
Generate config GenerationConfig {
  "_from_model_config": true,
  "bos_token_id": 50256,
  "eos_token_id": 50256,
  "transformers_version": "4.28.0.dev0"
}

Running tokenizer on dataset:   0%|          | 0/1801350 [00:00<?, ? examples/s]Running tokenizer on dataset:   0%|          | 0/1801350 [00:00<?, ? examples/s]Running tokenizer on dataset:   0%|          | 0/1801350 [00:00<?, ? examples/s]Running tokenizer on dataset:   0%|          | 0/1801350 [00:00<?, ? examples/s]Running tokenizer on dataset:   0%|          | 1000/1801350 [00:00<18:50, 1593.02 examples/s]Running tokenizer on dataset:   0%|          | 1000/1801350 [00:00<18:20, 1636.62 examples/s]Running tokenizer on dataset:   0%|          | 1000/1801350 [00:00<18:20, 1635.99 examples/s]Running tokenizer on dataset:   0%|          | 1000/1801350 [00:00<18:14, 1644.27 examples/s]Running tokenizer on dataset:   0%|          | 2000/1801350 [00:01<20:19, 1475.36 examples/s]Running tokenizer on dataset:   0%|          | 2000/1801350 [00:01<19:54, 1506.34 examples/s]Running tokenizer on dataset:   0%|          | 2000/1801350 [00:01<19:47, 1515.47 examples/s]Running tokenizer on dataset:   0%|          | 2000/1801350 [00:01<20:29, 1463.67 examples/s]Running tokenizer on dataset:   0%|          | 3000/1801350 [00:01<18:55, 1584.05 examples/s]Running tokenizer on dataset:   0%|          | 3000/1801350 [00:01<18:45, 1597.85 examples/s]Running tokenizer on dataset:   0%|          | 3000/1801350 [00:01<18:57, 1580.27 examples/s]Running tokenizer on dataset:   0%|          | 3000/1801350 [00:01<19:09, 1564.06 examples/s]Running tokenizer on dataset:   0%|          | 4000/1801350 [00:02<18:44, 1598.34 examples/s]Running tokenizer on dataset:   0%|          | 4000/1801350 [00:02<18:38, 1607.14 examples/s]Running tokenizer on dataset:   0%|          | 4000/1801350 [00:02<18:47, 1593.96 examples/s]Running tokenizer on dataset:   0%|          | 4000/1801350 [00:02<19:08, 1565.61 examples/s]Running tokenizer on dataset:   0%|          | 5000/1801350 [00:03<17:19, 1728.46 examples/s]Running tokenizer on dataset:   0%|          | 5000/1801350 [00:03<18:00, 1663.01 examples/s]Running tokenizer on dataset:   0%|          | 5000/1801350 [00:03<17:48, 1681.20 examples/s]Running tokenizer on dataset:   0%|          | 5000/1801350 [00:03<17:54, 1672.45 examples/s]Running tokenizer on dataset:   0%|          | 6000/1801350 [00:03<17:11, 1740.50 examples/s]Running tokenizer on dataset:   0%|          | 6000/1801350 [00:03<17:13, 1737.66 examples/s]Running tokenizer on dataset:   0%|          | 6000/1801350 [00:03<17:17, 1730.25 examples/s]Running tokenizer on dataset:   0%|          | 6000/1801350 [00:03<17:41, 1690.73 examples/s]Running tokenizer on dataset:   0%|          | 7000/1801350 [00:04<18:47, 1591.57 examples/s]Running tokenizer on dataset:   0%|          | 7000/1801350 [00:04<18:23, 1625.81 examples/s]Running tokenizer on dataset:   0%|          | 7000/1801350 [00:04<18:48, 1589.48 examples/s]Running tokenizer on dataset:   0%|          | 7000/1801350 [00:04<18:37, 1605.18 examples/s]Running tokenizer on dataset:   0%|          | 8000/1801350 [00:04<18:27, 1619.46 examples/s]Running tokenizer on dataset:   0%|          | 8000/1801350 [00:05<19:04, 1566.96 examples/s]Running tokenizer on dataset:   0%|          | 8000/1801350 [00:04<19:05, 1565.94 examples/s]Running tokenizer on dataset:   0%|          | 8000/1801350 [00:05<19:11, 1557.06 examples/s]Running tokenizer on dataset:   0%|          | 9000/1801350 [00:05<18:48, 1588.67 examples/s]Running tokenizer on dataset:   0%|          | 9000/1801350 [00:05<18:52, 1582.83 examples/s]Running tokenizer on dataset:   0%|          | 9000/1801350 [00:05<18:39, 1601.74 examples/s]Running tokenizer on dataset:   0%|          | 9000/1801350 [00:05<18:57, 1576.23 examples/s]Running tokenizer on dataset:   1%|          | 10000/1801350 [00:06<18:46, 1590.60 examples/s]Running tokenizer on dataset:   1%|          | 10000/1801350 [00:06<18:43, 1594.84 examples/s]Running tokenizer on dataset:   1%|          | 10000/1801350 [00:06<18:43, 1595.10 examples/s]Running tokenizer on dataset:   1%|          | 10000/1801350 [00:06<18:35, 1605.99 examples/s]Running tokenizer on dataset:   1%|          | 11000/1801350 [00:06<18:50, 1584.16 examples/s]Running tokenizer on dataset:   1%|          | 11000/1801350 [00:06<18:41, 1595.85 examples/s]Running tokenizer on dataset:   1%|          | 11000/1801350 [00:06<18:57, 1574.22 examples/s]Running tokenizer on dataset:   1%|          | 11000/1801350 [00:06<18:53, 1579.83 examples/s]Running tokenizer on dataset:   1%|          | 12000/1801350 [00:07<18:36, 1602.71 examples/s]Running tokenizer on dataset:   1%|          | 12000/1801350 [00:07<18:40, 1596.71 examples/s]Running tokenizer on dataset:   1%|          | 12000/1801350 [00:07<18:37, 1601.82 examples/s]Running tokenizer on dataset:   1%|          | 12000/1801350 [00:07<18:35, 1604.79 examples/s]Running tokenizer on dataset:   1%|          | 13000/1801350 [00:08<18:50, 1582.08 examples/s]Running tokenizer on dataset:   1%|          | 13000/1801350 [00:08<18:48, 1585.36 examples/s]Running tokenizer on dataset:   1%|          | 13000/1801350 [00:08<18:48, 1585.13 examples/s]Running tokenizer on dataset:   1%|          | 13000/1801350 [00:08<18:56, 1573.59 examples/s]Running tokenizer on dataset:   1%|          | 14000/1801350 [00:08<18:24, 1617.56 examples/s]Running tokenizer on dataset:   1%|          | 14000/1801350 [00:08<18:22, 1620.68 examples/s]Running tokenizer on dataset:   1%|          | 14000/1801350 [00:08<18:20, 1624.19 examples/s]Running tokenizer on dataset:   1%|          | 14000/1801350 [00:08<18:26, 1615.20 examples/s]Running tokenizer on dataset:   1%|          | 15000/1801350 [00:09<18:06, 1643.41 examples/s]Running tokenizer on dataset:   1%|          | 15000/1801350 [00:09<18:11, 1637.04 examples/s]Running tokenizer on dataset:   1%|          | 15000/1801350 [00:09<18:09, 1640.27 examples/s]Running tokenizer on dataset:   1%|          | 15000/1801350 [00:09<18:14, 1632.28 examples/s]Running tokenizer on dataset:   1%|          | 16000/1801350 [00:09<18:51, 1577.91 examples/s]Running tokenizer on dataset:   1%|          | 16000/1801350 [00:10<18:57, 1569.98 examples/s]Running tokenizer on dataset:   1%|          | 16000/1801350 [00:09<18:54, 1573.79 examples/s]Running tokenizer on dataset:   1%|          | 16000/1801350 [00:09<18:56, 1571.19 examples/s]Running tokenizer on dataset:   1%|          | 17000/1801350 [00:10<18:37, 1596.63 examples/s]Running tokenizer on dataset:   1%|          | 17000/1801350 [00:10<18:58, 1567.74 examples/s]Running tokenizer on dataset:   1%|          | 17000/1801350 [00:10<19:02, 1561.41 examples/s]Running tokenizer on dataset:   1%|          | 17000/1801350 [00:10<19:15, 1544.20 examples/s]Running tokenizer on dataset:   1%|          | 18000/1801350 [00:11<22:25, 1325.85 examples/s]Running tokenizer on dataset:   1%|          | 18000/1801350 [00:11<22:19, 1331.43 examples/s]Running tokenizer on dataset:   1%|          | 18000/1801350 [00:11<22:28, 1322.22 examples/s]Running tokenizer on dataset:   1%|          | 18000/1801350 [00:11<22:26, 1324.66 examples/s]Running tokenizer on dataset:   1%|          | 19000/1801350 [00:12<20:50, 1425.71 examples/s]Running tokenizer on dataset:   1%|          | 19000/1801350 [00:12<20:51, 1424.71 examples/s]Running tokenizer on dataset:   1%|          | 19000/1801350 [00:12<20:47, 1428.17 examples/s]Running tokenizer on dataset:   1%|          | 19000/1801350 [00:12<20:44, 1431.66 examples/s]Running tokenizer on dataset:   1%|          | 20000/1801350 [00:12<20:01, 1483.02 examples/s]Running tokenizer on dataset:   1%|          | 20000/1801350 [00:12<19:58, 1485.75 examples/s]Running tokenizer on dataset:   1%|          | 20000/1801350 [00:12<19:57, 1487.47 examples/s]Running tokenizer on dataset:   1%|          | 20000/1801350 [00:12<19:59, 1485.49 examples/s]Running tokenizer on dataset:   1%|          | 21000/1801350 [00:13<19:51, 1493.98 examples/s]Running tokenizer on dataset:   1%|          | 21000/1801350 [00:13<19:47, 1499.03 examples/s]Running tokenizer on dataset:   1%|          | 21000/1801350 [00:13<19:52, 1492.55 examples/s]Running tokenizer on dataset:   1%|          | 21000/1801350 [00:13<19:43, 1503.98 examples/s]Running tokenizer on dataset:   1%|          | 22000/1801350 [00:14<19:37, 1510.53 examples/s]Running tokenizer on dataset:   1%|          | 22000/1801350 [00:14<19:38, 1509.53 examples/s]Running tokenizer on dataset:   1%|          | 22000/1801350 [00:14<19:39, 1507.99 examples/s]Running tokenizer on dataset:   1%|          | 22000/1801350 [00:14<19:41, 1505.47 examples/s]Running tokenizer on dataset:   1%|▏         | 23000/1801350 [00:14<18:59, 1560.15 examples/s]Running tokenizer on dataset:   1%|▏         | 23000/1801350 [00:14<19:01, 1557.94 examples/s]Running tokenizer on dataset:   1%|▏         | 23000/1801350 [00:14<19:06, 1551.51 examples/s]Running tokenizer on dataset:   1%|▏         | 23000/1801350 [00:14<19:05, 1552.27 examples/s]Running tokenizer on dataset:   1%|▏         | 24000/1801350 [00:15<18:04, 1638.54 examples/s]Running tokenizer on dataset:   1%|▏         | 24000/1801350 [00:15<18:13, 1625.10 examples/s]Running tokenizer on dataset:   1%|▏         | 24000/1801350 [00:15<18:10, 1629.87 examples/s]Running tokenizer on dataset:   1%|▏         | 24000/1801350 [00:15<18:07, 1634.68 examples/s]Running tokenizer on dataset:   1%|▏         | 25000/1801350 [00:15<17:32, 1687.75 examples/s]Running tokenizer on dataset:   1%|▏         | 25000/1801350 [00:15<17:34, 1684.01 examples/s]Running tokenizer on dataset:   1%|▏         | 25000/1801350 [00:15<17:37, 1679.02 examples/s]Running tokenizer on dataset:   1%|▏         | 25000/1801350 [00:15<17:38, 1678.40 examples/s]Running tokenizer on dataset:   1%|▏         | 26000/1801350 [00:16<17:42, 1670.81 examples/s]Running tokenizer on dataset:   1%|▏         | 26000/1801350 [00:16<17:50, 1658.81 examples/s]Running tokenizer on dataset:   1%|▏         | 26000/1801350 [00:16<17:48, 1662.31 examples/s]Running tokenizer on dataset:   1%|▏         | 26000/1801350 [00:16<17:48, 1661.85 examples/s]Running tokenizer on dataset:   1%|▏         | 27000/1801350 [00:17<18:34, 1591.64 examples/s]Running tokenizer on dataset:   1%|▏         | 27000/1801350 [00:17<18:37, 1587.21 examples/s]Running tokenizer on dataset:   1%|▏         | 27000/1801350 [00:17<18:35, 1589.97 examples/s]Running tokenizer on dataset:   1%|▏         | 27000/1801350 [00:17<18:43, 1579.84 examples/s]Running tokenizer on dataset:   2%|▏         | 28000/1801350 [00:17<18:59, 1556.19 examples/s]Running tokenizer on dataset:   2%|▏         | 28000/1801350 [00:17<19:00, 1554.78 examples/s]Running tokenizer on dataset:   2%|▏         | 28000/1801350 [00:17<19:00, 1554.86 examples/s]Running tokenizer on dataset:   2%|▏         | 28000/1801350 [00:17<19:05, 1548.45 examples/s]Running tokenizer on dataset:   2%|▏         | 29000/1801350 [00:18<18:15, 1617.37 examples/s]Running tokenizer on dataset:   2%|▏         | 29000/1801350 [00:18<18:21, 1608.97 examples/s]Running tokenizer on dataset:   2%|▏         | 29000/1801350 [00:18<18:23, 1606.02 examples/s]Running tokenizer on dataset:   2%|▏         | 29000/1801350 [00:18<18:22, 1608.02 examples/s]Running tokenizer on dataset:   2%|▏         | 30000/1801350 [00:19<18:16, 1615.44 examples/s]Running tokenizer on dataset:   2%|▏         | 30000/1801350 [00:19<18:17, 1613.99 examples/s]Running tokenizer on dataset:   2%|▏         | 30000/1801350 [00:19<18:22, 1607.29 examples/s]Running tokenizer on dataset:   2%|▏         | 30000/1801350 [00:19<18:17, 1614.36 examples/s]Running tokenizer on dataset:   2%|▏         | 31000/1801350 [00:19<19:17, 1529.62 examples/s]Running tokenizer on dataset:   2%|▏         | 31000/1801350 [00:19<19:16, 1530.14 examples/s]Running tokenizer on dataset:   2%|▏         | 31000/1801350 [00:19<19:21, 1524.84 examples/s]Running tokenizer on dataset:   2%|▏         | 31000/1801350 [00:19<19:24, 1520.88 examples/s]Running tokenizer on dataset:   2%|▏         | 32000/1801350 [00:20<19:28, 1514.38 examples/s]Running tokenizer on dataset:   2%|▏         | 32000/1801350 [00:20<19:31, 1509.70 examples/s]Running tokenizer on dataset:   2%|▏         | 32000/1801350 [00:20<19:22, 1521.45 examples/s]Running tokenizer on dataset:   2%|▏         | 32000/1801350 [00:20<19:31, 1509.83 examples/s]Running tokenizer on dataset:   2%|▏         | 33000/1801350 [00:21<19:34, 1506.07 examples/s]Running tokenizer on dataset:   2%|▏         | 33000/1801350 [00:21<19:35, 1504.07 examples/s]Running tokenizer on dataset:   2%|▏         | 33000/1801350 [00:21<19:40, 1498.18 examples/s]Running tokenizer on dataset:   2%|▏         | 33000/1801350 [00:21<19:45, 1492.11 examples/s]Running tokenizer on dataset:   2%|▏         | 34000/1801350 [00:21<19:30, 1509.77 examples/s]Running tokenizer on dataset:   2%|▏         | 34000/1801350 [00:21<19:35, 1503.55 examples/s]Running tokenizer on dataset:   2%|▏         | 34000/1801350 [00:21<19:35, 1503.65 examples/s]Running tokenizer on dataset:   2%|▏         | 34000/1801350 [00:21<19:35, 1502.88 examples/s]Running tokenizer on dataset:   2%|▏         | 35000/1801350 [00:22<18:58, 1551.49 examples/s]Running tokenizer on dataset:   2%|▏         | 35000/1801350 [00:22<18:58, 1551.57 examples/s]Running tokenizer on dataset:   2%|▏         | 35000/1801350 [00:22<19:04, 1543.92 examples/s]Running tokenizer on dataset:   2%|▏         | 35000/1801350 [00:22<19:04, 1543.92 examples/s]Running tokenizer on dataset:   2%|▏         | 36000/1801350 [00:23<19:13, 1530.15 examples/s]Running tokenizer on dataset:   2%|▏         | 36000/1801350 [00:23<19:20, 1520.85 examples/s]Running tokenizer on dataset:   2%|▏         | 36000/1801350 [00:23<19:22, 1518.58 examples/s]Running tokenizer on dataset:   2%|▏         | 36000/1801350 [00:23<19:25, 1514.67 examples/s]Running tokenizer on dataset:   2%|▏         | 37000/1801350 [00:23<19:23, 1516.01 examples/s]Running tokenizer on dataset:   2%|▏         | 37000/1801350 [00:23<19:22, 1517.64 examples/s]Running tokenizer on dataset:   2%|▏         | 37000/1801350 [00:23<19:27, 1511.03 examples/s]Running tokenizer on dataset:   2%|▏         | 37000/1801350 [00:23<19:27, 1511.57 examples/s]Running tokenizer on dataset:   2%|▏         | 38000/1801350 [00:24<19:50, 1481.38 examples/s]Running tokenizer on dataset:   2%|▏         | 38000/1801350 [00:24<19:47, 1484.43 examples/s]Running tokenizer on dataset:   2%|▏         | 38000/1801350 [00:24<19:51, 1480.24 examples/s]Running tokenizer on dataset:   2%|▏         | 38000/1801350 [00:24<19:52, 1478.42 examples/s]Running tokenizer on dataset:   2%|▏         | 39000/1801350 [00:25<19:20, 1518.93 examples/s]Running tokenizer on dataset:   2%|▏         | 39000/1801350 [00:25<19:29, 1506.92 examples/s]Running tokenizer on dataset:   2%|▏         | 39000/1801350 [00:25<19:28, 1508.48 examples/s]Running tokenizer on dataset:   2%|▏         | 39000/1801350 [00:25<19:24, 1513.75 examples/s]Running tokenizer on dataset:   2%|▏         | 40000/1801350 [00:25<19:07, 1534.33 examples/s]Running tokenizer on dataset:   2%|▏         | 40000/1801350 [00:25<19:12, 1528.08 examples/s]Running tokenizer on dataset:   2%|▏         | 40000/1801350 [00:25<19:13, 1527.30 examples/s]Running tokenizer on dataset:   2%|▏         | 40000/1801350 [00:25<19:19, 1518.56 examples/s]Running tokenizer on dataset:   2%|▏         | 41000/1801350 [00:26<18:34, 1578.81 examples/s]Running tokenizer on dataset:   2%|▏         | 41000/1801350 [00:26<18:35, 1577.39 examples/s]Running tokenizer on dataset:   2%|▏         | 41000/1801350 [00:26<18:41, 1569.37 examples/s]Running tokenizer on dataset:   2%|▏         | 41000/1801350 [00:26<18:42, 1568.34 examples/s]Running tokenizer on dataset:   2%|▏         | 42000/1801350 [00:26<19:13, 1524.84 examples/s]Running tokenizer on dataset:   2%|▏         | 42000/1801350 [00:27<19:17, 1520.11 examples/s]Running tokenizer on dataset:   2%|▏         | 42000/1801350 [00:27<19:16, 1520.99 examples/s]Running tokenizer on dataset:   2%|▏         | 42000/1801350 [00:27<19:22, 1513.48 examples/s]Running tokenizer on dataset:   2%|▏         | 43000/1801350 [00:27<19:28, 1504.21 examples/s]Running tokenizer on dataset:   2%|▏         | 43000/1801350 [00:27<19:27, 1506.02 examples/s]Running tokenizer on dataset:   2%|▏         | 43000/1801350 [00:27<19:34, 1496.97 examples/s]Running tokenizer on dataset:   2%|▏         | 43000/1801350 [00:27<19:41, 1488.86 examples/s]Running tokenizer on dataset:   2%|▏         | 44000/1801350 [00:28<18:57, 1544.37 examples/s]Running tokenizer on dataset:   2%|▏         | 44000/1801350 [00:28<19:04, 1535.63 examples/s]Running tokenizer on dataset:   2%|▏         | 44000/1801350 [00:28<19:01, 1539.15 examples/s]Running tokenizer on dataset:   2%|▏         | 44000/1801350 [00:28<19:05, 1534.02 examples/s]Running tokenizer on dataset:   2%|▏         | 45000/1801350 [00:29<21:44, 1346.03 examples/s]Running tokenizer on dataset:   2%|▏         | 45000/1801350 [00:29<21:45, 1345.61 examples/s]Running tokenizer on dataset:   2%|▏         | 45000/1801350 [00:29<21:42, 1348.58 examples/s]Running tokenizer on dataset:   2%|▏         | 45000/1801350 [00:29<21:45, 1345.77 examples/s]Running tokenizer on dataset:   3%|▎         | 46000/1801350 [00:29<20:21, 1437.10 examples/s]Running tokenizer on dataset:   3%|▎         | 46000/1801350 [00:29<20:26, 1431.12 examples/s]Running tokenizer on dataset:   3%|▎         | 46000/1801350 [00:29<20:26, 1431.53 examples/s]Running tokenizer on dataset:   3%|▎         | 46000/1801350 [00:29<20:32, 1423.82 examples/s]Running tokenizer on dataset:   3%|▎         | 47000/1801350 [00:30<19:22, 1509.51 examples/s]Running tokenizer on dataset:   3%|▎         | 47000/1801350 [00:30<19:29, 1499.80 examples/s]Running tokenizer on dataset:   3%|▎         | 47000/1801350 [00:30<19:30, 1498.52 examples/s]Running tokenizer on dataset:   3%|▎         | 47000/1801350 [00:30<19:31, 1497.29 examples/s]Running tokenizer on dataset:   3%|▎         | 48000/1801350 [00:30<16:53, 1730.43 examples/s]Running tokenizer on dataset:   3%|▎         | 48000/1801350 [00:30<17:06, 1707.33 examples/s]Running tokenizer on dataset:   3%|▎         | 48000/1801350 [00:30<17:15, 1693.52 examples/s]Running tokenizer on dataset:   3%|▎         | 48000/1801350 [00:30<17:17, 1689.98 examples/s]Running tokenizer on dataset:   3%|▎         | 49000/1801350 [00:31<16:55, 1725.67 examples/s]Running tokenizer on dataset:   3%|▎         | 49000/1801350 [00:31<16:55, 1725.92 examples/s]Running tokenizer on dataset:   3%|▎         | 49000/1801350 [00:31<16:59, 1718.89 examples/s]Running tokenizer on dataset:   3%|▎         | 49000/1801350 [00:31<16:58, 1721.29 examples/s]Running tokenizer on dataset:   3%|▎         | 50000/1801350 [00:32<16:54, 1726.07 examples/s]Running tokenizer on dataset:   3%|▎         | 50000/1801350 [00:31<16:59, 1718.66 examples/s]Running tokenizer on dataset:   3%|▎         | 50000/1801350 [00:32<16:58, 1719.24 examples/s]Running tokenizer on dataset:   3%|▎         | 50000/1801350 [00:31<17:05, 1707.82 examples/s]Running tokenizer on dataset:   3%|▎         | 51000/1801350 [00:32<17:46, 1640.62 examples/s]Running tokenizer on dataset:   3%|▎         | 51000/1801350 [00:32<17:53, 1631.01 examples/s]Running tokenizer on dataset:   3%|▎         | 51000/1801350 [00:32<17:50, 1635.04 examples/s]Running tokenizer on dataset:   3%|▎         | 51000/1801350 [00:32<17:54, 1628.46 examples/s]Running tokenizer on dataset:   3%|▎         | 52000/1801350 [00:33<17:35, 1656.91 examples/s]Running tokenizer on dataset:   3%|▎         | 52000/1801350 [00:33<17:35, 1656.58 examples/s]Running tokenizer on dataset:   3%|▎         | 52000/1801350 [00:33<17:40, 1649.37 examples/s]Running tokenizer on dataset:   3%|▎         | 52000/1801350 [00:33<17:41, 1647.99 examples/s]Running tokenizer on dataset:   3%|▎         | 53000/1801350 [00:33<16:46, 1737.83 examples/s]Running tokenizer on dataset:   3%|▎         | 53000/1801350 [00:33<16:21, 1781.53 examples/s]Running tokenizer on dataset:   3%|▎         | 53000/1801350 [00:33<16:52, 1727.37 examples/s]Running tokenizer on dataset:   3%|▎         | 53000/1801350 [00:33<16:52, 1726.70 examples/s]Running tokenizer on dataset:   3%|▎         | 54000/1801350 [00:34<17:32, 1660.84 examples/s]Running tokenizer on dataset:   3%|▎         | 54000/1801350 [00:34<17:33, 1659.20 examples/s]Running tokenizer on dataset:   3%|▎         | 54000/1801350 [00:34<17:45, 1640.02 examples/s]Running tokenizer on dataset:   3%|▎         | 54000/1801350 [00:34<17:41, 1645.46 examples/s]Running tokenizer on dataset:   3%|▎         | 55000/1801350 [00:35<18:08, 1603.85 examples/s]Running tokenizer on dataset:   3%|▎         | 55000/1801350 [00:35<18:05, 1609.16 examples/s]Running tokenizer on dataset:   3%|▎         | 55000/1801350 [00:35<18:08, 1604.05 examples/s]Running tokenizer on dataset:   3%|▎         | 55000/1801350 [00:35<18:17, 1590.86 examples/s]Running tokenizer on dataset:   3%|▎         | 56000/1801350 [00:35<17:33, 1657.04 examples/s]Running tokenizer on dataset:   3%|▎         | 56000/1801350 [00:35<17:53, 1626.10 examples/s]Running tokenizer on dataset:   3%|▎         | 56000/1801350 [00:35<17:49, 1632.27 examples/s]Running tokenizer on dataset:   3%|▎         | 56000/1801350 [00:35<17:54, 1624.56 examples/s]Running tokenizer on dataset:   3%|▎         | 57000/1801350 [00:36<18:27, 1575.62 examples/s]Running tokenizer on dataset:   3%|▎         | 57000/1801350 [00:36<18:27, 1574.48 examples/s]Running tokenizer on dataset:   3%|▎         | 57000/1801350 [00:36<18:29, 1571.85 examples/s]Running tokenizer on dataset:   3%|▎         | 57000/1801350 [00:36<18:36, 1562.05 examples/s]Running tokenizer on dataset:   3%|▎         | 58000/1801350 [00:37<18:37, 1559.91 examples/s]Running tokenizer on dataset:   3%|▎         | 58000/1801350 [00:37<18:42, 1553.23 examples/s]Running tokenizer on dataset:   3%|▎         | 58000/1801350 [00:37<18:41, 1554.02 examples/s]Running tokenizer on dataset:   3%|▎         | 58000/1801350 [00:37<18:33, 1566.30 examples/s]Running tokenizer on dataset:   3%|▎         | 59000/1801350 [00:37<17:56, 1618.04 examples/s]Running tokenizer on dataset:   3%|▎         | 59000/1801350 [00:37<18:01, 1611.57 examples/s]Running tokenizer on dataset:   3%|▎         | 59000/1801350 [00:37<18:02, 1608.84 examples/s]Running tokenizer on dataset:   3%|▎         | 59000/1801350 [00:37<18:01, 1610.60 examples/s]Running tokenizer on dataset:   3%|▎         | 60000/1801350 [00:38<18:23, 1577.38 examples/s]Running tokenizer on dataset:   3%|▎         | 60000/1801350 [00:38<18:26, 1573.78 examples/s]Running tokenizer on dataset:   3%|▎         | 60000/1801350 [00:38<18:27, 1572.47 examples/s]Running tokenizer on dataset:   3%|▎         | 60000/1801350 [00:38<18:33, 1564.51 examples/s]Running tokenizer on dataset:   3%|▎         | 61000/1801350 [00:38<17:51, 1623.91 examples/s]Running tokenizer on dataset:   3%|▎         | 61000/1801350 [00:38<17:50, 1625.67 examples/s]Running tokenizer on dataset:   3%|▎         | 61000/1801350 [00:38<17:55, 1618.05 examples/s]Running tokenizer on dataset:   3%|▎         | 61000/1801350 [00:38<17:59, 1611.68 examples/s]Running tokenizer on dataset:   3%|▎         | 62000/1801350 [00:39<17:55, 1617.34 examples/s]Running tokenizer on dataset:   3%|▎         | 62000/1801350 [00:39<17:55, 1617.87 examples/s]Running tokenizer on dataset:   3%|▎         | 62000/1801350 [00:39<17:56, 1615.03 examples/s]Running tokenizer on dataset:   3%|▎         | 62000/1801350 [00:39<18:01, 1607.79 examples/s]Running tokenizer on dataset:   3%|▎         | 63000/1801350 [00:40<18:09, 1595.00 examples/s]Running tokenizer on dataset:   3%|▎         | 63000/1801350 [00:40<18:16, 1585.90 examples/s]Running tokenizer on dataset:   3%|▎         | 63000/1801350 [00:40<18:17, 1584.23 examples/s]Running tokenizer on dataset:   3%|▎         | 63000/1801350 [00:40<18:16, 1584.88 examples/s]Running tokenizer on dataset:   4%|▎         | 64000/1801350 [00:40<18:06, 1599.74 examples/s]Running tokenizer on dataset:   4%|▎         | 64000/1801350 [00:40<18:10, 1593.78 examples/s]Running tokenizer on dataset:   4%|▎         | 64000/1801350 [00:40<18:10, 1593.60 examples/s]Running tokenizer on dataset:   4%|▎         | 64000/1801350 [00:40<18:11, 1592.19 examples/s]Running tokenizer on dataset:   4%|▎         | 65000/1801350 [00:41<17:56, 1612.68 examples/s]Running tokenizer on dataset:   4%|▎         | 65000/1801350 [00:41<18:06, 1597.92 examples/s]Running tokenizer on dataset:   4%|▎         | 65000/1801350 [00:41<18:09, 1593.14 examples/s]Running tokenizer on dataset:   4%|▎         | 65000/1801350 [00:41<18:21, 1575.79 examples/s]Running tokenizer on dataset:   4%|▎         | 66000/1801350 [00:42<18:13, 1587.41 examples/s]Running tokenizer on dataset:   4%|▎         | 66000/1801350 [00:42<18:09, 1593.38 examples/s]Running tokenizer on dataset:   4%|▎         | 66000/1801350 [00:42<18:12, 1589.07 examples/s]Running tokenizer on dataset:   4%|▎         | 66000/1801350 [00:42<18:12, 1588.99 examples/s]Running tokenizer on dataset:   4%|▎         | 67000/1801350 [00:42<17:48, 1622.72 examples/s]Running tokenizer on dataset:   4%|▎         | 67000/1801350 [00:42<17:56, 1610.68 examples/s]Running tokenizer on dataset:   4%|▎         | 67000/1801350 [00:42<17:55, 1613.00 examples/s]Running tokenizer on dataset:   4%|▎         | 67000/1801350 [00:42<18:11, 1589.66 examples/s]Running tokenizer on dataset:   4%|▍         | 68000/1801350 [00:43<21:27, 1346.37 examples/s]Running tokenizer on dataset:   4%|▍         | 68000/1801350 [00:43<21:27, 1346.06 examples/s]Running tokenizer on dataset:   4%|▍         | 68000/1801350 [00:43<21:35, 1338.21 examples/s]Running tokenizer on dataset:   4%|▍         | 68000/1801350 [00:43<21:40, 1332.72 examples/s]Running tokenizer on dataset:   4%|▍         | 69000/1801350 [00:44<19:51, 1454.13 examples/s]Running tokenizer on dataset:   4%|▍         | 69000/1801350 [00:44<19:56, 1448.11 examples/s]Running tokenizer on dataset:   4%|▍         | 69000/1801350 [00:44<19:53, 1451.54 examples/s]Running tokenizer on dataset:   4%|▍         | 69000/1801350 [00:44<19:59, 1443.78 examples/s]Running tokenizer on dataset:   4%|▍         | 70000/1801350 [00:44<18:54, 1526.53 examples/s]Running tokenizer on dataset:   4%|▍         | 70000/1801350 [00:44<18:54, 1525.50 examples/s]Running tokenizer on dataset:   4%|▍         | 70000/1801350 [00:44<18:57, 1522.66 examples/s]Running tokenizer on dataset:   4%|▍         | 70000/1801350 [00:44<18:55, 1525.23 examples/s]Running tokenizer on dataset:   4%|▍         | 71000/1801350 [00:45<18:57, 1521.37 examples/s]Running tokenizer on dataset:   4%|▍         | 71000/1801350 [00:45<19:03, 1513.42 examples/s]Running tokenizer on dataset:   4%|▍         | 71000/1801350 [00:45<19:03, 1512.93 examples/s]Running tokenizer on dataset:   4%|▍         | 71000/1801350 [00:45<19:06, 1509.90 examples/s]Running tokenizer on dataset:   4%|▍         | 72000/1801350 [00:46<18:23, 1566.49 examples/s]Running tokenizer on dataset:   4%|▍         | 72000/1801350 [00:46<18:30, 1557.90 examples/s]Running tokenizer on dataset:   4%|▍         | 72000/1801350 [00:46<18:29, 1559.23 examples/s]Running tokenizer on dataset:   4%|▍         | 72000/1801350 [00:46<18:31, 1555.43 examples/s]Running tokenizer on dataset:   4%|▍         | 73000/1801350 [00:46<17:19, 1663.00 examples/s]Running tokenizer on dataset:   4%|▍         | 73000/1801350 [00:46<17:40, 1629.05 examples/s]Running tokenizer on dataset:   4%|▍         | 73000/1801350 [00:46<17:12, 1673.39 examples/s]Running tokenizer on dataset:   4%|▍         | 73000/1801350 [00:46<17:41, 1627.98 examples/s]Running tokenizer on dataset:   4%|▍         | 74000/1801350 [00:47<16:37, 1731.56 examples/s]Running tokenizer on dataset:   4%|▍         | 74000/1801350 [00:47<16:54, 1702.30 examples/s]Running tokenizer on dataset:   4%|▍         | 74000/1801350 [00:47<16:47, 1715.22 examples/s]Running tokenizer on dataset:   4%|▍         | 74000/1801350 [00:47<16:47, 1715.16 examples/s]Running tokenizer on dataset:   4%|▍         | 75000/1801350 [00:47<16:41, 1724.09 examples/s]Running tokenizer on dataset:   4%|▍         | 75000/1801350 [00:47<16:36, 1733.23 examples/s]Running tokenizer on dataset:   4%|▍         | 75000/1801350 [00:47<16:43, 1720.17 examples/s]Running tokenizer on dataset:   4%|▍         | 75000/1801350 [00:47<16:35, 1733.71 examples/s]Running tokenizer on dataset:   4%|▍         | 76000/1801350 [00:48<16:57, 1695.48 examples/s]Running tokenizer on dataset:   4%|▍         | 76000/1801350 [00:48<16:56, 1696.69 examples/s]Running tokenizer on dataset:   4%|▍         | 76000/1801350 [00:48<17:06, 1680.45 examples/s]Running tokenizer on dataset:   4%|▍         | 76000/1801350 [00:48<17:07, 1679.67 examples/s]Running tokenizer on dataset:   4%|▍         | 77000/1801350 [00:48<17:12, 1669.63 examples/s]Running tokenizer on dataset:   4%|▍         | 77000/1801350 [00:48<17:12, 1669.58 examples/s]Running tokenizer on dataset:   4%|▍         | 77000/1801350 [00:48<17:12, 1669.71 examples/s]Running tokenizer on dataset:   4%|▍         | 77000/1801350 [00:48<17:23, 1651.97 examples/s]Running tokenizer on dataset:   4%|▍         | 78000/1801350 [00:49<17:10, 1672.20 examples/s]Running tokenizer on dataset:   4%|▍         | 78000/1801350 [00:49<17:16, 1662.25 examples/s]Running tokenizer on dataset:   4%|▍         | 78000/1801350 [00:49<17:16, 1662.04 examples/s]Running tokenizer on dataset:   4%|▍         | 78000/1801350 [00:49<17:24, 1650.28 examples/s]Running tokenizer on dataset:   4%|▍         | 79000/1801350 [00:50<18:22, 1562.02 examples/s]Running tokenizer on dataset:   4%|▍         | 79000/1801350 [00:50<18:27, 1555.58 examples/s]Running tokenizer on dataset:   4%|▍         | 79000/1801350 [00:50<18:22, 1562.16 examples/s]Running tokenizer on dataset:   4%|▍         | 79000/1801350 [00:50<18:27, 1555.27 examples/s]Running tokenizer on dataset:   4%|▍         | 80000/1801350 [00:50<18:46, 1527.91 examples/s]Running tokenizer on dataset:   4%|▍         | 80000/1801350 [00:50<18:50, 1522.77 examples/s]Running tokenizer on dataset:   4%|▍         | 80000/1801350 [00:50<18:49, 1524.07 examples/s]Running tokenizer on dataset:   4%|▍         | 80000/1801350 [00:50<18:49, 1524.40 examples/s]Running tokenizer on dataset:   4%|▍         | 81000/1801350 [00:51<18:29, 1550.58 examples/s]Running tokenizer on dataset:   4%|▍         | 81000/1801350 [00:51<18:28, 1552.21 examples/s]Running tokenizer on dataset:   4%|▍         | 81000/1801350 [00:51<18:31, 1547.62 examples/s]Running tokenizer on dataset:   4%|▍         | 81000/1801350 [00:51<18:29, 1550.06 examples/s]Running tokenizer on dataset:   5%|▍         | 82000/1801350 [00:52<18:20, 1562.10 examples/s]Running tokenizer on dataset:   5%|▍         | 82000/1801350 [00:52<18:22, 1559.22 examples/s]Running tokenizer on dataset:   5%|▍         | 82000/1801350 [00:52<18:21, 1561.27 examples/s]Running tokenizer on dataset:   5%|▍         | 82000/1801350 [00:52<18:27, 1552.88 examples/s]Running tokenizer on dataset:   5%|▍         | 83000/1801350 [00:52<17:48, 1608.60 examples/s]Running tokenizer on dataset:   5%|▍         | 83000/1801350 [00:52<17:50, 1604.62 examples/s]Running tokenizer on dataset:   5%|▍         | 83000/1801350 [00:52<17:49, 1607.24 examples/s]Running tokenizer on dataset:   5%|▍         | 83000/1801350 [00:52<17:54, 1599.40 examples/s]Running tokenizer on dataset:   5%|▍         | 84000/1801350 [00:53<17:27, 1638.75 examples/s]Running tokenizer on dataset:   5%|▍         | 84000/1801350 [00:53<17:30, 1635.37 examples/s]Running tokenizer on dataset:   5%|▍         | 84000/1801350 [00:53<17:29, 1636.20 examples/s]Running tokenizer on dataset:   5%|▍         | 84000/1801350 [00:53<17:43, 1614.76 examples/s]Running tokenizer on dataset:   5%|▍         | 85000/1801350 [00:54<17:59, 1589.39 examples/s]Running tokenizer on dataset:   5%|▍         | 85000/1801350 [00:54<18:07, 1577.75 examples/s]Running tokenizer on dataset:   5%|▍         | 85000/1801350 [00:54<18:10, 1574.14 examples/s]Running tokenizer on dataset:   5%|▍         | 85000/1801350 [00:54<18:07, 1578.44 examples/s]Running tokenizer on dataset:   5%|▍         | 86000/1801350 [00:54<17:47, 1606.58 examples/s]Running tokenizer on dataset:   5%|▍         | 86000/1801350 [00:54<17:47, 1606.94 examples/s]Running tokenizer on dataset:   5%|▍         | 86000/1801350 [00:54<17:44, 1611.12 examples/s]Running tokenizer on dataset:   5%|▍         | 86000/1801350 [00:54<17:51, 1601.44 examples/s]Running tokenizer on dataset:   5%|▍         | 87000/1801350 [00:55<17:24, 1641.11 examples/s]Running tokenizer on dataset:   5%|▍         | 87000/1801350 [00:55<17:30, 1632.06 examples/s]Running tokenizer on dataset:   5%|▍         | 87000/1801350 [00:55<17:26, 1638.44 examples/s]Running tokenizer on dataset:   5%|▍         | 87000/1801350 [00:55<17:32, 1628.94 examples/s]Running tokenizer on dataset:   5%|▍         | 88000/1801350 [00:55<17:16, 1652.30 examples/s]Running tokenizer on dataset:   5%|▍         | 88000/1801350 [00:55<17:17, 1651.80 examples/s]Running tokenizer on dataset:   5%|▍         | 88000/1801350 [00:55<17:23, 1641.22 examples/s]Running tokenizer on dataset:   5%|▍         | 88000/1801350 [00:55<17:25, 1639.36 examples/s]Running tokenizer on dataset:   5%|▍         | 89000/1801350 [00:56<18:07, 1575.29 examples/s]Running tokenizer on dataset:   5%|▍         | 89000/1801350 [00:56<18:10, 1570.57 examples/s]Running tokenizer on dataset:   5%|▍         | 89000/1801350 [00:56<18:10, 1569.94 examples/s]Running tokenizer on dataset:   5%|▍         | 89000/1801350 [00:56<18:12, 1567.84 examples/s]Running tokenizer on dataset:   5%|▍         | 90000/1801350 [00:57<18:32, 1538.86 examples/s]Running tokenizer on dataset:   5%|▍         | 90000/1801350 [00:57<18:30, 1540.84 examples/s]Running tokenizer on dataset:   5%|▍         | 90000/1801350 [00:57<18:27, 1544.72 examples/s]Running tokenizer on dataset:   5%|▍         | 90000/1801350 [00:57<18:26, 1546.51 examples/s]Running tokenizer on dataset:   5%|▌         | 91000/1801350 [00:58<21:43, 1311.70 examples/s]Running tokenizer on dataset:   5%|▌         | 91000/1801350 [00:58<21:51, 1303.96 examples/s]Running tokenizer on dataset:   5%|▌         | 91000/1801350 [00:58<21:49, 1305.92 examples/s]Running tokenizer on dataset:   5%|▌         | 91000/1801350 [00:58<22:20, 1276.09 examples/s]Running tokenizer on dataset:   5%|▌         | 92000/1801350 [00:58<20:13, 1408.66 examples/s]Running tokenizer on dataset:   5%|▌         | 92000/1801350 [00:58<20:18, 1402.41 examples/s]Running tokenizer on dataset:   5%|▌         | 92000/1801350 [00:58<20:16, 1405.29 examples/s]Running tokenizer on dataset:   5%|▌         | 92000/1801350 [00:58<20:45, 1372.09 examples/s]Running tokenizer on dataset:   5%|▌         | 93000/1801350 [00:59<19:20, 1472.69 examples/s]Running tokenizer on dataset:   5%|▌         | 93000/1801350 [00:59<19:17, 1475.92 examples/s]Running tokenizer on dataset:   5%|▌         | 93000/1801350 [00:59<19:16, 1477.75 examples/s]Running tokenizer on dataset:   5%|▌         | 93000/1801350 [00:59<19:42, 1445.22 examples/s]Running tokenizer on dataset:   5%|▌         | 94000/1801350 [01:00<19:23, 1467.46 examples/s]Running tokenizer on dataset:   5%|▌         | 94000/1801350 [01:00<19:27, 1462.18 examples/s]Running tokenizer on dataset:   5%|▌         | 94000/1801350 [01:00<19:52, 1431.37 examples/s]Running tokenizer on dataset:   5%|▌         | 94000/1801350 [01:00<19:50, 1434.19 examples/s]Running tokenizer on dataset:   5%|▌         | 95000/1801350 [01:00<18:10, 1564.41 examples/s]Running tokenizer on dataset:   5%|▌         | 95000/1801350 [01:00<18:22, 1547.88 examples/s]Running tokenizer on dataset:   5%|▌         | 95000/1801350 [01:00<18:35, 1530.26 examples/s]Running tokenizer on dataset:   5%|▌         | 95000/1801350 [01:00<18:26, 1542.11 examples/s]Running tokenizer on dataset:   5%|▌         | 96000/1801350 [01:01<18:27, 1540.01 examples/s]Running tokenizer on dataset:   5%|▌         | 96000/1801350 [01:01<18:16, 1554.86 examples/s]Running tokenizer on dataset:   5%|▌         | 96000/1801350 [01:01<18:39, 1523.70 examples/s]Running tokenizer on dataset:   5%|▌         | 96000/1801350 [01:01<18:35, 1528.97 examples/s]Running tokenizer on dataset:   5%|▌         | 97000/1801350 [01:01<16:41, 1701.51 examples/s]Running tokenizer on dataset:   5%|▌         | 97000/1801350 [01:01<16:45, 1694.88 examples/s]Running tokenizer on dataset:   5%|▌         | 97000/1801350 [01:01<16:57, 1675.40 examples/s]Running tokenizer on dataset:   5%|▌         | 97000/1801350 [01:01<16:51, 1684.58 examples/s]Running tokenizer on dataset:   5%|▌         | 98000/1801350 [01:02<17:21, 1635.58 examples/s]Running tokenizer on dataset:   5%|▌         | 98000/1801350 [01:02<17:12, 1648.94 examples/s]Running tokenizer on dataset:   5%|▌         | 98000/1801350 [01:02<17:19, 1638.68 examples/s]Running tokenizer on dataset:   5%|▌         | 98000/1801350 [01:02<17:25, 1629.38 examples/s]Running tokenizer on dataset:   5%|▌         | 99000/1801350 [01:03<17:23, 1632.08 examples/s]Running tokenizer on dataset:   5%|▌         | 99000/1801350 [01:03<17:51, 1588.48 examples/s]Running tokenizer on dataset:   5%|▌         | 99000/1801350 [01:03<17:54, 1584.94 examples/s]Running tokenizer on dataset:   5%|▌         | 99000/1801350 [01:03<17:25, 1628.49 examples/s]Running tokenizer on dataset:   6%|▌         | 100000/1801350 [01:03<18:11, 1558.63 examples/s]Running tokenizer on dataset:   6%|▌         | 100000/1801350 [01:03<18:12, 1557.13 examples/s]Running tokenizer on dataset:   6%|▌         | 100000/1801350 [01:03<18:22, 1543.85 examples/s]Running tokenizer on dataset:   6%|▌         | 100000/1801350 [01:03<18:03, 1569.55 examples/s]Running tokenizer on dataset:   6%|▌         | 101000/1801350 [01:04<18:08, 1561.44 examples/s]Running tokenizer on dataset:   6%|▌         | 101000/1801350 [01:04<18:34, 1526.01 examples/s]Running tokenizer on dataset:   6%|▌         | 101000/1801350 [01:04<18:15, 1552.20 examples/s]Running tokenizer on dataset:   6%|▌         | 101000/1801350 [01:04<18:37, 1522.15 examples/s]Running tokenizer on dataset:   6%|▌         | 102000/1801350 [01:05<17:47, 1592.51 examples/s]Running tokenizer on dataset:   6%|▌         | 102000/1801350 [01:05<17:58, 1576.06 examples/s]Running tokenizer on dataset:   6%|▌         | 102000/1801350 [01:05<17:54, 1581.52 examples/s]Running tokenizer on dataset:   6%|▌         | 102000/1801350 [01:05<17:43, 1598.48 examples/s]Running tokenizer on dataset:   6%|▌         | 103000/1801350 [01:05<17:52, 1584.25 examples/s]Running tokenizer on dataset:   6%|▌         | 103000/1801350 [01:05<17:51, 1584.86 examples/s]Running tokenizer on dataset:   6%|▌         | 103000/1801350 [01:05<17:58, 1574.33 examples/s]Running tokenizer on dataset:   6%|▌         | 103000/1801350 [01:05<17:57, 1576.51 examples/s]Running tokenizer on dataset:   6%|▌         | 104000/1801350 [01:06<17:53, 1581.00 examples/s]Running tokenizer on dataset:   6%|▌         | 104000/1801350 [01:06<18:28, 1530.52 examples/s]Running tokenizer on dataset:   6%|▌         | 104000/1801350 [01:06<18:35, 1521.10 examples/s]Running tokenizer on dataset:   6%|▌         | 104000/1801350 [01:06<18:27, 1532.13 examples/s]Running tokenizer on dataset:   6%|▌         | 105000/1801350 [01:07<18:17, 1545.27 examples/s]Running tokenizer on dataset:   6%|▌         | 105000/1801350 [01:07<18:09, 1557.45 examples/s]Running tokenizer on dataset:   6%|▌         | 105000/1801350 [01:07<18:07, 1560.05 examples/s]Running tokenizer on dataset:   6%|▌         | 105000/1801350 [01:07<18:03, 1565.02 examples/s]Running tokenizer on dataset:   6%|▌         | 106000/1801350 [01:07<18:04, 1563.33 examples/s]Running tokenizer on dataset:   6%|▌         | 106000/1801350 [01:07<17:56, 1574.63 examples/s]Running tokenizer on dataset:   6%|▌         | 106000/1801350 [01:07<17:57, 1573.95 examples/s]Running tokenizer on dataset:   6%|▌         | 106000/1801350 [01:07<18:12, 1552.26 examples/s]Running tokenizer on dataset:   6%|▌         | 107000/1801350 [01:08<18:14, 1547.58 examples/s]Running tokenizer on dataset:   6%|▌         | 107000/1801350 [01:08<18:12, 1550.97 examples/s]Running tokenizer on dataset:   6%|▌         | 107000/1801350 [01:08<18:05, 1560.79 examples/s]Running tokenizer on dataset:   6%|▌         | 107000/1801350 [01:08<18:25, 1532.83 examples/s]Running tokenizer on dataset:   6%|▌         | 108000/1801350 [01:08<18:07, 1557.80 examples/s]Running tokenizer on dataset:   6%|▌         | 108000/1801350 [01:08<17:46, 1587.32 examples/s]Running tokenizer on dataset:   6%|▌         | 108000/1801350 [01:08<18:07, 1557.75 examples/s]Running tokenizer on dataset:   6%|▌         | 108000/1801350 [01:08<18:07, 1557.66 examples/s]Running tokenizer on dataset:   6%|▌         | 109000/1801350 [01:09<18:27, 1527.89 examples/s]Running tokenizer on dataset:   6%|▌         | 109000/1801350 [01:09<18:26, 1529.28 examples/s]Running tokenizer on dataset:   6%|▌         | 109000/1801350 [01:09<18:21, 1535.72 examples/s]Running tokenizer on dataset:   6%|▌         | 109000/1801350 [01:09<18:42, 1507.36 examples/s]Running tokenizer on dataset:   6%|▌         | 110000/1801350 [01:10<18:24, 1530.77 examples/s]Running tokenizer on dataset:   6%|▌         | 110000/1801350 [01:10<18:46, 1501.46 examples/s]Running tokenizer on dataset:   6%|▌         | 110000/1801350 [01:10<18:18, 1540.19 examples/s]Running tokenizer on dataset:   6%|▌         | 110000/1801350 [01:10<18:41, 1507.48 examples/s]Running tokenizer on dataset:   6%|▌         | 111000/1801350 [01:10<17:43, 1589.74 examples/s]Running tokenizer on dataset:   6%|▌         | 111000/1801350 [01:10<17:54, 1573.28 examples/s]Running tokenizer on dataset:   6%|▌         | 111000/1801350 [01:10<17:37, 1598.69 examples/s]Running tokenizer on dataset:   6%|▌         | 111000/1801350 [01:10<17:57, 1568.81 examples/s]Running tokenizer on dataset:   6%|▌         | 112000/1801350 [01:11<20:29, 1374.00 examples/s]Running tokenizer on dataset:   6%|▌         | 112000/1801350 [01:11<21:00, 1340.03 examples/s]Running tokenizer on dataset:   6%|▌         | 112000/1801350 [01:11<21:21, 1318.77 examples/s]Running tokenizer on dataset:   6%|▌         | 112000/1801350 [01:11<20:55, 1345.13 examples/s]Running tokenizer on dataset:   6%|▋         | 113000/1801350 [01:12<19:31, 1441.62 examples/s]Running tokenizer on dataset:   6%|▋         | 113000/1801350 [01:12<19:26, 1446.97 examples/s]Running tokenizer on dataset:   6%|▋         | 113000/1801350 [01:12<19:48, 1420.51 examples/s]Running tokenizer on dataset:   6%|▋         | 113000/1801350 [01:12<19:54, 1413.22 examples/s]Running tokenizer on dataset:   6%|▋         | 114000/1801350 [01:13<19:28, 1444.30 examples/s]Running tokenizer on dataset:   6%|▋         | 114000/1801350 [01:13<19:41, 1427.57 examples/s]Running tokenizer on dataset:   6%|▋         | 114000/1801350 [01:13<19:50, 1417.71 examples/s]Running tokenizer on dataset:   6%|▋         | 114000/1801350 [01:13<19:29, 1443.16 examples/s]Running tokenizer on dataset:   6%|▋         | 115000/1801350 [01:13<18:55, 1484.56 examples/s]Running tokenizer on dataset:   6%|▋         | 115000/1801350 [01:13<19:00, 1477.97 examples/s]Running tokenizer on dataset:   6%|▋         | 115000/1801350 [01:13<18:55, 1485.72 examples/s]Running tokenizer on dataset:   6%|▋         | 115000/1801350 [01:13<19:13, 1461.50 examples/s]Running tokenizer on dataset:   6%|▋         | 116000/1801350 [01:14<18:58, 1480.15 examples/s]Running tokenizer on dataset:   6%|▋         | 116000/1801350 [01:14<19:06, 1470.03 examples/s]Running tokenizer on dataset:   6%|▋         | 116000/1801350 [01:14<19:07, 1468.10 examples/s]Running tokenizer on dataset:   6%|▋         | 116000/1801350 [01:14<19:05, 1470.97 examples/s]Running tokenizer on dataset:   6%|▋         | 117000/1801350 [01:15<18:51, 1489.06 examples/s]Running tokenizer on dataset:   6%|▋         | 117000/1801350 [01:15<18:56, 1481.44 examples/s]Running tokenizer on dataset:   6%|▋         | 117000/1801350 [01:15<18:57, 1480.53 examples/s]Running tokenizer on dataset:   6%|▋         | 117000/1801350 [01:15<19:04, 1471.42 examples/s]Running tokenizer on dataset:   7%|▋         | 118000/1801350 [01:15<18:50, 1488.42 examples/s]Running tokenizer on dataset:   7%|▋         | 118000/1801350 [01:15<18:52, 1486.29 examples/s]Running tokenizer on dataset:   7%|▋         | 118000/1801350 [01:15<18:54, 1483.81 examples/s]Running tokenizer on dataset:   7%|▋         | 118000/1801350 [01:15<19:00, 1476.46 examples/s]Running tokenizer on dataset:   7%|▋         | 119000/1801350 [01:16<18:21, 1527.62 examples/s]Running tokenizer on dataset:   7%|▋         | 119000/1801350 [01:16<18:26, 1520.65 examples/s]Running tokenizer on dataset:   7%|▋         | 119000/1801350 [01:16<18:30, 1514.55 examples/s]Running tokenizer on dataset:   7%|▋         | 119000/1801350 [01:16<18:24, 1522.57 examples/s]Running tokenizer on dataset:   7%|▋         | 120000/1801350 [01:17<18:11, 1540.19 examples/s]Running tokenizer on dataset:   7%|▋         | 120000/1801350 [01:17<18:14, 1535.60 examples/s]Running tokenizer on dataset:   7%|▋         | 120000/1801350 [01:17<18:24, 1522.25 examples/s]Running tokenizer on dataset:   7%|▋         | 120000/1801350 [01:17<18:10, 1542.24 examples/s]Running tokenizer on dataset:   7%|▋         | 121000/1801350 [01:17<17:25, 1606.72 examples/s]Running tokenizer on dataset:   7%|▋         | 121000/1801350 [01:17<17:31, 1597.85 examples/s]Running tokenizer on dataset:   7%|▋         | 121000/1801350 [01:17<17:32, 1596.98 examples/s]Running tokenizer on dataset:   7%|▋         | 121000/1801350 [01:17<17:29, 1601.42 examples/s]Running tokenizer on dataset:   7%|▋         | 122000/1801350 [01:18<17:57, 1557.98 examples/s]Running tokenizer on dataset:   7%|▋         | 122000/1801350 [01:18<18:09, 1540.92 examples/s]Running tokenizer on dataset:   7%|▋         | 122000/1801350 [01:18<18:08, 1542.99 examples/s]Running tokenizer on dataset:   7%|▋         | 122000/1801350 [01:18<18:05, 1547.16 examples/s]Running tokenizer on dataset:   7%|▋         | 123000/1801350 [01:18<17:53, 1563.46 examples/s]Running tokenizer on dataset:   7%|▋         | 123000/1801350 [01:18<17:53, 1563.64 examples/s]Running tokenizer on dataset:   7%|▋         | 123000/1801350 [01:18<17:53, 1563.98 examples/s]Running tokenizer on dataset:   7%|▋         | 123000/1801350 [01:19<17:50, 1567.46 examples/s]Running tokenizer on dataset:   7%|▋         | 124000/1801350 [01:19<17:55, 1559.63 examples/s]Running tokenizer on dataset:   7%|▋         | 124000/1801350 [01:19<17:58, 1554.77 examples/s]Running tokenizer on dataset:   7%|▋         | 124000/1801350 [01:19<18:02, 1549.28 examples/s]Running tokenizer on dataset:   7%|▋         | 124000/1801350 [01:19<17:59, 1553.64 examples/s]Running tokenizer on dataset:   7%|▋         | 125000/1801350 [01:20<17:50, 1566.49 examples/s]Running tokenizer on dataset:   7%|▋         | 125000/1801350 [01:20<17:52, 1562.37 examples/s]Running tokenizer on dataset:   7%|▋         | 125000/1801350 [01:20<17:59, 1553.42 examples/s]Running tokenizer on dataset:   7%|▋         | 125000/1801350 [01:20<17:50, 1565.92 examples/s]Running tokenizer on dataset:   7%|▋         | 126000/1801350 [01:20<17:32, 1591.38 examples/s]Running tokenizer on dataset:   7%|▋         | 126000/1801350 [01:20<17:42, 1577.16 examples/s]Running tokenizer on dataset:   7%|▋         | 126000/1801350 [01:20<17:42, 1576.57 examples/s]Running tokenizer on dataset:   7%|▋         | 126000/1801350 [01:20<17:26, 1600.72 examples/s]Running tokenizer on dataset:   7%|▋         | 127000/1801350 [01:21<16:47, 1662.31 examples/s]Running tokenizer on dataset:   7%|▋         | 127000/1801350 [01:21<16:53, 1652.28 examples/s]Running tokenizer on dataset:   7%|▋         | 127000/1801350 [01:21<17:01, 1638.89 examples/s]Running tokenizer on dataset:   7%|▋         | 127000/1801350 [01:21<16:34, 1682.77 examples/s]Running tokenizer on dataset:   7%|▋         | 128000/1801350 [01:22<17:25, 1601.27 examples/s]Running tokenizer on dataset:   7%|▋         | 128000/1801350 [01:22<17:28, 1596.33 examples/s]Running tokenizer on dataset:   7%|▋         | 128000/1801350 [01:22<17:24, 1602.00 examples/s]Running tokenizer on dataset:   7%|▋         | 128000/1801350 [01:22<17:01, 1637.48 examples/s]Running tokenizer on dataset:   7%|▋         | 129000/1801350 [01:22<17:42, 1573.54 examples/s]Running tokenizer on dataset:   7%|▋         | 129000/1801350 [01:22<17:50, 1562.72 examples/s]Running tokenizer on dataset:   7%|▋         | 129000/1801350 [01:22<17:46, 1567.69 examples/s]Running tokenizer on dataset:   7%|▋         | 129000/1801350 [01:22<17:54, 1557.05 examples/s]Running tokenizer on dataset:   7%|▋         | 130000/1801350 [01:23<17:47, 1565.18 examples/s]Running tokenizer on dataset:   7%|▋         | 130000/1801350 [01:23<17:57, 1550.93 examples/s]Running tokenizer on dataset:   7%|▋         | 130000/1801350 [01:23<17:34, 1584.32 examples/s]Running tokenizer on dataset:   7%|▋         | 130000/1801350 [01:23<17:59, 1548.70 examples/s]Running tokenizer on dataset:   7%|▋         | 131000/1801350 [01:24<17:45, 1567.57 examples/s]Running tokenizer on dataset:   7%|▋         | 131000/1801350 [01:24<17:51, 1559.58 examples/s]Running tokenizer on dataset:   7%|▋         | 131000/1801350 [01:24<17:40, 1574.35 examples/s]Running tokenizer on dataset:   7%|▋         | 131000/1801350 [01:24<18:10, 1531.13 examples/s]Running tokenizer on dataset:   7%|▋         | 132000/1801350 [01:24<19:02, 1461.62 examples/s]Running tokenizer on dataset:   7%|▋         | 132000/1801350 [01:24<19:06, 1456.45 examples/s]Running tokenizer on dataset:   7%|▋         | 132000/1801350 [01:24<18:55, 1470.21 examples/s]Running tokenizer on dataset:   7%|▋         | 132000/1801350 [01:24<18:53, 1472.86 examples/s]Running tokenizer on dataset:   7%|▋         | 133000/1801350 [01:25<20:41, 1344.04 examples/s]Running tokenizer on dataset:   7%|▋         | 133000/1801350 [01:25<20:34, 1351.95 examples/s]Running tokenizer on dataset:   7%|▋         | 133000/1801350 [01:25<20:46, 1337.91 examples/s]Running tokenizer on dataset:   7%|▋         | 133000/1801350 [01:25<20:52, 1331.92 examples/s]Running tokenizer on dataset:   7%|▋         | 134000/1801350 [01:26<19:26, 1429.80 examples/s]Running tokenizer on dataset:   7%|▋         | 134000/1801350 [01:26<19:27, 1427.78 examples/s]Running tokenizer on dataset:   7%|▋         | 134000/1801350 [01:26<19:22, 1434.46 examples/s]Running tokenizer on dataset:   7%|▋         | 134000/1801350 [01:26<19:14, 1444.42 examples/s]Running tokenizer on dataset:   7%|▋         | 135000/1801350 [01:26<18:12, 1525.42 examples/s]Running tokenizer on dataset:   7%|▋         | 135000/1801350 [01:26<18:07, 1531.60 examples/s]Running tokenizer on dataset:   7%|▋         | 135000/1801350 [01:26<18:15, 1520.63 examples/s]Running tokenizer on dataset:   7%|▋         | 135000/1801350 [01:26<18:05, 1534.77 examples/s]Running tokenizer on dataset:   8%|▊         | 136000/1801350 [01:27<17:36, 1575.58 examples/s]Running tokenizer on dataset:   8%|▊         | 136000/1801350 [01:27<17:38, 1573.69 examples/s]Running tokenizer on dataset:   8%|▊         | 136000/1801350 [01:27<17:36, 1576.93 examples/s]Running tokenizer on dataset:   8%|▊         | 136000/1801350 [01:27<17:31, 1584.03 examples/s]Running tokenizer on dataset:   8%|▊         | 137000/1801350 [01:27<16:13, 1709.77 examples/s]Running tokenizer on dataset:   8%|▊         | 137000/1801350 [01:27<16:23, 1692.20 examples/s]Running tokenizer on dataset:   8%|▊         | 137000/1801350 [01:27<16:21, 1695.81 examples/s]Running tokenizer on dataset:   8%|▊         | 137000/1801350 [01:27<16:28, 1684.00 examples/s]Running tokenizer on dataset:   8%|▊         | 138000/1801350 [01:28<16:55, 1637.41 examples/s]Running tokenizer on dataset:   8%|▊         | 138000/1801350 [01:28<16:55, 1637.30 examples/s]Running tokenizer on dataset:   8%|▊         | 138000/1801350 [01:28<16:53, 1640.56 examples/s]Running tokenizer on dataset:   8%|▊         | 138000/1801350 [01:28<16:50, 1645.38 examples/s]Running tokenizer on dataset:   8%|▊         | 139000/1801350 [01:29<16:18, 1698.88 examples/s]Running tokenizer on dataset:   8%|▊         | 139000/1801350 [01:29<16:48, 1648.25 examples/s]Running tokenizer on dataset:   8%|▊         | 139000/1801350 [01:29<16:48, 1648.08 examples/s]Running tokenizer on dataset:   8%|▊         | 139000/1801350 [01:29<16:49, 1646.88 examples/s]Running tokenizer on dataset:   8%|▊         | 140000/1801350 [01:29<17:03, 1623.19 examples/s]Running tokenizer on dataset:   8%|▊         | 140000/1801350 [01:29<17:14, 1605.48 examples/s]Running tokenizer on dataset:   8%|▊         | 140000/1801350 [01:29<17:14, 1606.61 examples/s]Running tokenizer on dataset:   8%|▊         | 140000/1801350 [01:29<17:34, 1574.87 examples/s]Running tokenizer on dataset:   8%|▊         | 141000/1801350 [01:30<17:08, 1615.03 examples/s]Running tokenizer on dataset:   8%|▊         | 141000/1801350 [01:30<17:15, 1602.67 examples/s]Running tokenizer on dataset:   8%|▊         | 141000/1801350 [01:30<17:11, 1608.96 examples/s]Running tokenizer on dataset:   8%|▊         | 141000/1801350 [01:30<17:17, 1599.83 examples/s]Running tokenizer on dataset:   8%|▊         | 142000/1801350 [01:31<17:23, 1589.53 examples/s]Running tokenizer on dataset:   8%|▊         | 142000/1801350 [01:31<17:23, 1590.35 examples/s]Running tokenizer on dataset:   8%|▊         | 142000/1801350 [01:31<17:25, 1587.56 examples/s]Running tokenizer on dataset:   8%|▊         | 142000/1801350 [01:31<17:25, 1587.32 examples/s]Running tokenizer on dataset:   8%|▊         | 143000/1801350 [01:31<17:53, 1544.40 examples/s]Running tokenizer on dataset:   8%|▊         | 143000/1801350 [01:31<17:51, 1547.72 examples/s]Running tokenizer on dataset:   8%|▊         | 143000/1801350 [01:31<17:52, 1546.52 examples/s]Running tokenizer on dataset:   8%|▊         | 143000/1801350 [01:31<17:56, 1539.91 examples/s]Running tokenizer on dataset:   8%|▊         | 144000/1801350 [01:32<17:02, 1620.23 examples/s]Running tokenizer on dataset:   8%|▊         | 144000/1801350 [01:32<17:04, 1618.00 examples/s]Running tokenizer on dataset:   8%|▊         | 144000/1801350 [01:32<17:10, 1608.69 examples/s]Running tokenizer on dataset:   8%|▊         | 144000/1801350 [01:32<17:05, 1616.57 examples/s]Running tokenizer on dataset:   8%|▊         | 145000/1801350 [01:32<16:23, 1683.31 examples/s]Running tokenizer on dataset:   8%|▊         | 145000/1801350 [01:32<16:35, 1664.37 examples/s]Running tokenizer on dataset:   8%|▊         | 145000/1801350 [01:32<16:36, 1661.73 examples/s]Running tokenizer on dataset:   8%|▊         | 145000/1801350 [01:32<16:48, 1642.04 examples/s]Running tokenizer on dataset:   8%|▊         | 146000/1801350 [01:33<16:29, 1672.68 examples/s]Running tokenizer on dataset:   8%|▊         | 146000/1801350 [01:33<16:32, 1667.56 examples/s]Running tokenizer on dataset:   8%|▊         | 146000/1801350 [01:33<16:39, 1655.90 examples/s]Running tokenizer on dataset:   8%|▊         | 146000/1801350 [01:33<16:29, 1673.28 examples/s]Running tokenizer on dataset:   8%|▊         | 147000/1801350 [01:34<17:01, 1619.88 examples/s]Running tokenizer on dataset:   8%|▊         | 147000/1801350 [01:34<16:56, 1627.87 examples/s]Running tokenizer on dataset:   8%|▊         | 147000/1801350 [01:34<17:04, 1615.10 examples/s]Running tokenizer on dataset:   8%|▊         | 147000/1801350 [01:34<17:11, 1604.16 examples/s]Running tokenizer on dataset:   8%|▊         | 148000/1801350 [01:34<17:39, 1560.76 examples/s]Running tokenizer on dataset:   8%|▊         | 148000/1801350 [01:34<17:40, 1558.88 examples/s]Running tokenizer on dataset:   8%|▊         | 148000/1801350 [01:34<17:49, 1545.68 examples/s]Running tokenizer on dataset:   8%|▊         | 148000/1801350 [01:34<17:47, 1548.71 examples/s]Running tokenizer on dataset:   8%|▊         | 149000/1801350 [01:35<17:19, 1589.73 examples/s]Running tokenizer on dataset:   8%|▊         | 149000/1801350 [01:35<17:19, 1589.87 examples/s]Running tokenizer on dataset:   8%|▊         | 149000/1801350 [01:35<17:19, 1589.21 examples/s]Running tokenizer on dataset:   8%|▊         | 149000/1801350 [01:35<17:24, 1582.49 examples/s]Running tokenizer on dataset:   8%|▊         | 150000/1801350 [01:36<17:43, 1552.49 examples/s]Running tokenizer on dataset:   8%|▊         | 150000/1801350 [01:36<17:43, 1553.01 examples/s]Running tokenizer on dataset:   8%|▊         | 150000/1801350 [01:36<17:43, 1552.63 examples/s]Running tokenizer on dataset:   8%|▊         | 150000/1801350 [01:36<17:45, 1549.78 examples/s]Running tokenizer on dataset:   8%|▊         | 151000/1801350 [01:36<17:57, 1531.28 examples/s]Running tokenizer on dataset:   8%|▊         | 151000/1801350 [01:36<17:51, 1539.83 examples/s]Running tokenizer on dataset:   8%|▊         | 151000/1801350 [01:36<17:58, 1530.70 examples/s]Running tokenizer on dataset:   8%|▊         | 151000/1801350 [01:36<18:11, 1512.45 examples/s]Running tokenizer on dataset:   8%|▊         | 152000/1801350 [01:37<17:49, 1542.69 examples/s]Running tokenizer on dataset:   8%|▊         | 152000/1801350 [01:37<17:41, 1553.25 examples/s]Running tokenizer on dataset:   8%|▊         | 152000/1801350 [01:37<17:50, 1540.13 examples/s]Running tokenizer on dataset:   8%|▊         | 152000/1801350 [01:37<18:08, 1514.78 examples/s]Running tokenizer on dataset:   8%|▊         | 153000/1801350 [01:38<17:31, 1568.35 examples/s]Running tokenizer on dataset:   8%|▊         | 153000/1801350 [01:38<17:37, 1559.03 examples/s]Running tokenizer on dataset:   8%|▊         | 153000/1801350 [01:38<17:35, 1561.36 examples/s]Running tokenizer on dataset:   8%|▊         | 153000/1801350 [01:38<17:38, 1557.48 examples/s]Running tokenizer on dataset:   9%|▊         | 154000/1801350 [01:39<20:12, 1358.79 examples/s]Running tokenizer on dataset:   9%|▊         | 154000/1801350 [01:39<20:13, 1357.71 examples/s]Running tokenizer on dataset:   9%|▊         | 154000/1801350 [01:39<20:15, 1355.50 examples/s]Running tokenizer on dataset:   9%|▊         | 154000/1801350 [01:39<20:24, 1345.02 examples/s]Running tokenizer on dataset:   9%|▊         | 155000/1801350 [01:39<19:22, 1416.03 examples/s]Running tokenizer on dataset:   9%|▊         | 155000/1801350 [01:39<19:23, 1414.85 examples/s]Running tokenizer on dataset:   9%|▊         | 155000/1801350 [01:39<19:27, 1410.21 examples/s]Running tokenizer on dataset:   9%|▊         | 155000/1801350 [01:39<19:26, 1411.93 examples/s]Running tokenizer on dataset:   9%|▊         | 156000/1801350 [01:40<18:35, 1475.33 examples/s]Running tokenizer on dataset:   9%|▊         | 156000/1801350 [01:40<18:41, 1467.46 examples/s]Running tokenizer on dataset:   9%|▊         | 156000/1801350 [01:40<18:44, 1463.78 examples/s]Running tokenizer on dataset:   9%|▊         | 156000/1801350 [01:40<18:48, 1458.05 examples/s]Running tokenizer on dataset:   9%|▊         | 157000/1801350 [01:40<17:56, 1528.06 examples/s]Running tokenizer on dataset:   9%|▊         | 157000/1801350 [01:40<17:58, 1524.51 examples/s]Running tokenizer on dataset:   9%|▊         | 157000/1801350 [01:40<18:00, 1522.27 examples/s]Running tokenizer on dataset:   9%|▊         | 157000/1801350 [01:40<18:03, 1517.17 examples/s]Running tokenizer on dataset:   9%|▉         | 158000/1801350 [01:41<16:58, 1613.65 examples/s]Running tokenizer on dataset:   9%|▉         | 158000/1801350 [01:41<17:10, 1594.65 examples/s]Running tokenizer on dataset:   9%|▉         | 158000/1801350 [01:41<17:20, 1578.83 examples/s]Running tokenizer on dataset:   9%|▉         | 158000/1801350 [01:41<17:48, 1538.57 examples/s]Running tokenizer on dataset:   9%|▉         | 159000/1801350 [01:42<17:12, 1591.19 examples/s]Running tokenizer on dataset:   9%|▉         | 159000/1801350 [01:42<17:26, 1569.98 examples/s]Running tokenizer on dataset:   9%|▉         | 159000/1801350 [01:42<17:21, 1577.17 examples/s]Running tokenizer on dataset:   9%|▉         | 159000/1801350 [01:42<17:17, 1583.20 examples/s]Running tokenizer on dataset:   9%|▉         | 160000/1801350 [01:42<16:55, 1615.56 examples/s]Running tokenizer on dataset:   9%|▉         | 160000/1801350 [01:42<17:06, 1599.23 examples/s]Running tokenizer on dataset:   9%|▉         | 160000/1801350 [01:42<17:09, 1594.35 examples/s]Running tokenizer on dataset:   9%|▉         | 160000/1801350 [01:42<17:14, 1587.01 examples/s]Running tokenizer on dataset:   9%|▉         | 161000/1801350 [01:43<16:53, 1619.19 examples/s]Running tokenizer on dataset:   9%|▉         | 161000/1801350 [01:43<16:52, 1620.10 examples/s]Running tokenizer on dataset:   9%|▉         | 161000/1801350 [01:43<16:46, 1629.07 examples/s]Running tokenizer on dataset:   9%|▉         | 161000/1801350 [01:43<17:16, 1582.74 examples/s]Running tokenizer on dataset:   9%|▉         | 162000/1801350 [01:43<17:08, 1594.70 examples/s]Running tokenizer on dataset:   9%|▉         | 162000/1801350 [01:43<17:12, 1588.28 examples/s]Running tokenizer on dataset:   9%|▉         | 162000/1801350 [01:43<17:06, 1596.67 examples/s]Running tokenizer on dataset:   9%|▉         | 162000/1801350 [01:44<17:33, 1555.42 examples/s]Running tokenizer on dataset:   9%|▉         | 163000/1801350 [01:44<16:54, 1614.79 examples/s]Running tokenizer on dataset:   9%|▉         | 163000/1801350 [01:44<16:57, 1610.66 examples/s]Running tokenizer on dataset:   9%|▉         | 163000/1801350 [01:44<16:53, 1617.21 examples/s]Running tokenizer on dataset:   9%|▉         | 163000/1801350 [01:44<17:05, 1597.16 examples/s]Running tokenizer on dataset:   9%|▉         | 164000/1801350 [01:45<17:17, 1578.66 examples/s]Running tokenizer on dataset:   9%|▉         | 164000/1801350 [01:45<17:20, 1573.84 examples/s]Running tokenizer on dataset:   9%|▉         | 164000/1801350 [01:45<17:16, 1579.47 examples/s]Running tokenizer on dataset:   9%|▉         | 164000/1801350 [01:45<17:28, 1562.28 examples/s]Running tokenizer on dataset:   9%|▉         | 165000/1801350 [01:45<16:52, 1616.07 examples/s]Running tokenizer on dataset:   9%|▉         | 165000/1801350 [01:45<16:58, 1606.27 examples/s]Running tokenizer on dataset:   9%|▉         | 165000/1801350 [01:45<17:00, 1603.43 examples/s]Running tokenizer on dataset:   9%|▉         | 165000/1801350 [01:45<16:59, 1605.18 examples/s]Running tokenizer on dataset:   9%|▉         | 166000/1801350 [01:46<16:28, 1654.95 examples/s]Running tokenizer on dataset:   9%|▉         | 166000/1801350 [01:46<16:29, 1652.32 examples/s]Running tokenizer on dataset:   9%|▉         | 166000/1801350 [01:46<16:35, 1643.05 examples/s]Running tokenizer on dataset:   9%|▉         | 166000/1801350 [01:46<16:23, 1663.12 examples/s]Running tokenizer on dataset:   9%|▉         | 167000/1801350 [01:46<16:03, 1695.41 examples/s]Running tokenizer on dataset:   9%|▉         | 167000/1801350 [01:46<16:10, 1684.62 examples/s]Running tokenizer on dataset:   9%|▉         | 167000/1801350 [01:46<16:11, 1682.42 examples/s]Running tokenizer on dataset:   9%|▉         | 167000/1801350 [01:47<16:13, 1679.57 examples/s]Running tokenizer on dataset:   9%|▉         | 168000/1801350 [01:47<16:52, 1612.81 examples/s]Running tokenizer on dataset:   9%|▉         | 168000/1801350 [01:47<16:57, 1605.51 examples/s]Running tokenizer on dataset:   9%|▉         | 168000/1801350 [01:47<16:59, 1601.87 examples/s]Running tokenizer on dataset:   9%|▉         | 168000/1801350 [01:47<17:18, 1572.22 examples/s]Running tokenizer on dataset:   9%|▉         | 169000/1801350 [01:48<16:50, 1616.14 examples/s]Running tokenizer on dataset:   9%|▉         | 169000/1801350 [01:48<16:51, 1614.20 examples/s]Running tokenizer on dataset:   9%|▉         | 169000/1801350 [01:48<16:56, 1606.18 examples/s]Running tokenizer on dataset:   9%|▉         | 169000/1801350 [01:48<17:07, 1588.54 examples/s]Running tokenizer on dataset:   9%|▉         | 170000/1801350 [01:48<17:06, 1589.22 examples/s]Running tokenizer on dataset:   9%|▉         | 170000/1801350 [01:48<17:11, 1581.00 examples/s]Running tokenizer on dataset:   9%|▉         | 170000/1801350 [01:48<17:12, 1580.25 examples/s]Running tokenizer on dataset:   9%|▉         | 170000/1801350 [01:49<17:16, 1573.15 examples/s]Running tokenizer on dataset:   9%|▉         | 171000/1801350 [01:49<17:38, 1539.94 examples/s]Running tokenizer on dataset:   9%|▉         | 171000/1801350 [01:49<17:39, 1539.41 examples/s]Running tokenizer on dataset:   9%|▉         | 171000/1801350 [01:49<17:48, 1526.11 examples/s]Running tokenizer on dataset:   9%|▉         | 171000/1801350 [01:49<17:43, 1533.39 examples/s]Running tokenizer on dataset:  10%|▉         | 172000/1801350 [01:50<17:27, 1555.41 examples/s]Running tokenizer on dataset:  10%|▉         | 172000/1801350 [01:50<17:31, 1549.79 examples/s]Running tokenizer on dataset:  10%|▉         | 172000/1801350 [01:50<17:26, 1556.84 examples/s]Running tokenizer on dataset:  10%|▉         | 172000/1801350 [01:50<17:20, 1565.81 examples/s]Running tokenizer on dataset:  10%|▉         | 173000/1801350 [01:50<17:27, 1554.00 examples/s]Running tokenizer on dataset:  10%|▉         | 173000/1801350 [01:50<17:31, 1548.25 examples/s]Running tokenizer on dataset:  10%|▉         | 173000/1801350 [01:50<17:38, 1538.85 examples/s]Running tokenizer on dataset:  10%|▉         | 173000/1801350 [01:50<17:26, 1556.51 examples/s]Running tokenizer on dataset:  10%|▉         | 174000/1801350 [01:51<17:10, 1579.70 examples/s]Running tokenizer on dataset:  10%|▉         | 174000/1801350 [01:51<17:17, 1568.27 examples/s]Running tokenizer on dataset:  10%|▉         | 174000/1801350 [01:51<17:17, 1568.85 examples/s]Running tokenizer on dataset:  10%|▉         | 174000/1801350 [01:51<17:09, 1581.32 examples/s]Running tokenizer on dataset:  10%|▉         | 175000/1801350 [01:52<19:39, 1379.28 examples/s]Running tokenizer on dataset:  10%|▉         | 175000/1801350 [01:52<19:39, 1378.77 examples/s]Running tokenizer on dataset:  10%|▉         | 175000/1801350 [01:52<19:40, 1378.16 examples/s]Running tokenizer on dataset:  10%|▉         | 175000/1801350 [01:52<20:10, 1343.27 examples/s]Running tokenizer on dataset:  10%|▉         | 176000/1801350 [01:53<19:11, 1411.63 examples/s]Running tokenizer on dataset:  10%|▉         | 176000/1801350 [01:53<19:16, 1404.87 examples/s]Running tokenizer on dataset:  10%|▉         | 176000/1801350 [01:53<19:16, 1405.83 examples/s]Running tokenizer on dataset:  10%|▉         | 176000/1801350 [01:53<19:41, 1375.73 examples/s]Running tokenizer on dataset:  10%|▉         | 177000/1801350 [01:53<18:50, 1436.34 examples/s]Running tokenizer on dataset:  10%|▉         | 177000/1801350 [01:53<18:59, 1425.41 examples/s]Running tokenizer on dataset:  10%|▉         | 177000/1801350 [01:53<19:13, 1407.99 examples/s]Running tokenizer on dataset:  10%|▉         | 177000/1801350 [01:53<19:08, 1414.06 examples/s]Running tokenizer on dataset:  10%|▉         | 178000/1801350 [01:54<19:01, 1422.40 examples/s]Running tokenizer on dataset:  10%|▉         | 178000/1801350 [01:54<19:11, 1410.25 examples/s]Running tokenizer on dataset:  10%|▉         | 178000/1801350 [01:54<19:13, 1407.15 examples/s]Running tokenizer on dataset:  10%|▉         | 178000/1801350 [01:54<19:18, 1401.36 examples/s]Running tokenizer on dataset:  10%|▉         | 179000/1801350 [01:55<18:15, 1480.25 examples/s]Running tokenizer on dataset:  10%|▉         | 179000/1801350 [01:55<18:20, 1473.65 examples/s]Running tokenizer on dataset:  10%|▉         | 179000/1801350 [01:55<18:41, 1446.01 examples/s]Running tokenizer on dataset:  10%|▉         | 179000/1801350 [01:55<18:31, 1459.81 examples/s]Running tokenizer on dataset:  10%|▉         | 180000/1801350 [01:55<18:27, 1464.46 examples/s]Running tokenizer on dataset:  10%|▉         | 180000/1801350 [01:55<18:19, 1474.17 examples/s]Running tokenizer on dataset:  10%|▉         | 180000/1801350 [01:55<18:26, 1465.14 examples/s]Running tokenizer on dataset:  10%|▉         | 180000/1801350 [01:55<18:36, 1452.26 examples/s]Running tokenizer on dataset:  10%|█         | 181000/1801350 [01:56<18:05, 1493.29 examples/s]Running tokenizer on dataset:  10%|█         | 181000/1801350 [01:56<17:59, 1501.24 examples/s]Running tokenizer on dataset:  10%|█         | 181000/1801350 [01:56<18:05, 1492.68 examples/s]Running tokenizer on dataset:  10%|█         | 181000/1801350 [01:56<18:09, 1486.79 examples/s]Running tokenizer on dataset:  10%|█         | 182000/1801350 [01:57<17:57, 1503.08 examples/s]Running tokenizer on dataset:  10%|█         | 182000/1801350 [01:57<18:04, 1493.65 examples/s]Running tokenizer on dataset:  10%|█         | 182000/1801350 [01:57<18:00, 1499.29 examples/s]Running tokenizer on dataset:  10%|█         | 182000/1801350 [01:57<17:59, 1499.85 examples/s]Running tokenizer on dataset:  10%|█         | 183000/1801350 [01:57<17:33, 1535.54 examples/s]Running tokenizer on dataset:  10%|█         | 183000/1801350 [01:57<17:38, 1528.30 examples/s]Running tokenizer on dataset:  10%|█         | 183000/1801350 [01:57<18:03, 1493.02 examples/s]Running tokenizer on dataset:  10%|█         | 183000/1801350 [01:57<17:46, 1516.96 examples/s]Running tokenizer on dataset:  10%|█         | 184000/1801350 [01:58<18:19, 1471.42 examples/s]Running tokenizer on dataset:  10%|█         | 184000/1801350 [01:58<18:18, 1471.84 examples/s]Running tokenizer on dataset:  10%|█         | 184000/1801350 [01:58<18:49, 1431.78 examples/s]Running tokenizer on dataset:  10%|█         | 184000/1801350 [01:58<18:22, 1466.70 examples/s]Running tokenizer on dataset:  10%|█         | 185000/1801350 [01:59<17:56, 1501.79 examples/s]Running tokenizer on dataset:  10%|█         | 185000/1801350 [01:59<17:59, 1497.71 examples/s]Running tokenizer on dataset:  10%|█         | 185000/1801350 [01:59<18:13, 1478.37 examples/s]Running tokenizer on dataset:  10%|█         | 185000/1801350 [01:59<17:52, 1506.84 examples/s]Running tokenizer on dataset:  10%|█         | 186000/1801350 [01:59<18:16, 1473.03 examples/s]Running tokenizer on dataset:  10%|█         | 186000/1801350 [01:59<18:21, 1466.98 examples/s]Running tokenizer on dataset:  10%|█         | 186000/1801350 [01:59<18:50, 1428.26 examples/s]Running tokenizer on dataset:  10%|█         | 186000/1801350 [02:00<18:38, 1444.34 examples/s]Running tokenizer on dataset:  10%|█         | 187000/1801350 [02:00<18:03, 1490.63 examples/s]Running tokenizer on dataset:  10%|█         | 187000/1801350 [02:00<18:05, 1487.46 examples/s]Running tokenizer on dataset:  10%|█         | 187000/1801350 [02:00<18:10, 1480.48 examples/s]Running tokenizer on dataset:  10%|█         | 187000/1801350 [02:00<18:07, 1484.20 examples/s]Running tokenizer on dataset:  10%|█         | 188000/1801350 [02:01<17:52, 1504.96 examples/s]Running tokenizer on dataset:  10%|█         | 188000/1801350 [02:01<17:59, 1494.53 examples/s]Running tokenizer on dataset:  10%|█         | 188000/1801350 [02:01<17:58, 1495.52 examples/s]Running tokenizer on dataset:  10%|█         | 188000/1801350 [02:01<18:06, 1485.46 examples/s]Running tokenizer on dataset:  10%|█         | 189000/1801350 [02:01<17:12, 1561.69 examples/s]Running tokenizer on dataset:  10%|█         | 189000/1801350 [02:01<17:12, 1562.04 examples/s]Running tokenizer on dataset:  10%|█         | 189000/1801350 [02:01<17:15, 1557.50 examples/s]Running tokenizer on dataset:  10%|█         | 189000/1801350 [02:01<17:08, 1568.31 examples/s]Running tokenizer on dataset:  11%|█         | 190000/1801350 [02:02<17:02, 1576.20 examples/s]Running tokenizer on dataset:  11%|█         | 190000/1801350 [02:02<17:01, 1576.80 examples/s]Running tokenizer on dataset:  11%|█         | 190000/1801350 [02:02<16:59, 1581.23 examples/s]Running tokenizer on dataset:  11%|█         | 190000/1801350 [02:02<17:06, 1569.23 examples/s]Running tokenizer on dataset:  11%|█         | 191000/1801350 [02:02<16:52, 1590.42 examples/s]Running tokenizer on dataset:  11%|█         | 191000/1801350 [02:03<17:13, 1558.08 examples/s]Running tokenizer on dataset:  11%|█         | 191000/1801350 [02:03<16:51, 1592.11 examples/s]Running tokenizer on dataset:  11%|█         | 191000/1801350 [02:03<16:48, 1597.56 examples/s]Running tokenizer on dataset:  11%|█         | 192000/1801350 [02:03<16:56, 1583.16 examples/s]Running tokenizer on dataset:  11%|█         | 192000/1801350 [02:03<17:29, 1532.95 examples/s]Running tokenizer on dataset:  11%|█         | 192000/1801350 [02:03<17:02, 1574.23 examples/s]Running tokenizer on dataset:  11%|█         | 192000/1801350 [02:03<16:58, 1580.62 examples/s]Running tokenizer on dataset:  11%|█         | 193000/1801350 [02:04<16:54, 1585.76 examples/s]Running tokenizer on dataset:  11%|█         | 193000/1801350 [02:04<16:44, 1601.93 examples/s]Running tokenizer on dataset:  11%|█         | 193000/1801350 [02:04<17:10, 1561.49 examples/s]Running tokenizer on dataset:  11%|█         | 193000/1801350 [02:04<16:50, 1591.65 examples/s]Running tokenizer on dataset:  11%|█         | 194000/1801350 [02:04<16:28, 1625.29 examples/s]Running tokenizer on dataset:  11%|█         | 194000/1801350 [02:04<16:28, 1625.89 examples/s]Running tokenizer on dataset:  11%|█         | 194000/1801350 [02:04<16:45, 1598.09 examples/s]Running tokenizer on dataset:  11%|█         | 194000/1801350 [02:04<16:37, 1610.72 examples/s]Running tokenizer on dataset:  11%|█         | 195000/1801350 [02:05<16:44, 1599.94 examples/s]Running tokenizer on dataset:  11%|█         | 195000/1801350 [02:05<16:38, 1609.18 examples/s]Running tokenizer on dataset:  11%|█         | 195000/1801350 [02:05<16:50, 1590.31 examples/s]Running tokenizer on dataset:  11%|█         | 195000/1801350 [02:05<16:40, 1606.28 examples/s]Running tokenizer on dataset:  11%|█         | 196000/1801350 [02:06<19:37, 1363.24 examples/s]Running tokenizer on dataset:  11%|█         | 196000/1801350 [02:06<19:47, 1351.80 examples/s]Running tokenizer on dataset:  11%|█         | 196000/1801350 [02:06<20:23, 1311.85 examples/s]Running tokenizer on dataset:  11%|█         | 196000/1801350 [02:06<19:22, 1381.07 examples/s]Running tokenizer on dataset:  11%|█         | 197000/1801350 [02:07<18:28, 1447.89 examples/s]Running tokenizer on dataset:  11%|█         | 197000/1801350 [02:07<18:39, 1433.53 examples/s]Running tokenizer on dataset:  11%|█         | 197000/1801350 [02:07<19:26, 1375.87 examples/s]Running tokenizer on dataset:  11%|█         | 197000/1801350 [02:07<18:23, 1454.25 examples/s]Running tokenizer on dataset:  11%|█         | 198000/1801350 [02:07<17:06, 1562.17 examples/s]Running tokenizer on dataset:  11%|█         | 198000/1801350 [02:07<17:09, 1557.46 examples/s]Running tokenizer on dataset:  11%|█         | 198000/1801350 [02:07<17:22, 1538.24 examples/s]Running tokenizer on dataset:  11%|█         | 198000/1801350 [02:07<17:02, 1567.41 examples/s]Running tokenizer on dataset:  11%|█         | 199000/1801350 [02:08<17:17, 1544.62 examples/s]Running tokenizer on dataset:  11%|█         | 199000/1801350 [02:08<17:28, 1528.71 examples/s]Running tokenizer on dataset:  11%|█         | 199000/1801350 [02:08<17:29, 1527.10 examples/s]Running tokenizer on dataset:  11%|█         | 199000/1801350 [02:08<17:09, 1556.68 examples/s]Running tokenizer on dataset:  11%|█         | 200000/1801350 [02:08<17:33, 1519.55 examples/s]Running tokenizer on dataset:  11%|█         | 200000/1801350 [02:08<17:19, 1540.57 examples/s]Running tokenizer on dataset:  11%|█         | 200000/1801350 [02:08<17:32, 1520.75 examples/s]Running tokenizer on dataset:  11%|█         | 200000/1801350 [02:08<17:01, 1567.50 examples/s]Running tokenizer on dataset:  11%|█         | 201000/1801350 [02:09<17:29, 1525.40 examples/s]Running tokenizer on dataset:  11%|█         | 201000/1801350 [02:09<17:37, 1513.75 examples/s]Running tokenizer on dataset:  11%|█         | 201000/1801350 [02:09<17:38, 1512.21 examples/s]Running tokenizer on dataset:  11%|█         | 201000/1801350 [02:09<17:16, 1543.65 examples/s]Running tokenizer on dataset:  11%|█         | 202000/1801350 [02:10<17:41, 1506.31 examples/s]Running tokenizer on dataset:  11%|█         | 202000/1801350 [02:10<17:42, 1505.43 examples/s]Running tokenizer on dataset:  11%|█         | 202000/1801350 [02:10<17:40, 1508.22 examples/s]Running tokenizer on dataset:  11%|█         | 202000/1801350 [02:10<17:57, 1484.06 examples/s]Running tokenizer on dataset:  11%|█▏        | 203000/1801350 [02:10<17:22, 1533.23 examples/s]Running tokenizer on dataset:  11%|█▏        | 203000/1801350 [02:10<17:21, 1535.19 examples/s]Running tokenizer on dataset:  11%|█▏        | 203000/1801350 [02:10<17:19, 1537.69 examples/s]Running tokenizer on dataset:  11%|█▏        | 203000/1801350 [02:10<17:29, 1522.60 examples/s]Running tokenizer on dataset:  11%|█▏        | 204000/1801350 [02:11<16:43, 1591.98 examples/s]Running tokenizer on dataset:  11%|█▏        | 204000/1801350 [02:11<16:46, 1586.32 examples/s]Running tokenizer on dataset:  11%|█▏        | 204000/1801350 [02:11<16:52, 1577.88 examples/s]Running tokenizer on dataset:  11%|█▏        | 204000/1801350 [02:11<16:35, 1603.85 examples/s]Running tokenizer on dataset:  11%|█▏        | 205000/1801350 [02:12<17:20, 1534.71 examples/s]Running tokenizer on dataset:  11%|█▏        | 205000/1801350 [02:12<17:23, 1529.13 examples/s]Running tokenizer on dataset:  11%|█▏        | 205000/1801350 [02:12<17:29, 1521.31 examples/s]Running tokenizer on dataset:  11%|█▏        | 205000/1801350 [02:12<17:13, 1544.47 examples/s]Running tokenizer on dataset:  11%|█▏        | 206000/1801350 [02:12<17:25, 1525.44 examples/s]Running tokenizer on dataset:  11%|█▏        | 206000/1801350 [02:12<17:19, 1534.72 examples/s]Running tokenizer on dataset:  11%|█▏        | 206000/1801350 [02:12<17:21, 1531.71 examples/s]Running tokenizer on dataset:  11%|█▏        | 206000/1801350 [02:12<17:03, 1558.05 examples/s]Running tokenizer on dataset:  11%|█▏        | 207000/1801350 [02:13<17:18, 1535.79 examples/s]Running tokenizer on dataset:  11%|█▏        | 207000/1801350 [02:13<17:16, 1538.26 examples/s]Running tokenizer on dataset:  11%|█▏        | 207000/1801350 [02:13<17:04, 1555.63 examples/s]Running tokenizer on dataset:  11%|█▏        | 207000/1801350 [02:13<17:20, 1532.62 examples/s]Running tokenizer on dataset:  12%|█▏        | 208000/1801350 [02:14<17:15, 1538.30 examples/s]Running tokenizer on dataset:  12%|█▏        | 208000/1801350 [02:14<17:12, 1543.40 examples/s]Running tokenizer on dataset:  12%|█▏        | 208000/1801350 [02:14<17:15, 1539.05 examples/s]Running tokenizer on dataset:  12%|█▏        | 208000/1801350 [02:14<17:21, 1530.22 examples/s]Running tokenizer on dataset:  12%|█▏        | 209000/1801350 [02:14<17:39, 1503.08 examples/s]Running tokenizer on dataset:  12%|█▏        | 209000/1801350 [02:14<17:58, 1476.03 examples/s]Running tokenizer on dataset:  12%|█▏        | 209000/1801350 [02:14<17:55, 1480.47 examples/s]Running tokenizer on dataset:  12%|█▏        | 209000/1801350 [02:14<17:56, 1479.61 examples/s]Running tokenizer on dataset:  12%|█▏        | 210000/1801350 [02:15<17:19, 1530.48 examples/s]Running tokenizer on dataset:  12%|█▏        | 210000/1801350 [02:15<17:17, 1534.33 examples/s]Running tokenizer on dataset:  12%|█▏        | 210000/1801350 [02:15<17:17, 1533.83 examples/s]Running tokenizer on dataset:  12%|█▏        | 210000/1801350 [02:15<17:12, 1541.85 examples/s]Running tokenizer on dataset:  12%|█▏        | 211000/1801350 [02:16<16:48, 1576.71 examples/s]Running tokenizer on dataset:  12%|█▏        | 211000/1801350 [02:16<16:55, 1566.77 examples/s]Running tokenizer on dataset:  12%|█▏        | 211000/1801350 [02:16<16:53, 1568.98 examples/s]Running tokenizer on dataset:  12%|█▏        | 211000/1801350 [02:16<16:42, 1587.16 examples/s]Running tokenizer on dataset:  12%|█▏        | 212000/1801350 [02:16<16:42, 1585.09 examples/s]Running tokenizer on dataset:  12%|█▏        | 212000/1801350 [02:16<16:49, 1574.63 examples/s]Running tokenizer on dataset:  12%|█▏        | 212000/1801350 [02:16<16:51, 1570.89 examples/s]Running tokenizer on dataset:  12%|█▏        | 212000/1801350 [02:16<17:09, 1544.23 examples/s]Running tokenizer on dataset:  12%|█▏        | 213000/1801350 [02:17<16:09, 1638.87 examples/s]Running tokenizer on dataset:  12%|█▏        | 213000/1801350 [02:17<16:25, 1611.25 examples/s]Running tokenizer on dataset:  12%|█▏        | 213000/1801350 [02:17<16:21, 1618.35 examples/s]Running tokenizer on dataset:  12%|█▏        | 213000/1801350 [02:17<16:22, 1616.71 examples/s]Running tokenizer on dataset:  12%|█▏        | 214000/1801350 [02:17<16:56, 1561.02 examples/s]Running tokenizer on dataset:  12%|█▏        | 214000/1801350 [02:18<16:50, 1571.13 examples/s]Running tokenizer on dataset:  12%|█▏        | 214000/1801350 [02:18<17:05, 1547.40 examples/s]Running tokenizer on dataset:  12%|█▏        | 214000/1801350 [02:17<17:06, 1545.70 examples/s]Running tokenizer on dataset:  12%|█▏        | 215000/1801350 [02:18<17:22, 1521.38 examples/s]Running tokenizer on dataset:  12%|█▏        | 215000/1801350 [02:18<17:25, 1516.85 examples/s]Running tokenizer on dataset:  12%|█▏        | 215000/1801350 [02:18<17:21, 1523.71 examples/s]Running tokenizer on dataset:  12%|█▏        | 215000/1801350 [02:18<17:29, 1511.60 examples/s]Running tokenizer on dataset:  12%|█▏        | 216000/1801350 [02:19<17:19, 1525.00 examples/s]Running tokenizer on dataset:  12%|█▏        | 216000/1801350 [02:19<17:16, 1528.82 examples/s]Running tokenizer on dataset:  12%|█▏        | 216000/1801350 [02:19<17:27, 1514.10 examples/s]Running tokenizer on dataset:  12%|█▏        | 216000/1801350 [02:19<17:28, 1512.31 examples/s]Running tokenizer on dataset:  12%|█▏        | 217000/1801350 [02:20<20:02, 1317.35 examples/s]Running tokenizer on dataset:  12%|█▏        | 217000/1801350 [02:20<20:05, 1313.93 examples/s]Running tokenizer on dataset:  12%|█▏        | 217000/1801350 [02:20<20:35, 1282.47 examples/s]Running tokenizer on dataset:  12%|█▏        | 217000/1801350 [02:20<20:38, 1279.08 examples/s]Running tokenizer on dataset:  12%|█▏        | 218000/1801350 [02:20<18:37, 1416.44 examples/s]Running tokenizer on dataset:  12%|█▏        | 218000/1801350 [02:20<18:27, 1429.35 examples/s]Running tokenizer on dataset:  12%|█▏        | 218000/1801350 [02:20<19:02, 1386.27 examples/s]Running tokenizer on dataset:  12%|█▏        | 218000/1801350 [02:21<19:11, 1375.32 examples/s]Running tokenizer on dataset:  12%|█▏        | 219000/1801350 [02:21<17:44, 1486.95 examples/s]Running tokenizer on dataset:  12%|█▏        | 219000/1801350 [02:21<17:53, 1474.03 examples/s]Running tokenizer on dataset:  12%|█▏        | 219000/1801350 [02:21<17:59, 1466.00 examples/s]Running tokenizer on dataset:  12%|█▏        | 219000/1801350 [02:21<18:05, 1457.39 examples/s]Running tokenizer on dataset:  12%|█▏        | 220000/1801350 [02:22<17:36, 1497.16 examples/s]Running tokenizer on dataset:  12%|█▏        | 220000/1801350 [02:22<17:50, 1477.25 examples/s]Running tokenizer on dataset:  12%|█▏        | 220000/1801350 [02:22<17:29, 1506.46 examples/s]Running tokenizer on dataset:  12%|█▏        | 220000/1801350 [02:22<17:53, 1472.52 examples/s]Running tokenizer on dataset:  12%|█▏        | 221000/1801350 [02:22<17:38, 1493.11 examples/s]Running tokenizer on dataset:  12%|█▏        | 221000/1801350 [02:22<17:38, 1492.90 examples/s]Running tokenizer on dataset:  12%|█▏        | 221000/1801350 [02:22<17:16, 1524.91 examples/s]Running tokenizer on dataset:  12%|█▏        | 221000/1801350 [02:22<17:17, 1523.65 examples/s]Running tokenizer on dataset:  12%|█▏        | 222000/1801350 [02:23<17:39, 1491.32 examples/s]Running tokenizer on dataset:  12%|█▏        | 222000/1801350 [02:23<17:22, 1514.67 examples/s]Running tokenizer on dataset:  12%|█▏        | 222000/1801350 [02:23<17:43, 1485.59 examples/s]Running tokenizer on dataset:  12%|█▏        | 222000/1801350 [02:23<17:34, 1498.36 examples/s]Running tokenizer on dataset:  12%|█▏        | 223000/1801350 [02:24<17:34, 1496.44 examples/s]Running tokenizer on dataset:  12%|█▏        | 223000/1801350 [02:24<17:30, 1502.20 examples/s]Running tokenizer on dataset:  12%|█▏        | 223000/1801350 [02:24<17:42, 1485.86 examples/s]Running tokenizer on dataset:  12%|█▏        | 223000/1801350 [02:24<17:31, 1500.97 examples/s]Running tokenizer on dataset:  12%|█▏        | 224000/1801350 [02:24<17:59, 1460.98 examples/s]Running tokenizer on dataset:  12%|█▏        | 224000/1801350 [02:24<18:02, 1457.09 examples/s]Running tokenizer on dataset:  12%|█▏        | 224000/1801350 [02:24<17:54, 1468.66 examples/s]Running tokenizer on dataset:  12%|█▏        | 224000/1801350 [02:24<17:59, 1461.10 examples/s]Running tokenizer on dataset:  12%|█▏        | 225000/1801350 [02:25<17:10, 1529.43 examples/s]Running tokenizer on dataset:  12%|█▏        | 225000/1801350 [02:25<17:06, 1536.31 examples/s]Running tokenizer on dataset:  12%|█▏        | 225000/1801350 [02:25<17:13, 1524.89 examples/s]Running tokenizer on dataset:  12%|█▏        | 225000/1801350 [02:25<17:07, 1534.32 examples/s]Running tokenizer on dataset:  13%|█▎        | 226000/1801350 [02:25<15:48, 1660.57 examples/s]Running tokenizer on dataset:  13%|█▎        | 226000/1801350 [02:26<15:52, 1653.21 examples/s]Running tokenizer on dataset:  13%|█▎        | 226000/1801350 [02:26<16:15, 1614.45 examples/s]Running tokenizer on dataset:  13%|█▎        | 226000/1801350 [02:26<16:11, 1621.71 examples/s]Running tokenizer on dataset:  13%|█▎        | 227000/1801350 [02:26<16:35, 1581.22 examples/s]Running tokenizer on dataset:  13%|█▎        | 227000/1801350 [02:26<16:31, 1587.50 examples/s]Running tokenizer on dataset:  13%|█▎        | 227000/1801350 [02:26<16:29, 1590.72 examples/s]Running tokenizer on dataset:  13%|█▎        | 227000/1801350 [02:26<16:37, 1578.39 examples/s]Running tokenizer on dataset:  13%|█▎        | 228000/1801350 [02:27<16:43, 1567.27 examples/s]Running tokenizer on dataset:  13%|█▎        | 228000/1801350 [02:27<16:37, 1577.37 examples/s]Running tokenizer on dataset:  13%|█▎        | 228000/1801350 [02:27<16:48, 1560.15 examples/s]Running tokenizer on dataset:  13%|█▎        | 228000/1801350 [02:27<16:51, 1555.41 examples/s]Running tokenizer on dataset:  13%|█▎        | 229000/1801350 [02:28<16:58, 1543.90 examples/s]Running tokenizer on dataset:  13%|█▎        | 229000/1801350 [02:28<17:08, 1528.94 examples/s]Running tokenizer on dataset:  13%|█▎        | 229000/1801350 [02:28<17:12, 1522.86 examples/s]Running tokenizer on dataset:  13%|█▎        | 229000/1801350 [02:28<17:07, 1530.74 examples/s]Running tokenizer on dataset:  13%|█▎        | 230000/1801350 [02:28<17:39, 1482.61 examples/s]Running tokenizer on dataset:  13%|█▎        | 230000/1801350 [02:28<17:44, 1476.44 examples/s]Running tokenizer on dataset:  13%|█▎        | 230000/1801350 [02:28<17:41, 1479.96 examples/s]Running tokenizer on dataset:  13%|█▎        | 230000/1801350 [02:28<17:41, 1479.84 examples/s]Running tokenizer on dataset:  13%|█▎        | 231000/1801350 [02:29<17:14, 1518.59 examples/s]Running tokenizer on dataset:  13%|█▎        | 231000/1801350 [02:29<17:10, 1524.49 examples/s]Running tokenizer on dataset:  13%|█▎        | 231000/1801350 [02:29<17:18, 1512.24 examples/s]Running tokenizer on dataset:  13%|█▎        | 231000/1801350 [02:29<17:16, 1515.60 examples/s]Running tokenizer on dataset:  13%|█▎        | 232000/1801350 [02:30<17:16, 1513.87 examples/s]Running tokenizer on dataset:  13%|█▎        | 232000/1801350 [02:30<17:14, 1517.05 examples/s]Running tokenizer on dataset:  13%|█▎        | 232000/1801350 [02:30<17:21, 1506.66 examples/s]Running tokenizer on dataset:  13%|█▎        | 232000/1801350 [02:30<17:19, 1509.62 examples/s]Running tokenizer on dataset:  13%|█▎        | 233000/1801350 [02:30<16:40, 1567.40 examples/s]Running tokenizer on dataset:  13%|█▎        | 233000/1801350 [02:30<16:39, 1569.87 examples/s]Running tokenizer on dataset:  13%|█▎        | 233000/1801350 [02:30<16:39, 1568.45 examples/s]Running tokenizer on dataset:  13%|█▎        | 233000/1801350 [02:30<16:45, 1560.53 examples/s]Running tokenizer on dataset:  13%|█▎        | 234000/1801350 [02:31<16:09, 1616.69 examples/s]Running tokenizer on dataset:  13%|█▎        | 234000/1801350 [02:31<16:12, 1611.32 examples/s]Running tokenizer on dataset:  13%|█▎        | 234000/1801350 [02:31<16:16, 1605.00 examples/s]Running tokenizer on dataset:  13%|█▎        | 234000/1801350 [02:31<16:13, 1609.29 examples/s]Running tokenizer on dataset:  13%|█▎        | 235000/1801350 [02:31<15:48, 1650.70 examples/s]Running tokenizer on dataset:  13%|█▎        | 235000/1801350 [02:31<15:50, 1648.78 examples/s]Running tokenizer on dataset:  13%|█▎        | 235000/1801350 [02:31<15:52, 1645.09 examples/s]Running tokenizer on dataset:  13%|█▎        | 235000/1801350 [02:31<15:50, 1648.65 examples/s]Running tokenizer on dataset:  13%|█▎        | 236000/1801350 [02:32<15:40, 1664.08 examples/s]Running tokenizer on dataset:  13%|█▎        | 236000/1801350 [02:32<15:42, 1660.80 examples/s]Running tokenizer on dataset:  13%|█▎        | 236000/1801350 [02:32<15:43, 1658.40 examples/s]Running tokenizer on dataset:  13%|█▎        | 236000/1801350 [02:32<15:41, 1662.79 examples/s]Running tokenizer on dataset:  13%|█▎        | 237000/1801350 [02:33<16:23, 1589.87 examples/s]Running tokenizer on dataset:  13%|█▎        | 237000/1801350 [02:33<16:24, 1588.40 examples/s]Running tokenizer on dataset:  13%|█▎        | 237000/1801350 [02:33<16:27, 1584.59 examples/s]Running tokenizer on dataset:  13%|█▎        | 237000/1801350 [02:33<16:47, 1553.06 examples/s]Running tokenizer on dataset:  13%|█▎        | 238000/1801350 [02:34<19:22, 1344.55 examples/s]Running tokenizer on dataset:  13%|█▎        | 238000/1801350 [02:34<19:25, 1341.43 examples/s]Running tokenizer on dataset:  13%|█▎        | 238000/1801350 [02:34<19:27, 1339.59 examples/s]Running tokenizer on dataset:  13%|█▎        | 238000/1801350 [02:34<19:20, 1346.76 examples/s]Running tokenizer on dataset:  13%|█▎        | 239000/1801350 [02:34<17:37, 1477.95 examples/s]Running tokenizer on dataset:  13%|█▎        | 239000/1801350 [02:34<17:43, 1469.22 examples/s]Running tokenizer on dataset:  13%|█▎        | 239000/1801350 [02:34<17:48, 1462.43 examples/s]Running tokenizer on dataset:  13%|█▎        | 239000/1801350 [02:34<17:56, 1451.34 examples/s]Running tokenizer on dataset:  13%|█▎        | 240000/1801350 [02:35<17:46, 1464.65 examples/s]Running tokenizer on dataset:  13%|█▎        | 240000/1801350 [02:35<17:33, 1481.49 examples/s]Running tokenizer on dataset:  13%|█▎        | 240000/1801350 [02:35<17:46, 1464.08 examples/s]Running tokenizer on dataset:  13%|█▎        | 240000/1801350 [02:35<17:39, 1474.09 examples/s]Running tokenizer on dataset:  13%|█▎        | 241000/1801350 [02:35<16:02, 1621.29 examples/s]Running tokenizer on dataset:  13%|█▎        | 241000/1801350 [02:35<16:09, 1608.71 examples/s]Running tokenizer on dataset:  13%|█▎        | 241000/1801350 [02:35<16:31, 1573.71 examples/s]Running tokenizer on dataset:  13%|█▎        | 241000/1801350 [02:35<16:33, 1569.81 examples/s]Running tokenizer on dataset:  13%|█▎        | 242000/1801350 [02:36<15:47, 1645.45 examples/s]Running tokenizer on dataset:  13%|█▎        | 242000/1801350 [02:36<15:58, 1626.93 examples/s]Running tokenizer on dataset:  13%|█▎        | 242000/1801350 [02:36<15:53, 1635.68 examples/s]Running tokenizer on dataset:  13%|█▎        | 242000/1801350 [02:36<15:56, 1630.87 examples/s]Running tokenizer on dataset:  13%|█▎        | 243000/1801350 [02:37<16:10, 1606.04 examples/s]Running tokenizer on dataset:  13%|█▎        | 243000/1801350 [02:37<16:12, 1601.62 examples/s]Running tokenizer on dataset:  13%|█▎        | 243000/1801350 [02:37<16:13, 1601.55 examples/s]Running tokenizer on dataset:  13%|█▎        | 243000/1801350 [02:37<16:20, 1588.95 examples/s]Running tokenizer on dataset:  14%|█▎        | 244000/1801350 [02:37<16:00, 1621.14 examples/s]Running tokenizer on dataset:  14%|█▎        | 244000/1801350 [02:37<16:13, 1600.14 examples/s]Running tokenizer on dataset:  14%|█▎        | 244000/1801350 [02:37<16:20, 1588.30 examples/s]Running tokenizer on dataset:  14%|█▎        | 244000/1801350 [02:37<16:23, 1583.94 examples/s]Running tokenizer on dataset:  14%|█▎        | 245000/1801350 [02:38<16:09, 1605.14 examples/s]Running tokenizer on dataset:  14%|█▎        | 245000/1801350 [02:38<16:12, 1600.64 examples/s]Running tokenizer on dataset:  14%|█▎        | 245000/1801350 [02:38<16:10, 1603.18 examples/s]Running tokenizer on dataset:  14%|█▎        | 245000/1801350 [02:38<16:24, 1581.56 examples/s]Running tokenizer on dataset:  14%|█▎        | 246000/1801350 [02:38<15:48, 1639.66 examples/s]Running tokenizer on dataset:  14%|█▎        | 246000/1801350 [02:38<15:49, 1638.36 examples/s]Running tokenizer on dataset:  14%|█▎        | 246000/1801350 [02:38<15:52, 1632.35 examples/s]Running tokenizer on dataset:  14%|█▎        | 246000/1801350 [02:38<15:50, 1636.79 examples/s]Running tokenizer on dataset:  14%|█▎        | 247000/1801350 [02:39<14:47, 1751.75 examples/s]Running tokenizer on dataset:  14%|█▎        | 247000/1801350 [02:39<15:02, 1722.29 examples/s]Running tokenizer on dataset:  14%|█▎        | 247000/1801350 [02:39<14:40, 1765.87 examples/s]Running tokenizer on dataset:  14%|█▎        | 247000/1801350 [02:39<15:08, 1711.07 examples/s]Running tokenizer on dataset:  14%|█▍        | 248000/1801350 [02:40<15:37, 1657.51 examples/s]Running tokenizer on dataset:  14%|█▍        | 248000/1801350 [02:40<15:38, 1655.08 examples/s]Running tokenizer on dataset:  14%|█▍        | 248000/1801350 [02:40<15:38, 1655.03 examples/s]Running tokenizer on dataset:  14%|█▍        | 248000/1801350 [02:40<15:48, 1637.07 examples/s]Running tokenizer on dataset:  14%|█▍        | 249000/1801350 [02:40<15:19, 1688.10 examples/s]Running tokenizer on dataset:  14%|█▍        | 249000/1801350 [02:40<15:28, 1671.71 examples/s]Running tokenizer on dataset:  14%|█▍        | 249000/1801350 [02:40<15:42, 1647.36 examples/s]Running tokenizer on dataset:  14%|█▍        | 249000/1801350 [02:40<15:42, 1647.43 examples/s]Running tokenizer on dataset:  14%|█▍        | 250000/1801350 [02:41<15:02, 1718.31 examples/s]Running tokenizer on dataset:  14%|█▍        | 250000/1801350 [02:41<15:17, 1690.09 examples/s]Running tokenizer on dataset:  14%|█▍        | 250000/1801350 [02:41<15:12, 1700.12 examples/s]Running tokenizer on dataset:  14%|█▍        | 250000/1801350 [02:41<15:38, 1653.22 examples/s]Running tokenizer on dataset:  14%|█▍        | 251000/1801350 [02:41<15:37, 1652.84 examples/s]Running tokenizer on dataset:  14%|█▍        | 251000/1801350 [02:41<15:34, 1658.69 examples/s]Running tokenizer on dataset:  14%|█▍        | 251000/1801350 [02:41<15:25, 1674.93 examples/s]Running tokenizer on dataset:  14%|█▍        | 251000/1801350 [02:41<15:33, 1660.18 examples/s]Running tokenizer on dataset:  14%|█▍        | 252000/1801350 [02:42<15:38, 1650.58 examples/s]Running tokenizer on dataset:  14%|█▍        | 252000/1801350 [02:42<15:47, 1635.09 examples/s]Running tokenizer on dataset:  14%|█▍        | 252000/1801350 [02:42<15:37, 1653.35 examples/s]Running tokenizer on dataset:  14%|█▍        | 252000/1801350 [02:42<15:36, 1654.69 examples/s]Running tokenizer on dataset:  14%|█▍        | 253000/1801350 [02:43<15:53, 1624.03 examples/s]Running tokenizer on dataset:  14%|█▍        | 253000/1801350 [02:43<15:49, 1630.56 examples/s]Running tokenizer on dataset:  14%|█▍        | 253000/1801350 [02:43<15:43, 1640.63 examples/s]Running tokenizer on dataset:  14%|█▍        | 253000/1801350 [02:43<15:49, 1631.27 examples/s]Running tokenizer on dataset:  14%|█▍        | 254000/1801350 [02:43<15:25, 1672.53 examples/s]Running tokenizer on dataset:  14%|█▍        | 254000/1801350 [02:43<15:32, 1659.89 examples/s]Running tokenizer on dataset:  14%|█▍        | 254000/1801350 [02:43<15:28, 1666.78 examples/s]Running tokenizer on dataset:  14%|█▍        | 254000/1801350 [02:43<15:39, 1646.16 examples/s]Running tokenizer on dataset:  14%|█▍        | 255000/1801350 [02:44<15:49, 1628.24 examples/s]Running tokenizer on dataset:  14%|█▍        | 255000/1801350 [02:44<15:55, 1617.65 examples/s]Running tokenizer on dataset:  14%|█▍        | 255000/1801350 [02:44<15:51, 1625.40 examples/s]Running tokenizer on dataset:  14%|█▍        | 255000/1801350 [02:44<15:58, 1614.10 examples/s]Running tokenizer on dataset:  14%|█▍        | 256000/1801350 [02:44<15:42, 1639.11 examples/s]Running tokenizer on dataset:  14%|█▍        | 256000/1801350 [02:44<15:38, 1645.95 examples/s]Running tokenizer on dataset:  14%|█▍        | 256000/1801350 [02:44<15:43, 1638.18 examples/s]Running tokenizer on dataset:  14%|█▍        | 256000/1801350 [02:44<15:44, 1635.45 examples/s]Running tokenizer on dataset:  14%|█▍        | 257000/1801350 [02:45<15:41, 1640.75 examples/s]Running tokenizer on dataset:  14%|█▍        | 257000/1801350 [02:45<15:44, 1635.76 examples/s]Running tokenizer on dataset:  14%|█▍        | 257000/1801350 [02:45<15:45, 1632.88 examples/s]Running tokenizer on dataset:  14%|█▍        | 257000/1801350 [02:45<15:52, 1622.08 examples/s]Running tokenizer on dataset:  14%|█▍        | 258000/1801350 [02:46<15:36, 1648.37 examples/s]Running tokenizer on dataset:  14%|█▍        | 258000/1801350 [02:46<15:38, 1644.78 examples/s]Running tokenizer on dataset:  14%|█▍        | 258000/1801350 [02:46<15:40, 1640.42 examples/s]Running tokenizer on dataset:  14%|█▍        | 258000/1801350 [02:46<15:40, 1640.52 examples/s]Running tokenizer on dataset:  14%|█▍        | 259000/1801350 [02:47<19:05, 1346.01 examples/s]Running tokenizer on dataset:  14%|█▍        | 259000/1801350 [02:47<19:09, 1342.14 examples/s]Running tokenizer on dataset:  14%|█▍        | 259000/1801350 [02:47<19:09, 1341.30 examples/s]Running tokenizer on dataset:  14%|█▍        | 259000/1801350 [02:47<19:13, 1336.59 examples/s]Running tokenizer on dataset:  14%|█▍        | 260000/1801350 [02:47<18:24, 1395.56 examples/s]Running tokenizer on dataset:  14%|█▍        | 260000/1801350 [02:47<18:26, 1392.80 examples/s]Running tokenizer on dataset:  14%|█▍        | 260000/1801350 [02:47<18:27, 1391.31 examples/s]Running tokenizer on dataset:  14%|█▍        | 260000/1801350 [02:47<18:31, 1386.80 examples/s]Running tokenizer on dataset:  14%|█▍        | 261000/1801350 [02:48<16:50, 1523.77 examples/s]Running tokenizer on dataset:  14%|█▍        | 261000/1801350 [02:48<16:54, 1518.94 examples/s]Running tokenizer on dataset:  14%|█▍        | 261000/1801350 [02:48<17:00, 1508.89 examples/s]Running tokenizer on dataset:  14%|█▍        | 261000/1801350 [02:48<17:05, 1502.12 examples/s]Running tokenizer on dataset:  15%|█▍        | 262000/1801350 [02:49<16:52, 1520.38 examples/s]Running tokenizer on dataset:  15%|█▍        | 262000/1801350 [02:49<16:57, 1513.33 examples/s]Running tokenizer on dataset:  15%|█▍        | 262000/1801350 [02:49<16:58, 1512.04 examples/s]Running tokenizer on dataset:  15%|█▍        | 262000/1801350 [02:49<16:56, 1514.84 examples/s]Running tokenizer on dataset:  15%|█▍        | 263000/1801350 [02:49<17:13, 1488.60 examples/s]Running tokenizer on dataset:  15%|█▍        | 263000/1801350 [02:49<17:14, 1487.41 examples/s]Running tokenizer on dataset:  15%|█▍        | 263000/1801350 [02:49<17:16, 1484.78 examples/s]Running tokenizer on dataset:  15%|█▍        | 263000/1801350 [02:49<17:27, 1469.17 examples/s]Running tokenizer on dataset:  15%|█▍        | 264000/1801350 [02:50<17:08, 1495.21 examples/s]Running tokenizer on dataset:  15%|█▍        | 264000/1801350 [02:50<17:12, 1488.59 examples/s]Running tokenizer on dataset:  15%|█▍        | 264000/1801350 [02:50<17:11, 1490.30 examples/s]Running tokenizer on dataset:  15%|█▍        | 264000/1801350 [02:50<17:18, 1481.01 examples/s]Running tokenizer on dataset:  15%|█▍        | 265000/1801350 [02:51<16:53, 1516.55 examples/s]Running tokenizer on dataset:  15%|█▍        | 265000/1801350 [02:51<16:54, 1514.18 examples/s]Running tokenizer on dataset:  15%|█▍        | 265000/1801350 [02:51<16:53, 1515.22 examples/s]Running tokenizer on dataset:  15%|█▍        | 265000/1801350 [02:51<16:56, 1512.10 examples/s]Running tokenizer on dataset:  15%|█▍        | 266000/1801350 [02:51<17:07, 1493.57 examples/s]Running tokenizer on dataset:  15%|█▍        | 266000/1801350 [02:51<17:09, 1491.35 examples/s]Running tokenizer on dataset:  15%|█▍        | 266000/1801350 [02:51<17:14, 1484.56 examples/s]Running tokenizer on dataset:  15%|█▍        | 266000/1801350 [02:51<17:14, 1484.23 examples/s]Running tokenizer on dataset:  15%|█▍        | 267000/1801350 [02:52<16:48, 1520.90 examples/s]Running tokenizer on dataset:  15%|█▍        | 267000/1801350 [02:52<16:51, 1516.38 examples/s]Running tokenizer on dataset:  15%|█▍        | 267000/1801350 [02:52<17:00, 1504.08 examples/s]Running tokenizer on dataset:  15%|█▍        | 267000/1801350 [02:52<17:22, 1471.18 examples/s]Running tokenizer on dataset:  15%|█▍        | 268000/1801350 [02:53<16:51, 1515.84 examples/s]Running tokenizer on dataset:  15%|█▍        | 268000/1801350 [02:53<16:55, 1509.41 examples/s]Running tokenizer on dataset:  15%|█▍        | 268000/1801350 [02:53<16:53, 1513.06 examples/s]Running tokenizer on dataset:  15%|█▍        | 268000/1801350 [02:53<17:07, 1493.02 examples/s]Running tokenizer on dataset:  15%|█▍        | 269000/1801350 [02:53<16:16, 1569.24 examples/s]Running tokenizer on dataset:  15%|█▍        | 269000/1801350 [02:53<16:13, 1574.33 examples/s]Running tokenizer on dataset:  15%|█▍        | 269000/1801350 [02:53<16:25, 1554.39 examples/s]Running tokenizer on dataset:  15%|█▍        | 269000/1801350 [02:53<16:34, 1540.51 examples/s]Running tokenizer on dataset:  15%|█▍        | 270000/1801350 [02:54<16:23, 1557.80 examples/s]Running tokenizer on dataset:  15%|█▍        | 270000/1801350 [02:54<16:22, 1558.69 examples/s]Running tokenizer on dataset:  15%|█▍        | 270000/1801350 [02:54<16:32, 1543.49 examples/s]Running tokenizer on dataset:  15%|█▍        | 270000/1801350 [02:54<16:19, 1563.61 examples/s]Running tokenizer on dataset:  15%|█▌        | 271000/1801350 [02:54<16:15, 1568.41 examples/s]Running tokenizer on dataset:  15%|█▌        | 271000/1801350 [02:54<16:13, 1571.59 examples/s]Running tokenizer on dataset:  15%|█▌        | 271000/1801350 [02:54<16:21, 1559.72 examples/s]Running tokenizer on dataset:  15%|█▌        | 271000/1801350 [02:54<16:24, 1554.77 examples/s]Running tokenizer on dataset:  15%|█▌        | 272000/1801350 [02:55<15:55, 1600.20 examples/s]Running tokenizer on dataset:  15%|█▌        | 272000/1801350 [02:55<15:55, 1600.82 examples/s]Running tokenizer on dataset:  15%|█▌        | 272000/1801350 [02:55<15:53, 1604.34 examples/s]Running tokenizer on dataset:  15%|█▌        | 272000/1801350 [02:55<16:17, 1564.58 examples/s]Running tokenizer on dataset:  15%|█▌        | 273000/1801350 [02:55<15:04, 1690.27 examples/s]Running tokenizer on dataset:  15%|█▌        | 273000/1801350 [02:56<15:11, 1676.04 examples/s]Running tokenizer on dataset:  15%|█▌        | 273000/1801350 [02:56<15:10, 1678.83 examples/s]Running tokenizer on dataset:  15%|█▌        | 273000/1801350 [02:56<15:22, 1657.38 examples/s]Running tokenizer on dataset:  15%|█▌        | 274000/1801350 [02:56<15:08, 1680.49 examples/s]Running tokenizer on dataset:  15%|█▌        | 274000/1801350 [02:56<15:14, 1670.25 examples/s]Running tokenizer on dataset:  15%|█▌        | 274000/1801350 [02:56<15:14, 1670.98 examples/s]Running tokenizer on dataset:  15%|█▌        | 274000/1801350 [02:56<15:15, 1669.18 examples/s]Running tokenizer on dataset:  15%|█▌        | 275000/1801350 [02:57<15:34, 1633.12 examples/s]Running tokenizer on dataset:  15%|█▌        | 275000/1801350 [02:57<15:46, 1612.67 examples/s]Running tokenizer on dataset:  15%|█▌        | 275000/1801350 [02:57<15:42, 1619.26 examples/s]Running tokenizer on dataset:  15%|█▌        | 275000/1801350 [02:57<16:13, 1567.40 examples/s]Running tokenizer on dataset:  15%|█▌        | 276000/1801350 [02:57<15:55, 1596.73 examples/s]Running tokenizer on dataset:  15%|█▌        | 276000/1801350 [02:57<16:12, 1567.90 examples/s]Running tokenizer on dataset:  15%|█▌        | 276000/1801350 [02:58<16:06, 1577.94 examples/s]Running tokenizer on dataset:  15%|█▌        | 276000/1801350 [02:58<16:28, 1543.12 examples/s]Running tokenizer on dataset:  15%|█▌        | 277000/1801350 [02:58<16:35, 1531.91 examples/s]Running tokenizer on dataset:  15%|█▌        | 277000/1801350 [02:58<16:33, 1535.03 examples/s]Running tokenizer on dataset:  15%|█▌        | 277000/1801350 [02:58<16:34, 1533.39 examples/s]Running tokenizer on dataset:  15%|█▌        | 277000/1801350 [02:58<16:31, 1537.90 examples/s]Running tokenizer on dataset:  15%|█▌        | 278000/1801350 [02:59<16:16, 1559.69 examples/s]Running tokenizer on dataset:  15%|█▌        | 278000/1801350 [02:59<16:32, 1535.00 examples/s]Running tokenizer on dataset:  15%|█▌        | 278000/1801350 [02:59<16:12, 1566.93 examples/s]Running tokenizer on dataset:  15%|█▌        | 278000/1801350 [02:59<16:35, 1529.95 examples/s]Running tokenizer on dataset:  15%|█▌        | 279000/1801350 [02:59<15:56, 1591.67 examples/s]Running tokenizer on dataset:  15%|█▌        | 279000/1801350 [02:59<16:15, 1559.95 examples/s]Running tokenizer on dataset:  15%|█▌        | 279000/1801350 [02:59<15:51, 1599.26 examples/s]Running tokenizer on dataset:  15%|█▌        | 279000/1801350 [02:59<16:17, 1557.67 examples/s]Running tokenizer on dataset:  16%|█▌        | 280000/1801350 [03:00<18:54, 1341.49 examples/s]Running tokenizer on dataset:  16%|█▌        | 280000/1801350 [03:00<18:35, 1363.81 examples/s]Running tokenizer on dataset:  16%|█▌        | 280000/1801350 [03:00<19:32, 1297.57 examples/s]Running tokenizer on dataset:  16%|█▌        | 280000/1801350 [03:01<19:28, 1302.10 examples/s]Running tokenizer on dataset:  16%|█▌        | 281000/1801350 [03:01<17:57, 1410.44 examples/s]Running tokenizer on dataset:  16%|█▌        | 281000/1801350 [03:01<17:50, 1419.92 examples/s]Running tokenizer on dataset:  16%|█▌        | 281000/1801350 [03:01<18:47, 1347.99 examples/s]Running tokenizer on dataset:  16%|█▌        | 281000/1801350 [03:01<18:36, 1362.25 examples/s]Running tokenizer on dataset:  16%|█▌        | 282000/1801350 [03:02<17:22, 1456.82 examples/s]Running tokenizer on dataset:  16%|█▌        | 282000/1801350 [03:02<17:15, 1466.59 examples/s]Running tokenizer on dataset:  16%|█▌        | 282000/1801350 [03:02<17:38, 1435.80 examples/s]Running tokenizer on dataset:  16%|█▌        | 282000/1801350 [03:02<17:42, 1430.52 examples/s]Running tokenizer on dataset:  16%|█▌        | 283000/1801350 [03:02<17:09, 1474.45 examples/s]Running tokenizer on dataset:  16%|█▌        | 283000/1801350 [03:02<17:10, 1473.81 examples/s]Running tokenizer on dataset:  16%|█▌        | 283000/1801350 [03:02<17:24, 1453.89 examples/s]Running tokenizer on dataset:  16%|█▌        | 283000/1801350 [03:02<17:24, 1454.36 examples/s]Running tokenizer on dataset:  16%|█▌        | 284000/1801350 [03:03<16:26, 1537.35 examples/s]Running tokenizer on dataset:  16%|█▌        | 284000/1801350 [03:03<16:25, 1539.57 examples/s]Running tokenizer on dataset:  16%|█▌        | 284000/1801350 [03:03<16:39, 1518.28 examples/s]Running tokenizer on dataset:  16%|█▌        | 284000/1801350 [03:03<16:37, 1521.16 examples/s]Running tokenizer on dataset:  16%|█▌        | 285000/1801350 [03:04<16:12, 1558.68 examples/s]Running tokenizer on dataset:  16%|█▌        | 285000/1801350 [03:04<16:20, 1546.97 examples/s]Running tokenizer on dataset:  16%|█▌        | 285000/1801350 [03:04<16:15, 1553.90 examples/s]Running tokenizer on dataset:  16%|█▌        | 285000/1801350 [03:04<16:35, 1522.58 examples/s]Running tokenizer on dataset:  16%|█▌        | 286000/1801350 [03:04<15:59, 1579.83 examples/s]Running tokenizer on dataset:  16%|█▌        | 286000/1801350 [03:04<15:50, 1593.49 examples/s]Running tokenizer on dataset:  16%|█▌        | 286000/1801350 [03:04<16:01, 1576.03 examples/s]Running tokenizer on dataset:  16%|█▌        | 286000/1801350 [03:04<15:58, 1581.34 examples/s]Running tokenizer on dataset:  16%|█▌        | 287000/1801350 [03:05<16:25, 1536.77 examples/s]Running tokenizer on dataset:  16%|█▌        | 287000/1801350 [03:05<16:31, 1527.56 examples/s]Running tokenizer on dataset:  16%|█▌        | 287000/1801350 [03:05<16:24, 1537.43 examples/s]Running tokenizer on dataset:  16%|█▌        | 287000/1801350 [03:05<16:36, 1519.17 examples/s]Running tokenizer on dataset:  16%|█▌        | 288000/1801350 [03:05<16:02, 1572.51 examples/s]Running tokenizer on dataset:  16%|█▌        | 288000/1801350 [03:05<16:10, 1560.05 examples/s]Running tokenizer on dataset:  16%|█▌        | 288000/1801350 [03:06<15:58, 1578.84 examples/s]Running tokenizer on dataset:  16%|█▌        | 288000/1801350 [03:06<16:09, 1560.34 examples/s]Running tokenizer on dataset:  16%|█▌        | 289000/1801350 [03:06<15:46, 1597.34 examples/s]Running tokenizer on dataset:  16%|█▌        | 289000/1801350 [03:06<15:52, 1587.06 examples/s]Running tokenizer on dataset:  16%|█▌        | 289000/1801350 [03:06<15:46, 1598.00 examples/s]Running tokenizer on dataset:  16%|█▌        | 289000/1801350 [03:06<15:54, 1584.26 examples/s]Running tokenizer on dataset:  16%|█▌        | 290000/1801350 [03:07<16:24, 1535.60 examples/s]Running tokenizer on dataset:  16%|█▌        | 290000/1801350 [03:07<16:22, 1538.02 examples/s]Running tokenizer on dataset:  16%|█▌        | 290000/1801350 [03:07<16:16, 1548.41 examples/s]Running tokenizer on dataset:  16%|█▌        | 290000/1801350 [03:07<16:18, 1544.32 examples/s]Running tokenizer on dataset:  16%|█▌        | 291000/1801350 [03:07<16:17, 1545.51 examples/s]Running tokenizer on dataset:  16%|█▌        | 291000/1801350 [03:07<16:22, 1537.97 examples/s]Running tokenizer on dataset:  16%|█▌        | 291000/1801350 [03:07<16:09, 1557.34 examples/s]Running tokenizer on dataset:  16%|█▌        | 291000/1801350 [03:08<16:22, 1537.53 examples/s]Running tokenizer on dataset:  16%|█▌        | 292000/1801350 [03:08<16:16, 1545.60 examples/s]Running tokenizer on dataset:  16%|█▌        | 292000/1801350 [03:08<16:21, 1537.65 examples/s]Running tokenizer on dataset:  16%|█▌        | 292000/1801350 [03:08<16:20, 1538.93 examples/s]Running tokenizer on dataset:  16%|█▌        | 292000/1801350 [03:08<16:24, 1532.76 examples/s]Running tokenizer on dataset:  16%|█▋        | 293000/1801350 [03:09<16:21, 1536.32 examples/s]Running tokenizer on dataset:  16%|█▋        | 293000/1801350 [03:09<16:39, 1508.69 examples/s]Running tokenizer on dataset:  16%|█▋        | 293000/1801350 [03:09<16:12, 1551.74 examples/s]Running tokenizer on dataset:  16%|█▋        | 293000/1801350 [03:09<16:24, 1532.08 examples/s]Running tokenizer on dataset:  16%|█▋        | 294000/1801350 [03:09<16:19, 1539.25 examples/s]Running tokenizer on dataset:  16%|█▋        | 294000/1801350 [03:09<16:29, 1524.09 examples/s]Running tokenizer on dataset:  16%|█▋        | 294000/1801350 [03:09<16:09, 1554.15 examples/s]Running tokenizer on dataset:  16%|█▋        | 294000/1801350 [03:09<16:26, 1528.28 examples/s]Running tokenizer on dataset:  16%|█▋        | 295000/1801350 [03:10<15:36, 1607.70 examples/s]Running tokenizer on dataset:  16%|█▋        | 295000/1801350 [03:10<15:39, 1603.79 examples/s]Running tokenizer on dataset:  16%|█▋        | 295000/1801350 [03:10<15:18, 1639.51 examples/s]Running tokenizer on dataset:  16%|█▋        | 295000/1801350 [03:10<15:41, 1600.39 examples/s]Running tokenizer on dataset:  16%|█▋        | 296000/1801350 [03:11<15:50, 1584.39 examples/s]Running tokenizer on dataset:  16%|█▋        | 296000/1801350 [03:11<15:40, 1601.24 examples/s]Running tokenizer on dataset:  16%|█▋        | 296000/1801350 [03:11<15:57, 1572.19 examples/s]Running tokenizer on dataset:  16%|█▋        | 296000/1801350 [03:11<15:37, 1605.47 examples/s]Running tokenizer on dataset:  16%|█▋        | 297000/1801350 [03:11<15:41, 1598.22 examples/s]Running tokenizer on dataset:  16%|█▋        | 297000/1801350 [03:11<15:30, 1616.11 examples/s]Running tokenizer on dataset:  16%|█▋        | 297000/1801350 [03:11<15:27, 1621.84 examples/s]Running tokenizer on dataset:  16%|█▋        | 297000/1801350 [03:11<15:47, 1586.92 examples/s]Running tokenizer on dataset:  17%|█▋        | 298000/1801350 [03:12<15:33, 1609.69 examples/s]Running tokenizer on dataset:  17%|█▋        | 298000/1801350 [03:12<15:37, 1603.38 examples/s]Running tokenizer on dataset:  17%|█▋        | 298000/1801350 [03:12<15:26, 1622.29 examples/s]Running tokenizer on dataset:  17%|█▋        | 298000/1801350 [03:12<15:35, 1606.83 examples/s]Running tokenizer on dataset:  17%|█▋        | 299000/1801350 [03:12<15:45, 1588.59 examples/s]Running tokenizer on dataset:  17%|█▋        | 299000/1801350 [03:12<15:34, 1608.15 examples/s]Running tokenizer on dataset:  17%|█▋        | 299000/1801350 [03:12<15:41, 1595.30 examples/s]Running tokenizer on dataset:  17%|█▋        | 299000/1801350 [03:12<15:49, 1581.80 examples/s]Running tokenizer on dataset:  17%|█▋        | 300000/1801350 [03:13<15:16, 1638.40 examples/s]Running tokenizer on dataset:  17%|█▋        | 300000/1801350 [03:13<15:15, 1640.52 examples/s]Running tokenizer on dataset:  17%|█▋        | 300000/1801350 [03:13<15:12, 1646.04 examples/s]Running tokenizer on dataset:  17%|█▋        | 300000/1801350 [03:13<15:17, 1636.73 examples/s]Running tokenizer on dataset:  17%|█▋        | 301000/1801350 [03:14<18:31, 1350.31 examples/s]Running tokenizer on dataset:  17%|█▋        | 301000/1801350 [03:14<18:19, 1364.80 examples/s]Running tokenizer on dataset:  17%|█▋        | 301000/1801350 [03:14<18:25, 1356.98 examples/s]Running tokenizer on dataset:  17%|█▋        | 301000/1801350 [03:14<18:57, 1319.31 examples/s]Running tokenizer on dataset:  17%|█▋        | 302000/1801350 [03:15<17:58, 1390.34 examples/s]Running tokenizer on dataset:  17%|█▋        | 302000/1801350 [03:15<18:03, 1383.48 examples/s]Running tokenizer on dataset:  17%|█▋        | 302000/1801350 [03:15<18:03, 1384.29 examples/s]Running tokenizer on dataset:  17%|█▋        | 302000/1801350 [03:15<18:30, 1350.47 examples/s]Running tokenizer on dataset:  17%|█▋        | 303000/1801350 [03:15<16:58, 1470.59 examples/s]Running tokenizer on dataset:  17%|█▋        | 303000/1801350 [03:15<16:58, 1471.20 examples/s]Running tokenizer on dataset:  17%|█▋        | 303000/1801350 [03:15<17:03, 1463.65 examples/s]Running tokenizer on dataset:  17%|█▋        | 303000/1801350 [03:15<17:13, 1449.24 examples/s]Running tokenizer on dataset:  17%|█▋        | 304000/1801350 [03:16<16:12, 1539.61 examples/s]Running tokenizer on dataset:  17%|█▋        | 304000/1801350 [03:16<16:13, 1538.56 examples/s]Running tokenizer on dataset:  17%|█▋        | 304000/1801350 [03:16<16:13, 1538.68 examples/s]Running tokenizer on dataset:  17%|█▋        | 304000/1801350 [03:16<16:18, 1530.48 examples/s]Running tokenizer on dataset:  17%|█▋        | 305000/1801350 [03:17<16:02, 1554.72 examples/s]Running tokenizer on dataset:  17%|█▋        | 305000/1801350 [03:17<16:13, 1537.29 examples/s]Running tokenizer on dataset:  17%|█▋        | 305000/1801350 [03:17<16:15, 1533.25 examples/s]Running tokenizer on dataset:  17%|█▋        | 305000/1801350 [03:17<16:15, 1534.12 examples/s]Running tokenizer on dataset:  17%|█▋        | 306000/1801350 [03:17<16:08, 1543.60 examples/s]Running tokenizer on dataset:  17%|█▋        | 306000/1801350 [03:17<15:59, 1557.89 examples/s]Running tokenizer on dataset:  17%|█▋        | 306000/1801350 [03:17<16:02, 1552.83 examples/s]Running tokenizer on dataset:  17%|█▋        | 306000/1801350 [03:17<16:18, 1528.55 examples/s]Running tokenizer on dataset:  17%|█▋        | 307000/1801350 [03:18<16:18, 1526.58 examples/s]Running tokenizer on dataset:  17%|█▋        | 307000/1801350 [03:18<16:11, 1537.65 examples/s]Running tokenizer on dataset:  17%|█▋        | 307000/1801350 [03:18<16:32, 1505.74 examples/s]Running tokenizer on dataset:  17%|█▋        | 307000/1801350 [03:18<16:07, 1544.56 examples/s]Running tokenizer on dataset:  17%|█▋        | 308000/1801350 [03:18<15:40, 1588.53 examples/s]Running tokenizer on dataset:  17%|█▋        | 308000/1801350 [03:18<15:36, 1595.06 examples/s]Running tokenizer on dataset:  17%|█▋        | 308000/1801350 [03:19<15:56, 1561.76 examples/s]Running tokenizer on dataset:  17%|█▋        | 308000/1801350 [03:19<15:46, 1578.14 examples/s]Running tokenizer on dataset:  17%|█▋        | 309000/1801350 [03:19<16:10, 1536.93 examples/s]Running tokenizer on dataset:  17%|█▋        | 309000/1801350 [03:19<16:16, 1528.11 examples/s]Running tokenizer on dataset:  17%|█▋        | 309000/1801350 [03:19<16:09, 1538.74 examples/s]Running tokenizer on dataset:  17%|█▋        | 309000/1801350 [03:19<16:09, 1539.44 examples/s]Running tokenizer on dataset:  17%|█▋        | 310000/1801350 [03:20<15:01, 1653.62 examples/s]Running tokenizer on dataset:  17%|█▋        | 310000/1801350 [03:20<14:55, 1664.78 examples/s]Running tokenizer on dataset:  17%|█▋        | 310000/1801350 [03:20<14:48, 1678.71 examples/s]Running tokenizer on dataset:  17%|█▋        | 310000/1801350 [03:20<15:10, 1637.70 examples/s]Running tokenizer on dataset:  17%|█▋        | 311000/1801350 [03:20<15:13, 1631.66 examples/s]Running tokenizer on dataset:  17%|█▋        | 311000/1801350 [03:20<15:11, 1635.05 examples/s]Running tokenizer on dataset:  17%|█▋        | 311000/1801350 [03:20<15:08, 1639.75 examples/s]Running tokenizer on dataset:  17%|█▋        | 311000/1801350 [03:20<15:33, 1597.14 examples/s]Running tokenizer on dataset:  17%|█▋        | 312000/1801350 [03:21<15:08, 1638.77 examples/s]Running tokenizer on dataset:  17%|█▋        | 312000/1801350 [03:21<14:59, 1656.58 examples/s]Running tokenizer on dataset:  17%|█▋        | 312000/1801350 [03:21<15:18, 1622.38 examples/s]Running tokenizer on dataset:  17%|█▋        | 312000/1801350 [03:21<15:12, 1633.02 examples/s]Running tokenizer on dataset:  17%|█▋        | 313000/1801350 [03:21<15:10, 1634.76 examples/s]Running tokenizer on dataset:  17%|█▋        | 313000/1801350 [03:22<15:06, 1641.91 examples/s]Running tokenizer on dataset:  17%|█▋        | 313000/1801350 [03:22<14:59, 1654.35 examples/s]Running tokenizer on dataset:  17%|█▋        | 313000/1801350 [03:22<15:05, 1643.63 examples/s]Running tokenizer on dataset:  17%|█▋        | 314000/1801350 [03:22<14:41, 1688.18 examples/s]Running tokenizer on dataset:  17%|█▋        | 314000/1801350 [03:22<14:43, 1682.70 examples/s]Running tokenizer on dataset:  17%|█▋        | 314000/1801350 [03:22<14:42, 1685.86 examples/s]Running tokenizer on dataset:  17%|█▋        | 314000/1801350 [03:22<14:42, 1685.96 examples/s]Running tokenizer on dataset:  17%|█▋        | 315000/1801350 [03:23<15:30, 1597.45 examples/s]Running tokenizer on dataset:  17%|█▋        | 315000/1801350 [03:23<15:24, 1607.96 examples/s]Running tokenizer on dataset:  17%|█▋        | 315000/1801350 [03:23<15:28, 1600.26 examples/s]Running tokenizer on dataset:  17%|█▋        | 315000/1801350 [03:23<15:39, 1582.17 examples/s]Running tokenizer on dataset:  18%|█▊        | 316000/1801350 [03:23<15:38, 1582.66 examples/s]Running tokenizer on dataset:  18%|█▊        | 316000/1801350 [03:23<15:33, 1591.58 examples/s]Running tokenizer on dataset:  18%|█▊        | 316000/1801350 [03:23<15:38, 1583.30 examples/s]Running tokenizer on dataset:  18%|█▊        | 316000/1801350 [03:23<15:37, 1584.57 examples/s]Running tokenizer on dataset:  18%|█▊        | 317000/1801350 [03:24<15:59, 1547.01 examples/s]Running tokenizer on dataset:  18%|█▊        | 317000/1801350 [03:24<15:56, 1551.29 examples/s]Running tokenizer on dataset:  18%|█▊        | 317000/1801350 [03:24<15:57, 1549.92 examples/s]Running tokenizer on dataset:  18%|█▊        | 317000/1801350 [03:24<16:00, 1545.38 examples/s]Running tokenizer on dataset:  18%|█▊        | 318000/1801350 [03:25<16:11, 1527.55 examples/s]Running tokenizer on dataset:  18%|█▊        | 318000/1801350 [03:25<16:06, 1534.53 examples/s]Running tokenizer on dataset:  18%|█▊        | 318000/1801350 [03:25<16:10, 1529.12 examples/s]Running tokenizer on dataset:  18%|█▊        | 318000/1801350 [03:25<16:13, 1523.06 examples/s]Running tokenizer on dataset:  18%|█▊        | 319000/1801350 [03:25<16:03, 1538.44 examples/s]Running tokenizer on dataset:  18%|█▊        | 319000/1801350 [03:25<16:00, 1544.11 examples/s]Running tokenizer on dataset:  18%|█▊        | 319000/1801350 [03:25<16:05, 1535.20 examples/s]Running tokenizer on dataset:  18%|█▊        | 319000/1801350 [03:25<16:06, 1534.42 examples/s]Running tokenizer on dataset:  18%|█▊        | 320000/1801350 [03:26<15:53, 1554.29 examples/s]Running tokenizer on dataset:  18%|█▊        | 320000/1801350 [03:26<15:54, 1551.88 examples/s]Running tokenizer on dataset:  18%|█▊        | 320000/1801350 [03:26<15:56, 1548.61 examples/s]Running tokenizer on dataset:  18%|█▊        | 320000/1801350 [03:26<15:56, 1548.31 examples/s]Running tokenizer on dataset:  18%|█▊        | 321000/1801350 [03:27<16:02, 1538.03 examples/s]Running tokenizer on dataset:  18%|█▊        | 321000/1801350 [03:27<15:45, 1565.48 examples/s]Running tokenizer on dataset:  18%|█▊        | 321000/1801350 [03:27<15:45, 1565.16 examples/s]Running tokenizer on dataset:  18%|█▊        | 321000/1801350 [03:27<15:51, 1555.95 examples/s]Running tokenizer on dataset:  18%|█▊        | 322000/1801350 [03:28<18:02, 1366.90 examples/s]Running tokenizer on dataset:  18%|█▊        | 322000/1801350 [03:28<18:04, 1364.10 examples/s]Running tokenizer on dataset:  18%|█▊        | 322000/1801350 [03:28<18:17, 1348.53 examples/s]Running tokenizer on dataset:  18%|█▊        | 322000/1801350 [03:28<19:41, 1252.30 examples/s]Running tokenizer on dataset:  18%|█▊        | 323000/1801350 [03:28<17:31, 1405.35 examples/s]Running tokenizer on dataset:  18%|█▊        | 323000/1801350 [03:28<17:44, 1389.01 examples/s]Running tokenizer on dataset:  18%|█▊        | 323000/1801350 [03:28<17:40, 1394.30 examples/s]Running tokenizer on dataset:  18%|█▊        | 323000/1801350 [03:28<18:49, 1308.64 examples/s]Running tokenizer on dataset:  18%|█▊        | 324000/1801350 [03:29<16:46, 1467.55 examples/s]Running tokenizer on dataset:  18%|█▊        | 324000/1801350 [03:29<16:48, 1464.49 examples/s]Running tokenizer on dataset:  18%|█▊        | 324000/1801350 [03:29<16:55, 1454.84 examples/s]Running tokenizer on dataset:  18%|█▊        | 324000/1801350 [03:29<17:27, 1410.11 examples/s]Running tokenizer on dataset:  18%|█▊        | 325000/1801350 [03:30<16:23, 1500.67 examples/s]Running tokenizer on dataset:  18%|█▊        | 325000/1801350 [03:30<16:20, 1505.78 examples/s]Running tokenizer on dataset:  18%|█▊        | 325000/1801350 [03:30<16:27, 1494.96 examples/s]Running tokenizer on dataset:  18%|█▊        | 325000/1801350 [03:30<16:32, 1486.89 examples/s]Running tokenizer on dataset:  18%|█▊        | 326000/1801350 [03:30<16:54, 1454.64 examples/s]Running tokenizer on dataset:  18%|█▊        | 326000/1801350 [03:30<17:02, 1442.68 examples/s]Running tokenizer on dataset:  18%|█▊        | 326000/1801350 [03:30<17:10, 1431.95 examples/s]Running tokenizer on dataset:  18%|█▊        | 326000/1801350 [03:30<17:00, 1445.65 examples/s]Running tokenizer on dataset:  18%|█▊        | 327000/1801350 [03:31<15:55, 1543.71 examples/s]Running tokenizer on dataset:  18%|█▊        | 327000/1801350 [03:31<15:54, 1543.91 examples/s]Running tokenizer on dataset:  18%|█▊        | 327000/1801350 [03:31<16:02, 1531.15 examples/s]Running tokenizer on dataset:  18%|█▊        | 327000/1801350 [03:31<16:15, 1511.73 examples/s]Running tokenizer on dataset:  18%|█▊        | 328000/1801350 [03:31<14:56, 1643.14 examples/s]Running tokenizer on dataset:  18%|█▊        | 328000/1801350 [03:31<15:01, 1635.10 examples/s]Running tokenizer on dataset:  18%|█▊        | 328000/1801350 [03:31<15:08, 1621.10 examples/s]Running tokenizer on dataset:  18%|█▊        | 328000/1801350 [03:31<15:27, 1588.03 examples/s]Running tokenizer on dataset:  18%|█▊        | 329000/1801350 [03:32<14:40, 1672.57 examples/s]Running tokenizer on dataset:  18%|█▊        | 329000/1801350 [03:32<14:42, 1667.58 examples/s]Running tokenizer on dataset:  18%|█▊        | 329000/1801350 [03:32<14:32, 1687.45 examples/s]Running tokenizer on dataset:  18%|█▊        | 329000/1801350 [03:32<14:41, 1669.49 examples/s]Running tokenizer on dataset:  18%|█▊        | 330000/1801350 [03:33<15:28, 1585.01 examples/s]Running tokenizer on dataset:  18%|█▊        | 330000/1801350 [03:33<15:29, 1582.31 examples/s]Running tokenizer on dataset:  18%|█▊        | 330000/1801350 [03:33<15:23, 1593.11 examples/s]Running tokenizer on dataset:  18%|█▊        | 330000/1801350 [03:33<15:18, 1602.48 examples/s]Running tokenizer on dataset:  18%|█▊        | 331000/1801350 [03:33<15:41, 1561.29 examples/s]Running tokenizer on dataset:  18%|█▊        | 331000/1801350 [03:33<15:44, 1556.60 examples/s]Running tokenizer on dataset:  18%|█▊        | 331000/1801350 [03:33<15:41, 1561.12 examples/s]Running tokenizer on dataset:  18%|█▊        | 331000/1801350 [03:33<15:27, 1585.12 examples/s]Running tokenizer on dataset:  18%|█▊        | 332000/1801350 [03:34<16:03, 1525.71 examples/s]Running tokenizer on dataset:  18%|█▊        | 332000/1801350 [03:34<16:05, 1521.66 examples/s]Running tokenizer on dataset:  18%|█▊        | 332000/1801350 [03:34<15:59, 1530.64 examples/s]Running tokenizer on dataset:  18%|█▊        | 332000/1801350 [03:34<15:53, 1541.16 examples/s]Running tokenizer on dataset:  18%|█▊        | 333000/1801350 [03:35<15:33, 1572.35 examples/s]Running tokenizer on dataset:  18%|█▊        | 333000/1801350 [03:35<15:45, 1553.58 examples/s]Running tokenizer on dataset:  18%|█▊        | 333000/1801350 [03:35<15:42, 1558.44 examples/s]Running tokenizer on dataset:  18%|█▊        | 333000/1801350 [03:35<15:50, 1545.00 examples/s]Running tokenizer on dataset:  19%|█▊        | 334000/1801350 [03:35<15:17, 1599.19 examples/s]Running tokenizer on dataset:  19%|█▊        | 334000/1801350 [03:35<15:20, 1593.46 examples/s]Running tokenizer on dataset:  19%|█▊        | 334000/1801350 [03:35<15:15, 1602.86 examples/s]Running tokenizer on dataset:  19%|█▊        | 334000/1801350 [03:35<15:25, 1584.73 examples/s]Running tokenizer on dataset:  19%|█▊        | 335000/1801350 [03:36<15:34, 1569.07 examples/s]Running tokenizer on dataset:  19%|█▊        | 335000/1801350 [03:36<15:39, 1561.53 examples/s]Running tokenizer on dataset:  19%|█▊        | 335000/1801350 [03:36<15:34, 1569.61 examples/s]Running tokenizer on dataset:  19%|█▊        | 335000/1801350 [03:36<15:31, 1574.60 examples/s]Running tokenizer on dataset:  19%|█▊        | 336000/1801350 [03:36<15:21, 1590.16 examples/s]Running tokenizer on dataset:  19%|█▊        | 336000/1801350 [03:36<15:24, 1585.80 examples/s]Running tokenizer on dataset:  19%|█▊        | 336000/1801350 [03:36<15:20, 1592.52 examples/s]Running tokenizer on dataset:  19%|█▊        | 336000/1801350 [03:37<15:22, 1587.73 examples/s]Running tokenizer on dataset:  19%|█▊        | 337000/1801350 [03:37<15:14, 1601.03 examples/s]Running tokenizer on dataset:  19%|█▊        | 337000/1801350 [03:37<15:17, 1596.53 examples/s]Running tokenizer on dataset:  19%|█▊        | 337000/1801350 [03:37<15:14, 1601.89 examples/s]Running tokenizer on dataset:  19%|█▊        | 337000/1801350 [03:37<15:15, 1599.03 examples/s]Running tokenizer on dataset:  19%|█▉        | 338000/1801350 [03:38<14:57, 1631.11 examples/s]Running tokenizer on dataset:  19%|█▉        | 338000/1801350 [03:38<14:54, 1635.65 examples/s]Running tokenizer on dataset:  19%|█▉        | 338000/1801350 [03:38<14:56, 1633.15 examples/s]Running tokenizer on dataset:  19%|█▉        | 338000/1801350 [03:38<15:02, 1621.81 examples/s]Running tokenizer on dataset:  19%|█▉        | 339000/1801350 [03:38<14:45, 1651.26 examples/s]Running tokenizer on dataset:  19%|█▉        | 339000/1801350 [03:38<14:46, 1649.50 examples/s]Running tokenizer on dataset:  19%|█▉        | 339000/1801350 [03:38<14:46, 1649.38 examples/s]Running tokenizer on dataset:  19%|█▉        | 339000/1801350 [03:38<14:52, 1639.34 examples/s]Running tokenizer on dataset:  19%|█▉        | 340000/1801350 [03:39<15:42, 1551.33 examples/s]Running tokenizer on dataset:  19%|█▉        | 340000/1801350 [03:39<15:41, 1552.19 examples/s]Running tokenizer on dataset:  19%|█▉        | 340000/1801350 [03:39<15:41, 1551.36 examples/s]Running tokenizer on dataset:  19%|█▉        | 340000/1801350 [03:39<15:45, 1544.98 examples/s]Running tokenizer on dataset:  19%|█▉        | 341000/1801350 [03:40<15:50, 1537.06 examples/s]Running tokenizer on dataset:  19%|█▉        | 341000/1801350 [03:40<15:50, 1536.24 examples/s]Running tokenizer on dataset:  19%|█▉        | 341000/1801350 [03:40<15:53, 1531.86 examples/s]Running tokenizer on dataset:  19%|█▉        | 341000/1801350 [03:40<15:56, 1526.29 examples/s]Running tokenizer on dataset:  19%|█▉        | 342000/1801350 [03:40<15:29, 1569.24 examples/s]Running tokenizer on dataset:  19%|█▉        | 342000/1801350 [03:40<15:31, 1566.58 examples/s]Running tokenizer on dataset:  19%|█▉        | 342000/1801350 [03:40<15:33, 1562.95 examples/s]Running tokenizer on dataset:  19%|█▉        | 342000/1801350 [03:40<15:34, 1561.08 examples/s]Running tokenizer on dataset:  19%|█▉        | 343000/1801350 [03:41<17:32, 1385.44 examples/s]Running tokenizer on dataset:  19%|█▉        | 343000/1801350 [03:41<17:35, 1381.58 examples/s]Running tokenizer on dataset:  19%|█▉        | 343000/1801350 [03:41<17:37, 1378.76 examples/s]Running tokenizer on dataset:  19%|█▉        | 343000/1801350 [03:41<17:38, 1377.66 examples/s]Running tokenizer on dataset:  19%|█▉        | 344000/1801350 [03:42<16:34, 1465.22 examples/s]Running tokenizer on dataset:  19%|█▉        | 344000/1801350 [03:42<16:37, 1461.44 examples/s]Running tokenizer on dataset:  19%|█▉        | 344000/1801350 [03:42<16:38, 1459.50 examples/s]Running tokenizer on dataset:  19%|█▉        | 344000/1801350 [03:42<16:38, 1459.17 examples/s]Running tokenizer on dataset:  19%|█▉        | 345000/1801350 [03:42<16:20, 1485.14 examples/s]Running tokenizer on dataset:  19%|█▉        | 345000/1801350 [03:43<16:20, 1484.64 examples/s]Running tokenizer on dataset:  19%|█▉        | 345000/1801350 [03:42<16:25, 1478.04 examples/s]Running tokenizer on dataset:  19%|█▉        | 345000/1801350 [03:42<16:27, 1475.02 examples/s]Running tokenizer on dataset:  19%|█▉        | 346000/1801350 [03:43<16:46, 1446.01 examples/s]Running tokenizer on dataset:  19%|█▉        | 346000/1801350 [03:43<16:47, 1443.89 examples/s]Running tokenizer on dataset:  19%|█▉        | 346000/1801350 [03:43<16:51, 1438.16 examples/s]Running tokenizer on dataset:  19%|█▉        | 346000/1801350 [03:43<16:52, 1438.08 examples/s]Running tokenizer on dataset:  19%|█▉        | 347000/1801350 [03:44<15:55, 1522.62 examples/s]Running tokenizer on dataset:  19%|█▉        | 347000/1801350 [03:44<15:57, 1519.69 examples/s]Running tokenizer on dataset:  19%|█▉        | 347000/1801350 [03:44<15:59, 1516.34 examples/s]Running tokenizer on dataset:  19%|█▉        | 347000/1801350 [03:44<15:58, 1517.34 examples/s]Running tokenizer on dataset:  19%|█▉        | 348000/1801350 [03:44<15:54, 1522.03 examples/s]Running tokenizer on dataset:  19%|█▉        | 348000/1801350 [03:44<15:52, 1525.38 examples/s]Running tokenizer on dataset:  19%|█▉        | 348000/1801350 [03:44<15:58, 1516.26 examples/s]Running tokenizer on dataset:  19%|█▉        | 348000/1801350 [03:45<16:14, 1491.31 examples/s]Running tokenizer on dataset:  19%|█▉        | 349000/1801350 [03:45<15:41, 1542.32 examples/s]Running tokenizer on dataset:  19%|█▉        | 349000/1801350 [03:45<15:42, 1540.84 examples/s]Running tokenizer on dataset:  19%|█▉        | 349000/1801350 [03:45<15:37, 1549.90 examples/s]Running tokenizer on dataset:  19%|█▉        | 349000/1801350 [03:45<15:41, 1541.97 examples/s]Running tokenizer on dataset:  19%|█▉        | 350000/1801350 [03:46<15:14, 1587.68 examples/s]Running tokenizer on dataset:  19%|█▉        | 350000/1801350 [03:46<15:17, 1581.70 examples/s]Running tokenizer on dataset:  19%|█▉        | 350000/1801350 [03:46<15:18, 1580.14 examples/s]Running tokenizer on dataset:  19%|█▉        | 350000/1801350 [03:46<15:13, 1588.93 examples/s]Running tokenizer on dataset:  19%|█▉        | 351000/1801350 [03:46<14:40, 1648.11 examples/s]Running tokenizer on dataset:  19%|█▉        | 351000/1801350 [03:46<14:46, 1636.71 examples/s]Running tokenizer on dataset:  19%|█▉        | 351000/1801350 [03:46<14:48, 1631.47 examples/s]Running tokenizer on dataset:  19%|█▉        | 351000/1801350 [03:46<14:49, 1630.13 examples/s]Running tokenizer on dataset:  20%|█▉        | 352000/1801350 [03:47<14:59, 1610.95 examples/s]Running tokenizer on dataset:  20%|█▉        | 352000/1801350 [03:47<15:02, 1605.58 examples/s]Running tokenizer on dataset:  20%|█▉        | 352000/1801350 [03:47<15:03, 1603.51 examples/s]Running tokenizer on dataset:  20%|█▉        | 352000/1801350 [03:47<15:02, 1606.53 examples/s]Running tokenizer on dataset:  20%|█▉        | 353000/1801350 [03:48<15:37, 1544.23 examples/s]Running tokenizer on dataset:  20%|█▉        | 353000/1801350 [03:48<15:38, 1543.11 examples/s]Running tokenizer on dataset:  20%|█▉        | 353000/1801350 [03:48<15:37, 1545.30 examples/s]Running tokenizer on dataset:  20%|█▉        | 353000/1801350 [03:48<15:41, 1538.34 examples/s]Running tokenizer on dataset:  20%|█▉        | 354000/1801350 [03:48<16:05, 1499.16 examples/s]Running tokenizer on dataset:  20%|█▉        | 354000/1801350 [03:48<16:09, 1493.54 examples/s]Running tokenizer on dataset:  20%|█▉        | 354000/1801350 [03:48<16:13, 1487.33 examples/s]Running tokenizer on dataset:  20%|█▉        | 354000/1801350 [03:48<16:14, 1485.79 examples/s]Running tokenizer on dataset:  20%|█▉        | 355000/1801350 [03:49<15:19, 1573.33 examples/s]Running tokenizer on dataset:  20%|█▉        | 355000/1801350 [03:49<15:28, 1557.00 examples/s]Running tokenizer on dataset:  20%|█▉        | 355000/1801350 [03:49<15:29, 1556.24 examples/s]Running tokenizer on dataset:  20%|█▉        | 355000/1801350 [03:49<15:29, 1555.61 examples/s]Running tokenizer on dataset:  20%|█▉        | 356000/1801350 [03:50<15:23, 1565.32 examples/s]Running tokenizer on dataset:  20%|█▉        | 356000/1801350 [03:49<15:21, 1568.10 examples/s]Running tokenizer on dataset:  20%|█▉        | 356000/1801350 [03:50<15:25, 1562.28 examples/s]Running tokenizer on dataset:  20%|█▉        | 356000/1801350 [03:50<15:27, 1557.52 examples/s]Running tokenizer on dataset:  20%|█▉        | 357000/1801350 [03:50<15:43, 1531.56 examples/s]Running tokenizer on dataset:  20%|█▉        | 357000/1801350 [03:50<15:43, 1531.05 examples/s]Running tokenizer on dataset:  20%|█▉        | 357000/1801350 [03:50<15:53, 1514.89 examples/s]Running tokenizer on dataset:  20%|█▉        | 357000/1801350 [03:50<15:56, 1510.49 examples/s]Running tokenizer on dataset:  20%|█▉        | 358000/1801350 [03:51<15:38, 1537.15 examples/s]Running tokenizer on dataset:  20%|█▉        | 358000/1801350 [03:51<15:43, 1529.17 examples/s]Running tokenizer on dataset:  20%|█▉        | 358000/1801350 [03:51<15:38, 1537.50 examples/s]Running tokenizer on dataset:  20%|█▉        | 358000/1801350 [03:51<16:07, 1492.16 examples/s]Running tokenizer on dataset:  20%|█▉        | 359000/1801350 [03:51<15:17, 1571.95 examples/s]Running tokenizer on dataset:  20%|█▉        | 359000/1801350 [03:51<15:21, 1565.14 examples/s]Running tokenizer on dataset:  20%|█▉        | 359000/1801350 [03:52<15:41, 1531.33 examples/s]Running tokenizer on dataset:  20%|█▉        | 359000/1801350 [03:52<15:47, 1521.51 examples/s]Running tokenizer on dataset:  20%|█▉        | 360000/1801350 [03:52<15:24, 1559.60 examples/s]Running tokenizer on dataset:  20%|█▉        | 360000/1801350 [03:52<15:31, 1546.61 examples/s]Running tokenizer on dataset:  20%|█▉        | 360000/1801350 [03:52<15:42, 1528.96 examples/s]Running tokenizer on dataset:  20%|█▉        | 360000/1801350 [03:52<16:01, 1499.07 examples/s]Running tokenizer on dataset:  20%|██        | 361000/1801350 [03:53<14:51, 1616.00 examples/s]Running tokenizer on dataset:  20%|██        | 361000/1801350 [03:53<14:53, 1612.40 examples/s]Running tokenizer on dataset:  20%|██        | 361000/1801350 [03:53<15:12, 1579.24 examples/s]Running tokenizer on dataset:  20%|██        | 361000/1801350 [03:53<15:08, 1586.22 examples/s]Running tokenizer on dataset:  20%|██        | 362000/1801350 [03:53<14:11, 1689.85 examples/s]Running tokenizer on dataset:  20%|██        | 362000/1801350 [03:53<14:20, 1673.57 examples/s]Running tokenizer on dataset:  20%|██        | 362000/1801350 [03:53<14:28, 1658.23 examples/s]Running tokenizer on dataset:  20%|██        | 362000/1801350 [03:53<14:19, 1674.01 examples/s]Running tokenizer on dataset:  20%|██        | 363000/1801350 [03:54<14:13, 1686.06 examples/s]Running tokenizer on dataset:  20%|██        | 363000/1801350 [03:54<14:14, 1683.27 examples/s]Running tokenizer on dataset:  20%|██        | 363000/1801350 [03:54<14:18, 1675.85 examples/s]Running tokenizer on dataset:  20%|██        | 363000/1801350 [03:54<14:27, 1658.91 examples/s]Running tokenizer on dataset:  20%|██        | 364000/1801350 [03:55<16:39, 1437.88 examples/s]Running tokenizer on dataset:  20%|██        | 364000/1801350 [03:55<16:44, 1430.82 examples/s]Running tokenizer on dataset:  20%|██        | 364000/1801350 [03:55<16:43, 1432.25 examples/s]Running tokenizer on dataset:  20%|██        | 364000/1801350 [03:55<17:19, 1383.06 examples/s]Running tokenizer on dataset:  20%|██        | 365000/1801350 [03:55<15:42, 1523.78 examples/s]Running tokenizer on dataset:  20%|██        | 365000/1801350 [03:55<15:50, 1510.97 examples/s]Running tokenizer on dataset:  20%|██        | 365000/1801350 [03:55<15:40, 1527.88 examples/s]Running tokenizer on dataset:  20%|██        | 365000/1801350 [03:55<16:10, 1479.96 examples/s]Running tokenizer on dataset:  20%|██        | 366000/1801350 [03:56<15:02, 1590.05 examples/s]Running tokenizer on dataset:  20%|██        | 366000/1801350 [03:56<15:04, 1587.77 examples/s]Running tokenizer on dataset:  20%|██        | 366000/1801350 [03:56<14:51, 1609.84 examples/s]Running tokenizer on dataset:  20%|██        | 366000/1801350 [03:56<15:21, 1557.89 examples/s]Running tokenizer on dataset:  20%|██        | 367000/1801350 [03:57<15:21, 1556.57 examples/s]Running tokenizer on dataset:  20%|██        | 367000/1801350 [03:57<15:02, 1588.89 examples/s]Running tokenizer on dataset:  20%|██        | 367000/1801350 [03:57<15:23, 1552.56 examples/s]Running tokenizer on dataset:  20%|██        | 367000/1801350 [03:57<15:30, 1541.16 examples/s]Running tokenizer on dataset:  20%|██        | 368000/1801350 [03:57<15:48, 1510.87 examples/s]Running tokenizer on dataset:  20%|██        | 368000/1801350 [03:57<15:36, 1530.77 examples/s]Running tokenizer on dataset:  20%|██        | 368000/1801350 [03:57<16:07, 1481.32 examples/s]Running tokenizer on dataset:  20%|██        | 368000/1801350 [03:57<15:57, 1496.75 examples/s]Running tokenizer on dataset:  20%|██        | 369000/1801350 [03:58<15:14, 1565.86 examples/s]Running tokenizer on dataset:  20%|██        | 369000/1801350 [03:58<15:16, 1563.62 examples/s]Running tokenizer on dataset:  20%|██        | 369000/1801350 [03:58<15:11, 1571.28 examples/s]Running tokenizer on dataset:  20%|██        | 369000/1801350 [03:58<15:28, 1543.47 examples/s]Running tokenizer on dataset:  21%|██        | 370000/1801350 [03:58<14:40, 1625.72 examples/s]Running tokenizer on dataset:  21%|██        | 370000/1801350 [03:58<15:01, 1588.44 examples/s]Running tokenizer on dataset:  21%|██        | 370000/1801350 [03:58<15:01, 1587.95 examples/s]Running tokenizer on dataset:  21%|██        | 370000/1801350 [03:59<14:56, 1596.52 examples/s]Running tokenizer on dataset:  21%|██        | 371000/1801350 [03:59<15:05, 1578.98 examples/s]Running tokenizer on dataset:  21%|██        | 371000/1801350 [03:59<15:09, 1573.32 examples/s]Running tokenizer on dataset:  21%|██        | 371000/1801350 [03:59<15:17, 1559.44 examples/s]Running tokenizer on dataset:  21%|██        | 371000/1801350 [03:59<15:12, 1567.97 examples/s]Running tokenizer on dataset:  21%|██        | 372000/1801350 [04:00<15:22, 1550.25 examples/s]Running tokenizer on dataset:  21%|██        | 372000/1801350 [04:00<15:25, 1544.54 examples/s]Running tokenizer on dataset:  21%|██        | 372000/1801350 [04:00<15:27, 1540.88 examples/s]Running tokenizer on dataset:  21%|██        | 372000/1801350 [04:00<15:20, 1552.91 examples/s]Running tokenizer on dataset:  21%|██        | 373000/1801350 [04:00<15:08, 1572.66 examples/s]Running tokenizer on dataset:  21%|██        | 373000/1801350 [04:00<15:05, 1577.33 examples/s]Running tokenizer on dataset:  21%|██        | 373000/1801350 [04:00<15:31, 1533.93 examples/s]Running tokenizer on dataset:  21%|██        | 373000/1801350 [04:01<15:25, 1543.96 examples/s]Running tokenizer on dataset:  21%|██        | 374000/1801350 [04:01<15:11, 1566.03 examples/s]Running tokenizer on dataset:  21%|██        | 374000/1801350 [04:01<15:12, 1563.80 examples/s]Running tokenizer on dataset:  21%|██        | 374000/1801350 [04:01<15:26, 1539.87 examples/s]Running tokenizer on dataset:  21%|██        | 374000/1801350 [04:01<15:05, 1576.32 examples/s]Running tokenizer on dataset:  21%|██        | 375000/1801350 [04:02<14:24, 1649.91 examples/s]Running tokenizer on dataset:  21%|██        | 375000/1801350 [04:02<14:47, 1606.95 examples/s]Running tokenizer on dataset:  21%|██        | 375000/1801350 [04:02<14:42, 1615.62 examples/s]Running tokenizer on dataset:  21%|██        | 375000/1801350 [04:02<14:30, 1638.14 examples/s]Running tokenizer on dataset:  21%|██        | 376000/1801350 [04:02<15:16, 1555.07 examples/s]Running tokenizer on dataset:  21%|██        | 376000/1801350 [04:02<15:09, 1567.80 examples/s]Running tokenizer on dataset:  21%|██        | 376000/1801350 [04:02<15:06, 1572.21 examples/s]Running tokenizer on dataset:  21%|██        | 376000/1801350 [04:02<15:14, 1559.21 examples/s]Running tokenizer on dataset:  21%|██        | 377000/1801350 [04:03<15:22, 1544.72 examples/s]Running tokenizer on dataset:  21%|██        | 377000/1801350 [04:03<15:36, 1521.53 examples/s]Running tokenizer on dataset:  21%|██        | 377000/1801350 [04:03<15:47, 1502.57 examples/s]Running tokenizer on dataset:  21%|██        | 377000/1801350 [04:03<15:34, 1524.67 examples/s]Running tokenizer on dataset:  21%|██        | 378000/1801350 [04:04<15:29, 1531.98 examples/s]Running tokenizer on dataset:  21%|██        | 378000/1801350 [04:04<15:15, 1554.42 examples/s]Running tokenizer on dataset:  21%|██        | 378000/1801350 [04:04<15:26, 1536.86 examples/s]Running tokenizer on dataset:  21%|██        | 378000/1801350 [04:04<15:16, 1553.19 examples/s]Running tokenizer on dataset:  21%|██        | 379000/1801350 [04:04<14:51, 1595.56 examples/s]Running tokenizer on dataset:  21%|██        | 379000/1801350 [04:04<15:01, 1576.96 examples/s]Running tokenizer on dataset:  21%|██        | 379000/1801350 [04:04<15:08, 1566.39 examples/s]Running tokenizer on dataset:  21%|██        | 379000/1801350 [04:04<15:00, 1578.83 examples/s]Running tokenizer on dataset:  21%|██        | 380000/1801350 [04:05<14:29, 1634.36 examples/s]Running tokenizer on dataset:  21%|██        | 380000/1801350 [04:05<14:39, 1616.27 examples/s]Running tokenizer on dataset:  21%|██        | 380000/1801350 [04:05<14:42, 1610.85 examples/s]Running tokenizer on dataset:  21%|██        | 380000/1801350 [04:05<14:38, 1618.51 examples/s]Running tokenizer on dataset:  21%|██        | 381000/1801350 [04:05<14:15, 1659.98 examples/s]Running tokenizer on dataset:  21%|██        | 381000/1801350 [04:05<14:09, 1671.44 examples/s]Running tokenizer on dataset:  21%|██        | 381000/1801350 [04:05<14:18, 1655.11 examples/s]Running tokenizer on dataset:  21%|██        | 381000/1801350 [04:06<14:19, 1651.68 examples/s]Running tokenizer on dataset:  21%|██        | 382000/1801350 [04:06<14:55, 1585.76 examples/s]Running tokenizer on dataset:  21%|██        | 382000/1801350 [04:06<14:41, 1609.61 examples/s]Running tokenizer on dataset:  21%|██        | 382000/1801350 [04:06<14:45, 1603.70 examples/s]Running tokenizer on dataset:  21%|██        | 382000/1801350 [04:06<14:43, 1606.23 examples/s]Running tokenizer on dataset:  21%|██▏       | 383000/1801350 [04:07<15:31, 1522.64 examples/s]Running tokenizer on dataset:  21%|██▏       | 383000/1801350 [04:07<15:21, 1539.44 examples/s]Running tokenizer on dataset:  21%|██▏       | 383000/1801350 [04:07<15:23, 1535.34 examples/s]Running tokenizer on dataset:  21%|██▏       | 383000/1801350 [04:07<15:31, 1522.81 examples/s]Running tokenizer on dataset:  21%|██▏       | 384000/1801350 [04:07<15:20, 1539.04 examples/s]Running tokenizer on dataset:  21%|██▏       | 384000/1801350 [04:07<15:12, 1552.75 examples/s]Running tokenizer on dataset:  21%|██▏       | 384000/1801350 [04:07<15:17, 1544.62 examples/s]Running tokenizer on dataset:  21%|██▏       | 384000/1801350 [04:08<15:24, 1532.89 examples/s]Running tokenizer on dataset:  21%|██▏       | 385000/1801350 [04:08<17:12, 1371.25 examples/s]Running tokenizer on dataset:  21%|██▏       | 385000/1801350 [04:08<17:04, 1382.37 examples/s]Running tokenizer on dataset:  21%|██▏       | 385000/1801350 [04:08<16:50, 1402.00 examples/s]Running tokenizer on dataset:  21%|██▏       | 385000/1801350 [04:08<17:46, 1328.61 examples/s]Running tokenizer on dataset:  21%|██▏       | 386000/1801350 [04:09<16:41, 1413.16 examples/s]Running tokenizer on dataset:  21%|██▏       | 386000/1801350 [04:09<16:33, 1424.57 examples/s]Running tokenizer on dataset:  21%|██▏       | 386000/1801350 [04:09<17:12, 1370.35 examples/s]Running tokenizer on dataset:  21%|██▏       | 386000/1801350 [04:09<16:42, 1412.13 examples/s]Running tokenizer on dataset:  21%|██▏       | 387000/1801350 [04:10<16:01, 1471.23 examples/s]Running tokenizer on dataset:  21%|██▏       | 387000/1801350 [04:10<15:55, 1480.29 examples/s]Running tokenizer on dataset:  21%|██▏       | 387000/1801350 [04:10<16:24, 1436.20 examples/s]Running tokenizer on dataset:  21%|██▏       | 387000/1801350 [04:10<15:59, 1473.38 examples/s]Running tokenizer on dataset:  22%|██▏       | 388000/1801350 [04:10<14:56, 1575.80 examples/s]Running tokenizer on dataset:  22%|██▏       | 388000/1801350 [04:10<15:07, 1557.40 examples/s]Running tokenizer on dataset:  22%|██▏       | 388000/1801350 [04:10<14:55, 1578.62 examples/s]Running tokenizer on dataset:  22%|██▏       | 388000/1801350 [04:10<15:17, 1539.93 examples/s]Running tokenizer on dataset:  22%|██▏       | 389000/1801350 [04:11<15:03, 1563.13 examples/s]Running tokenizer on dataset:  22%|██▏       | 389000/1801350 [04:11<15:13, 1546.09 examples/s]Running tokenizer on dataset:  22%|██▏       | 389000/1801350 [04:11<15:20, 1534.48 examples/s]Running tokenizer on dataset:  22%|██▏       | 389000/1801350 [04:11<15:13, 1545.74 examples/s]Running tokenizer on dataset:  22%|██▏       | 390000/1801350 [04:11<14:36, 1610.17 examples/s]Running tokenizer on dataset:  22%|██▏       | 390000/1801350 [04:11<15:03, 1562.07 examples/s]Running tokenizer on dataset:  22%|██▏       | 390000/1801350 [04:11<14:59, 1569.27 examples/s]Running tokenizer on dataset:  22%|██▏       | 390000/1801350 [04:12<15:03, 1561.80 examples/s]Running tokenizer on dataset:  22%|██▏       | 391000/1801350 [04:12<14:28, 1623.47 examples/s]Running tokenizer on dataset:  22%|██▏       | 391000/1801350 [04:12<14:41, 1600.67 examples/s]Running tokenizer on dataset:  22%|██▏       | 391000/1801350 [04:12<14:43, 1596.43 examples/s]Running tokenizer on dataset:  22%|██▏       | 391000/1801350 [04:12<14:31, 1618.20 examples/s]Running tokenizer on dataset:  22%|██▏       | 392000/1801350 [04:13<15:15, 1540.08 examples/s]Running tokenizer on dataset:  22%|██▏       | 392000/1801350 [04:13<15:13, 1542.67 examples/s]Running tokenizer on dataset:  22%|██▏       | 392000/1801350 [04:13<15:10, 1547.97 examples/s]Running tokenizer on dataset:  22%|██▏       | 392000/1801350 [04:13<15:24, 1524.43 examples/s]Running tokenizer on dataset:  22%|██▏       | 393000/1801350 [04:13<15:15, 1539.17 examples/s]Running tokenizer on dataset:  22%|██▏       | 393000/1801350 [04:13<15:19, 1531.19 examples/s]Running tokenizer on dataset:  22%|██▏       | 393000/1801350 [04:13<15:31, 1512.13 examples/s]Running tokenizer on dataset:  22%|██▏       | 393000/1801350 [04:14<15:27, 1519.20 examples/s]Running tokenizer on dataset:  22%|██▏       | 394000/1801350 [04:14<15:31, 1510.56 examples/s]Running tokenizer on dataset:  22%|██▏       | 394000/1801350 [04:14<15:38, 1500.28 examples/s]Running tokenizer on dataset:  22%|██▏       | 394000/1801350 [04:14<15:25, 1520.09 examples/s]Running tokenizer on dataset:  22%|██▏       | 394000/1801350 [04:14<15:34, 1506.11 examples/s]Running tokenizer on dataset:  22%|██▏       | 395000/1801350 [04:15<15:11, 1542.79 examples/s]Running tokenizer on dataset:  22%|██▏       | 395000/1801350 [04:15<15:17, 1532.50 examples/s]Running tokenizer on dataset:  22%|██▏       | 395000/1801350 [04:15<15:15, 1536.33 examples/s]Running tokenizer on dataset:  22%|██▏       | 395000/1801350 [04:15<15:18, 1530.45 examples/s]Running tokenizer on dataset:  22%|██▏       | 396000/1801350 [04:15<14:44, 1588.18 examples/s]Running tokenizer on dataset:  22%|██▏       | 396000/1801350 [04:15<14:52, 1574.62 examples/s]Running tokenizer on dataset:  22%|██▏       | 396000/1801350 [04:15<14:44, 1588.68 examples/s]Running tokenizer on dataset:  22%|██▏       | 396000/1801350 [04:15<14:50, 1578.11 examples/s]Running tokenizer on dataset:  22%|██▏       | 397000/1801350 [04:16<15:10, 1542.96 examples/s]Running tokenizer on dataset:  22%|██▏       | 397000/1801350 [04:16<15:09, 1543.64 examples/s]Running tokenizer on dataset:  22%|██▏       | 397000/1801350 [04:16<15:07, 1546.93 examples/s]Running tokenizer on dataset:  22%|██▏       | 397000/1801350 [04:16<15:15, 1534.66 examples/s]Running tokenizer on dataset:  22%|██▏       | 398000/1801350 [04:17<15:14, 1534.63 examples/s]Running tokenizer on dataset:  22%|██▏       | 398000/1801350 [04:17<15:20, 1525.38 examples/s]Running tokenizer on dataset:  22%|██▏       | 398000/1801350 [04:17<15:09, 1542.74 examples/s]Running tokenizer on dataset:  22%|██▏       | 398000/1801350 [04:17<15:10, 1540.60 examples/s]Running tokenizer on dataset:  22%|██▏       | 399000/1801350 [04:17<14:31, 1609.43 examples/s]Running tokenizer on dataset:  22%|██▏       | 399000/1801350 [04:17<14:39, 1595.02 examples/s]Running tokenizer on dataset:  22%|██▏       | 399000/1801350 [04:17<14:29, 1612.79 examples/s]Running tokenizer on dataset:  22%|██▏       | 399000/1801350 [04:17<14:28, 1614.89 examples/s]Running tokenizer on dataset:  22%|██▏       | 400000/1801350 [04:18<13:47, 1693.79 examples/s]Running tokenizer on dataset:  22%|██▏       | 400000/1801350 [04:18<14:16, 1636.91 examples/s]Running tokenizer on dataset:  22%|██▏       | 400000/1801350 [04:18<13:56, 1676.04 examples/s]Running tokenizer on dataset:  22%|██▏       | 400000/1801350 [04:18<13:55, 1677.88 examples/s]Running tokenizer on dataset:  22%|██▏       | 401000/1801350 [04:18<14:23, 1621.29 examples/s]Running tokenizer on dataset:  22%|██▏       | 401000/1801350 [04:18<14:41, 1588.12 examples/s]Running tokenizer on dataset:  22%|██▏       | 401000/1801350 [04:18<14:18, 1631.64 examples/s]Running tokenizer on dataset:  22%|██▏       | 401000/1801350 [04:18<14:18, 1630.35 examples/s]Running tokenizer on dataset:  22%|██▏       | 402000/1801350 [04:19<15:03, 1548.58 examples/s]Running tokenizer on dataset:  22%|██▏       | 402000/1801350 [04:19<15:13, 1531.23 examples/s]Running tokenizer on dataset:  22%|██▏       | 402000/1801350 [04:19<15:04, 1547.88 examples/s]Running tokenizer on dataset:  22%|██▏       | 402000/1801350 [04:19<15:10, 1537.12 examples/s]Running tokenizer on dataset:  22%|██▏       | 403000/1801350 [04:20<15:38, 1490.73 examples/s]Running tokenizer on dataset:  22%|██▏       | 403000/1801350 [04:20<15:34, 1496.37 examples/s]Running tokenizer on dataset:  22%|██▏       | 403000/1801350 [04:20<15:33, 1497.69 examples/s]Running tokenizer on dataset:  22%|██▏       | 403000/1801350 [04:20<15:34, 1496.67 examples/s]Running tokenizer on dataset:  22%|██▏       | 404000/1801350 [04:20<15:29, 1502.90 examples/s]Running tokenizer on dataset:  22%|██▏       | 404000/1801350 [04:20<15:30, 1502.10 examples/s]Running tokenizer on dataset:  22%|██▏       | 404000/1801350 [04:21<15:23, 1512.42 examples/s]Running tokenizer on dataset:  22%|██▏       | 404000/1801350 [04:21<15:32, 1497.94 examples/s]Running tokenizer on dataset:  22%|██▏       | 405000/1801350 [04:21<15:04, 1543.99 examples/s]Running tokenizer on dataset:  22%|██▏       | 405000/1801350 [04:21<15:03, 1545.62 examples/s]Running tokenizer on dataset:  22%|██▏       | 405000/1801350 [04:21<15:02, 1547.31 examples/s]Running tokenizer on dataset:  22%|██▏       | 405000/1801350 [04:21<15:04, 1543.90 examples/s]Running tokenizer on dataset:  23%|██▎       | 406000/1801350 [04:22<17:35, 1322.49 examples/s]Running tokenizer on dataset:  23%|██▎       | 406000/1801350 [04:22<18:18, 1269.91 examples/s]Running tokenizer on dataset:  23%|██▎       | 406000/1801350 [04:22<17:36, 1320.76 examples/s]Running tokenizer on dataset:  23%|██▎       | 406000/1801350 [04:22<17:40, 1315.59 examples/s]Running tokenizer on dataset:  23%|██▎       | 407000/1801350 [04:23<16:50, 1380.07 examples/s]Running tokenizer on dataset:  23%|██▎       | 407000/1801350 [04:23<17:16, 1345.38 examples/s]Running tokenizer on dataset:  23%|██▎       | 407000/1801350 [04:23<16:57, 1370.27 examples/s]Running tokenizer on dataset:  23%|██▎       | 407000/1801350 [04:23<17:10, 1352.49 examples/s]Running tokenizer on dataset:  23%|██▎       | 408000/1801350 [04:23<16:39, 1393.90 examples/s]Running tokenizer on dataset:  23%|██▎       | 408000/1801350 [04:24<17:10, 1351.79 examples/s]Running tokenizer on dataset:  23%|██▎       | 408000/1801350 [04:24<16:42, 1389.56 examples/s]Running tokenizer on dataset:  23%|██▎       | 408000/1801350 [04:24<16:57, 1369.18 examples/s]Running tokenizer on dataset:  23%|██▎       | 409000/1801350 [04:24<15:29, 1497.71 examples/s]Running tokenizer on dataset:  23%|██▎       | 409000/1801350 [04:24<15:20, 1512.57 examples/s]Running tokenizer on dataset:  23%|██▎       | 409000/1801350 [04:24<15:50, 1464.44 examples/s]Running tokenizer on dataset:  23%|██▎       | 409000/1801350 [04:24<15:31, 1495.32 examples/s]Running tokenizer on dataset:  23%|██▎       | 410000/1801350 [04:25<15:25, 1503.71 examples/s]Running tokenizer on dataset:  23%|██▎       | 410000/1801350 [04:25<15:30, 1495.89 examples/s]Running tokenizer on dataset:  23%|██▎       | 410000/1801350 [04:25<15:27, 1499.71 examples/s]Running tokenizer on dataset:  23%|██▎       | 410000/1801350 [04:25<15:51, 1461.99 examples/s]Running tokenizer on dataset:  23%|██▎       | 411000/1801350 [04:25<15:07, 1531.82 examples/s]Running tokenizer on dataset:  23%|██▎       | 411000/1801350 [04:25<15:10, 1527.30 examples/s]Running tokenizer on dataset:  23%|██▎       | 411000/1801350 [04:25<15:05, 1534.68 examples/s]Running tokenizer on dataset:  23%|██▎       | 411000/1801350 [04:25<15:07, 1532.34 examples/s]Running tokenizer on dataset:  23%|██▎       | 412000/1801350 [04:26<15:18, 1512.06 examples/s]Running tokenizer on dataset:  23%|██▎       | 412000/1801350 [04:26<15:11, 1524.50 examples/s]Running tokenizer on dataset:  23%|██▎       | 412000/1801350 [04:26<15:16, 1515.15 examples/s]Running tokenizer on dataset:  23%|██▎       | 412000/1801350 [04:26<15:25, 1500.72 examples/s]Running tokenizer on dataset:  23%|██▎       | 413000/1801350 [04:27<16:15, 1422.72 examples/s]Running tokenizer on dataset:  23%|██▎       | 413000/1801350 [04:27<16:10, 1429.88 examples/s]Running tokenizer on dataset:  23%|██▎       | 413000/1801350 [04:27<16:24, 1410.82 examples/s]Running tokenizer on dataset:  23%|██▎       | 413000/1801350 [04:27<16:28, 1404.17 examples/s]Running tokenizer on dataset:  23%|██▎       | 414000/1801350 [04:28<16:28, 1403.54 examples/s]Running tokenizer on dataset:  23%|██▎       | 414000/1801350 [04:28<16:26, 1405.87 examples/s]Running tokenizer on dataset:  23%|██▎       | 414000/1801350 [04:28<16:23, 1410.67 examples/s]Running tokenizer on dataset:  23%|██▎       | 414000/1801350 [04:28<16:27, 1405.23 examples/s]Running tokenizer on dataset:  23%|██▎       | 415000/1801350 [04:28<16:25, 1406.96 examples/s]Running tokenizer on dataset:  23%|██▎       | 415000/1801350 [04:28<16:19, 1414.81 examples/s]Running tokenizer on dataset:  23%|██▎       | 415000/1801350 [04:28<16:17, 1418.23 examples/s]Running tokenizer on dataset:  23%|██▎       | 415000/1801350 [04:28<16:23, 1409.41 examples/s]Running tokenizer on dataset:  23%|██▎       | 416000/1801350 [04:29<15:59, 1444.16 examples/s]Running tokenizer on dataset:  23%|██▎       | 416000/1801350 [04:29<15:43, 1468.27 examples/s]Running tokenizer on dataset:  23%|██▎       | 416000/1801350 [04:29<15:49, 1458.73 examples/s]Running tokenizer on dataset:  23%|██▎       | 416000/1801350 [04:29<15:47, 1461.63 examples/s]Running tokenizer on dataset:  23%|██▎       | 417000/1801350 [04:30<15:49, 1457.28 examples/s]Running tokenizer on dataset:  23%|██▎       | 417000/1801350 [04:30<15:43, 1467.46 examples/s]Running tokenizer on dataset:  23%|██▎       | 417000/1801350 [04:30<15:47, 1461.23 examples/s]Running tokenizer on dataset:  23%|██▎       | 417000/1801350 [04:30<15:52, 1453.80 examples/s]Running tokenizer on dataset:  23%|██▎       | 418000/1801350 [04:30<15:13, 1514.77 examples/s]Running tokenizer on dataset:  23%|██▎       | 418000/1801350 [04:30<15:04, 1529.90 examples/s]Running tokenizer on dataset:  23%|██▎       | 418000/1801350 [04:30<15:06, 1526.24 examples/s]Running tokenizer on dataset:  23%|██▎       | 418000/1801350 [04:30<15:06, 1526.61 examples/s]Running tokenizer on dataset:  23%|██▎       | 419000/1801350 [04:31<15:13, 1512.42 examples/s]Running tokenizer on dataset:  23%|██▎       | 419000/1801350 [04:31<15:17, 1506.64 examples/s]Running tokenizer on dataset:  23%|██▎       | 419000/1801350 [04:31<15:20, 1501.26 examples/s]Running tokenizer on dataset:  23%|██▎       | 419000/1801350 [04:31<15:25, 1494.35 examples/s]Running tokenizer on dataset:  23%|██▎       | 420000/1801350 [04:31<15:05, 1525.34 examples/s]Running tokenizer on dataset:  23%|██▎       | 420000/1801350 [04:32<15:00, 1534.56 examples/s]Running tokenizer on dataset:  23%|██▎       | 420000/1801350 [04:32<15:06, 1523.73 examples/s]Running tokenizer on dataset:  23%|██▎       | 420000/1801350 [04:32<15:07, 1521.40 examples/s]Running tokenizer on dataset:  23%|██▎       | 421000/1801350 [04:32<14:54, 1543.55 examples/s]Running tokenizer on dataset:  23%|██▎       | 421000/1801350 [04:32<14:54, 1543.52 examples/s]Running tokenizer on dataset:  23%|██▎       | 421000/1801350 [04:32<14:56, 1540.01 examples/s]Running tokenizer on dataset:  23%|██▎       | 421000/1801350 [04:32<14:57, 1537.76 examples/s]Running tokenizer on dataset:  23%|██▎       | 422000/1801350 [04:33<15:20, 1498.59 examples/s]Running tokenizer on dataset:  23%|██▎       | 422000/1801350 [04:33<15:16, 1505.11 examples/s]Running tokenizer on dataset:  23%|██▎       | 422000/1801350 [04:33<15:19, 1499.45 examples/s]Running tokenizer on dataset:  23%|██▎       | 422000/1801350 [04:33<15:22, 1494.58 examples/s]Running tokenizer on dataset:  23%|██▎       | 423000/1801350 [04:33<14:45, 1556.34 examples/s]Running tokenizer on dataset:  23%|██▎       | 423000/1801350 [04:33<14:44, 1559.11 examples/s]Running tokenizer on dataset:  23%|██▎       | 423000/1801350 [04:33<14:46, 1554.72 examples/s]Running tokenizer on dataset:  23%|██▎       | 423000/1801350 [04:33<14:46, 1554.65 examples/s]Running tokenizer on dataset:  24%|██▎       | 424000/1801350 [04:34<14:52, 1542.91 examples/s]Running tokenizer on dataset:  24%|██▎       | 424000/1801350 [04:34<14:48, 1549.85 examples/s]Running tokenizer on dataset:  24%|██▎       | 424000/1801350 [04:34<14:54, 1540.01 examples/s]Running tokenizer on dataset:  24%|██▎       | 424000/1801350 [04:34<14:56, 1536.51 examples/s]Running tokenizer on dataset:  24%|██▎       | 425000/1801350 [04:35<14:58, 1531.62 examples/s]Running tokenizer on dataset:  24%|██▎       | 425000/1801350 [04:35<14:55, 1536.46 examples/s]Running tokenizer on dataset:  24%|██▎       | 425000/1801350 [04:35<14:58, 1532.19 examples/s]Running tokenizer on dataset:  24%|██▎       | 425000/1801350 [04:35<15:03, 1524.00 examples/s]Running tokenizer on dataset:  24%|██▎       | 426000/1801350 [04:35<14:42, 1558.43 examples/s]Running tokenizer on dataset:  24%|██▎       | 426000/1801350 [04:35<14:46, 1551.06 examples/s]Running tokenizer on dataset:  24%|██▎       | 426000/1801350 [04:35<14:52, 1540.94 examples/s]Running tokenizer on dataset:  24%|██▎       | 426000/1801350 [04:35<14:44, 1554.89 examples/s]Running tokenizer on dataset:  24%|██▎       | 427000/1801350 [04:36<16:09, 1417.40 examples/s]Running tokenizer on dataset:  24%|██▎       | 427000/1801350 [04:36<16:17, 1405.86 examples/s]Running tokenizer on dataset:  24%|██▎       | 427000/1801350 [04:36<17:02, 1343.73 examples/s]Running tokenizer on dataset:  24%|██▎       | 427000/1801350 [04:36<16:37, 1377.33 examples/s]Running tokenizer on dataset:  24%|██▍       | 428000/1801350 [04:37<15:48, 1447.45 examples/s]Running tokenizer on dataset:  24%|██▍       | 428000/1801350 [04:37<15:50, 1445.21 examples/s]Running tokenizer on dataset:  24%|██▍       | 428000/1801350 [04:37<16:20, 1400.11 examples/s]Running tokenizer on dataset:  24%|██▍       | 428000/1801350 [04:37<16:15, 1408.07 examples/s]Running tokenizer on dataset:  24%|██▍       | 429000/1801350 [04:38<15:16, 1497.44 examples/s]Running tokenizer on dataset:  24%|██▍       | 429000/1801350 [04:38<15:15, 1498.87 examples/s]Running tokenizer on dataset:  24%|██▍       | 429000/1801350 [04:38<15:58, 1432.35 examples/s]Running tokenizer on dataset:  24%|██▍       | 429000/1801350 [04:38<15:30, 1474.10 examples/s]Running tokenizer on dataset:  24%|██▍       | 430000/1801350 [04:38<14:23, 1587.30 examples/s]Running tokenizer on dataset:  24%|██▍       | 430000/1801350 [04:38<14:33, 1569.80 examples/s]Running tokenizer on dataset:  24%|██▍       | 430000/1801350 [04:38<14:59, 1524.67 examples/s]Running tokenizer on dataset:  24%|██▍       | 430000/1801350 [04:38<14:47, 1545.39 examples/s]Running tokenizer on dataset:  24%|██▍       | 431000/1801350 [04:39<14:47, 1543.53 examples/s]Running tokenizer on dataset:  24%|██▍       | 431000/1801350 [04:39<14:52, 1535.43 examples/s]Running tokenizer on dataset:  24%|██▍       | 431000/1801350 [04:39<14:58, 1525.66 examples/s]Running tokenizer on dataset:  24%|██▍       | 431000/1801350 [04:39<14:57, 1526.78 examples/s]Running tokenizer on dataset:  24%|██▍       | 432000/1801350 [04:39<15:16, 1494.17 examples/s]Running tokenizer on dataset:  24%|██▍       | 432000/1801350 [04:40<15:14, 1497.56 examples/s]Running tokenizer on dataset:  24%|██▍       | 432000/1801350 [04:39<15:22, 1484.51 examples/s]Running tokenizer on dataset:  24%|██▍       | 432000/1801350 [04:40<15:20, 1487.59 examples/s]Running tokenizer on dataset:  24%|██▍       | 433000/1801350 [04:40<13:45, 1657.60 examples/s]Running tokenizer on dataset:  24%|██▍       | 433000/1801350 [04:40<13:38, 1672.10 examples/s]Running tokenizer on dataset:  24%|██▍       | 433000/1801350 [04:40<13:53, 1641.56 examples/s]Running tokenizer on dataset:  24%|██▍       | 433000/1801350 [04:40<13:55, 1637.47 examples/s]Running tokenizer on dataset:  24%|██▍       | 434000/1801350 [04:41<14:13, 1602.92 examples/s]Running tokenizer on dataset:  24%|██▍       | 434000/1801350 [04:41<14:13, 1602.25 examples/s]Running tokenizer on dataset:  24%|██▍       | 434000/1801350 [04:41<14:08, 1611.49 examples/s]Running tokenizer on dataset:  24%|██▍       | 434000/1801350 [04:41<14:15, 1597.62 examples/s]Running tokenizer on dataset:  24%|██▍       | 435000/1801350 [04:41<14:54, 1528.04 examples/s]Running tokenizer on dataset:  24%|██▍       | 435000/1801350 [04:41<14:49, 1535.57 examples/s]Running tokenizer on dataset:  24%|██▍       | 435000/1801350 [04:41<14:56, 1524.46 examples/s]Running tokenizer on dataset:  24%|██▍       | 435000/1801350 [04:41<14:56, 1524.05 examples/s]Running tokenizer on dataset:  24%|██▍       | 436000/1801350 [04:42<14:47, 1539.06 examples/s]Running tokenizer on dataset:  24%|██▍       | 436000/1801350 [04:42<14:50, 1532.43 examples/s]Running tokenizer on dataset:  24%|██▍       | 436000/1801350 [04:42<14:46, 1539.73 examples/s]Running tokenizer on dataset:  24%|██▍       | 436000/1801350 [04:42<14:50, 1533.15 examples/s]Running tokenizer on dataset:  24%|██▍       | 437000/1801350 [04:43<14:34, 1559.70 examples/s]Running tokenizer on dataset:  24%|██▍       | 437000/1801350 [04:43<14:38, 1552.99 examples/s]Running tokenizer on dataset:  24%|██▍       | 437000/1801350 [04:43<14:35, 1557.96 examples/s]Running tokenizer on dataset:  24%|██▍       | 437000/1801350 [04:43<14:38, 1552.75 examples/s]Running tokenizer on dataset:  24%|██▍       | 438000/1801350 [04:43<14:28, 1570.05 examples/s]Running tokenizer on dataset:  24%|██▍       | 438000/1801350 [04:43<14:30, 1566.81 examples/s]Running tokenizer on dataset:  24%|██▍       | 438000/1801350 [04:43<14:28, 1569.92 examples/s]Running tokenizer on dataset:  24%|██▍       | 438000/1801350 [04:43<14:28, 1569.17 examples/s]Running tokenizer on dataset:  24%|██▍       | 439000/1801350 [04:44<14:38, 1551.19 examples/s]Running tokenizer on dataset:  24%|██▍       | 439000/1801350 [04:44<14:39, 1548.85 examples/s]Running tokenizer on dataset:  24%|██▍       | 439000/1801350 [04:44<14:38, 1549.95 examples/s]Running tokenizer on dataset:  24%|██▍       | 439000/1801350 [04:44<14:46, 1536.03 examples/s]Running tokenizer on dataset:  24%|██▍       | 440000/1801350 [04:45<15:00, 1512.12 examples/s]Running tokenizer on dataset:  24%|██▍       | 440000/1801350 [04:45<15:01, 1510.84 examples/s]Running tokenizer on dataset:  24%|██▍       | 440000/1801350 [04:45<15:07, 1500.41 examples/s]Running tokenizer on dataset:  24%|██▍       | 440000/1801350 [04:45<14:49, 1531.32 examples/s]Running tokenizer on dataset:  24%|██▍       | 441000/1801350 [04:45<14:46, 1534.28 examples/s]Running tokenizer on dataset:  24%|██▍       | 441000/1801350 [04:45<14:48, 1531.29 examples/s]Running tokenizer on dataset:  24%|██▍       | 441000/1801350 [04:45<14:47, 1532.58 examples/s]Running tokenizer on dataset:  24%|██▍       | 441000/1801350 [04:45<14:41, 1542.54 examples/s]Running tokenizer on dataset:  25%|██▍       | 442000/1801350 [04:46<14:13, 1593.33 examples/s]Running tokenizer on dataset:  25%|██▍       | 442000/1801350 [04:46<14:22, 1575.82 examples/s]Running tokenizer on dataset:  25%|██▍       | 442000/1801350 [04:46<14:27, 1566.37 examples/s]Running tokenizer on dataset:  25%|██▍       | 442000/1801350 [04:46<14:22, 1575.76 examples/s]Running tokenizer on dataset:  25%|██▍       | 443000/1801350 [04:46<14:29, 1562.51 examples/s]Running tokenizer on dataset:  25%|██▍       | 443000/1801350 [04:46<14:34, 1553.79 examples/s]Running tokenizer on dataset:  25%|██▍       | 443000/1801350 [04:47<14:46, 1531.90 examples/s]Running tokenizer on dataset:  25%|██▍       | 443000/1801350 [04:47<14:37, 1547.22 examples/s]Running tokenizer on dataset:  25%|██▍       | 444000/1801350 [04:47<13:58, 1618.38 examples/s]Running tokenizer on dataset:  25%|██▍       | 444000/1801350 [04:47<13:49, 1635.42 examples/s]Running tokenizer on dataset:  25%|██▍       | 444000/1801350 [04:47<14:04, 1607.79 examples/s]Running tokenizer on dataset:  25%|██▍       | 444000/1801350 [04:47<14:05, 1604.78 examples/s]Running tokenizer on dataset:  25%|██▍       | 445000/1801350 [04:48<14:52, 1519.82 examples/s]Running tokenizer on dataset:  25%|██▍       | 445000/1801350 [04:48<14:44, 1533.05 examples/s]Running tokenizer on dataset:  25%|██▍       | 445000/1801350 [04:48<14:55, 1514.99 examples/s]Running tokenizer on dataset:  25%|██▍       | 445000/1801350 [04:48<14:43, 1535.60 examples/s]Running tokenizer on dataset:  25%|██▍       | 446000/1801350 [04:48<14:52, 1519.34 examples/s]Running tokenizer on dataset:  25%|██▍       | 446000/1801350 [04:48<14:58, 1507.97 examples/s]Running tokenizer on dataset:  25%|██▍       | 446000/1801350 [04:48<15:10, 1489.14 examples/s]Running tokenizer on dataset:  25%|██▍       | 446000/1801350 [04:48<14:50, 1521.74 examples/s]Running tokenizer on dataset:  25%|██▍       | 447000/1801350 [04:49<15:06, 1494.41 examples/s]Running tokenizer on dataset:  25%|██▍       | 447000/1801350 [04:49<15:10, 1486.76 examples/s]Running tokenizer on dataset:  25%|██▍       | 447000/1801350 [04:49<15:06, 1493.58 examples/s]Running tokenizer on dataset:  25%|██▍       | 447000/1801350 [04:49<14:47, 1526.08 examples/s]Running tokenizer on dataset:  25%|██▍       | 448000/1801350 [04:50<16:28, 1368.83 examples/s]Running tokenizer on dataset:  25%|██▍       | 448000/1801350 [04:50<16:53, 1335.24 examples/s]Running tokenizer on dataset:  25%|██▍       | 448000/1801350 [04:50<16:53, 1335.13 examples/s]Running tokenizer on dataset:  25%|██▍       | 448000/1801350 [04:50<17:09, 1314.01 examples/s]Running tokenizer on dataset:  25%|██▍       | 449000/1801350 [04:51<15:40, 1437.32 examples/s]Running tokenizer on dataset:  25%|██▍       | 449000/1801350 [04:51<15:30, 1453.19 examples/s]Running tokenizer on dataset:  25%|██▍       | 449000/1801350 [04:51<15:47, 1427.23 examples/s]Running tokenizer on dataset:  25%|██▍       | 449000/1801350 [04:51<16:07, 1398.24 examples/s]Running tokenizer on dataset:  25%|██▍       | 450000/1801350 [04:51<15:35, 1444.41 examples/s]Running tokenizer on dataset:  25%|██▍       | 450000/1801350 [04:51<15:29, 1453.98 examples/s]Running tokenizer on dataset:  25%|██▍       | 450000/1801350 [04:51<15:46, 1427.21 examples/s]Running tokenizer on dataset:  25%|██▍       | 450000/1801350 [04:51<16:01, 1405.24 examples/s]Running tokenizer on dataset:  25%|██▌       | 451000/1801350 [04:52<14:37, 1538.40 examples/s]Running tokenizer on dataset:  25%|██▌       | 451000/1801350 [04:52<14:45, 1524.33 examples/s]Running tokenizer on dataset:  25%|██▌       | 451000/1801350 [04:52<14:48, 1519.42 examples/s]Running tokenizer on dataset:  25%|██▌       | 451000/1801350 [04:52<14:57, 1504.91 examples/s]Running tokenizer on dataset:  25%|██▌       | 452000/1801350 [04:53<14:49, 1516.86 examples/s]Running tokenizer on dataset:  25%|██▌       | 452000/1801350 [04:53<14:47, 1520.56 examples/s]Running tokenizer on dataset:  25%|██▌       | 452000/1801350 [04:53<14:52, 1511.96 examples/s]Running tokenizer on dataset:  25%|██▌       | 452000/1801350 [04:53<15:09, 1484.23 examples/s]Running tokenizer on dataset:  25%|██▌       | 453000/1801350 [04:53<14:51, 1512.22 examples/s]Running tokenizer on dataset:  25%|██▌       | 453000/1801350 [04:53<14:55, 1504.93 examples/s]Running tokenizer on dataset:  25%|██▌       | 453000/1801350 [04:53<14:57, 1502.90 examples/s]Running tokenizer on dataset:  25%|██▌       | 453000/1801350 [04:53<15:06, 1488.13 examples/s]Running tokenizer on dataset:  25%|██▌       | 454000/1801350 [04:54<14:51, 1512.05 examples/s]Running tokenizer on dataset:  25%|██▌       | 454000/1801350 [04:54<14:56, 1503.70 examples/s]Running tokenizer on dataset:  25%|██▌       | 454000/1801350 [04:54<14:53, 1507.30 examples/s]Running tokenizer on dataset:  25%|██▌       | 454000/1801350 [04:54<15:00, 1495.40 examples/s]Running tokenizer on dataset:  25%|██▌       | 455000/1801350 [04:55<14:54, 1505.01 examples/s]Running tokenizer on dataset:  25%|██▌       | 455000/1801350 [04:55<14:53, 1506.77 examples/s]Running tokenizer on dataset:  25%|██▌       | 455000/1801350 [04:55<14:58, 1498.16 examples/s]Running tokenizer on dataset:  25%|██▌       | 455000/1801350 [04:55<15:05, 1486.09 examples/s]Running tokenizer on dataset:  25%|██▌       | 456000/1801350 [04:55<14:52, 1507.97 examples/s]Running tokenizer on dataset:  25%|██▌       | 456000/1801350 [04:55<14:50, 1510.05 examples/s]Running tokenizer on dataset:  25%|██▌       | 456000/1801350 [04:55<15:09, 1479.74 examples/s]Running tokenizer on dataset:  25%|██▌       | 456000/1801350 [04:55<14:56, 1500.83 examples/s]Running tokenizer on dataset:  25%|██▌       | 457000/1801350 [04:56<13:43, 1631.72 examples/s]Running tokenizer on dataset:  25%|██▌       | 457000/1801350 [04:56<13:56, 1606.57 examples/s]Running tokenizer on dataset:  25%|██▌       | 457000/1801350 [04:56<14:07, 1586.46 examples/s]Running tokenizer on dataset:  25%|██▌       | 457000/1801350 [04:56<13:51, 1617.52 examples/s]Running tokenizer on dataset:  25%|██▌       | 458000/1801350 [04:56<13:49, 1619.07 examples/s]Running tokenizer on dataset:  25%|██▌       | 458000/1801350 [04:56<13:53, 1611.51 examples/s]Running tokenizer on dataset:  25%|██▌       | 458000/1801350 [04:56<13:53, 1612.13 examples/s]Running tokenizer on dataset:  25%|██▌       | 458000/1801350 [04:57<13:51, 1615.03 examples/s]Running tokenizer on dataset:  25%|██▌       | 459000/1801350 [04:57<14:11, 1577.35 examples/s]Running tokenizer on dataset:  25%|██▌       | 459000/1801350 [04:57<14:13, 1572.19 examples/s]Running tokenizer on dataset:  25%|██▌       | 459000/1801350 [04:57<14:19, 1561.73 examples/s]Running tokenizer on dataset:  25%|██▌       | 459000/1801350 [04:57<14:11, 1576.21 examples/s]Running tokenizer on dataset:  26%|██▌       | 460000/1801350 [04:58<14:05, 1587.28 examples/s]Running tokenizer on dataset:  26%|██▌       | 460000/1801350 [04:58<14:06, 1584.41 examples/s]Running tokenizer on dataset:  26%|██▌       | 460000/1801350 [04:58<14:03, 1589.81 examples/s]Running tokenizer on dataset:  26%|██▌       | 460000/1801350 [04:58<14:04, 1588.28 examples/s]Running tokenizer on dataset:  26%|██▌       | 461000/1801350 [04:58<14:11, 1573.90 examples/s]Running tokenizer on dataset:  26%|██▌       | 461000/1801350 [04:58<14:16, 1564.87 examples/s]Running tokenizer on dataset:  26%|██▌       | 461000/1801350 [04:58<14:24, 1551.24 examples/s]Running tokenizer on dataset:  26%|██▌       | 461000/1801350 [04:58<14:14, 1568.60 examples/s]Running tokenizer on dataset:  26%|██▌       | 462000/1801350 [04:59<14:16, 1564.58 examples/s]Running tokenizer on dataset:  26%|██▌       | 462000/1801350 [04:59<14:25, 1547.24 examples/s]Running tokenizer on dataset:  26%|██▌       | 462000/1801350 [04:59<14:26, 1545.52 examples/s]Running tokenizer on dataset:  26%|██▌       | 462000/1801350 [04:59<14:20, 1555.83 examples/s]Running tokenizer on dataset:  26%|██▌       | 463000/1801350 [05:00<14:35, 1528.47 examples/s]Running tokenizer on dataset:  26%|██▌       | 463000/1801350 [05:00<14:34, 1529.89 examples/s]Running tokenizer on dataset:  26%|██▌       | 463000/1801350 [05:00<14:39, 1521.10 examples/s]Running tokenizer on dataset:  26%|██▌       | 463000/1801350 [05:00<14:09, 1575.44 examples/s]Running tokenizer on dataset:  26%|██▌       | 464000/1801350 [05:00<14:37, 1523.93 examples/s]Running tokenizer on dataset:  26%|██▌       | 464000/1801350 [05:00<14:38, 1521.67 examples/s]Running tokenizer on dataset:  26%|██▌       | 464000/1801350 [05:00<14:39, 1519.99 examples/s]Running tokenizer on dataset:  26%|██▌       | 464000/1801350 [05:00<14:43, 1513.15 examples/s]Running tokenizer on dataset:  26%|██▌       | 465000/1801350 [05:01<14:14, 1563.16 examples/s]Running tokenizer on dataset:  26%|██▌       | 465000/1801350 [05:01<14:17, 1558.93 examples/s]Running tokenizer on dataset:  26%|██▌       | 465000/1801350 [05:01<14:16, 1559.93 examples/s]Running tokenizer on dataset:  26%|██▌       | 465000/1801350 [05:01<14:05, 1581.01 examples/s]Running tokenizer on dataset:  26%|██▌       | 466000/1801350 [05:02<14:06, 1578.12 examples/s]Running tokenizer on dataset:  26%|██▌       | 466000/1801350 [05:02<14:10, 1569.60 examples/s]Running tokenizer on dataset:  26%|██▌       | 466000/1801350 [05:02<14:10, 1569.30 examples/s]Running tokenizer on dataset:  26%|██▌       | 466000/1801350 [05:02<13:50, 1607.29 examples/s]Running tokenizer on dataset:  26%|██▌       | 467000/1801350 [05:02<14:11, 1567.90 examples/s]Running tokenizer on dataset:  26%|██▌       | 467000/1801350 [05:02<14:13, 1564.26 examples/s]Running tokenizer on dataset:  26%|██▌       | 467000/1801350 [05:02<14:00, 1587.86 examples/s]Running tokenizer on dataset:  26%|██▌       | 467000/1801350 [05:02<14:19, 1553.18 examples/s]Running tokenizer on dataset:  26%|██▌       | 468000/1801350 [05:03<14:12, 1563.51 examples/s]Running tokenizer on dataset:  26%|██▌       | 468000/1801350 [05:03<14:13, 1561.85 examples/s]Running tokenizer on dataset:  26%|██▌       | 468000/1801350 [05:03<14:04, 1578.82 examples/s]Running tokenizer on dataset:  26%|██▌       | 468000/1801350 [05:03<14:18, 1552.84 examples/s]Running tokenizer on dataset:  26%|██▌       | 469000/1801350 [05:04<16:05, 1379.89 examples/s]Running tokenizer on dataset:  26%|██▌       | 469000/1801350 [05:04<16:16, 1363.92 examples/s]Running tokenizer on dataset:  26%|██▌       | 469000/1801350 [05:04<16:18, 1362.02 examples/s]Running tokenizer on dataset:  26%|██▌       | 469000/1801350 [05:04<16:17, 1362.87 examples/s]Running tokenizer on dataset:  26%|██▌       | 470000/1801350 [05:04<15:43, 1411.18 examples/s]Running tokenizer on dataset:  26%|██▌       | 470000/1801350 [05:04<15:50, 1400.65 examples/s]Running tokenizer on dataset:  26%|██▌       | 470000/1801350 [05:04<15:50, 1400.34 examples/s]Running tokenizer on dataset:  26%|██▌       | 470000/1801350 [05:04<15:54, 1394.82 examples/s]Running tokenizer on dataset:  26%|██▌       | 471000/1801350 [05:05<14:59, 1479.72 examples/s]Running tokenizer on dataset:  26%|██▌       | 471000/1801350 [05:05<15:00, 1477.85 examples/s]Running tokenizer on dataset:  26%|██▌       | 471000/1801350 [05:05<15:00, 1476.71 examples/s]Running tokenizer on dataset:  26%|██▌       | 471000/1801350 [05:05<15:01, 1475.08 examples/s]Running tokenizer on dataset:  26%|██▌       | 472000/1801350 [05:06<14:50, 1492.04 examples/s]Running tokenizer on dataset:  26%|██▌       | 472000/1801350 [05:06<14:51, 1491.89 examples/s]Running tokenizer on dataset:  26%|██▌       | 472000/1801350 [05:06<14:56, 1482.25 examples/s]Running tokenizer on dataset:  26%|██▌       | 472000/1801350 [05:06<14:59, 1478.28 examples/s]Running tokenizer on dataset:  26%|██▋       | 473000/1801350 [05:06<14:33, 1520.35 examples/s]Running tokenizer on dataset:  26%|██▋       | 473000/1801350 [05:06<14:37, 1513.10 examples/s]Running tokenizer on dataset:  26%|██▋       | 473000/1801350 [05:06<14:41, 1507.33 examples/s]Running tokenizer on dataset:  26%|██▋       | 473000/1801350 [05:06<14:42, 1505.08 examples/s]Running tokenizer on dataset:  26%|██▋       | 474000/1801350 [05:07<14:36, 1515.14 examples/s]Running tokenizer on dataset:  26%|██▋       | 474000/1801350 [05:07<14:37, 1512.21 examples/s]Running tokenizer on dataset:  26%|██▋       | 474000/1801350 [05:07<14:39, 1509.26 examples/s]Running tokenizer on dataset:  26%|██▋       | 474000/1801350 [05:07<14:40, 1506.72 examples/s]Running tokenizer on dataset:  26%|██▋       | 475000/1801350 [05:08<14:05, 1569.24 examples/s]Running tokenizer on dataset:  26%|██▋       | 475000/1801350 [05:08<14:07, 1565.75 examples/s]Running tokenizer on dataset:  26%|██▋       | 475000/1801350 [05:08<14:07, 1565.61 examples/s]Running tokenizer on dataset:  26%|██▋       | 475000/1801350 [05:08<14:22, 1538.62 examples/s]Running tokenizer on dataset:  26%|██▋       | 476000/1801350 [05:08<12:56, 1705.99 examples/s]Running tokenizer on dataset:  26%|██▋       | 476000/1801350 [05:08<13:08, 1679.88 examples/s]Running tokenizer on dataset:  26%|██▋       | 476000/1801350 [05:08<13:16, 1664.20 examples/s]Running tokenizer on dataset:  26%|██▋       | 476000/1801350 [05:08<13:11, 1674.91 examples/s]Running tokenizer on dataset:  26%|██▋       | 477000/1801350 [05:09<14:14, 1549.80 examples/s]Running tokenizer on dataset:  26%|██▋       | 477000/1801350 [05:09<14:21, 1536.70 examples/s]Running tokenizer on dataset:  26%|██▋       | 477000/1801350 [05:09<14:14, 1550.50 examples/s]Running tokenizer on dataset:  26%|██▋       | 477000/1801350 [05:09<14:18, 1543.52 examples/s]Running tokenizer on dataset:  27%|██▋       | 478000/1801350 [05:09<14:00, 1574.58 examples/s]Running tokenizer on dataset:  27%|██▋       | 478000/1801350 [05:09<14:08, 1559.05 examples/s]Running tokenizer on dataset:  27%|██▋       | 478000/1801350 [05:10<14:05, 1565.75 examples/s]Running tokenizer on dataset:  27%|██▋       | 478000/1801350 [05:10<14:14, 1549.46 examples/s]Running tokenizer on dataset:  27%|██▋       | 479000/1801350 [05:10<13:20, 1651.10 examples/s]Running tokenizer on dataset:  27%|██▋       | 479000/1801350 [05:10<13:32, 1627.74 examples/s]Running tokenizer on dataset:  27%|██▋       | 479000/1801350 [05:10<13:32, 1626.84 examples/s]Running tokenizer on dataset:  27%|██▋       | 479000/1801350 [05:10<13:38, 1615.58 examples/s]Running tokenizer on dataset:  27%|██▋       | 480000/1801350 [05:11<13:44, 1602.53 examples/s]Running tokenizer on dataset:  27%|██▋       | 480000/1801350 [05:11<13:45, 1601.50 examples/s]Running tokenizer on dataset:  27%|██▋       | 480000/1801350 [05:11<13:46, 1598.36 examples/s]Running tokenizer on dataset:  27%|██▋       | 480000/1801350 [05:11<13:43, 1605.26 examples/s]Running tokenizer on dataset:  27%|██▋       | 481000/1801350 [05:11<13:46, 1598.34 examples/s]Running tokenizer on dataset:  27%|██▋       | 481000/1801350 [05:11<13:46, 1598.14 examples/s]Running tokenizer on dataset:  27%|██▋       | 481000/1801350 [05:11<13:41, 1607.25 examples/s]Running tokenizer on dataset:  27%|██▋       | 481000/1801350 [05:11<13:49, 1592.70 examples/s]Running tokenizer on dataset:  27%|██▋       | 482000/1801350 [05:12<14:02, 1566.32 examples/s]Running tokenizer on dataset:  27%|██▋       | 482000/1801350 [05:12<14:01, 1567.73 examples/s]Running tokenizer on dataset:  27%|██▋       | 482000/1801350 [05:12<14:01, 1567.04 examples/s]Running tokenizer on dataset:  27%|██▋       | 482000/1801350 [05:12<14:08, 1554.41 examples/s]Running tokenizer on dataset:  27%|██▋       | 483000/1801350 [05:13<13:47, 1592.72 examples/s]Running tokenizer on dataset:  27%|██▋       | 483000/1801350 [05:13<13:53, 1581.21 examples/s]Running tokenizer on dataset:  27%|██▋       | 483000/1801350 [05:13<13:52, 1584.17 examples/s]Running tokenizer on dataset:  27%|██▋       | 483000/1801350 [05:13<13:57, 1574.86 examples/s]Running tokenizer on dataset:  27%|██▋       | 484000/1801350 [05:13<14:04, 1559.64 examples/s]Running tokenizer on dataset:  27%|██▋       | 484000/1801350 [05:13<14:10, 1549.55 examples/s]Running tokenizer on dataset:  27%|██▋       | 484000/1801350 [05:13<14:10, 1548.26 examples/s]Running tokenizer on dataset:  27%|██▋       | 484000/1801350 [05:13<14:14, 1541.74 examples/s]Running tokenizer on dataset:  27%|██▋       | 485000/1801350 [05:14<13:17, 1651.49 examples/s]Running tokenizer on dataset:  27%|██▋       | 485000/1801350 [05:14<13:32, 1619.30 examples/s]Running tokenizer on dataset:  27%|██▋       | 485000/1801350 [05:14<13:28, 1628.80 examples/s]Running tokenizer on dataset:  27%|██▋       | 485000/1801350 [05:14<13:38, 1609.10 examples/s]Running tokenizer on dataset:  27%|██▋       | 486000/1801350 [05:14<13:15, 1653.81 examples/s]Running tokenizer on dataset:  27%|██▋       | 486000/1801350 [05:14<13:26, 1631.11 examples/s]Running tokenizer on dataset:  27%|██▋       | 486000/1801350 [05:14<13:18, 1646.57 examples/s]Running tokenizer on dataset:  27%|██▋       | 486000/1801350 [05:14<13:18, 1647.38 examples/s]Running tokenizer on dataset:  27%|██▋       | 487000/1801350 [05:15<13:54, 1575.21 examples/s]Running tokenizer on dataset:  27%|██▋       | 487000/1801350 [05:15<13:55, 1572.44 examples/s]Running tokenizer on dataset:  27%|██▋       | 487000/1801350 [05:15<13:51, 1581.27 examples/s]Running tokenizer on dataset:  27%|██▋       | 487000/1801350 [05:15<13:50, 1582.49 examples/s]Running tokenizer on dataset:  27%|██▋       | 488000/1801350 [05:16<13:35, 1609.79 examples/s]Running tokenizer on dataset:  27%|██▋       | 488000/1801350 [05:16<13:42, 1596.50 examples/s]Running tokenizer on dataset:  27%|██▋       | 488000/1801350 [05:16<13:50, 1581.91 examples/s]Running tokenizer on dataset:  27%|██▋       | 488000/1801350 [05:16<13:54, 1574.11 examples/s]Running tokenizer on dataset:  27%|██▋       | 489000/1801350 [05:16<13:46, 1588.04 examples/s]Running tokenizer on dataset:  27%|██▋       | 489000/1801350 [05:16<13:22, 1634.45 examples/s]Running tokenizer on dataset:  27%|██▋       | 489000/1801350 [05:16<14:03, 1555.76 examples/s]Running tokenizer on dataset:  27%|██▋       | 489000/1801350 [05:16<13:55, 1570.81 examples/s]Running tokenizer on dataset:  27%|██▋       | 490000/1801350 [05:17<16:10, 1350.72 examples/s]Running tokenizer on dataset:  27%|██▋       | 490000/1801350 [05:17<16:16, 1343.16 examples/s]Running tokenizer on dataset:  27%|██▋       | 490000/1801350 [05:17<16:09, 1352.78 examples/s]Running tokenizer on dataset:  27%|██▋       | 490000/1801350 [05:18<16:52, 1294.66 examples/s]Running tokenizer on dataset:  27%|██▋       | 491000/1801350 [05:18<15:37, 1397.87 examples/s]Running tokenizer on dataset:  27%|██▋       | 491000/1801350 [05:18<15:29, 1409.02 examples/s]Running tokenizer on dataset:  27%|██▋       | 491000/1801350 [05:18<15:39, 1394.73 examples/s]Running tokenizer on dataset:  27%|██▋       | 491000/1801350 [05:18<16:01, 1362.57 examples/s]Running tokenizer on dataset:  27%|██▋       | 492000/1801350 [05:19<15:00, 1454.01 examples/s]Running tokenizer on dataset:  27%|██▋       | 492000/1801350 [05:19<14:57, 1459.57 examples/s]Running tokenizer on dataset:  27%|██▋       | 492000/1801350 [05:19<15:12, 1434.30 examples/s]Running tokenizer on dataset:  27%|██▋       | 492000/1801350 [05:19<15:18, 1425.12 examples/s]Running tokenizer on dataset:  27%|██▋       | 493000/1801350 [05:19<14:41, 1484.43 examples/s]Running tokenizer on dataset:  27%|██▋       | 493000/1801350 [05:19<14:38, 1489.68 examples/s]Running tokenizer on dataset:  27%|██▋       | 493000/1801350 [05:19<14:38, 1488.75 examples/s]Running tokenizer on dataset:  27%|██▋       | 493000/1801350 [05:19<14:54, 1462.63 examples/s]Running tokenizer on dataset:  27%|██▋       | 494000/1801350 [05:20<14:28, 1505.65 examples/s]Running tokenizer on dataset:  27%|██▋       | 494000/1801350 [05:20<14:24, 1512.48 examples/s]Running tokenizer on dataset:  27%|██▋       | 494000/1801350 [05:20<14:30, 1501.61 examples/s]Running tokenizer on dataset:  27%|██▋       | 494000/1801350 [05:20<14:31, 1500.34 examples/s]Running tokenizer on dataset:  27%|██▋       | 495000/1801350 [05:20<13:28, 1615.03 examples/s]Running tokenizer on dataset:  27%|██▋       | 495000/1801350 [05:21<13:44, 1583.52 examples/s]Running tokenizer on dataset:  27%|██▋       | 495000/1801350 [05:20<13:47, 1579.62 examples/s]Running tokenizer on dataset:  27%|██▋       | 495000/1801350 [05:21<13:50, 1573.88 examples/s]Running tokenizer on dataset:  28%|██▊       | 496000/1801350 [05:21<13:33, 1604.41 examples/s]Running tokenizer on dataset:  28%|██▊       | 496000/1801350 [05:21<13:44, 1583.10 examples/s]Running tokenizer on dataset:  28%|██▊       | 496000/1801350 [05:21<13:57, 1559.21 examples/s]Running tokenizer on dataset:  28%|██▊       | 496000/1801350 [05:21<13:47, 1577.78 examples/s]Running tokenizer on dataset:  28%|██▊       | 497000/1801350 [05:22<13:38, 1594.02 examples/s]Running tokenizer on dataset:  28%|██▊       | 497000/1801350 [05:22<13:48, 1574.10 examples/s]Running tokenizer on dataset:  28%|██▊       | 497000/1801350 [05:22<13:38, 1592.68 examples/s]Running tokenizer on dataset:  28%|██▊       | 497000/1801350 [05:22<13:46, 1578.64 examples/s]Running tokenizer on dataset:  28%|██▊       | 498000/1801350 [05:22<13:25, 1618.30 examples/s]Running tokenizer on dataset:  28%|██▊       | 498000/1801350 [05:22<13:20, 1629.18 examples/s]Running tokenizer on dataset:  28%|██▊       | 498000/1801350 [05:22<13:28, 1612.93 examples/s]Running tokenizer on dataset:  28%|██▊       | 498000/1801350 [05:22<13:25, 1618.29 examples/s]Running tokenizer on dataset:  28%|██▊       | 499000/1801350 [05:23<13:28, 1610.38 examples/s]Running tokenizer on dataset:  28%|██▊       | 499000/1801350 [05:23<13:23, 1620.74 examples/s]Running tokenizer on dataset:  28%|██▊       | 499000/1801350 [05:23<13:31, 1604.91 examples/s]Running tokenizer on dataset:  28%|██▊       | 499000/1801350 [05:23<13:29, 1608.66 examples/s]Running tokenizer on dataset:  28%|██▊       | 500000/1801350 [05:24<13:01, 1665.03 examples/s]Running tokenizer on dataset:  28%|██▊       | 500000/1801350 [05:24<13:07, 1652.87 examples/s]Running tokenizer on dataset:  28%|██▊       | 500000/1801350 [05:24<13:06, 1655.18 examples/s]Running tokenizer on dataset:  28%|██▊       | 500000/1801350 [05:24<13:07, 1652.21 examples/s]Running tokenizer on dataset:  28%|██▊       | 501000/1801350 [05:24<13:02, 1661.67 examples/s]Running tokenizer on dataset:  28%|██▊       | 501000/1801350 [05:24<13:01, 1664.48 examples/s]Running tokenizer on dataset:  28%|██▊       | 501000/1801350 [05:24<13:03, 1660.25 examples/s]Running tokenizer on dataset:  28%|██▊       | 501000/1801350 [05:24<13:00, 1666.25 examples/s]Running tokenizer on dataset:  28%|██▊       | 502000/1801350 [05:25<13:39, 1585.20 examples/s]Running tokenizer on dataset:  28%|██▊       | 502000/1801350 [05:25<13:38, 1587.26 examples/s]Running tokenizer on dataset:  28%|██▊       | 502000/1801350 [05:25<13:39, 1585.15 examples/s]Running tokenizer on dataset:  28%|██▊       | 502000/1801350 [05:25<13:38, 1587.31 examples/s]Running tokenizer on dataset:  28%|██▊       | 503000/1801350 [05:25<13:46, 1570.84 examples/s]Running tokenizer on dataset:  28%|██▊       | 503000/1801350 [05:26<13:50, 1564.11 examples/s]Running tokenizer on dataset:  28%|██▊       | 503000/1801350 [05:25<13:49, 1565.43 examples/s]Running tokenizer on dataset:  28%|██▊       | 503000/1801350 [05:26<13:49, 1565.35 examples/s]Running tokenizer on dataset:  28%|██▊       | 504000/1801350 [05:26<13:59, 1546.10 examples/s]Running tokenizer on dataset:  28%|██▊       | 504000/1801350 [05:26<14:05, 1534.28 examples/s]Running tokenizer on dataset:  28%|██▊       | 504000/1801350 [05:26<14:06, 1533.28 examples/s]Running tokenizer on dataset:  28%|██▊       | 504000/1801350 [05:26<13:59, 1546.26 examples/s]Running tokenizer on dataset:  28%|██▊       | 505000/1801350 [05:27<13:50, 1561.79 examples/s]Running tokenizer on dataset:  28%|██▊       | 505000/1801350 [05:27<13:52, 1557.27 examples/s]Running tokenizer on dataset:  28%|██▊       | 505000/1801350 [05:27<13:56, 1550.02 examples/s]Running tokenizer on dataset:  28%|██▊       | 505000/1801350 [05:27<13:50, 1561.63 examples/s]Running tokenizer on dataset:  28%|██▊       | 506000/1801350 [05:27<13:36, 1586.58 examples/s]Running tokenizer on dataset:  28%|██▊       | 506000/1801350 [05:27<13:39, 1579.99 examples/s]Running tokenizer on dataset:  28%|██▊       | 506000/1801350 [05:27<13:40, 1578.58 examples/s]Running tokenizer on dataset:  28%|██▊       | 506000/1801350 [05:27<13:36, 1586.52 examples/s]Running tokenizer on dataset:  28%|██▊       | 507000/1801350 [05:28<13:25, 1606.99 examples/s]Running tokenizer on dataset:  28%|██▊       | 507000/1801350 [05:28<13:26, 1605.67 examples/s]Running tokenizer on dataset:  28%|██▊       | 507000/1801350 [05:28<13:47, 1563.47 examples/s]Running tokenizer on dataset:  28%|██▊       | 507000/1801350 [05:28<13:30, 1596.46 examples/s]Running tokenizer on dataset:  28%|██▊       | 508000/1801350 [05:29<14:06, 1528.33 examples/s]Running tokenizer on dataset:  28%|██▊       | 508000/1801350 [05:29<14:08, 1524.81 examples/s]Running tokenizer on dataset:  28%|██▊       | 508000/1801350 [05:29<14:14, 1513.82 examples/s]Running tokenizer on dataset:  28%|██▊       | 508000/1801350 [05:29<14:08, 1525.02 examples/s]Running tokenizer on dataset:  28%|██▊       | 509000/1801350 [05:29<13:49, 1557.18 examples/s]Running tokenizer on dataset:  28%|██▊       | 509000/1801350 [05:29<13:55, 1547.33 examples/s]Running tokenizer on dataset:  28%|██▊       | 509000/1801350 [05:29<14:04, 1530.47 examples/s]Running tokenizer on dataset:  28%|██▊       | 509000/1801350 [05:29<13:56, 1544.92 examples/s]Running tokenizer on dataset:  28%|██▊       | 510000/1801350 [05:30<13:15, 1622.40 examples/s]Running tokenizer on dataset:  28%|██▊       | 510000/1801350 [05:30<13:18, 1616.44 examples/s]Running tokenizer on dataset:  28%|██▊       | 510000/1801350 [05:30<13:32, 1589.64 examples/s]Running tokenizer on dataset:  28%|██▊       | 510000/1801350 [05:30<13:15, 1622.98 examples/s]Running tokenizer on dataset:  28%|██▊       | 511000/1801350 [05:31<15:51, 1355.91 examples/s]Running tokenizer on dataset:  28%|██▊       | 511000/1801350 [05:31<15:56, 1349.49 examples/s]Running tokenizer on dataset:  28%|██▊       | 511000/1801350 [05:31<15:59, 1344.15 examples/s]Running tokenizer on dataset:  28%|██▊       | 511000/1801350 [05:31<15:43, 1367.46 examples/s]Running tokenizer on dataset:  28%|██▊       | 512000/1801350 [05:32<14:45, 1456.49 examples/s]Running tokenizer on dataset:  28%|██▊       | 512000/1801350 [05:32<14:44, 1456.90 examples/s]Running tokenizer on dataset:  28%|██▊       | 512000/1801350 [05:32<15:07, 1420.19 examples/s]Running tokenizer on dataset:  28%|██▊       | 512000/1801350 [05:32<14:51, 1445.95 examples/s]Running tokenizer on dataset:  28%|██▊       | 513000/1801350 [05:32<13:54, 1544.26 examples/s]Running tokenizer on dataset:  28%|██▊       | 513000/1801350 [05:32<13:53, 1545.73 examples/s]Running tokenizer on dataset:  28%|██▊       | 513000/1801350 [05:32<14:12, 1510.84 examples/s]Running tokenizer on dataset:  28%|██▊       | 513000/1801350 [05:32<14:09, 1516.87 examples/s]Running tokenizer on dataset:  29%|██▊       | 514000/1801350 [05:33<13:56, 1539.43 examples/s]Running tokenizer on dataset:  29%|██▊       | 514000/1801350 [05:33<13:47, 1556.02 examples/s]Running tokenizer on dataset:  29%|██▊       | 514000/1801350 [05:33<13:55, 1540.66 examples/s]Running tokenizer on dataset:  29%|██▊       | 514000/1801350 [05:33<13:52, 1546.14 examples/s]Running tokenizer on dataset:  29%|██▊       | 515000/1801350 [05:33<13:49, 1551.15 examples/s]Running tokenizer on dataset:  29%|██▊       | 515000/1801350 [05:33<14:04, 1523.55 examples/s]Running tokenizer on dataset:  29%|██▊       | 515000/1801350 [05:33<14:09, 1514.11 examples/s]Running tokenizer on dataset:  29%|██▊       | 515000/1801350 [05:33<13:59, 1531.44 examples/s]Running tokenizer on dataset:  29%|██▊       | 516000/1801350 [05:34<13:40, 1566.49 examples/s]Running tokenizer on dataset:  29%|██▊       | 516000/1801350 [05:34<13:53, 1542.78 examples/s]Running tokenizer on dataset:  29%|██▊       | 516000/1801350 [05:34<13:51, 1546.40 examples/s]Running tokenizer on dataset:  29%|██▊       | 516000/1801350 [05:34<13:50, 1547.63 examples/s]Running tokenizer on dataset:  29%|██▊       | 517000/1801350 [05:35<14:02, 1525.25 examples/s]Running tokenizer on dataset:  29%|██▊       | 517000/1801350 [05:35<14:10, 1509.96 examples/s]Running tokenizer on dataset:  29%|██▊       | 517000/1801350 [05:35<14:14, 1503.39 examples/s]Running tokenizer on dataset:  29%|██▊       | 517000/1801350 [05:35<14:07, 1516.33 examples/s]Running tokenizer on dataset:  29%|██▉       | 518000/1801350 [05:35<13:39, 1566.20 examples/s]Running tokenizer on dataset:  29%|██▉       | 518000/1801350 [05:35<13:41, 1562.65 examples/s]Running tokenizer on dataset:  29%|██▉       | 518000/1801350 [05:35<13:46, 1553.33 examples/s]Running tokenizer on dataset:  29%|██▉       | 518000/1801350 [05:35<13:40, 1564.52 examples/s]Running tokenizer on dataset:  29%|██▉       | 519000/1801350 [05:36<13:40, 1563.40 examples/s]Running tokenizer on dataset:  29%|██▉       | 519000/1801350 [05:36<13:40, 1562.85 examples/s]Running tokenizer on dataset:  29%|██▉       | 519000/1801350 [05:36<13:46, 1551.76 examples/s]Running tokenizer on dataset:  29%|██▉       | 519000/1801350 [05:36<13:42, 1559.34 examples/s]Running tokenizer on dataset:  29%|██▉       | 520000/1801350 [05:37<13:31, 1578.68 examples/s]Running tokenizer on dataset:  29%|██▉       | 520000/1801350 [05:37<13:33, 1574.20 examples/s]Running tokenizer on dataset:  29%|██▉       | 520000/1801350 [05:37<13:36, 1568.73 examples/s]Running tokenizer on dataset:  29%|██▉       | 520000/1801350 [05:37<13:41, 1560.02 examples/s]Running tokenizer on dataset:  29%|██▉       | 521000/1801350 [05:37<13:23, 1592.90 examples/s]Running tokenizer on dataset:  29%|██▉       | 521000/1801350 [05:37<13:27, 1586.52 examples/s]Running tokenizer on dataset:  29%|██▉       | 521000/1801350 [05:37<13:29, 1582.22 examples/s]Running tokenizer on dataset:  29%|██▉       | 521000/1801350 [05:37<13:21, 1598.02 examples/s]Running tokenizer on dataset:  29%|██▉       | 522000/1801350 [05:38<13:06, 1625.96 examples/s]Running tokenizer on dataset:  29%|██▉       | 522000/1801350 [05:38<13:05, 1628.37 examples/s]Running tokenizer on dataset:  29%|██▉       | 522000/1801350 [05:38<13:09, 1621.47 examples/s]Running tokenizer on dataset:  29%|██▉       | 522000/1801350 [05:38<13:13, 1612.07 examples/s]Running tokenizer on dataset:  29%|██▉       | 523000/1801350 [05:38<13:34, 1569.40 examples/s]Running tokenizer on dataset:  29%|██▉       | 523000/1801350 [05:38<13:43, 1551.85 examples/s]Running tokenizer on dataset:  29%|██▉       | 523000/1801350 [05:39<13:49, 1541.75 examples/s]Running tokenizer on dataset:  29%|██▉       | 523000/1801350 [05:39<13:38, 1562.05 examples/s]Running tokenizer on dataset:  29%|██▉       | 524000/1801350 [05:39<13:38, 1560.71 examples/s]Running tokenizer on dataset:  29%|██▉       | 524000/1801350 [05:39<13:39, 1558.27 examples/s]Running tokenizer on dataset:  29%|██▉       | 524000/1801350 [05:39<13:41, 1554.72 examples/s]Running tokenizer on dataset:  29%|██▉       | 524000/1801350 [05:39<13:42, 1553.11 examples/s]Running tokenizer on dataset:  29%|██▉       | 525000/1801350 [05:40<13:41, 1554.06 examples/s]Running tokenizer on dataset:  29%|██▉       | 525000/1801350 [05:40<13:44, 1547.26 examples/s]Running tokenizer on dataset:  29%|██▉       | 525000/1801350 [05:40<13:46, 1544.85 examples/s]Running tokenizer on dataset:  29%|██▉       | 525000/1801350 [05:40<13:45, 1547.01 examples/s]Running tokenizer on dataset:  29%|██▉       | 526000/1801350 [05:40<13:54, 1527.84 examples/s]Running tokenizer on dataset:  29%|██▉       | 526000/1801350 [05:40<13:59, 1519.54 examples/s]Running tokenizer on dataset:  29%|██▉       | 526000/1801350 [05:40<13:59, 1519.36 examples/s]Running tokenizer on dataset:  29%|██▉       | 526000/1801350 [05:41<13:56, 1524.75 examples/s]Running tokenizer on dataset:  29%|██▉       | 527000/1801350 [05:41<13:19, 1593.58 examples/s]Running tokenizer on dataset:  29%|██▉       | 527000/1801350 [05:41<13:19, 1593.65 examples/s]Running tokenizer on dataset:  29%|██▉       | 527000/1801350 [05:41<13:21, 1589.30 examples/s]Running tokenizer on dataset:  29%|██▉       | 527000/1801350 [05:41<13:27, 1577.89 examples/s]Running tokenizer on dataset:  29%|██▉       | 528000/1801350 [05:42<13:49, 1534.47 examples/s]Running tokenizer on dataset:  29%|██▉       | 528000/1801350 [05:42<13:44, 1544.87 examples/s]Running tokenizer on dataset:  29%|██▉       | 528000/1801350 [05:42<13:50, 1533.64 examples/s]Running tokenizer on dataset:  29%|██▉       | 528000/1801350 [05:42<13:48, 1536.22 examples/s]Running tokenizer on dataset:  29%|██▉       | 529000/1801350 [05:42<13:11, 1606.89 examples/s]Running tokenizer on dataset:  29%|██▉       | 529000/1801350 [05:42<13:18, 1593.69 examples/s]Running tokenizer on dataset:  29%|██▉       | 529000/1801350 [05:42<13:13, 1604.46 examples/s]Running tokenizer on dataset:  29%|██▉       | 529000/1801350 [05:42<13:19, 1592.12 examples/s]Running tokenizer on dataset:  29%|██▉       | 530000/1801350 [05:43<13:28, 1572.32 examples/s]Running tokenizer on dataset:  29%|██▉       | 530000/1801350 [05:43<13:32, 1564.85 examples/s]Running tokenizer on dataset:  29%|██▉       | 530000/1801350 [05:43<13:35, 1558.98 examples/s]Running tokenizer on dataset:  29%|██▉       | 530000/1801350 [05:43<13:25, 1577.64 examples/s]Running tokenizer on dataset:  29%|██▉       | 531000/1801350 [05:44<13:43, 1542.25 examples/s]Running tokenizer on dataset:  29%|██▉       | 531000/1801350 [05:44<13:50, 1530.24 examples/s]Running tokenizer on dataset:  29%|██▉       | 531000/1801350 [05:44<13:51, 1528.35 examples/s]Running tokenizer on dataset:  29%|██▉       | 531000/1801350 [05:44<13:59, 1513.52 examples/s]Running tokenizer on dataset:  30%|██▉       | 532000/1801350 [05:45<15:51, 1334.43 examples/s]Running tokenizer on dataset:  30%|██▉       | 532000/1801350 [05:45<15:41, 1348.32 examples/s]Running tokenizer on dataset:  30%|██▉       | 532000/1801350 [05:45<15:42, 1347.02 examples/s]Running tokenizer on dataset:  30%|██▉       | 532000/1801350 [05:45<16:21, 1293.54 examples/s]Running tokenizer on dataset:  30%|██▉       | 533000/1801350 [05:45<14:50, 1424.53 examples/s]Running tokenizer on dataset:  30%|██▉       | 533000/1801350 [05:45<14:53, 1419.62 examples/s]Running tokenizer on dataset:  30%|██▉       | 533000/1801350 [05:45<14:56, 1414.41 examples/s]Running tokenizer on dataset:  30%|██▉       | 533000/1801350 [05:45<15:21, 1375.80 examples/s]Running tokenizer on dataset:  30%|██▉       | 534000/1801350 [05:46<14:36, 1446.41 examples/s]Running tokenizer on dataset:  30%|██▉       | 534000/1801350 [05:46<14:35, 1447.43 examples/s]Running tokenizer on dataset:  30%|██▉       | 534000/1801350 [05:46<14:46, 1429.03 examples/s]Running tokenizer on dataset:  30%|██▉       | 534000/1801350 [05:46<15:05, 1399.85 examples/s]Running tokenizer on dataset:  30%|██▉       | 535000/1801350 [05:46<14:32, 1451.63 examples/s]Running tokenizer on dataset:  30%|██▉       | 535000/1801350 [05:47<14:35, 1446.26 examples/s]Running tokenizer on dataset:  30%|██▉       | 535000/1801350 [05:47<14:40, 1438.69 examples/s]Running tokenizer on dataset:  30%|██▉       | 535000/1801350 [05:47<14:49, 1422.93 examples/s]Running tokenizer on dataset:  30%|██▉       | 536000/1801350 [05:47<14:31, 1451.41 examples/s]Running tokenizer on dataset:  30%|██▉       | 536000/1801350 [05:47<14:33, 1449.18 examples/s]Running tokenizer on dataset:  30%|██▉       | 536000/1801350 [05:47<14:35, 1444.54 examples/s]Running tokenizer on dataset:  30%|██▉       | 536000/1801350 [05:47<14:35, 1445.46 examples/s]Running tokenizer on dataset:  30%|██▉       | 537000/1801350 [05:48<13:54, 1515.05 examples/s]Running tokenizer on dataset:  30%|██▉       | 537000/1801350 [05:48<13:58, 1508.71 examples/s]Running tokenizer on dataset:  30%|██▉       | 537000/1801350 [05:48<13:57, 1508.89 examples/s]Running tokenizer on dataset:  30%|██▉       | 537000/1801350 [05:48<14:00, 1505.05 examples/s]Running tokenizer on dataset:  30%|██▉       | 538000/1801350 [05:48<13:54, 1514.54 examples/s]Running tokenizer on dataset:  30%|██▉       | 538000/1801350 [05:49<13:53, 1515.92 examples/s]Running tokenizer on dataset:  30%|██▉       | 538000/1801350 [05:49<13:57, 1509.12 examples/s]Running tokenizer on dataset:  30%|██▉       | 538000/1801350 [05:49<14:03, 1498.29 examples/s]Running tokenizer on dataset:  30%|██▉       | 539000/1801350 [05:49<13:20, 1576.68 examples/s]Running tokenizer on dataset:  30%|██▉       | 539000/1801350 [05:49<13:15, 1587.29 examples/s]Running tokenizer on dataset:  30%|██▉       | 539000/1801350 [05:49<13:15, 1586.47 examples/s]Running tokenizer on dataset:  30%|██▉       | 539000/1801350 [05:49<13:23, 1570.54 examples/s]Running tokenizer on dataset:  30%|██▉       | 540000/1801350 [05:50<13:35, 1547.22 examples/s]Running tokenizer on dataset:  30%|██▉       | 540000/1801350 [05:50<13:43, 1531.59 examples/s]Running tokenizer on dataset:  30%|██▉       | 540000/1801350 [05:50<13:27, 1561.63 examples/s]Running tokenizer on dataset:  30%|██▉       | 540000/1801350 [05:50<13:35, 1547.21 examples/s]Running tokenizer on dataset:  30%|███       | 541000/1801350 [05:50<13:38, 1540.61 examples/s]Running tokenizer on dataset:  30%|███       | 541000/1801350 [05:50<13:36, 1544.49 examples/s]Running tokenizer on dataset:  30%|███       | 541000/1801350 [05:50<13:30, 1554.68 examples/s]Running tokenizer on dataset:  30%|███       | 541000/1801350 [05:51<13:33, 1548.67 examples/s]Running tokenizer on dataset:  30%|███       | 542000/1801350 [05:51<13:25, 1562.97 examples/s]Running tokenizer on dataset:  30%|███       | 542000/1801350 [05:51<13:29, 1555.08 examples/s]Running tokenizer on dataset:  30%|███       | 542000/1801350 [05:51<13:28, 1557.17 examples/s]Running tokenizer on dataset:  30%|███       | 542000/1801350 [05:51<13:25, 1563.74 examples/s]Running tokenizer on dataset:  30%|███       | 543000/1801350 [05:52<13:02, 1609.02 examples/s]Running tokenizer on dataset:  30%|███       | 543000/1801350 [05:52<13:08, 1596.72 examples/s]Running tokenizer on dataset:  30%|███       | 543000/1801350 [05:52<13:06, 1600.94 examples/s]Running tokenizer on dataset:  30%|███       | 543000/1801350 [05:52<13:13, 1585.74 examples/s]Running tokenizer on dataset:  30%|███       | 544000/1801350 [05:52<13:03, 1605.42 examples/s]Running tokenizer on dataset:  30%|███       | 544000/1801350 [05:52<13:12, 1586.06 examples/s]Running tokenizer on dataset:  30%|███       | 544000/1801350 [05:52<13:02, 1606.74 examples/s]Running tokenizer on dataset:  30%|███       | 544000/1801350 [05:52<13:13, 1585.21 examples/s]Running tokenizer on dataset:  30%|███       | 545000/1801350 [05:53<13:27, 1556.68 examples/s]Running tokenizer on dataset:  30%|███       | 545000/1801350 [05:53<13:23, 1563.85 examples/s]Running tokenizer on dataset:  30%|███       | 545000/1801350 [05:53<13:18, 1574.36 examples/s]Running tokenizer on dataset:  30%|███       | 545000/1801350 [05:53<13:24, 1562.16 examples/s]Running tokenizer on dataset:  30%|███       | 546000/1801350 [05:54<13:30, 1549.10 examples/s]Running tokenizer on dataset:  30%|███       | 546000/1801350 [05:54<13:25, 1557.78 examples/s]Running tokenizer on dataset:  30%|███       | 546000/1801350 [05:54<13:24, 1559.47 examples/s]Running tokenizer on dataset:  30%|███       | 546000/1801350 [05:54<13:32, 1545.64 examples/s]Running tokenizer on dataset:  30%|███       | 547000/1801350 [05:54<13:23, 1561.94 examples/s]Running tokenizer on dataset:  30%|███       | 547000/1801350 [05:54<13:28, 1551.92 examples/s]Running tokenizer on dataset:  30%|███       | 547000/1801350 [05:54<13:24, 1559.93 examples/s]Running tokenizer on dataset:  30%|███       | 547000/1801350 [05:54<13:27, 1552.79 examples/s]Running tokenizer on dataset:  30%|███       | 548000/1801350 [05:55<13:07, 1592.18 examples/s]Running tokenizer on dataset:  30%|███       | 548000/1801350 [05:55<13:04, 1597.60 examples/s]Running tokenizer on dataset:  30%|███       | 548000/1801350 [05:55<12:53, 1620.58 examples/s]Running tokenizer on dataset:  30%|███       | 548000/1801350 [05:55<13:13, 1579.38 examples/s]Running tokenizer on dataset:  30%|███       | 549000/1801350 [05:55<13:02, 1601.31 examples/s]Running tokenizer on dataset:  30%|███       | 549000/1801350 [05:55<13:17, 1570.47 examples/s]Running tokenizer on dataset:  30%|███       | 549000/1801350 [05:56<13:14, 1575.88 examples/s]Running tokenizer on dataset:  30%|███       | 549000/1801350 [05:56<13:07, 1590.13 examples/s]Running tokenizer on dataset:  31%|███       | 550000/1801350 [05:56<12:54, 1616.27 examples/s]Running tokenizer on dataset:  31%|███       | 550000/1801350 [05:56<12:57, 1610.32 examples/s]Running tokenizer on dataset:  31%|███       | 550000/1801350 [05:56<12:59, 1605.48 examples/s]Running tokenizer on dataset:  31%|███       | 550000/1801350 [05:56<12:53, 1617.10 examples/s]Running tokenizer on dataset:  31%|███       | 551000/1801350 [05:57<13:06, 1589.92 examples/s]Running tokenizer on dataset:  31%|███       | 551000/1801350 [05:57<12:58, 1605.52 examples/s]Running tokenizer on dataset:  31%|███       | 551000/1801350 [05:57<13:08, 1586.21 examples/s]Running tokenizer on dataset:  31%|███       | 551000/1801350 [05:57<13:01, 1600.26 examples/s]Running tokenizer on dataset:  31%|███       | 552000/1801350 [05:57<13:03, 1595.20 examples/s]Running tokenizer on dataset:  31%|███       | 552000/1801350 [05:57<13:04, 1591.75 examples/s]Running tokenizer on dataset:  31%|███       | 552000/1801350 [05:57<13:08, 1583.53 examples/s]Running tokenizer on dataset:  31%|███       | 552000/1801350 [05:57<13:06, 1589.50 examples/s]Running tokenizer on dataset:  31%|███       | 553000/1801350 [05:58<15:32, 1338.40 examples/s]Running tokenizer on dataset:  31%|███       | 553000/1801350 [05:58<15:08, 1373.43 examples/s]Running tokenizer on dataset:  31%|███       | 553000/1801350 [05:58<15:20, 1356.37 examples/s]Running tokenizer on dataset:  31%|███       | 553000/1801350 [05:58<16:03, 1295.09 examples/s]Running tokenizer on dataset:  31%|███       | 554000/1801350 [05:59<14:33, 1428.41 examples/s]Running tokenizer on dataset:  31%|███       | 554000/1801350 [05:59<14:23, 1445.00 examples/s]Running tokenizer on dataset:  31%|███       | 554000/1801350 [05:59<15:13, 1365.43 examples/s]Running tokenizer on dataset:  31%|███       | 554000/1801350 [05:59<14:58, 1388.37 examples/s]Running tokenizer on dataset:  31%|███       | 555000/1801350 [06:00<14:28, 1435.01 examples/s]Running tokenizer on dataset:  31%|███       | 555000/1801350 [06:00<14:32, 1428.29 examples/s]Running tokenizer on dataset:  31%|███       | 555000/1801350 [06:00<14:36, 1422.66 examples/s]Running tokenizer on dataset:  31%|███       | 555000/1801350 [06:00<14:49, 1400.70 examples/s]Running tokenizer on dataset:  31%|███       | 556000/1801350 [06:00<13:47, 1505.20 examples/s]Running tokenizer on dataset:  31%|███       | 556000/1801350 [06:00<13:33, 1531.47 examples/s]Running tokenizer on dataset:  31%|███       | 556000/1801350 [06:00<13:45, 1509.36 examples/s]Running tokenizer on dataset:  31%|███       | 556000/1801350 [06:00<14:12, 1461.52 examples/s]Running tokenizer on dataset:  31%|███       | 557000/1801350 [06:01<13:24, 1546.75 examples/s]Running tokenizer on dataset:  31%|███       | 557000/1801350 [06:01<13:22, 1550.05 examples/s]Running tokenizer on dataset:  31%|███       | 557000/1801350 [06:01<13:24, 1547.13 examples/s]Running tokenizer on dataset:  31%|███       | 557000/1801350 [06:01<13:34, 1527.90 examples/s]Running tokenizer on dataset:  31%|███       | 558000/1801350 [06:01<13:18, 1557.24 examples/s]Running tokenizer on dataset:  31%|███       | 558000/1801350 [06:02<13:26, 1541.75 examples/s]Running tokenizer on dataset:  31%|███       | 558000/1801350 [06:02<13:27, 1539.59 examples/s]Running tokenizer on dataset:  31%|███       | 558000/1801350 [06:02<13:34, 1525.61 examples/s]Running tokenizer on dataset:  31%|███       | 559000/1801350 [06:02<13:47, 1500.49 examples/s]Running tokenizer on dataset:  31%|███       | 559000/1801350 [06:02<13:53, 1490.04 examples/s]Running tokenizer on dataset:  31%|███       | 559000/1801350 [06:02<14:01, 1476.26 examples/s]Running tokenizer on dataset:  31%|███       | 559000/1801350 [06:02<14:03, 1473.48 examples/s]Running tokenizer on dataset:  31%|███       | 560000/1801350 [06:03<13:48, 1497.94 examples/s]Running tokenizer on dataset:  31%|███       | 560000/1801350 [06:03<13:49, 1495.82 examples/s]Running tokenizer on dataset:  31%|███       | 560000/1801350 [06:03<13:58, 1480.38 examples/s]Running tokenizer on dataset:  31%|███       | 560000/1801350 [06:03<14:06, 1465.64 examples/s]Running tokenizer on dataset:  31%|███       | 561000/1801350 [06:03<13:36, 1519.32 examples/s]Running tokenizer on dataset:  31%|███       | 561000/1801350 [06:04<13:38, 1516.06 examples/s]Running tokenizer on dataset:  31%|███       | 561000/1801350 [06:04<13:38, 1515.14 examples/s]Running tokenizer on dataset:  31%|███       | 561000/1801350 [06:04<13:49, 1495.95 examples/s]Running tokenizer on dataset:  31%|███       | 562000/1801350 [06:04<13:16, 1556.90 examples/s]Running tokenizer on dataset:  31%|███       | 562000/1801350 [06:04<13:11, 1565.41 examples/s]Running tokenizer on dataset:  31%|███       | 562000/1801350 [06:04<13:14, 1560.09 examples/s]Running tokenizer on dataset:  31%|███       | 562000/1801350 [06:04<13:22, 1545.00 examples/s]Running tokenizer on dataset:  31%|███▏      | 563000/1801350 [06:05<12:48, 1611.03 examples/s]Running tokenizer on dataset:  31%|███▏      | 563000/1801350 [06:05<12:48, 1610.58 examples/s]Running tokenizer on dataset:  31%|███▏      | 563000/1801350 [06:05<12:51, 1605.64 examples/s]Running tokenizer on dataset:  31%|███▏      | 563000/1801350 [06:05<12:49, 1609.30 examples/s]Running tokenizer on dataset:  31%|███▏      | 564000/1801350 [06:05<13:06, 1572.93 examples/s]Running tokenizer on dataset:  31%|███▏      | 564000/1801350 [06:05<12:57, 1591.06 examples/s]Running tokenizer on dataset:  31%|███▏      | 564000/1801350 [06:05<13:02, 1581.93 examples/s]Running tokenizer on dataset:  31%|███▏      | 564000/1801350 [06:05<13:11, 1563.91 examples/s]Running tokenizer on dataset:  31%|███▏      | 565000/1801350 [06:06<13:36, 1514.84 examples/s]Running tokenizer on dataset:  31%|███▏      | 565000/1801350 [06:06<13:31, 1523.75 examples/s]Running tokenizer on dataset:  31%|███▏      | 565000/1801350 [06:06<13:36, 1513.54 examples/s]Running tokenizer on dataset:  31%|███▏      | 565000/1801350 [06:06<13:33, 1519.38 examples/s]Running tokenizer on dataset:  31%|███▏      | 566000/1801350 [06:07<13:29, 1526.30 examples/s]Running tokenizer on dataset:  31%|███▏      | 566000/1801350 [06:07<13:21, 1542.00 examples/s]Running tokenizer on dataset:  31%|███▏      | 566000/1801350 [06:07<13:25, 1532.89 examples/s]Running tokenizer on dataset:  31%|███▏      | 566000/1801350 [06:07<13:21, 1540.85 examples/s]Running tokenizer on dataset:  31%|███▏      | 567000/1801350 [06:07<13:49, 1487.49 examples/s]Running tokenizer on dataset:  31%|███▏      | 567000/1801350 [06:07<13:47, 1491.69 examples/s]Running tokenizer on dataset:  31%|███▏      | 567000/1801350 [06:07<13:51, 1483.99 examples/s]Running tokenizer on dataset:  31%|███▏      | 567000/1801350 [06:08<13:56, 1475.00 examples/s]Running tokenizer on dataset:  32%|███▏      | 568000/1801350 [06:08<13:02, 1575.95 examples/s]Running tokenizer on dataset:  32%|███▏      | 568000/1801350 [06:08<12:59, 1582.90 examples/s]Running tokenizer on dataset:  32%|███▏      | 568000/1801350 [06:08<13:02, 1576.32 examples/s]Running tokenizer on dataset:  32%|███▏      | 568000/1801350 [06:08<13:03, 1573.59 examples/s]Running tokenizer on dataset:  32%|███▏      | 569000/1801350 [06:08<12:50, 1600.45 examples/s]Running tokenizer on dataset:  32%|███▏      | 569000/1801350 [06:09<12:48, 1603.55 examples/s]Running tokenizer on dataset:  32%|███▏      | 569000/1801350 [06:09<12:49, 1600.70 examples/s]Running tokenizer on dataset:  32%|███▏      | 569000/1801350 [06:09<12:52, 1594.82 examples/s]Running tokenizer on dataset:  32%|███▏      | 570000/1801350 [06:09<12:38, 1623.90 examples/s]Running tokenizer on dataset:  32%|███▏      | 570000/1801350 [06:09<12:42, 1615.77 examples/s]Running tokenizer on dataset:  32%|███▏      | 570000/1801350 [06:09<12:44, 1609.99 examples/s]Running tokenizer on dataset:  32%|███▏      | 570000/1801350 [06:09<12:46, 1607.15 examples/s]Running tokenizer on dataset:  32%|███▏      | 571000/1801350 [06:10<12:32, 1635.77 examples/s]Running tokenizer on dataset:  32%|███▏      | 571000/1801350 [06:10<12:28, 1644.50 examples/s]Running tokenizer on dataset:  32%|███▏      | 571000/1801350 [06:10<12:34, 1631.09 examples/s]Running tokenizer on dataset:  32%|███▏      | 571000/1801350 [06:10<12:30, 1639.18 examples/s]Running tokenizer on dataset:  32%|███▏      | 572000/1801350 [06:10<12:00, 1706.69 examples/s]Running tokenizer on dataset:  32%|███▏      | 572000/1801350 [06:10<12:01, 1703.05 examples/s]Running tokenizer on dataset:  32%|███▏      | 572000/1801350 [06:10<12:01, 1704.51 examples/s]Running tokenizer on dataset:  32%|███▏      | 572000/1801350 [06:10<12:04, 1697.30 examples/s]Running tokenizer on dataset:  32%|███▏      | 573000/1801350 [06:11<12:32, 1632.39 examples/s]Running tokenizer on dataset:  32%|███▏      | 573000/1801350 [06:11<12:38, 1619.02 examples/s]Running tokenizer on dataset:  32%|███▏      | 573000/1801350 [06:11<12:41, 1612.18 examples/s]Running tokenizer on dataset:  32%|███▏      | 573000/1801350 [06:11<12:42, 1611.23 examples/s]Running tokenizer on dataset:  32%|███▏      | 574000/1801350 [06:12<14:41, 1392.99 examples/s]Running tokenizer on dataset:  32%|███▏      | 574000/1801350 [06:12<14:35, 1401.55 examples/s]Running tokenizer on dataset:  32%|███▏      | 574000/1801350 [06:12<14:36, 1400.16 examples/s]Running tokenizer on dataset:  32%|███▏      | 574000/1801350 [06:12<14:48, 1381.21 examples/s]Running tokenizer on dataset:  32%|███▏      | 575000/1801350 [06:13<14:26, 1414.92 examples/s]Running tokenizer on dataset:  32%|███▏      | 575000/1801350 [06:13<14:37, 1397.15 examples/s]Running tokenizer on dataset:  32%|███▏      | 575000/1801350 [06:13<14:37, 1397.12 examples/s]Running tokenizer on dataset:  32%|███▏      | 575000/1801350 [06:13<14:52, 1374.25 examples/s]Running tokenizer on dataset:  32%|███▏      | 576000/1801350 [06:13<14:09, 1443.07 examples/s]Running tokenizer on dataset:  32%|███▏      | 576000/1801350 [06:13<14:13, 1435.85 examples/s]Running tokenizer on dataset:  32%|███▏      | 576000/1801350 [06:13<14:13, 1436.38 examples/s]Running tokenizer on dataset:  32%|███▏      | 576000/1801350 [06:13<14:21, 1422.24 examples/s]Running tokenizer on dataset:  32%|███▏      | 577000/1801350 [06:14<13:42, 1489.35 examples/s]Running tokenizer on dataset:  32%|███▏      | 577000/1801350 [06:14<13:30, 1510.25 examples/s]Running tokenizer on dataset:  32%|███▏      | 577000/1801350 [06:14<13:48, 1478.38 examples/s]Running tokenizer on dataset:  32%|███▏      | 577000/1801350 [06:14<13:49, 1475.98 examples/s]Running tokenizer on dataset:  32%|███▏      | 578000/1801350 [06:14<13:44, 1484.20 examples/s]Running tokenizer on dataset:  32%|███▏      | 578000/1801350 [06:15<13:44, 1483.85 examples/s]Running tokenizer on dataset:  32%|███▏      | 578000/1801350 [06:15<13:43, 1484.76 examples/s]Running tokenizer on dataset:  32%|███▏      | 578000/1801350 [06:15<13:45, 1481.70 examples/s]Running tokenizer on dataset:  32%|███▏      | 579000/1801350 [06:15<13:34, 1501.41 examples/s]Running tokenizer on dataset:  32%|███▏      | 579000/1801350 [06:15<13:39, 1491.23 examples/s]Running tokenizer on dataset:  32%|███▏      | 579000/1801350 [06:15<13:40, 1489.60 examples/s]Running tokenizer on dataset:  32%|███▏      | 579000/1801350 [06:15<13:36, 1496.24 examples/s]Running tokenizer on dataset:  32%|███▏      | 580000/1801350 [06:16<13:13, 1538.54 examples/s]Running tokenizer on dataset:  32%|███▏      | 580000/1801350 [06:16<12:54, 1577.11 examples/s]Running tokenizer on dataset:  32%|███▏      | 580000/1801350 [06:16<13:06, 1551.94 examples/s]Running tokenizer on dataset:  32%|███▏      | 580000/1801350 [06:16<13:06, 1552.65 examples/s]Running tokenizer on dataset:  32%|███▏      | 581000/1801350 [06:16<13:09, 1545.03 examples/s]Running tokenizer on dataset:  32%|███▏      | 581000/1801350 [06:17<12:58, 1567.50 examples/s]Running tokenizer on dataset:  32%|███▏      | 581000/1801350 [06:17<13:05, 1554.29 examples/s]Running tokenizer on dataset:  32%|███▏      | 581000/1801350 [06:17<12:59, 1564.96 examples/s]Running tokenizer on dataset:  32%|███▏      | 582000/1801350 [06:17<12:42, 1599.00 examples/s]Running tokenizer on dataset:  32%|███▏      | 582000/1801350 [06:17<12:39, 1605.35 examples/s]Running tokenizer on dataset:  32%|███▏      | 582000/1801350 [06:17<12:44, 1594.01 examples/s]Running tokenizer on dataset:  32%|███▏      | 582000/1801350 [06:17<12:44, 1594.22 examples/s]Running tokenizer on dataset:  32%|███▏      | 583000/1801350 [06:18<12:21, 1644.19 examples/s]Running tokenizer on dataset:  32%|███▏      | 583000/1801350 [06:18<12:20, 1644.95 examples/s]Running tokenizer on dataset:  32%|███▏      | 583000/1801350 [06:18<12:26, 1631.45 examples/s]Running tokenizer on dataset:  32%|███▏      | 583000/1801350 [06:18<12:18, 1649.70 examples/s]Running tokenizer on dataset:  32%|███▏      | 584000/1801350 [06:18<11:53, 1706.55 examples/s]Running tokenizer on dataset:  32%|███▏      | 584000/1801350 [06:18<11:58, 1693.78 examples/s]Running tokenizer on dataset:  32%|███▏      | 584000/1801350 [06:18<12:04, 1680.46 examples/s]Running tokenizer on dataset:  32%|███▏      | 584000/1801350 [06:18<12:01, 1687.94 examples/s]Running tokenizer on dataset:  32%|███▏      | 585000/1801350 [06:19<11:40, 1736.45 examples/s]Running tokenizer on dataset:  32%|███▏      | 585000/1801350 [06:19<11:50, 1711.69 examples/s]Running tokenizer on dataset:  32%|███▏      | 585000/1801350 [06:19<11:38, 1741.36 examples/s]Running tokenizer on dataset:  32%|███▏      | 585000/1801350 [06:19<11:44, 1725.50 examples/s]Running tokenizer on dataset:  33%|███▎      | 586000/1801350 [06:19<11:54, 1700.19 examples/s]Running tokenizer on dataset:  33%|███▎      | 586000/1801350 [06:19<11:54, 1700.01 examples/s]Running tokenizer on dataset:  33%|███▎      | 586000/1801350 [06:19<12:03, 1680.42 examples/s]Running tokenizer on dataset:  33%|███▎      | 586000/1801350 [06:20<11:55, 1698.89 examples/s]Running tokenizer on dataset:  33%|███▎      | 587000/1801350 [06:20<12:17, 1647.64 examples/s]Running tokenizer on dataset:  33%|███▎      | 587000/1801350 [06:20<12:24, 1630.15 examples/s]Running tokenizer on dataset:  33%|███▎      | 587000/1801350 [06:20<12:31, 1616.78 examples/s]Running tokenizer on dataset:  33%|███▎      | 587000/1801350 [06:20<12:21, 1638.44 examples/s]Running tokenizer on dataset:  33%|███▎      | 588000/1801350 [06:21<12:45, 1584.54 examples/s]Running tokenizer on dataset:  33%|███▎      | 588000/1801350 [06:21<13:04, 1546.91 examples/s]Running tokenizer on dataset:  33%|███▎      | 588000/1801350 [06:21<13:04, 1546.73 examples/s]Running tokenizer on dataset:  33%|███▎      | 588000/1801350 [06:21<12:54, 1567.16 examples/s]Running tokenizer on dataset:  33%|███▎      | 589000/1801350 [06:21<12:50, 1573.75 examples/s]Running tokenizer on dataset:  33%|███▎      | 589000/1801350 [06:21<12:50, 1573.49 examples/s]Running tokenizer on dataset:  33%|███▎      | 589000/1801350 [06:21<12:51, 1572.33 examples/s]Running tokenizer on dataset:  33%|███▎      | 589000/1801350 [06:22<12:55, 1562.31 examples/s]Running tokenizer on dataset:  33%|███▎      | 590000/1801350 [06:22<12:34, 1605.45 examples/s]Running tokenizer on dataset:  33%|███▎      | 590000/1801350 [06:22<12:42, 1587.68 examples/s]Running tokenizer on dataset:  33%|███▎      | 590000/1801350 [06:22<12:30, 1613.55 examples/s]Running tokenizer on dataset:  33%|███▎      | 590000/1801350 [06:22<12:37, 1598.50 examples/s]Running tokenizer on dataset:  33%|███▎      | 591000/1801350 [06:22<12:27, 1619.72 examples/s]Running tokenizer on dataset:  33%|███▎      | 591000/1801350 [06:23<12:33, 1606.85 examples/s]Running tokenizer on dataset:  33%|███▎      | 591000/1801350 [06:23<12:36, 1600.91 examples/s]Running tokenizer on dataset:  33%|███▎      | 591000/1801350 [06:23<12:37, 1597.44 examples/s]Running tokenizer on dataset:  33%|███▎      | 592000/1801350 [06:23<12:27, 1618.05 examples/s]Running tokenizer on dataset:  33%|███▎      | 592000/1801350 [06:23<12:36, 1598.52 examples/s]Running tokenizer on dataset:  33%|███▎      | 592000/1801350 [06:23<12:25, 1622.75 examples/s]Running tokenizer on dataset:  33%|███▎      | 592000/1801350 [06:23<12:34, 1603.55 examples/s]Running tokenizer on dataset:  33%|███▎      | 593000/1801350 [06:24<13:03, 1542.20 examples/s]Running tokenizer on dataset:  33%|███▎      | 593000/1801350 [06:24<13:10, 1527.70 examples/s]Running tokenizer on dataset:  33%|███▎      | 593000/1801350 [06:24<13:08, 1532.41 examples/s]Running tokenizer on dataset:  33%|███▎      | 593000/1801350 [06:24<13:10, 1528.95 examples/s]Running tokenizer on dataset:  33%|███▎      | 594000/1801350 [06:24<12:55, 1556.90 examples/s]Running tokenizer on dataset:  33%|███▎      | 594000/1801350 [06:25<12:50, 1567.37 examples/s]Running tokenizer on dataset:  33%|███▎      | 594000/1801350 [06:25<12:59, 1549.70 examples/s]Running tokenizer on dataset:  33%|███▎      | 594000/1801350 [06:25<13:03, 1540.80 examples/s]Running tokenizer on dataset:  33%|███▎      | 595000/1801350 [06:25<15:18, 1313.33 examples/s]Running tokenizer on dataset:  33%|███▎      | 595000/1801350 [06:26<14:35, 1377.73 examples/s]Running tokenizer on dataset:  33%|███▎      | 595000/1801350 [06:26<14:44, 1364.35 examples/s]Running tokenizer on dataset:  33%|███▎      | 595000/1801350 [06:26<14:37, 1374.63 examples/s]Running tokenizer on dataset:  33%|███▎      | 596000/1801350 [06:26<14:41, 1367.73 examples/s]Running tokenizer on dataset:  33%|███▎      | 596000/1801350 [06:26<14:25, 1392.88 examples/s]Running tokenizer on dataset:  33%|███▎      | 596000/1801350 [06:26<14:33, 1379.41 examples/s]Running tokenizer on dataset:  33%|███▎      | 596000/1801350 [06:26<14:30, 1384.57 examples/s]Running tokenizer on dataset:  33%|███▎      | 597000/1801350 [06:27<13:49, 1451.30 examples/s]Running tokenizer on dataset:  33%|███▎      | 597000/1801350 [06:27<13:41, 1465.17 examples/s]Running tokenizer on dataset:  33%|███▎      | 597000/1801350 [06:27<13:44, 1461.31 examples/s]Running tokenizer on dataset:  33%|███▎      | 597000/1801350 [06:27<13:42, 1464.06 examples/s]Running tokenizer on dataset:  33%|███▎      | 598000/1801350 [06:27<13:37, 1472.30 examples/s]Running tokenizer on dataset:  33%|███▎      | 598000/1801350 [06:27<13:32, 1480.92 examples/s]Running tokenizer on dataset:  33%|███▎      | 598000/1801350 [06:27<13:36, 1473.14 examples/s]Running tokenizer on dataset:  33%|███▎      | 598000/1801350 [06:28<13:34, 1477.71 examples/s]Running tokenizer on dataset:  33%|███▎      | 599000/1801350 [06:28<13:22, 1497.55 examples/s]Running tokenizer on dataset:  33%|███▎      | 599000/1801350 [06:28<13:14, 1512.48 examples/s]Running tokenizer on dataset:  33%|███▎      | 599000/1801350 [06:28<13:16, 1510.14 examples/s]Running tokenizer on dataset:  33%|███▎      | 599000/1801350 [06:28<13:17, 1507.59 examples/s]Running tokenizer on dataset:  33%|███▎      | 600000/1801350 [06:29<12:52, 1555.70 examples/s]Running tokenizer on dataset:  33%|███▎      | 600000/1801350 [06:29<12:46, 1568.16 examples/s]Running tokenizer on dataset:  33%|███▎      | 600000/1801350 [06:29<12:51, 1556.31 examples/s]Running tokenizer on dataset:  33%|███▎      | 600000/1801350 [06:29<12:54, 1550.64 examples/s]Running tokenizer on dataset:  33%|███▎      | 601000/1801350 [06:29<12:53, 1550.91 examples/s]Running tokenizer on dataset:  33%|███▎      | 601000/1801350 [06:29<12:45, 1568.98 examples/s]Running tokenizer on dataset:  33%|███▎      | 601000/1801350 [06:29<12:44, 1569.56 examples/s]Running tokenizer on dataset:  33%|███▎      | 601000/1801350 [06:29<12:42, 1573.38 examples/s]Running tokenizer on dataset:  33%|███▎      | 602000/1801350 [06:30<13:28, 1483.92 examples/s]Running tokenizer on dataset:  33%|███▎      | 602000/1801350 [06:30<13:24, 1490.80 examples/s]Running tokenizer on dataset:  33%|███▎      | 602000/1801350 [06:30<13:33, 1473.61 examples/s]Running tokenizer on dataset:  33%|███▎      | 602000/1801350 [06:30<13:30, 1479.99 examples/s]Running tokenizer on dataset:  33%|███▎      | 603000/1801350 [06:31<13:29, 1480.68 examples/s]Running tokenizer on dataset:  33%|███▎      | 603000/1801350 [06:31<13:24, 1489.22 examples/s]Running tokenizer on dataset:  33%|███▎      | 603000/1801350 [06:31<13:27, 1484.90 examples/s]Running tokenizer on dataset:  33%|███▎      | 603000/1801350 [06:31<13:33, 1473.94 examples/s]Running tokenizer on dataset:  34%|███▎      | 604000/1801350 [06:31<12:55, 1544.75 examples/s]Running tokenizer on dataset:  34%|███▎      | 604000/1801350 [06:31<12:54, 1546.84 examples/s]Running tokenizer on dataset:  34%|███▎      | 604000/1801350 [06:31<12:57, 1540.08 examples/s]Running tokenizer on dataset:  34%|███▎      | 604000/1801350 [06:31<12:57, 1540.63 examples/s]Running tokenizer on dataset:  34%|███▎      | 605000/1801350 [06:32<12:49, 1553.94 examples/s]Running tokenizer on dataset:  34%|███▎      | 605000/1801350 [06:32<12:51, 1550.80 examples/s]Running tokenizer on dataset:  34%|███▎      | 605000/1801350 [06:32<12:47, 1559.51 examples/s]Running tokenizer on dataset:  34%|███▎      | 605000/1801350 [06:32<12:48, 1556.48 examples/s]Running tokenizer on dataset:  34%|███▎      | 606000/1801350 [06:32<12:55, 1542.05 examples/s]Running tokenizer on dataset:  34%|███▎      | 606000/1801350 [06:33<13:02, 1527.36 examples/s]Running tokenizer on dataset:  34%|███▎      | 606000/1801350 [06:33<13:04, 1523.28 examples/s]Running tokenizer on dataset:  34%|███▎      | 606000/1801350 [06:33<13:03, 1525.09 examples/s]Running tokenizer on dataset:  34%|███▎      | 607000/1801350 [06:33<12:38, 1574.81 examples/s]Running tokenizer on dataset:  34%|███▎      | 607000/1801350 [06:33<12:34, 1582.81 examples/s]Running tokenizer on dataset:  34%|███▎      | 607000/1801350 [06:33<12:35, 1580.45 examples/s]Running tokenizer on dataset:  34%|███▎      | 607000/1801350 [06:33<12:41, 1568.81 examples/s]Running tokenizer on dataset:  34%|███▍      | 608000/1801350 [06:34<12:38, 1572.33 examples/s]Running tokenizer on dataset:  34%|███▍      | 608000/1801350 [06:34<12:36, 1576.91 examples/s]Running tokenizer on dataset:  34%|███▍      | 608000/1801350 [06:34<12:40, 1568.87 examples/s]Running tokenizer on dataset:  34%|███▍      | 608000/1801350 [06:34<12:44, 1561.40 examples/s]Running tokenizer on dataset:  34%|███▍      | 609000/1801350 [06:34<13:10, 1508.65 examples/s]Running tokenizer on dataset:  34%|███▍      | 609000/1801350 [06:35<13:13, 1502.75 examples/s]Running tokenizer on dataset:  34%|███▍      | 609000/1801350 [06:35<13:19, 1490.83 examples/s]Running tokenizer on dataset:  34%|███▍      | 609000/1801350 [06:35<13:17, 1494.62 examples/s]Running tokenizer on dataset:  34%|███▍      | 610000/1801350 [06:35<12:32, 1583.60 examples/s]Running tokenizer on dataset:  34%|███▍      | 610000/1801350 [06:35<12:33, 1581.20 examples/s]Running tokenizer on dataset:  34%|███▍      | 610000/1801350 [06:35<12:35, 1577.40 examples/s]Running tokenizer on dataset:  34%|███▍      | 610000/1801350 [06:35<12:35, 1577.42 examples/s]Running tokenizer on dataset:  34%|███▍      | 611000/1801350 [06:36<12:10, 1629.54 examples/s]Running tokenizer on dataset:  34%|███▍      | 611000/1801350 [06:36<12:09, 1632.81 examples/s]Running tokenizer on dataset:  34%|███▍      | 611000/1801350 [06:36<12:14, 1620.85 examples/s]Running tokenizer on dataset:  34%|███▍      | 611000/1801350 [06:36<12:11, 1627.52 examples/s]Running tokenizer on dataset:  34%|███▍      | 612000/1801350 [06:36<12:18, 1610.26 examples/s]Running tokenizer on dataset:  34%|███▍      | 612000/1801350 [06:36<12:19, 1608.62 examples/s]Running tokenizer on dataset:  34%|███▍      | 612000/1801350 [06:36<12:23, 1599.94 examples/s]Running tokenizer on dataset:  34%|███▍      | 612000/1801350 [06:37<12:28, 1588.76 examples/s]Running tokenizer on dataset:  34%|███▍      | 613000/1801350 [06:37<12:25, 1594.61 examples/s]Running tokenizer on dataset:  34%|███▍      | 613000/1801350 [06:37<12:24, 1595.66 examples/s]Running tokenizer on dataset:  34%|███▍      | 613000/1801350 [06:37<12:41, 1560.85 examples/s]Running tokenizer on dataset:  34%|███▍      | 613000/1801350 [06:37<12:30, 1583.74 examples/s]Running tokenizer on dataset:  34%|███▍      | 614000/1801350 [06:38<12:39, 1563.23 examples/s]Running tokenizer on dataset:  34%|███▍      | 614000/1801350 [06:38<12:33, 1575.89 examples/s]Running tokenizer on dataset:  34%|███▍      | 614000/1801350 [06:38<12:41, 1559.56 examples/s]Running tokenizer on dataset:  34%|███▍      | 614000/1801350 [06:38<12:49, 1543.67 examples/s]Running tokenizer on dataset:  34%|███▍      | 615000/1801350 [06:38<13:05, 1511.16 examples/s]Running tokenizer on dataset:  34%|███▍      | 615000/1801350 [06:38<13:12, 1497.30 examples/s]Running tokenizer on dataset:  34%|███▍      | 615000/1801350 [06:38<13:08, 1504.13 examples/s]Running tokenizer on dataset:  34%|███▍      | 615000/1801350 [06:39<13:05, 1511.21 examples/s]Running tokenizer on dataset:  34%|███▍      | 616000/1801350 [06:39<15:26, 1279.58 examples/s]Running tokenizer on dataset:  34%|███▍      | 616000/1801350 [06:39<15:16, 1292.70 examples/s]Running tokenizer on dataset:  34%|███▍      | 616000/1801350 [06:39<15:12, 1298.61 examples/s]Running tokenizer on dataset:  34%|███▍      | 616000/1801350 [06:40<15:13, 1297.80 examples/s]Running tokenizer on dataset:  34%|███▍      | 617000/1801350 [06:40<13:37, 1448.74 examples/s]Running tokenizer on dataset:  34%|███▍      | 617000/1801350 [06:40<13:28, 1465.38 examples/s]Running tokenizer on dataset:  34%|███▍      | 617000/1801350 [06:40<13:37, 1449.58 examples/s]Running tokenizer on dataset:  34%|███▍      | 617000/1801350 [06:40<13:25, 1469.47 examples/s]Running tokenizer on dataset:  34%|███▍      | 618000/1801350 [06:40<12:53, 1529.88 examples/s]Running tokenizer on dataset:  34%|███▍      | 618000/1801350 [06:41<12:47, 1541.45 examples/s]Running tokenizer on dataset:  34%|███▍      | 618000/1801350 [06:41<12:53, 1530.48 examples/s]Running tokenizer on dataset:  34%|███▍      | 618000/1801350 [06:41<12:53, 1530.17 examples/s]Running tokenizer on dataset:  34%|███▍      | 619000/1801350 [06:41<12:23, 1590.41 examples/s]Running tokenizer on dataset:  34%|███▍      | 619000/1801350 [06:41<12:20, 1595.68 examples/s]Running tokenizer on dataset:  34%|███▍      | 619000/1801350 [06:41<12:20, 1596.76 examples/s]Running tokenizer on dataset:  34%|███▍      | 619000/1801350 [06:41<12:18, 1600.10 examples/s]Running tokenizer on dataset:  34%|███▍      | 620000/1801350 [06:41<11:38, 1690.67 examples/s]Running tokenizer on dataset:  34%|███▍      | 620000/1801350 [06:42<11:35, 1697.41 examples/s]Running tokenizer on dataset:  34%|███▍      | 620000/1801350 [06:42<11:26, 1720.64 examples/s]Running tokenizer on dataset:  34%|███▍      | 620000/1801350 [06:42<11:34, 1701.27 examples/s]Running tokenizer on dataset:  34%|███▍      | 621000/1801350 [06:42<11:24, 1723.34 examples/s]Running tokenizer on dataset:  34%|███▍      | 621000/1801350 [06:42<11:24, 1724.56 examples/s]Running tokenizer on dataset:  34%|███▍      | 621000/1801350 [06:42<11:24, 1723.85 examples/s]Running tokenizer on dataset:  34%|███▍      | 621000/1801350 [06:42<11:25, 1721.48 examples/s]Running tokenizer on dataset:  35%|███▍      | 622000/1801350 [06:43<11:58, 1640.42 examples/s]Running tokenizer on dataset:  35%|███▍      | 622000/1801350 [06:43<12:03, 1629.27 examples/s]Running tokenizer on dataset:  35%|███▍      | 622000/1801350 [06:43<12:07, 1621.59 examples/s]Running tokenizer on dataset:  35%|███▍      | 622000/1801350 [06:43<12:01, 1635.39 examples/s]Running tokenizer on dataset:  35%|███▍      | 623000/1801350 [06:43<11:48, 1663.50 examples/s]Running tokenizer on dataset:  35%|███▍      | 623000/1801350 [06:43<11:48, 1662.97 examples/s]Running tokenizer on dataset:  35%|███▍      | 623000/1801350 [06:43<11:48, 1663.72 examples/s]Running tokenizer on dataset:  35%|███▍      | 623000/1801350 [06:44<11:49, 1660.22 examples/s]Running tokenizer on dataset:  35%|███▍      | 624000/1801350 [06:44<11:56, 1642.71 examples/s]Running tokenizer on dataset:  35%|███▍      | 624000/1801350 [06:44<11:58, 1639.72 examples/s]Running tokenizer on dataset:  35%|███▍      | 624000/1801350 [06:44<12:01, 1631.32 examples/s]Running tokenizer on dataset:  35%|███▍      | 624000/1801350 [06:44<12:07, 1617.62 examples/s]Running tokenizer on dataset:  35%|███▍      | 625000/1801350 [06:44<12:05, 1620.91 examples/s]Running tokenizer on dataset:  35%|███▍      | 625000/1801350 [06:45<12:03, 1626.29 examples/s]Running tokenizer on dataset:  35%|███▍      | 625000/1801350 [06:45<12:09, 1613.57 examples/s]Running tokenizer on dataset:  35%|███▍      | 625000/1801350 [06:45<12:13, 1602.81 examples/s]Running tokenizer on dataset:  35%|███▍      | 626000/1801350 [06:45<11:32, 1698.28 examples/s]Running tokenizer on dataset:  35%|███▍      | 626000/1801350 [06:45<11:35, 1689.11 examples/s]Running tokenizer on dataset:  35%|███▍      | 626000/1801350 [06:45<11:34, 1691.87 examples/s]Running tokenizer on dataset:  35%|███▍      | 626000/1801350 [06:45<11:40, 1676.78 examples/s]Running tokenizer on dataset:  35%|███▍      | 627000/1801350 [06:46<12:07, 1614.55 examples/s]Running tokenizer on dataset:  35%|███▍      | 627000/1801350 [06:46<12:04, 1621.19 examples/s]Running tokenizer on dataset:  35%|███▍      | 627000/1801350 [06:46<12:03, 1622.27 examples/s]Running tokenizer on dataset:  35%|███▍      | 627000/1801350 [06:46<12:07, 1614.54 examples/s]Running tokenizer on dataset:  35%|███▍      | 628000/1801350 [06:46<12:03, 1621.16 examples/s]Running tokenizer on dataset:  35%|███▍      | 628000/1801350 [06:47<12:11, 1603.63 examples/s]Running tokenizer on dataset:  35%|███▍      | 628000/1801350 [06:47<12:14, 1596.69 examples/s]Running tokenizer on dataset:  35%|███▍      | 628000/1801350 [06:47<12:15, 1594.48 examples/s]Running tokenizer on dataset:  35%|███▍      | 629000/1801350 [06:47<11:58, 1632.03 examples/s]Running tokenizer on dataset:  35%|███▍      | 629000/1801350 [06:47<11:59, 1629.19 examples/s]Running tokenizer on dataset:  35%|███▍      | 629000/1801350 [06:47<12:00, 1627.64 examples/s]Running tokenizer on dataset:  35%|███▍      | 629000/1801350 [06:47<11:59, 1629.20 examples/s]Running tokenizer on dataset:  35%|███▍      | 630000/1801350 [06:48<12:08, 1608.60 examples/s]Running tokenizer on dataset:  35%|███▍      | 630000/1801350 [06:48<12:15, 1592.94 examples/s]Running tokenizer on dataset:  35%|███▍      | 630000/1801350 [06:48<12:17, 1587.96 examples/s]Running tokenizer on dataset:  35%|███▍      | 630000/1801350 [06:48<12:15, 1592.01 examples/s]Running tokenizer on dataset:  35%|███▌      | 631000/1801350 [06:48<11:54, 1638.50 examples/s]Running tokenizer on dataset:  35%|███▌      | 631000/1801350 [06:48<11:53, 1640.03 examples/s]Running tokenizer on dataset:  35%|███▌      | 631000/1801350 [06:48<11:58, 1629.35 examples/s]Running tokenizer on dataset:  35%|███▌      | 631000/1801350 [06:49<11:58, 1629.46 examples/s]Running tokenizer on dataset:  35%|███▌      | 632000/1801350 [06:49<11:30, 1694.24 examples/s]Running tokenizer on dataset:  35%|███▌      | 632000/1801350 [06:49<11:35, 1682.50 examples/s]Running tokenizer on dataset:  35%|███▌      | 632000/1801350 [06:49<11:34, 1684.38 examples/s]Running tokenizer on dataset:  35%|███▌      | 632000/1801350 [06:49<11:41, 1667.83 examples/s]Running tokenizer on dataset:  35%|███▌      | 633000/1801350 [06:49<11:24, 1707.87 examples/s]Running tokenizer on dataset:  35%|███▌      | 633000/1801350 [06:49<11:26, 1701.13 examples/s]Running tokenizer on dataset:  35%|███▌      | 633000/1801350 [06:49<11:30, 1693.03 examples/s]Running tokenizer on dataset:  35%|███▌      | 633000/1801350 [06:50<11:31, 1689.17 examples/s]Running tokenizer on dataset:  35%|███▌      | 634000/1801350 [06:50<11:12, 1734.82 examples/s]Running tokenizer on dataset:  35%|███▌      | 634000/1801350 [06:50<11:13, 1733.05 examples/s]Running tokenizer on dataset:  35%|███▌      | 634000/1801350 [06:50<11:16, 1725.16 examples/s]Running tokenizer on dataset:  35%|███▌      | 634000/1801350 [06:50<11:19, 1717.05 examples/s]Running tokenizer on dataset:  35%|███▌      | 635000/1801350 [06:50<11:36, 1674.22 examples/s]Running tokenizer on dataset:  35%|███▌      | 635000/1801350 [06:51<11:39, 1667.61 examples/s]Running tokenizer on dataset:  35%|███▌      | 635000/1801350 [06:51<11:43, 1657.94 examples/s]Running tokenizer on dataset:  35%|███▌      | 635000/1801350 [06:51<11:46, 1651.80 examples/s]Running tokenizer on dataset:  35%|███▌      | 636000/1801350 [06:51<11:29, 1690.75 examples/s]Running tokenizer on dataset:  35%|███▌      | 636000/1801350 [06:51<11:36, 1672.89 examples/s]Running tokenizer on dataset:  35%|███▌      | 636000/1801350 [06:51<11:37, 1669.73 examples/s]Running tokenizer on dataset:  35%|███▌      | 636000/1801350 [06:51<11:39, 1664.93 examples/s]Running tokenizer on dataset:  35%|███▌      | 637000/1801350 [06:52<13:58, 1389.43 examples/s]Running tokenizer on dataset:  35%|███▌      | 637000/1801350 [06:52<13:53, 1397.23 examples/s]Running tokenizer on dataset:  35%|███▌      | 637000/1801350 [06:52<14:01, 1383.29 examples/s]Running tokenizer on dataset:  35%|███▌      | 637000/1801350 [06:52<13:57, 1390.83 examples/s]Running tokenizer on dataset:  35%|███▌      | 638000/1801350 [06:53<13:09, 1474.37 examples/s]Running tokenizer on dataset:  35%|███▌      | 638000/1801350 [06:53<13:14, 1465.12 examples/s]Running tokenizer on dataset:  35%|███▌      | 638000/1801350 [06:53<13:18, 1457.75 examples/s]Running tokenizer on dataset:  35%|███▌      | 638000/1801350 [06:53<13:10, 1470.87 examples/s]Running tokenizer on dataset:  35%|███▌      | 639000/1801350 [06:53<12:42, 1523.51 examples/s]Running tokenizer on dataset:  35%|███▌      | 639000/1801350 [06:53<12:44, 1519.86 examples/s]Running tokenizer on dataset:  35%|███▌      | 639000/1801350 [06:53<12:45, 1518.72 examples/s]Running tokenizer on dataset:  35%|███▌      | 639000/1801350 [06:54<12:43, 1521.82 examples/s]Running tokenizer on dataset:  36%|███▌      | 640000/1801350 [06:54<12:47, 1513.58 examples/s]Running tokenizer on dataset:  36%|███▌      | 640000/1801350 [06:54<12:45, 1517.66 examples/s]Running tokenizer on dataset:  36%|███▌      | 640000/1801350 [06:54<13:00, 1487.59 examples/s]Running tokenizer on dataset:  36%|███▌      | 640000/1801350 [06:54<12:56, 1495.34 examples/s]Running tokenizer on dataset:  36%|███▌      | 641000/1801350 [06:54<12:01, 1608.46 examples/s]Running tokenizer on dataset:  36%|███▌      | 641000/1801350 [06:55<12:03, 1603.67 examples/s]Running tokenizer on dataset:  36%|███▌      | 641000/1801350 [06:55<12:15, 1577.55 examples/s]Running tokenizer on dataset:  36%|███▌      | 641000/1801350 [06:55<12:02, 1605.82 examples/s]Running tokenizer on dataset:  36%|███▌      | 642000/1801350 [06:55<11:56, 1618.02 examples/s]Running tokenizer on dataset:  36%|███▌      | 642000/1801350 [06:55<11:56, 1617.52 examples/s]Running tokenizer on dataset:  36%|███▌      | 642000/1801350 [06:55<12:12, 1582.20 examples/s]Running tokenizer on dataset:  36%|███▌      | 642000/1801350 [06:55<12:04, 1600.30 examples/s]Running tokenizer on dataset:  36%|███▌      | 643000/1801350 [06:56<12:00, 1608.22 examples/s]Running tokenizer on dataset:  36%|███▌      | 643000/1801350 [06:56<11:59, 1610.62 examples/s]Running tokenizer on dataset:  36%|███▌      | 643000/1801350 [06:56<12:07, 1592.99 examples/s]Running tokenizer on dataset:  36%|███▌      | 643000/1801350 [06:56<12:06, 1595.40 examples/s]Running tokenizer on dataset:  36%|███▌      | 644000/1801350 [06:56<12:23, 1557.31 examples/s]Running tokenizer on dataset:  36%|███▌      | 644000/1801350 [06:57<12:23, 1556.75 examples/s]Running tokenizer on dataset:  36%|███▌      | 644000/1801350 [06:57<12:20, 1562.01 examples/s]Running tokenizer on dataset:  36%|███▌      | 644000/1801350 [06:57<12:36, 1530.19 examples/s]Running tokenizer on dataset:  36%|███▌      | 645000/1801350 [06:57<12:38, 1525.24 examples/s]Running tokenizer on dataset:  36%|███▌      | 645000/1801350 [06:57<12:43, 1514.24 examples/s]Running tokenizer on dataset:  36%|███▌      | 645000/1801350 [06:57<12:47, 1507.57 examples/s]Running tokenizer on dataset:  36%|███▌      | 646000/1801350 [06:58<11:50, 1626.35 examples/s]Running tokenizer on dataset:  36%|███▌      | 645000/1801350 [06:58<12:56, 1489.59 examples/s]Running tokenizer on dataset:  36%|███▌      | 646000/1801350 [06:58<11:58, 1608.38 examples/s]Running tokenizer on dataset:  36%|███▌      | 646000/1801350 [06:58<12:03, 1595.92 examples/s]Running tokenizer on dataset:  36%|███▌      | 646000/1801350 [06:58<11:54, 1618.01 examples/s]Running tokenizer on dataset:  36%|███▌      | 647000/1801350 [06:58<12:16, 1568.37 examples/s]Running tokenizer on dataset:  36%|███▌      | 647000/1801350 [06:59<12:17, 1565.07 examples/s]Running tokenizer on dataset:  36%|███▌      | 647000/1801350 [06:59<12:21, 1556.78 examples/s]Running tokenizer on dataset:  36%|███▌      | 647000/1801350 [06:59<12:19, 1561.99 examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1059 > 1024). Running this sequence through the model will result in indexing errors
Running tokenizer on dataset:  36%|███▌      | 648000/1801350 [06:59<12:53, 1491.47 examples/s]Running tokenizer on dataset:  36%|███▌      | 648000/1801350 [06:59<13:07, 1463.85 examples/s]Running tokenizer on dataset:  36%|███▌      | 648000/1801350 [06:59<13:07, 1463.92 examples/s]Running tokenizer on dataset:  36%|███▌      | 648000/1801350 [07:00<13:04, 1470.74 examples/s]Running tokenizer on dataset:  36%|███▌      | 649000/1801350 [07:00<12:53, 1489.84 examples/s]Running tokenizer on dataset:  36%|███▌      | 649000/1801350 [07:00<12:59, 1478.15 examples/s]Running tokenizer on dataset:  36%|███▌      | 649000/1801350 [07:00<13:02, 1472.68 examples/s]Running tokenizer on dataset:  36%|███▌      | 649000/1801350 [07:00<12:58, 1480.54 examples/s]Running tokenizer on dataset:  36%|███▌      | 650000/1801350 [07:00<13:27, 1424.94 examples/s]Running tokenizer on dataset:  36%|███▌      | 650000/1801350 [07:01<13:18, 1441.21 examples/s]Running tokenizer on dataset:  36%|███▌      | 650000/1801350 [07:01<13:25, 1428.48 examples/s]Running tokenizer on dataset:  36%|███▌      | 650000/1801350 [07:01<13:22, 1435.03 examples/s]Running tokenizer on dataset:  36%|███▌      | 651000/1801350 [07:01<13:08, 1458.86 examples/s]Running tokenizer on dataset:  36%|███▌      | 651000/1801350 [07:01<12:54, 1485.08 examples/s]Running tokenizer on dataset:  36%|███▌      | 651000/1801350 [07:01<13:02, 1469.80 examples/s]Running tokenizer on dataset:  36%|███▌      | 651000/1801350 [07:02<13:03, 1468.10 examples/s]Running tokenizer on dataset:  36%|███▌      | 652000/1801350 [07:02<12:33, 1525.50 examples/s]Running tokenizer on dataset:  36%|███▌      | 652000/1801350 [07:02<12:37, 1517.45 examples/s]Running tokenizer on dataset:  36%|███▌      | 652000/1801350 [07:02<12:32, 1527.04 examples/s]Running tokenizer on dataset:  36%|███▌      | 652000/1801350 [07:02<12:32, 1527.48 examples/s]Running tokenizer on dataset:  36%|███▋      | 653000/1801350 [07:02<12:27, 1537.02 examples/s]Running tokenizer on dataset:  36%|███▋      | 653000/1801350 [07:03<12:31, 1528.89 examples/s]Running tokenizer on dataset:  36%|███▋      | 653000/1801350 [07:03<12:25, 1539.47 examples/s]Running tokenizer on dataset:  36%|███▋      | 653000/1801350 [07:03<12:27, 1537.16 examples/s]Running tokenizer on dataset:  36%|███▋      | 654000/1801350 [07:03<12:06, 1578.43 examples/s]Running tokenizer on dataset:  36%|███▋      | 654000/1801350 [07:03<12:04, 1583.27 examples/s]Running tokenizer on dataset:  36%|███▋      | 654000/1801350 [07:03<12:08, 1574.29 examples/s]Running tokenizer on dataset:  36%|███▋      | 654000/1801350 [07:03<12:10, 1570.64 examples/s]Running tokenizer on dataset:  36%|███▋      | 655000/1801350 [07:04<11:53, 1605.79 examples/s]Running tokenizer on dataset:  36%|███▋      | 655000/1801350 [07:04<11:56, 1600.25 examples/s]Running tokenizer on dataset:  36%|███▋      | 655000/1801350 [07:04<11:55, 1602.74 examples/s]Running tokenizer on dataset:  36%|███▋      | 655000/1801350 [07:04<11:59, 1593.28 examples/s]Running tokenizer on dataset:  36%|███▋      | 656000/1801350 [07:04<12:02, 1585.52 examples/s]Running tokenizer on dataset:  36%|███▋      | 656000/1801350 [07:04<11:57, 1595.55 examples/s]Running tokenizer on dataset:  36%|███▋      | 656000/1801350 [07:05<12:05, 1577.90 examples/s]Running tokenizer on dataset:  36%|███▋      | 656000/1801350 [07:05<12:02, 1585.69 examples/s]Running tokenizer on dataset:  36%|███▋      | 657000/1801350 [07:05<11:59, 1590.56 examples/s]Running tokenizer on dataset:  36%|███▋      | 657000/1801350 [07:05<12:02, 1584.42 examples/s]Running tokenizer on dataset:  36%|███▋      | 657000/1801350 [07:05<11:59, 1590.02 examples/s]Running tokenizer on dataset:  36%|███▋      | 657000/1801350 [07:05<12:04, 1579.89 examples/s]Running tokenizer on dataset:  37%|███▋      | 658000/1801350 [07:06<13:38, 1397.26 examples/s]Running tokenizer on dataset:  37%|███▋      | 658000/1801350 [07:06<13:43, 1387.97 examples/s]Running tokenizer on dataset:  37%|███▋      | 658000/1801350 [07:06<14:18, 1332.17 examples/s]Running tokenizer on dataset:  37%|███▋      | 658000/1801350 [07:06<13:39, 1394.97 examples/s]Running tokenizer on dataset:  37%|███▋      | 659000/1801350 [07:06<13:01, 1461.11 examples/s]Running tokenizer on dataset:  37%|███▋      | 659000/1801350 [07:07<13:09, 1446.05 examples/s]Running tokenizer on dataset:  37%|███▋      | 659000/1801350 [07:07<13:22, 1423.33 examples/s]Running tokenizer on dataset:  37%|███▋      | 659000/1801350 [07:07<13:06, 1451.91 examples/s]Running tokenizer on dataset:  37%|███▋      | 660000/1801350 [07:07<12:37, 1506.15 examples/s]Running tokenizer on dataset:  37%|███▋      | 660000/1801350 [07:07<12:48, 1485.26 examples/s]Running tokenizer on dataset:  37%|███▋      | 660000/1801350 [07:07<12:42, 1496.35 examples/s]Running tokenizer on dataset:  37%|███▋      | 660000/1801350 [07:07<12:39, 1503.53 examples/s]Running tokenizer on dataset:  37%|███▋      | 661000/1801350 [07:08<12:27, 1525.96 examples/s]Running tokenizer on dataset:  37%|███▋      | 661000/1801350 [07:08<12:39, 1500.80 examples/s]Running tokenizer on dataset:  37%|███▋      | 661000/1801350 [07:08<12:35, 1509.09 examples/s]Running tokenizer on dataset:  37%|███▋      | 661000/1801350 [07:08<12:32, 1514.92 examples/s]Running tokenizer on dataset:  37%|███▋      | 662000/1801350 [07:08<12:12, 1555.15 examples/s]Running tokenizer on dataset:  37%|███▋      | 662000/1801350 [07:09<12:11, 1556.68 examples/s]Running tokenizer on dataset:  37%|███▋      | 662000/1801350 [07:09<12:26, 1526.73 examples/s]Running tokenizer on dataset:  37%|███▋      | 662000/1801350 [07:09<12:16, 1546.55 examples/s]Running tokenizer on dataset:  37%|███▋      | 663000/1801350 [07:09<12:03, 1572.63 examples/s]Running tokenizer on dataset:  37%|███▋      | 663000/1801350 [07:09<12:09, 1561.49 examples/s]Running tokenizer on dataset:  37%|███▋      | 663000/1801350 [07:09<12:10, 1557.62 examples/s]Running tokenizer on dataset:  37%|███▋      | 663000/1801350 [07:09<12:10, 1559.04 examples/s]Running tokenizer on dataset:  37%|███▋      | 664000/1801350 [07:09<11:59, 1580.10 examples/s]Running tokenizer on dataset:  37%|███▋      | 664000/1801350 [07:10<12:12, 1553.00 examples/s]Running tokenizer on dataset:  37%|███▋      | 664000/1801350 [07:10<12:16, 1544.96 examples/s]Running tokenizer on dataset:  37%|███▋      | 664000/1801350 [07:10<12:10, 1557.80 examples/s]Running tokenizer on dataset:  37%|███▋      | 665000/1801350 [07:10<12:01, 1574.33 examples/s]Running tokenizer on dataset:  37%|███▋      | 665000/1801350 [07:10<12:05, 1565.93 examples/s]Running tokenizer on dataset:  37%|███▋      | 665000/1801350 [07:10<12:08, 1559.58 examples/s]Running tokenizer on dataset:  37%|███▋      | 666000/1801350 [07:11<11:33, 1637.35 examples/s]Running tokenizer on dataset:  37%|███▋      | 665000/1801350 [07:11<12:08, 1559.78 examples/s]Running tokenizer on dataset:  37%|███▋      | 666000/1801350 [07:11<11:38, 1624.36 examples/s]Running tokenizer on dataset:  37%|███▋      | 666000/1801350 [07:11<11:48, 1601.97 examples/s]Running tokenizer on dataset:  37%|███▋      | 666000/1801350 [07:11<11:40, 1619.95 examples/s]Running tokenizer on dataset:  37%|███▋      | 667000/1801350 [07:11<11:53, 1588.85 examples/s]Running tokenizer on dataset:  37%|███▋      | 667000/1801350 [07:12<11:50, 1596.79 examples/s]Running tokenizer on dataset:  37%|███▋      | 667000/1801350 [07:12<11:59, 1577.14 examples/s]Running tokenizer on dataset:  37%|███▋      | 667000/1801350 [07:12<11:49, 1599.80 examples/s]Running tokenizer on dataset:  37%|███▋      | 668000/1801350 [07:12<11:49, 1598.47 examples/s]Running tokenizer on dataset:  37%|███▋      | 668000/1801350 [07:12<11:47, 1601.05 examples/s]Running tokenizer on dataset:  37%|███▋      | 668000/1801350 [07:12<11:52, 1590.57 examples/s]Running tokenizer on dataset:  37%|███▋      | 669000/1801350 [07:13<11:26, 1648.67 examples/s]Running tokenizer on dataset:  37%|███▋      | 668000/1801350 [07:12<11:53, 1589.52 examples/s]Running tokenizer on dataset:  37%|███▋      | 669000/1801350 [07:13<11:33, 1632.04 examples/s]Running tokenizer on dataset:  37%|███▋      | 669000/1801350 [07:13<11:41, 1614.28 examples/s]Running tokenizer on dataset:  37%|███▋      | 670000/1801350 [07:13<11:20, 1662.47 examples/s]Running tokenizer on dataset:  37%|███▋      | 669000/1801350 [07:13<11:41, 1614.04 examples/s]Running tokenizer on dataset:  37%|███▋      | 670000/1801350 [07:13<11:18, 1667.01 examples/s]Running tokenizer on dataset:  37%|███▋      | 670000/1801350 [07:14<11:25, 1650.75 examples/s]Running tokenizer on dataset:  37%|███▋      | 671000/1801350 [07:14<11:17, 1669.54 examples/s]Running tokenizer on dataset:  37%|███▋      | 670000/1801350 [07:14<11:29, 1641.68 examples/s]Running tokenizer on dataset:  37%|███▋      | 671000/1801350 [07:14<11:24, 1650.87 examples/s]Running tokenizer on dataset:  37%|███▋      | 671000/1801350 [07:14<11:26, 1645.98 examples/s]Running tokenizer on dataset:  37%|███▋      | 672000/1801350 [07:14<11:07, 1691.68 examples/s]Running tokenizer on dataset:  37%|███▋      | 671000/1801350 [07:14<11:31, 1634.32 examples/s]Running tokenizer on dataset:  37%|███▋      | 672000/1801350 [07:15<11:08, 1689.17 examples/s]Running tokenizer on dataset:  37%|███▋      | 672000/1801350 [07:15<11:14, 1674.70 examples/s]Running tokenizer on dataset:  37%|███▋      | 673000/1801350 [07:15<11:12, 1677.38 examples/s]Running tokenizer on dataset:  37%|███▋      | 672000/1801350 [07:15<11:14, 1674.63 examples/s]Running tokenizer on dataset:  37%|███▋      | 673000/1801350 [07:15<11:22, 1652.66 examples/s]Running tokenizer on dataset:  37%|███▋      | 673000/1801350 [07:15<11:20, 1657.34 examples/s]Running tokenizer on dataset:  37%|███▋      | 673000/1801350 [07:15<11:16, 1666.89 examples/s]Running tokenizer on dataset:  37%|███▋      | 674000/1801350 [07:16<11:38, 1613.62 examples/s]Running tokenizer on dataset:  37%|███▋      | 674000/1801350 [07:16<11:37, 1616.60 examples/s]Running tokenizer on dataset:  37%|███▋      | 674000/1801350 [07:16<11:40, 1608.90 examples/s]Running tokenizer on dataset:  37%|███▋      | 675000/1801350 [07:16<11:19, 1656.52 examples/s]Running tokenizer on dataset:  37%|███▋      | 674000/1801350 [07:16<11:45, 1598.24 examples/s]Running tokenizer on dataset:  37%|███▋      | 675000/1801350 [07:16<11:28, 1635.12 examples/s]Running tokenizer on dataset:  37%|███▋      | 675000/1801350 [07:17<11:33, 1623.01 examples/s]Running tokenizer on dataset:  38%|███▊      | 676000/1801350 [07:17<11:14, 1667.47 examples/s]Running tokenizer on dataset:  37%|███▋      | 675000/1801350 [07:17<11:37, 1613.86 examples/s]Running tokenizer on dataset:  38%|███▊      | 676000/1801350 [07:17<11:17, 1661.22 examples/s]Running tokenizer on dataset:  38%|███▊      | 676000/1801350 [07:17<11:20, 1654.04 examples/s]Running tokenizer on dataset:  38%|███▊      | 676000/1801350 [07:17<11:11, 1676.38 examples/s]Running tokenizer on dataset:  38%|███▊      | 677000/1801350 [07:17<11:43, 1597.83 examples/s]Running tokenizer on dataset:  38%|███▊      | 677000/1801350 [07:18<11:40, 1605.02 examples/s]Running tokenizer on dataset:  38%|███▊      | 677000/1801350 [07:18<11:45, 1592.63 examples/s]Running tokenizer on dataset:  38%|███▊      | 678000/1801350 [07:18<11:41, 1602.05 examples/s]Running tokenizer on dataset:  38%|███▊      | 677000/1801350 [07:18<11:49, 1584.12 examples/s]Running tokenizer on dataset:  38%|███▊      | 678000/1801350 [07:18<11:50, 1581.77 examples/s]Running tokenizer on dataset:  38%|███▊      | 678000/1801350 [07:19<11:57, 1566.36 examples/s]Running tokenizer on dataset:  38%|███▊      | 678000/1801350 [07:19<11:56, 1567.03 examples/s]Running tokenizer on dataset:  38%|███▊      | 679000/1801350 [07:19<13:41, 1365.64 examples/s]Running tokenizer on dataset:  38%|███▊      | 679000/1801350 [07:19<13:54, 1344.72 examples/s]Running tokenizer on dataset:  38%|███▊      | 679000/1801350 [07:20<14:20, 1305.01 examples/s]Running tokenizer on dataset:  38%|███▊      | 680000/1801350 [07:20<13:04, 1429.81 examples/s]Running tokenizer on dataset:  38%|███▊      | 679000/1801350 [07:20<13:54, 1345.05 examples/s]Running tokenizer on dataset:  38%|███▊      | 680000/1801350 [07:20<13:09, 1420.84 examples/s]Running tokenizer on dataset:  38%|███▊      | 681000/1801350 [07:20<12:03, 1548.33 examples/s]Running tokenizer on dataset:  38%|███▊      | 680000/1801350 [07:20<13:39, 1367.94 examples/s]Running tokenizer on dataset:  38%|███▊      | 680000/1801350 [07:20<13:19, 1401.95 examples/s]Running tokenizer on dataset:  38%|███▊      | 681000/1801350 [07:21<12:24, 1504.30 examples/s]Running tokenizer on dataset:  38%|███▊      | 681000/1801350 [07:21<12:32, 1489.73 examples/s]Running tokenizer on dataset:  38%|███▊      | 681000/1801350 [07:21<12:21, 1511.22 examples/s]Running tokenizer on dataset:  38%|███▊      | 682000/1801350 [07:21<12:32, 1487.37 examples/s]Running tokenizer on dataset:  38%|███▊      | 682000/1801350 [07:21<12:29, 1493.77 examples/s]Running tokenizer on dataset:  38%|███▊      | 683000/1801350 [07:21<12:13, 1523.72 examples/s]Running tokenizer on dataset:  38%|███▊      | 682000/1801350 [07:21<12:38, 1474.85 examples/s]Running tokenizer on dataset:  38%|███▊      | 682000/1801350 [07:22<12:39, 1474.66 examples/s]Running tokenizer on dataset:  38%|███▊      | 683000/1801350 [07:22<12:19, 1512.05 examples/s]Running tokenizer on dataset:  38%|███▊      | 684000/1801350 [07:22<11:35, 1606.26 examples/s]Running tokenizer on dataset:  38%|███▊      | 683000/1801350 [07:22<12:38, 1474.32 examples/s]Running tokenizer on dataset:  38%|███▊      | 683000/1801350 [07:22<12:34, 1482.45 examples/s]Running tokenizer on dataset:  38%|███▊      | 684000/1801350 [07:22<11:44, 1586.46 examples/s]Running tokenizer on dataset:  38%|███▊      | 685000/1801350 [07:23<11:19, 1643.61 examples/s]Running tokenizer on dataset:  38%|███▊      | 684000/1801350 [07:23<12:03, 1544.34 examples/s]Running tokenizer on dataset:  38%|███▊      | 684000/1801350 [07:23<11:53, 1565.54 examples/s]Running tokenizer on dataset:  38%|███▊      | 685000/1801350 [07:23<11:24, 1629.75 examples/s]Running tokenizer on dataset:  38%|███▊      | 686000/1801350 [07:23<11:35, 1603.76 examples/s]Running tokenizer on dataset:  38%|███▊      | 685000/1801350 [07:23<11:26, 1625.91 examples/s]Running tokenizer on dataset:  38%|███▊      | 685000/1801350 [07:23<11:33, 1610.53 examples/s]Running tokenizer on dataset:  38%|███▊      | 686000/1801350 [07:24<11:29, 1618.26 examples/s]Running tokenizer on dataset:  38%|███▊      | 686000/1801350 [07:24<11:42, 1588.82 examples/s]Running tokenizer on dataset:  38%|███▊      | 687000/1801350 [07:24<11:51, 1565.53 examples/s]Running tokenizer on dataset:  38%|███▊      | 686000/1801350 [07:24<11:37, 1598.29 examples/s]Running tokenizer on dataset:  38%|███▊      | 687000/1801350 [07:24<11:50, 1567.74 examples/s]Running tokenizer on dataset:  38%|███▊      | 688000/1801350 [07:25<11:29, 1614.89 examples/s]Running tokenizer on dataset:  38%|███▊      | 687000/1801350 [07:25<11:56, 1554.55 examples/s]Running tokenizer on dataset:  38%|███▊      | 687000/1801350 [07:25<12:00, 1546.72 examples/s]Running tokenizer on dataset:  38%|███▊      | 688000/1801350 [07:25<11:40, 1589.63 examples/s]Running tokenizer on dataset:  38%|███▊      | 688000/1801350 [07:25<11:38, 1593.62 examples/s]Running tokenizer on dataset:  38%|███▊      | 689000/1801350 [07:25<11:53, 1558.21 examples/s]Running tokenizer on dataset:  38%|███▊      | 688000/1801350 [07:25<11:45, 1578.65 examples/s]Running tokenizer on dataset:  38%|███▊      | 689000/1801350 [07:26<11:57, 1549.75 examples/s]Running tokenizer on dataset:  38%|███▊      | 690000/1801350 [07:26<11:37, 1593.31 examples/s]Running tokenizer on dataset:  38%|███▊      | 689000/1801350 [07:26<11:54, 1555.90 examples/s]Running tokenizer on dataset:  38%|███▊      | 689000/1801350 [07:26<11:56, 1552.42 examples/s]Running tokenizer on dataset:  38%|███▊      | 690000/1801350 [07:26<11:47, 1571.92 examples/s]Running tokenizer on dataset:  38%|███▊      | 691000/1801350 [07:27<12:06, 1527.48 examples/s]Running tokenizer on dataset:  38%|███▊      | 690000/1801350 [07:26<11:54, 1555.42 examples/s]Running tokenizer on dataset:  38%|███▊      | 690000/1801350 [07:27<11:48, 1569.31 examples/s]Running tokenizer on dataset:  38%|███▊      | 691000/1801350 [07:27<12:11, 1517.11 examples/s]Running tokenizer on dataset:  38%|███▊      | 691000/1801350 [07:27<12:05, 1531.36 examples/s]Running tokenizer on dataset:  38%|███▊      | 692000/1801350 [07:27<12:20, 1498.51 examples/s]Running tokenizer on dataset:  38%|███▊      | 691000/1801350 [07:27<12:06, 1527.79 examples/s]Running tokenizer on dataset:  38%|███▊      | 692000/1801350 [07:28<12:17, 1504.94 examples/s]Running tokenizer on dataset:  38%|███▊      | 693000/1801350 [07:28<12:24, 1489.19 examples/s]Running tokenizer on dataset:  38%|███▊      | 692000/1801350 [07:28<12:23, 1492.70 examples/s]Running tokenizer on dataset:  38%|███▊      | 692000/1801350 [07:28<12:25, 1488.72 examples/s]Running tokenizer on dataset:  38%|███▊      | 693000/1801350 [07:28<12:27, 1483.41 examples/s]Running tokenizer on dataset:  39%|███▊      | 694000/1801350 [07:29<12:09, 1517.93 examples/s]Running tokenizer on dataset:  38%|███▊      | 693000/1801350 [07:29<12:32, 1472.11 examples/s]Running tokenizer on dataset:  38%|███▊      | 693000/1801350 [07:29<12:29, 1478.58 examples/s]Running tokenizer on dataset:  39%|███▊      | 694000/1801350 [07:29<12:15, 1504.80 examples/s]Running tokenizer on dataset:  39%|███▊      | 695000/1801350 [07:29<11:55, 1545.39 examples/s]Running tokenizer on dataset:  39%|███▊      | 694000/1801350 [07:29<12:18, 1498.55 examples/s]Running tokenizer on dataset:  39%|███▊      | 694000/1801350 [07:29<12:16, 1502.60 examples/s]Running tokenizer on dataset:  39%|███▊      | 695000/1801350 [07:30<12:04, 1527.73 examples/s]Running tokenizer on dataset:  39%|███▊      | 696000/1801350 [07:30<11:57, 1539.73 examples/s]Running tokenizer on dataset:  39%|███▊      | 695000/1801350 [07:30<12:08, 1518.32 examples/s]Running tokenizer on dataset:  39%|███▊      | 695000/1801350 [07:30<12:04, 1527.53 examples/s]Running tokenizer on dataset:  39%|███▊      | 696000/1801350 [07:30<12:04, 1525.31 examples/s]Running tokenizer on dataset:  39%|███▊      | 697000/1801350 [07:30<12:08, 1514.94 examples/s]Running tokenizer on dataset:  39%|███▊      | 696000/1801350 [07:30<12:05, 1524.53 examples/s]Running tokenizer on dataset:  39%|███▊      | 696000/1801350 [07:31<12:10, 1512.58 examples/s]Running tokenizer on dataset:  39%|███▊      | 697000/1801350 [07:31<12:05, 1522.40 examples/s]Running tokenizer on dataset:  39%|███▊      | 698000/1801350 [07:31<11:45, 1563.68 examples/s]Running tokenizer on dataset:  39%|███▊      | 697000/1801350 [07:31<12:10, 1512.70 examples/s]Running tokenizer on dataset:  39%|███▊      | 697000/1801350 [07:31<12:11, 1509.01 examples/s]Running tokenizer on dataset:  39%|███▊      | 698000/1801350 [07:32<11:52, 1548.34 examples/s]Running tokenizer on dataset:  39%|███▉      | 699000/1801350 [07:32<11:56, 1538.60 examples/s]Running tokenizer on dataset:  39%|███▊      | 698000/1801350 [07:32<11:44, 1565.46 examples/s]Running tokenizer on dataset:  39%|███▊      | 698000/1801350 [07:32<11:56, 1540.06 examples/s]Running tokenizer on dataset:  39%|███▉      | 699000/1801350 [07:32<11:59, 1532.13 examples/s]Running tokenizer on dataset:  39%|███▉      | 699000/1801350 [07:32<12:01, 1528.27 examples/s]Running tokenizer on dataset:  39%|███▉      | 699000/1801350 [07:33<12:02, 1526.23 examples/s]Running tokenizer on dataset:  39%|███▉      | 700000/1801350 [07:33<13:42, 1339.03 examples/s]Running tokenizer on dataset:  39%|███▉      | 700000/1801350 [07:33<13:51, 1325.25 examples/s]Running tokenizer on dataset:  39%|███▉      | 701000/1801350 [07:33<12:59, 1412.39 examples/s]Running tokenizer on dataset:  39%|███▉      | 700000/1801350 [07:33<13:49, 1326.99 examples/s]Running tokenizer on dataset:  39%|███▉      | 700000/1801350 [07:34<14:03, 1305.48 examples/s]Running tokenizer on dataset:  39%|███▉      | 702000/1801350 [07:34<11:51, 1545.59 examples/s]Running tokenizer on dataset:  39%|███▉      | 701000/1801350 [07:34<13:06, 1398.48 examples/s]Running tokenizer on dataset:  39%|███▉      | 701000/1801350 [07:34<13:04, 1402.01 examples/s]Running tokenizer on dataset:  39%|███▉      | 701000/1801350 [07:34<13:07, 1397.32 examples/s]Running tokenizer on dataset:  39%|███▉      | 702000/1801350 [07:34<12:06, 1513.95 examples/s]Running tokenizer on dataset:  39%|███▉      | 703000/1801350 [07:34<11:45, 1555.80 examples/s]Running tokenizer on dataset:  39%|███▉      | 702000/1801350 [07:35<12:21, 1483.59 examples/s]Running tokenizer on dataset:  39%|███▉      | 702000/1801350 [07:35<12:18, 1487.68 examples/s]Running tokenizer on dataset:  39%|███▉      | 703000/1801350 [07:35<11:45, 1557.55 examples/s]Running tokenizer on dataset:  39%|███▉      | 704000/1801350 [07:35<11:39, 1568.59 examples/s]Running tokenizer on dataset:  39%|███▉      | 703000/1801350 [07:35<11:50, 1545.74 examples/s]Running tokenizer on dataset:  39%|███▉      | 703000/1801350 [07:35<11:56, 1533.92 examples/s]Running tokenizer on dataset:  39%|███▉      | 704000/1801350 [07:36<11:36, 1575.96 examples/s]Running tokenizer on dataset:  39%|███▉      | 705000/1801350 [07:36<11:49, 1545.94 examples/s]Running tokenizer on dataset:  39%|███▉      | 704000/1801350 [07:36<11:40, 1567.17 examples/s]Running tokenizer on dataset:  39%|███▉      | 704000/1801350 [07:36<11:50, 1545.00 examples/s]Running tokenizer on dataset:  39%|███▉      | 705000/1801350 [07:36<11:49, 1546.13 examples/s]Running tokenizer on dataset:  39%|███▉      | 706000/1801350 [07:37<12:27, 1464.65 examples/s]Running tokenizer on dataset:  39%|███▉      | 705000/1801350 [07:37<11:50, 1544.04 examples/s]Running tokenizer on dataset:  39%|███▉      | 705000/1801350 [07:37<12:00, 1521.70 examples/s]Running tokenizer on dataset:  39%|███▉      | 706000/1801350 [07:37<12:29, 1461.24 examples/s]Running tokenizer on dataset:  39%|███▉      | 707000/1801350 [07:37<11:56, 1528.23 examples/s]Running tokenizer on dataset:  39%|███▉      | 706000/1801350 [07:37<12:33, 1452.80 examples/s]Running tokenizer on dataset:  39%|███▉      | 706000/1801350 [07:37<12:29, 1462.01 examples/s]Running tokenizer on dataset:  39%|███▉      | 707000/1801350 [07:38<12:07, 1503.88 examples/s]Running tokenizer on dataset:  39%|███▉      | 708000/1801350 [07:38<11:55, 1527.05 examples/s]Running tokenizer on dataset:  39%|███▉      | 707000/1801350 [07:38<12:10, 1497.54 examples/s]Running tokenizer on dataset:  39%|███▉      | 707000/1801350 [07:38<12:09, 1499.30 examples/s]Running tokenizer on dataset:  39%|███▉      | 708000/1801350 [07:38<11:59, 1518.62 examples/s]Running tokenizer on dataset:  39%|███▉      | 709000/1801350 [07:38<11:36, 1568.34 examples/s]Running tokenizer on dataset:  39%|███▉      | 708000/1801350 [07:39<11:54, 1529.56 examples/s]Running tokenizer on dataset:  39%|███▉      | 708000/1801350 [07:39<11:59, 1519.18 examples/s]Running tokenizer on dataset:  39%|███▉      | 709000/1801350 [07:39<11:36, 1567.56 examples/s]Running tokenizer on dataset:  39%|███▉      | 710000/1801350 [07:39<11:28, 1585.12 examples/s]Running tokenizer on dataset:  39%|███▉      | 709000/1801350 [07:39<11:37, 1566.50 examples/s]Running tokenizer on dataset:  39%|███▉      | 709000/1801350 [07:39<11:44, 1551.55 examples/s]Running tokenizer on dataset:  39%|███▉      | 710000/1801350 [07:40<11:29, 1583.13 examples/s]Running tokenizer on dataset:  39%|███▉      | 711000/1801350 [07:40<11:20, 1601.57 examples/s]Running tokenizer on dataset:  39%|███▉      | 710000/1801350 [07:40<11:33, 1574.15 examples/s]Running tokenizer on dataset:  39%|███▉      | 710000/1801350 [07:40<11:32, 1576.92 examples/s]Running tokenizer on dataset:  39%|███▉      | 711000/1801350 [07:40<11:33, 1572.56 examples/s]Running tokenizer on dataset:  40%|███▉      | 712000/1801350 [07:40<11:05, 1637.13 examples/s]Running tokenizer on dataset:  39%|███▉      | 711000/1801350 [07:40<11:28, 1583.24 examples/s]Running tokenizer on dataset:  39%|███▉      | 711000/1801350 [07:41<11:27, 1586.74 examples/s]Running tokenizer on dataset:  40%|███▉      | 713000/1801350 [07:41<10:59, 1651.35 examples/s]Running tokenizer on dataset:  40%|███▉      | 712000/1801350 [07:41<11:21, 1597.55 examples/s]Running tokenizer on dataset:  40%|███▉      | 712000/1801350 [07:41<11:17, 1607.49 examples/s]Running tokenizer on dataset:  40%|███▉      | 712000/1801350 [07:41<11:13, 1617.69 examples/s]Running tokenizer on dataset:  40%|███▉      | 713000/1801350 [07:41<11:01, 1644.43 examples/s]Running tokenizer on dataset:  40%|███▉      | 714000/1801350 [07:41<11:14, 1611.36 examples/s]Running tokenizer on dataset:  40%|███▉      | 713000/1801350 [07:42<11:00, 1647.24 examples/s]Running tokenizer on dataset:  40%|███▉      | 713000/1801350 [07:42<11:06, 1633.50 examples/s]Running tokenizer on dataset:  40%|███▉      | 714000/1801350 [07:42<11:09, 1623.95 examples/s]Running tokenizer on dataset:  40%|███▉      | 715000/1801350 [07:42<11:15, 1607.59 examples/s]Running tokenizer on dataset:  40%|███▉      | 714000/1801350 [07:42<11:10, 1622.19 examples/s]Running tokenizer on dataset:  40%|███▉      | 714000/1801350 [07:42<11:09, 1624.80 examples/s]Running tokenizer on dataset:  40%|███▉      | 716000/1801350 [07:43<11:00, 1642.35 examples/s]Running tokenizer on dataset:  40%|███▉      | 715000/1801350 [07:43<11:18, 1600.77 examples/s]Running tokenizer on dataset:  40%|███▉      | 715000/1801350 [07:43<11:15, 1609.09 examples/s]Running tokenizer on dataset:  40%|███▉      | 715000/1801350 [07:43<11:21, 1595.12 examples/s]Running tokenizer on dataset:  40%|███▉      | 716000/1801350 [07:43<11:11, 1615.56 examples/s]Running tokenizer on dataset:  40%|███▉      | 717000/1801350 [07:43<10:54, 1657.68 examples/s]Running tokenizer on dataset:  40%|███▉      | 716000/1801350 [07:43<11:12, 1613.26 examples/s]Running tokenizer on dataset:  40%|███▉      | 716000/1801350 [07:44<11:06, 1629.22 examples/s]Running tokenizer on dataset:  40%|███▉      | 717000/1801350 [07:44<11:05, 1628.34 examples/s]Running tokenizer on dataset:  40%|███▉      | 718000/1801350 [07:44<11:35, 1558.01 examples/s]Running tokenizer on dataset:  40%|███▉      | 717000/1801350 [07:44<11:00, 1641.98 examples/s]Running tokenizer on dataset:  40%|███▉      | 717000/1801350 [07:44<11:02, 1637.46 examples/s]Running tokenizer on dataset:  40%|███▉      | 718000/1801350 [07:44<11:31, 1565.73 examples/s]Running tokenizer on dataset:  40%|███▉      | 719000/1801350 [07:45<11:33, 1560.79 examples/s]Running tokenizer on dataset:  40%|███▉      | 718000/1801350 [07:45<11:34, 1560.83 examples/s]Running tokenizer on dataset:  40%|███▉      | 718000/1801350 [07:45<11:30, 1569.67 examples/s]Running tokenizer on dataset:  40%|███▉      | 719000/1801350 [07:45<11:34, 1558.34 examples/s]Running tokenizer on dataset:  40%|███▉      | 720000/1801350 [07:45<11:45, 1533.19 examples/s]Running tokenizer on dataset:  40%|███▉      | 719000/1801350 [07:45<11:30, 1568.36 examples/s]Running tokenizer on dataset:  40%|███▉      | 719000/1801350 [07:46<11:31, 1564.78 examples/s]Running tokenizer on dataset:  40%|███▉      | 720000/1801350 [07:46<11:47, 1529.44 examples/s]Running tokenizer on dataset:  40%|███▉      | 720000/1801350 [07:46<11:45, 1532.55 examples/s]Running tokenizer on dataset:  40%|███▉      | 720000/1801350 [07:46<11:48, 1525.87 examples/s]Running tokenizer on dataset:  40%|████      | 721000/1801350 [07:46<13:38, 1319.13 examples/s]Running tokenizer on dataset:  40%|████      | 722000/1801350 [07:47<12:38, 1423.91 examples/s]Running tokenizer on dataset:  40%|████      | 721000/1801350 [07:47<13:42, 1313.42 examples/s]Running tokenizer on dataset:  40%|████      | 721000/1801350 [07:47<13:32, 1330.43 examples/s]Running tokenizer on dataset:  40%|████      | 721000/1801350 [07:47<13:29, 1334.24 examples/s]Running tokenizer on dataset:  40%|████      | 722000/1801350 [07:47<12:42, 1415.42 examples/s]Running tokenizer on dataset:  40%|████      | 723000/1801350 [07:47<12:10, 1476.94 examples/s]Running tokenizer on dataset:  40%|████      | 722000/1801350 [07:48<12:41, 1416.47 examples/s]Running tokenizer on dataset:  40%|████      | 722000/1801350 [07:48<12:47, 1407.17 examples/s]Running tokenizer on dataset:  40%|████      | 724000/1801350 [07:48<11:43, 1531.58 examples/s]Running tokenizer on dataset:  40%|████      | 723000/1801350 [07:48<12:16, 1464.18 examples/s]Running tokenizer on dataset:  40%|████      | 723000/1801350 [07:48<12:12, 1472.83 examples/s]Running tokenizer on dataset:  40%|████      | 723000/1801350 [07:48<12:12, 1471.17 examples/s]Running tokenizer on dataset:  40%|████      | 724000/1801350 [07:49<11:50, 1516.67 examples/s]Running tokenizer on dataset:  40%|████      | 725000/1801350 [07:49<11:44, 1527.66 examples/s]Running tokenizer on dataset:  40%|████      | 724000/1801350 [07:49<11:48, 1520.34 examples/s]Running tokenizer on dataset:  40%|████      | 724000/1801350 [07:49<11:52, 1512.25 examples/s]Running tokenizer on dataset:  40%|████      | 725000/1801350 [07:49<11:41, 1535.27 examples/s]Running tokenizer on dataset:  40%|████      | 726000/1801350 [07:49<11:58, 1496.11 examples/s]Running tokenizer on dataset:  40%|████      | 725000/1801350 [07:50<11:43, 1529.67 examples/s]Running tokenizer on dataset:  40%|████      | 725000/1801350 [07:50<11:49, 1517.00 examples/s]Running tokenizer on dataset:  40%|████      | 726000/1801350 [07:50<12:00, 1492.15 examples/s]Running tokenizer on dataset:  40%|████      | 727000/1801350 [07:50<11:39, 1535.95 examples/s]Running tokenizer on dataset:  40%|████      | 726000/1801350 [07:50<11:59, 1494.25 examples/s]Running tokenizer on dataset:  40%|████      | 726000/1801350 [07:50<11:59, 1494.06 examples/s]Running tokenizer on dataset:  40%|████      | 728000/1801350 [07:51<11:11, 1597.25 examples/s]Running tokenizer on dataset:  40%|████      | 727000/1801350 [07:51<11:45, 1522.59 examples/s]Running tokenizer on dataset:  40%|████      | 727000/1801350 [07:51<11:34, 1547.67 examples/s]Running tokenizer on dataset:  40%|████      | 727000/1801350 [07:51<11:38, 1538.81 examples/s]Running tokenizer on dataset:  40%|████      | 728000/1801350 [07:51<11:15, 1588.90 examples/s]Running tokenizer on dataset:  40%|████      | 729000/1801350 [07:51<11:44, 1523.15 examples/s]Running tokenizer on dataset:  40%|████      | 728000/1801350 [07:51<11:17, 1585.12 examples/s]Running tokenizer on dataset:  40%|████      | 728000/1801350 [07:52<11:18, 1582.71 examples/s]Running tokenizer on dataset:  40%|████      | 729000/1801350 [07:52<11:33, 1545.52 examples/s]Running tokenizer on dataset:  41%|████      | 730000/1801350 [07:52<11:41, 1526.65 examples/s]Running tokenizer on dataset:  40%|████      | 729000/1801350 [07:52<11:39, 1532.79 examples/s]Running tokenizer on dataset:  40%|████      | 729000/1801350 [07:52<11:37, 1538.38 examples/s]Running tokenizer on dataset:  41%|████      | 731000/1801350 [07:53<11:32, 1546.54 examples/s]Running tokenizer on dataset:  41%|████      | 730000/1801350 [07:53<11:52, 1504.63 examples/s]Running tokenizer on dataset:  41%|████      | 730000/1801350 [07:53<11:42, 1524.79 examples/s]Running tokenizer on dataset:  41%|████      | 730000/1801350 [07:53<11:43, 1522.00 examples/s]Running tokenizer on dataset:  41%|████      | 731000/1801350 [07:53<11:33, 1542.50 examples/s]Running tokenizer on dataset:  41%|████      | 732000/1801350 [07:53<11:43, 1519.94 examples/s]Running tokenizer on dataset:  41%|████      | 731000/1801350 [07:53<11:38, 1532.68 examples/s]Running tokenizer on dataset:  41%|████      | 731000/1801350 [07:54<11:36, 1536.70 examples/s]Running tokenizer on dataset:  41%|████      | 733000/1801350 [07:54<11:23, 1562.90 examples/s]Running tokenizer on dataset:  41%|████      | 732000/1801350 [07:54<11:44, 1518.25 examples/s]Running tokenizer on dataset:  41%|████      | 732000/1801350 [07:54<11:37, 1533.23 examples/s]Running tokenizer on dataset:  41%|████      | 732000/1801350 [07:54<11:35, 1537.10 examples/s]Running tokenizer on dataset:  41%|████      | 734000/1801350 [07:54<10:36, 1676.93 examples/s]Running tokenizer on dataset:  41%|████      | 733000/1801350 [07:55<11:32, 1542.30 examples/s]Running tokenizer on dataset:  41%|████      | 733000/1801350 [07:55<11:26, 1556.30 examples/s]Running tokenizer on dataset:  41%|████      | 733000/1801350 [07:55<11:28, 1550.92 examples/s]Running tokenizer on dataset:  41%|████      | 734000/1801350 [07:55<10:37, 1673.10 examples/s]Running tokenizer on dataset:  41%|████      | 735000/1801350 [07:55<11:04, 1605.16 examples/s]Running tokenizer on dataset:  41%|████      | 734000/1801350 [07:55<10:44, 1656.50 examples/s]Running tokenizer on dataset:  41%|████      | 734000/1801350 [07:55<10:42, 1661.80 examples/s]Running tokenizer on dataset:  41%|████      | 735000/1801350 [07:56<11:00, 1613.35 examples/s]Running tokenizer on dataset:  41%|████      | 736000/1801350 [07:56<11:02, 1606.92 examples/s]Running tokenizer on dataset:  41%|████      | 735000/1801350 [07:56<10:59, 1617.28 examples/s]Running tokenizer on dataset:  41%|████      | 735000/1801350 [07:56<11:05, 1601.64 examples/s]Running tokenizer on dataset:  41%|████      | 737000/1801350 [07:56<10:33, 1681.02 examples/s]Running tokenizer on dataset:  41%|████      | 736000/1801350 [07:56<11:12, 1584.43 examples/s]Running tokenizer on dataset:  41%|████      | 736000/1801350 [07:56<11:05, 1601.39 examples/s]Running tokenizer on dataset:  41%|████      | 736000/1801350 [07:57<11:10, 1587.87 examples/s]Running tokenizer on dataset:  41%|████      | 738000/1801350 [07:57<10:42, 1654.80 examples/s]Running tokenizer on dataset:  41%|████      | 737000/1801350 [07:57<10:35, 1675.96 examples/s]Running tokenizer on dataset:  41%|████      | 737000/1801350 [07:57<10:34, 1677.26 examples/s]Running tokenizer on dataset:  41%|████      | 737000/1801350 [07:57<10:38, 1666.30 examples/s]Running tokenizer on dataset:  41%|████      | 739000/1801350 [07:57<10:35, 1670.77 examples/s]Running tokenizer on dataset:  41%|████      | 738000/1801350 [07:57<10:40, 1659.65 examples/s]Running tokenizer on dataset:  41%|████      | 738000/1801350 [07:58<10:41, 1658.24 examples/s]Running tokenizer on dataset:  41%|████      | 738000/1801350 [07:58<10:41, 1658.09 examples/s]Running tokenizer on dataset:  41%|████      | 739000/1801350 [07:58<10:44, 1649.02 examples/s]Running tokenizer on dataset:  41%|████      | 740000/1801350 [07:58<11:09, 1585.20 examples/s]Running tokenizer on dataset:  41%|████      | 739000/1801350 [07:58<10:43, 1651.56 examples/s]Running tokenizer on dataset:  41%|████      | 739000/1801350 [07:58<10:52, 1628.35 examples/s]Running tokenizer on dataset:  41%|████      | 741000/1801350 [07:59<10:52, 1624.92 examples/s]Running tokenizer on dataset:  41%|████      | 740000/1801350 [07:59<11:13, 1576.30 examples/s]Running tokenizer on dataset:  41%|████      | 740000/1801350 [07:59<11:05, 1593.73 examples/s]Running tokenizer on dataset:  41%|████      | 740000/1801350 [07:59<11:12, 1577.59 examples/s]Running tokenizer on dataset:  41%|████      | 741000/1801350 [07:59<10:53, 1622.72 examples/s]Running tokenizer on dataset:  41%|████      | 741000/1801350 [08:00<10:54, 1619.17 examples/s]Running tokenizer on dataset:  41%|████      | 741000/1801350 [08:00<10:55, 1618.24 examples/s]Running tokenizer on dataset:  41%|████      | 742000/1801350 [08:00<13:20, 1323.56 examples/s]Running tokenizer on dataset:  41%|████      | 742000/1801350 [08:00<13:04, 1350.38 examples/s]Running tokenizer on dataset:  41%|████      | 743000/1801350 [08:00<12:39, 1393.01 examples/s]Running tokenizer on dataset:  41%|████      | 742000/1801350 [08:01<13:15, 1331.80 examples/s]Running tokenizer on dataset:  41%|████      | 742000/1801350 [08:01<13:15, 1331.27 examples/s]Running tokenizer on dataset:  41%|████▏     | 744000/1801350 [08:01<12:03, 1460.82 examples/s]Running tokenizer on dataset:  41%|████      | 743000/1801350 [08:01<12:51, 1371.42 examples/s]Running tokenizer on dataset:  41%|████      | 743000/1801350 [08:01<12:40, 1391.31 examples/s]Running tokenizer on dataset:  41%|████      | 743000/1801350 [08:01<12:46, 1381.51 examples/s]Running tokenizer on dataset:  41%|████▏     | 745000/1801350 [08:02<11:46, 1494.48 examples/s]Running tokenizer on dataset:  41%|████▏     | 744000/1801350 [08:02<12:13, 1440.55 examples/s]Running tokenizer on dataset:  41%|████▏     | 744000/1801350 [08:02<12:12, 1443.56 examples/s]Running tokenizer on dataset:  41%|████▏     | 744000/1801350 [08:02<12:18, 1432.28 examples/s]Running tokenizer on dataset:  41%|████▏     | 745000/1801350 [08:02<11:58, 1470.04 examples/s]Running tokenizer on dataset:  41%|████▏     | 746000/1801350 [08:02<12:05, 1454.77 examples/s]Running tokenizer on dataset:  41%|████▏     | 745000/1801350 [08:03<11:54, 1479.23 examples/s]Running tokenizer on dataset:  41%|████▏     | 745000/1801350 [08:03<12:02, 1462.65 examples/s]Running tokenizer on dataset:  41%|████▏     | 747000/1801350 [08:03<11:30, 1526.71 examples/s]Running tokenizer on dataset:  41%|████▏     | 746000/1801350 [08:03<12:00, 1465.26 examples/s]Running tokenizer on dataset:  41%|████▏     | 746000/1801350 [08:03<11:50, 1484.62 examples/s]Running tokenizer on dataset:  41%|████▏     | 746000/1801350 [08:03<12:00, 1464.88 examples/s]Running tokenizer on dataset:  41%|████▏     | 747000/1801350 [08:04<11:32, 1522.05 examples/s]Running tokenizer on dataset:  42%|████▏     | 748000/1801350 [08:04<11:41, 1501.56 examples/s]Running tokenizer on dataset:  41%|████▏     | 747000/1801350 [08:04<11:33, 1520.20 examples/s]Running tokenizer on dataset:  41%|████▏     | 747000/1801350 [08:04<11:35, 1516.57 examples/s]Running tokenizer on dataset:  42%|████▏     | 748000/1801350 [08:04<11:37, 1510.24 examples/s]Running tokenizer on dataset:  42%|████▏     | 749000/1801350 [08:04<11:34, 1515.64 examples/s]Running tokenizer on dataset:  42%|████▏     | 748000/1801350 [08:04<11:34, 1517.38 examples/s]Running tokenizer on dataset:  42%|████▏     | 748000/1801350 [08:05<11:40, 1502.81 examples/s]Running tokenizer on dataset:  42%|████▏     | 749000/1801350 [08:05<11:26, 1532.71 examples/s]Running tokenizer on dataset:  42%|████▏     | 750000/1801350 [08:05<11:24, 1535.96 examples/s]Running tokenizer on dataset:  42%|████▏     | 749000/1801350 [08:05<11:31, 1522.14 examples/s]Running tokenizer on dataset:  42%|████▏     | 749000/1801350 [08:05<11:30, 1523.93 examples/s]Running tokenizer on dataset:  42%|████▏     | 751000/1801350 [08:06<11:16, 1551.92 examples/s]Running tokenizer on dataset:  42%|████▏     | 750000/1801350 [08:06<11:24, 1536.60 examples/s]Running tokenizer on dataset:  42%|████▏     | 750000/1801350 [08:06<11:27, 1529.70 examples/s]Running tokenizer on dataset:  42%|████▏     | 750000/1801350 [08:06<11:19, 1546.83 examples/s]Running tokenizer on dataset:  42%|████▏     | 751000/1801350 [08:06<11:16, 1553.06 examples/s]Running tokenizer on dataset:  42%|████▏     | 752000/1801350 [08:06<11:20, 1541.55 examples/s]Running tokenizer on dataset:  42%|████▏     | 751000/1801350 [08:06<11:16, 1552.81 examples/s]Running tokenizer on dataset:  42%|████▏     | 751000/1801350 [08:07<11:20, 1544.42 examples/s]Running tokenizer on dataset:  42%|████▏     | 753000/1801350 [08:07<11:07, 1570.29 examples/s]Running tokenizer on dataset:  42%|████▏     | 752000/1801350 [08:07<11:29, 1520.83 examples/s]Running tokenizer on dataset:  42%|████▏     | 752000/1801350 [08:07<11:15, 1553.64 examples/s]Running tokenizer on dataset:  42%|████▏     | 752000/1801350 [08:07<11:18, 1545.65 examples/s]Running tokenizer on dataset:  42%|████▏     | 754000/1801350 [08:07<10:46, 1620.84 examples/s]Running tokenizer on dataset:  42%|████▏     | 753000/1801350 [08:07<11:17, 1548.12 examples/s]Running tokenizer on dataset:  42%|████▏     | 753000/1801350 [08:08<11:12, 1559.74 examples/s]Running tokenizer on dataset:  42%|████▏     | 753000/1801350 [08:08<11:13, 1557.64 examples/s]Running tokenizer on dataset:  42%|████▏     | 754000/1801350 [08:08<10:48, 1614.59 examples/s]Running tokenizer on dataset:  42%|████▏     | 755000/1801350 [08:08<11:26, 1523.08 examples/s]Running tokenizer on dataset:  42%|████▏     | 754000/1801350 [08:08<10:49, 1611.51 examples/s]Running tokenizer on dataset:  42%|████▏     | 754000/1801350 [08:08<10:53, 1602.18 examples/s]Running tokenizer on dataset:  42%|████▏     | 755000/1801350 [08:09<11:16, 1546.09 examples/s]Running tokenizer on dataset:  42%|████▏     | 756000/1801350 [08:09<11:47, 1476.63 examples/s]Running tokenizer on dataset:  42%|████▏     | 755000/1801350 [08:09<11:18, 1542.17 examples/s]Running tokenizer on dataset:  42%|████▏     | 755000/1801350 [08:09<11:16, 1545.74 examples/s]Running tokenizer on dataset:  42%|████▏     | 757000/1801350 [08:09<11:21, 1532.83 examples/s]Running tokenizer on dataset:  42%|████▏     | 756000/1801350 [08:10<11:47, 1477.59 examples/s]Running tokenizer on dataset:  42%|████▏     | 756000/1801350 [08:10<11:40, 1491.35 examples/s]Running tokenizer on dataset:  42%|████▏     | 756000/1801350 [08:10<11:45, 1482.48 examples/s]Running tokenizer on dataset:  42%|████▏     | 758000/1801350 [08:10<11:17, 1540.47 examples/s]Running tokenizer on dataset:  42%|████▏     | 757000/1801350 [08:10<11:35, 1501.19 examples/s]Running tokenizer on dataset:  42%|████▏     | 757000/1801350 [08:10<11:33, 1506.05 examples/s]Running tokenizer on dataset:  42%|████▏     | 757000/1801350 [08:11<11:35, 1501.53 examples/s]Running tokenizer on dataset:  42%|████▏     | 759000/1801350 [08:11<11:05, 1565.17 examples/s]Running tokenizer on dataset:  42%|████▏     | 758000/1801350 [08:11<11:26, 1518.90 examples/s]Running tokenizer on dataset:  42%|████▏     | 758000/1801350 [08:11<11:25, 1521.58 examples/s]Running tokenizer on dataset:  42%|████▏     | 758000/1801350 [08:11<11:25, 1522.61 examples/s]Running tokenizer on dataset:  42%|████▏     | 760000/1801350 [08:11<11:03, 1569.74 examples/s]Running tokenizer on dataset:  42%|████▏     | 759000/1801350 [08:11<11:15, 1543.21 examples/s]Running tokenizer on dataset:  42%|████▏     | 759000/1801350 [08:12<11:16, 1540.59 examples/s]Running tokenizer on dataset:  42%|████▏     | 759000/1801350 [08:12<11:16, 1540.82 examples/s]Running tokenizer on dataset:  42%|████▏     | 761000/1801350 [08:12<10:39, 1626.50 examples/s]Running tokenizer on dataset:  42%|████▏     | 760000/1801350 [08:12<11:02, 1572.43 examples/s]Running tokenizer on dataset:  42%|████▏     | 760000/1801350 [08:12<11:01, 1573.55 examples/s]Running tokenizer on dataset:  42%|████▏     | 760000/1801350 [08:12<11:02, 1571.44 examples/s]Running tokenizer on dataset:  42%|████▏     | 762000/1801350 [08:13<10:34, 1637.03 examples/s]Running tokenizer on dataset:  42%|████▏     | 761000/1801350 [08:13<10:42, 1618.59 examples/s]Running tokenizer on dataset:  42%|████▏     | 761000/1801350 [08:13<10:40, 1623.78 examples/s]Running tokenizer on dataset:  42%|████▏     | 761000/1801350 [08:13<10:45, 1611.48 examples/s]Running tokenizer on dataset:  42%|████▏     | 762000/1801350 [08:13<10:30, 1647.96 examples/s]Running tokenizer on dataset:  42%|████▏     | 762000/1801350 [08:13<10:37, 1630.40 examples/s]Running tokenizer on dataset:  42%|████▏     | 762000/1801350 [08:14<10:32, 1642.28 examples/s]Running tokenizer on dataset:  42%|████▏     | 763000/1801350 [08:14<13:47, 1255.36 examples/s]Running tokenizer on dataset:  42%|████▏     | 763000/1801350 [08:14<13:12, 1310.27 examples/s]Running tokenizer on dataset:  42%|████▏     | 764000/1801350 [08:14<12:39, 1365.44 examples/s]Running tokenizer on dataset:  42%|████▏     | 763000/1801350 [08:14<13:07, 1317.80 examples/s]Running tokenizer on dataset:  42%|████▏     | 763000/1801350 [08:15<13:06, 1319.55 examples/s]Running tokenizer on dataset:  42%|████▏     | 764000/1801350 [08:15<12:20, 1401.59 examples/s]Running tokenizer on dataset:  42%|████▏     | 765000/1801350 [08:15<12:15, 1409.72 examples/s]Running tokenizer on dataset:  42%|████▏     | 764000/1801350 [08:15<12:30, 1382.14 examples/s]Running tokenizer on dataset:  42%|████▏     | 764000/1801350 [08:15<12:32, 1378.70 examples/s]Running tokenizer on dataset:  42%|████▏     | 765000/1801350 [08:16<11:52, 1453.83 examples/s]Running tokenizer on dataset:  43%|████▎     | 766000/1801350 [08:16<11:54, 1448.56 examples/s]Running tokenizer on dataset:  42%|████▏     | 765000/1801350 [08:16<12:07, 1425.48 examples/s]Running tokenizer on dataset:  42%|████▏     | 765000/1801350 [08:16<12:05, 1428.84 examples/s]Running tokenizer on dataset:  43%|████▎     | 767000/1801350 [08:16<11:04, 1556.63 examples/s]Running tokenizer on dataset:  43%|████▎     | 766000/1801350 [08:16<11:56, 1444.52 examples/s]Running tokenizer on dataset:  43%|████▎     | 766000/1801350 [08:16<11:50, 1457.75 examples/s]Running tokenizer on dataset:  43%|████▎     | 766000/1801350 [08:17<11:54, 1449.49 examples/s]Running tokenizer on dataset:  43%|████▎     | 767000/1801350 [08:17<11:01, 1564.08 examples/s]Running tokenizer on dataset:  43%|████▎     | 768000/1801350 [08:17<11:09, 1542.75 examples/s]Running tokenizer on dataset:  43%|████▎     | 767000/1801350 [08:17<11:13, 1535.25 examples/s]Running tokenizer on dataset:  43%|████▎     | 767000/1801350 [08:17<11:12, 1538.95 examples/s]Running tokenizer on dataset:  43%|████▎     | 768000/1801350 [08:17<11:01, 1561.53 examples/s]Running tokenizer on dataset:  43%|████▎     | 769000/1801350 [08:18<11:25, 1506.35 examples/s]Running tokenizer on dataset:  43%|████▎     | 768000/1801350 [08:18<10:55, 1575.38 examples/s]Running tokenizer on dataset:  43%|████▎     | 768000/1801350 [08:18<11:02, 1560.04 examples/s]Running tokenizer on dataset:  43%|████▎     | 769000/1801350 [08:18<11:29, 1497.05 examples/s]Running tokenizer on dataset:  43%|████▎     | 770000/1801350 [08:18<11:44, 1464.45 examples/s]Running tokenizer on dataset:  43%|████▎     | 769000/1801350 [08:18<11:24, 1508.33 examples/s]Running tokenizer on dataset:  43%|████▎     | 769000/1801350 [08:19<11:24, 1509.17 examples/s]Running tokenizer on dataset:  43%|████▎     | 770000/1801350 [08:19<11:41, 1470.16 examples/s]Running tokenizer on dataset:  43%|████▎     | 771000/1801350 [08:19<11:32, 1487.01 examples/s]Running tokenizer on dataset:  43%|████▎     | 770000/1801350 [08:19<11:38, 1477.52 examples/s]Running tokenizer on dataset:  43%|████▎     | 770000/1801350 [08:19<11:38, 1475.75 examples/s]Running tokenizer on dataset:  43%|████▎     | 772000/1801350 [08:20<11:07, 1541.45 examples/s]Running tokenizer on dataset:  43%|████▎     | 771000/1801350 [08:20<11:37, 1477.23 examples/s]Running tokenizer on dataset:  43%|████▎     | 771000/1801350 [08:20<11:40, 1470.38 examples/s]Running tokenizer on dataset:  43%|████▎     | 771000/1801350 [08:20<11:41, 1469.18 examples/s]Running tokenizer on dataset:  43%|████▎     | 772000/1801350 [08:20<11:09, 1536.64 examples/s]Running tokenizer on dataset:  43%|████▎     | 773000/1801350 [08:20<10:59, 1559.86 examples/s]Running tokenizer on dataset:  43%|████▎     | 772000/1801350 [08:20<11:10, 1535.56 examples/s]Running tokenizer on dataset:  43%|████▎     | 772000/1801350 [08:21<11:13, 1527.80 examples/s]Running tokenizer on dataset:  43%|████▎     | 774000/1801350 [08:21<10:30, 1629.66 examples/s]Running tokenizer on dataset:  43%|████▎     | 773000/1801350 [08:21<10:59, 1560.11 examples/s]Running tokenizer on dataset:  43%|████▎     | 773000/1801350 [08:21<10:55, 1569.66 examples/s]Running tokenizer on dataset:  43%|████▎     | 773000/1801350 [08:21<10:53, 1573.40 examples/s]Running tokenizer on dataset:  43%|████▎     | 774000/1801350 [08:21<10:34, 1619.05 examples/s]Running tokenizer on dataset:  43%|████▎     | 775000/1801350 [08:21<10:58, 1558.69 examples/s]Running tokenizer on dataset:  43%|████▎     | 774000/1801350 [08:21<10:36, 1613.03 examples/s]Running tokenizer on dataset:  43%|████▎     | 774000/1801350 [08:22<10:42, 1599.85 examples/s]Running tokenizer on dataset:  43%|████▎     | 775000/1801350 [08:22<11:01, 1552.40 examples/s]Running tokenizer on dataset:  43%|████▎     | 776000/1801350 [08:22<10:52, 1571.03 examples/s]Running tokenizer on dataset:  43%|████▎     | 775000/1801350 [08:22<11:04, 1545.54 examples/s]Running tokenizer on dataset:  43%|████▎     | 775000/1801350 [08:22<11:03, 1546.10 examples/s]Running tokenizer on dataset:  43%|████▎     | 776000/1801350 [08:23<10:58, 1556.35 examples/s]Running tokenizer on dataset:  43%|████▎     | 777000/1801350 [08:23<11:21, 1503.05 examples/s]Running tokenizer on dataset:  43%|████▎     | 776000/1801350 [08:23<10:52, 1571.11 examples/s]Running tokenizer on dataset:  43%|████▎     | 776000/1801350 [08:23<10:57, 1558.94 examples/s]Running tokenizer on dataset:  43%|████▎     | 778000/1801350 [08:23<10:42, 1592.31 examples/s]Running tokenizer on dataset:  43%|████▎     | 777000/1801350 [08:23<11:20, 1504.92 examples/s]Running tokenizer on dataset:  43%|████▎     | 777000/1801350 [08:23<11:08, 1531.56 examples/s]Running tokenizer on dataset:  43%|████▎     | 777000/1801350 [08:24<11:08, 1532.15 examples/s]Running tokenizer on dataset:  43%|████▎     | 779000/1801350 [08:24<10:45, 1582.98 examples/s]Running tokenizer on dataset:  43%|████▎     | 778000/1801350 [08:24<10:52, 1569.07 examples/s]Running tokenizer on dataset:  43%|████▎     | 778000/1801350 [08:24<10:52, 1567.34 examples/s]Running tokenizer on dataset:  43%|████▎     | 778000/1801350 [08:24<10:54, 1564.63 examples/s]Running tokenizer on dataset:  43%|████▎     | 779000/1801350 [08:25<10:55, 1560.77 examples/s]Running tokenizer on dataset:  43%|████▎     | 780000/1801350 [08:25<11:03, 1540.05 examples/s]Running tokenizer on dataset:  43%|████▎     | 779000/1801350 [08:25<10:53, 1563.63 examples/s]Running tokenizer on dataset:  43%|████▎     | 779000/1801350 [08:25<10:50, 1570.90 examples/s]Running tokenizer on dataset:  43%|████▎     | 781000/1801350 [08:25<11:07, 1529.70 examples/s]Running tokenizer on dataset:  43%|████▎     | 780000/1801350 [08:25<11:12, 1519.30 examples/s]Running tokenizer on dataset:  43%|████▎     | 780000/1801350 [08:25<11:02, 1540.96 examples/s]Running tokenizer on dataset:  43%|████▎     | 780000/1801350 [08:26<11:09, 1525.85 examples/s]Running tokenizer on dataset:  43%|████▎     | 782000/1801350 [08:26<10:26, 1626.01 examples/s]Running tokenizer on dataset:  43%|████▎     | 781000/1801350 [08:26<11:07, 1529.65 examples/s]Running tokenizer on dataset:  43%|████▎     | 781000/1801350 [08:26<11:07, 1529.19 examples/s]Running tokenizer on dataset:  43%|████▎     | 781000/1801350 [08:26<11:10, 1522.44 examples/s]Running tokenizer on dataset:  43%|████▎     | 782000/1801350 [08:26<10:24, 1631.37 examples/s]Running tokenizer on dataset:  43%|████▎     | 782000/1801350 [08:27<10:21, 1639.64 examples/s]Running tokenizer on dataset:  43%|████▎     | 783000/1801350 [08:27<11:40, 1454.53 examples/s]Running tokenizer on dataset:  43%|████▎     | 782000/1801350 [08:27<10:29, 1618.56 examples/s]Running tokenizer on dataset:  43%|████▎     | 783000/1801350 [08:27<11:18, 1500.82 examples/s]Running tokenizer on dataset:  43%|████▎     | 783000/1801350 [08:27<11:16, 1505.19 examples/s]Running tokenizer on dataset:  43%|████▎     | 783000/1801350 [08:28<11:21, 1495.26 examples/s]Running tokenizer on dataset:  44%|████▎     | 784000/1801350 [08:28<13:28, 1258.03 examples/s]Running tokenizer on dataset:  44%|████▎     | 784000/1801350 [08:28<13:13, 1282.22 examples/s]Running tokenizer on dataset:  44%|████▎     | 785000/1801350 [08:28<12:22, 1369.13 examples/s]Running tokenizer on dataset:  44%|████▎     | 784000/1801350 [08:28<13:17, 1275.36 examples/s]Running tokenizer on dataset:  44%|████▎     | 784000/1801350 [08:29<13:17, 1276.06 examples/s]Running tokenizer on dataset:  44%|████▎     | 785000/1801350 [08:29<12:13, 1386.44 examples/s]Running tokenizer on dataset:  44%|████▎     | 786000/1801350 [08:29<11:52, 1424.57 examples/s]Running tokenizer on dataset:  44%|████▎     | 785000/1801350 [08:29<12:25, 1363.72 examples/s]Running tokenizer on dataset:  44%|████▎     | 785000/1801350 [08:29<12:19, 1374.44 examples/s]Running tokenizer on dataset:  44%|████▎     | 786000/1801350 [08:29<11:48, 1432.09 examples/s]Running tokenizer on dataset:  44%|████▎     | 787000/1801350 [08:30<11:18, 1494.45 examples/s]Running tokenizer on dataset:  44%|████▎     | 786000/1801350 [08:30<11:52, 1425.03 examples/s]Running tokenizer on dataset:  44%|████▎     | 786000/1801350 [08:30<11:57, 1414.90 examples/s]Running tokenizer on dataset:  44%|████▎     | 787000/1801350 [08:30<11:14, 1503.64 examples/s]Running tokenizer on dataset:  44%|████▎     | 788000/1801350 [08:30<11:12, 1506.93 examples/s]Running tokenizer on dataset:  44%|████▎     | 787000/1801350 [08:30<11:20, 1490.54 examples/s]Running tokenizer on dataset:  44%|████▎     | 787000/1801350 [08:31<11:21, 1487.50 examples/s]Running tokenizer on dataset:  44%|████▎     | 788000/1801350 [08:31<11:03, 1528.40 examples/s]Running tokenizer on dataset:  44%|████▍     | 789000/1801350 [08:31<10:59, 1535.22 examples/s]Running tokenizer on dataset:  44%|████▎     | 788000/1801350 [08:31<11:03, 1528.39 examples/s]Running tokenizer on dataset:  44%|████▎     | 788000/1801350 [08:31<11:14, 1503.22 examples/s]Running tokenizer on dataset:  44%|████▍     | 789000/1801350 [08:31<10:59, 1534.69 examples/s]Running tokenizer on dataset:  44%|████▍     | 790000/1801350 [08:31<10:50, 1555.10 examples/s]Running tokenizer on dataset:  44%|████▍     | 789000/1801350 [08:32<11:05, 1520.65 examples/s]Running tokenizer on dataset:  44%|████▍     | 789000/1801350 [08:32<11:09, 1513.17 examples/s]Running tokenizer on dataset:  44%|████▍     | 790000/1801350 [08:32<10:55, 1543.21 examples/s]Running tokenizer on dataset:  44%|████▍     | 791000/1801350 [08:32<10:38, 1582.82 examples/s]Running tokenizer on dataset:  44%|████▍     | 790000/1801350 [08:32<11:01, 1529.06 examples/s]Running tokenizer on dataset:  44%|████▍     | 790000/1801350 [08:32<11:04, 1523.00 examples/s]Running tokenizer on dataset:  44%|████▍     | 791000/1801350 [08:33<10:40, 1577.50 examples/s]Running tokenizer on dataset:  44%|████▍     | 791000/1801350 [08:33<10:34, 1591.25 examples/s]Running tokenizer on dataset:  44%|████▍     | 792000/1801350 [08:33<11:21, 1481.09 examples/s]Running tokenizer on dataset:  44%|████▍     | 791000/1801350 [08:33<10:37, 1584.43 examples/s]Running tokenizer on dataset:  44%|████▍     | 793000/1801350 [08:33<10:30, 1598.31 examples/s]Running tokenizer on dataset:  44%|████▍     | 792000/1801350 [08:33<11:25, 1473.10 examples/s]Running tokenizer on dataset:  44%|████▍     | 792000/1801350 [08:34<11:15, 1494.51 examples/s]Running tokenizer on dataset:  44%|████▍     | 792000/1801350 [08:34<11:12, 1501.67 examples/s]Running tokenizer on dataset:  44%|████▍     | 793000/1801350 [08:34<10:35, 1586.26 examples/s]Running tokenizer on dataset:  44%|████▍     | 794000/1801350 [08:34<11:04, 1516.76 examples/s]Running tokenizer on dataset:  44%|████▍     | 793000/1801350 [08:34<10:40, 1574.09 examples/s]Running tokenizer on dataset:  44%|████▍     | 793000/1801350 [08:34<10:43, 1567.50 examples/s]Running tokenizer on dataset:  44%|████▍     | 795000/1801350 [08:35<10:28, 1601.05 examples/s]Running tokenizer on dataset:  44%|████▍     | 794000/1801350 [08:35<11:08, 1507.34 examples/s]Running tokenizer on dataset:  44%|████▍     | 794000/1801350 [08:35<10:59, 1528.27 examples/s]Running tokenizer on dataset:  44%|████▍     | 794000/1801350 [08:35<11:04, 1517.03 examples/s]Running tokenizer on dataset:  44%|████▍     | 796000/1801350 [08:35<10:29, 1597.92 examples/s]Running tokenizer on dataset:  44%|████▍     | 795000/1801350 [08:35<10:41, 1569.74 examples/s]Running tokenizer on dataset:  44%|████▍     | 795000/1801350 [08:35<10:40, 1571.24 examples/s]Running tokenizer on dataset:  44%|████▍     | 795000/1801350 [08:36<10:40, 1571.97 examples/s]Running tokenizer on dataset:  44%|████▍     | 797000/1801350 [08:36<10:26, 1602.32 examples/s]Running tokenizer on dataset:  44%|████▍     | 796000/1801350 [08:36<10:32, 1590.52 examples/s]Running tokenizer on dataset:  44%|████▍     | 796000/1801350 [08:36<10:36, 1579.55 examples/s]Running tokenizer on dataset:  44%|████▍     | 796000/1801350 [08:36<10:32, 1589.09 examples/s]Running tokenizer on dataset:  44%|████▍     | 798000/1801350 [08:36<10:27, 1598.11 examples/s]Running tokenizer on dataset:  44%|████▍     | 797000/1801350 [08:36<10:36, 1578.19 examples/s]Running tokenizer on dataset:  44%|████▍     | 797000/1801350 [08:37<10:30, 1592.83 examples/s]Running tokenizer on dataset:  44%|████▍     | 797000/1801350 [08:37<10:26, 1601.94 examples/s]Running tokenizer on dataset:  44%|████▍     | 799000/1801350 [08:37<10:22, 1609.43 examples/s]Running tokenizer on dataset:  44%|████▍     | 798000/1801350 [08:37<10:37, 1573.22 examples/s]Running tokenizer on dataset:  44%|████▍     | 798000/1801350 [08:37<10:32, 1586.45 examples/s]Running tokenizer on dataset:  44%|████▍     | 798000/1801350 [08:38<10:32, 1585.54 examples/s]Running tokenizer on dataset:  44%|████▍     | 800000/1801350 [08:38<10:24, 1602.85 examples/s]Running tokenizer on dataset:  44%|████▍     | 799000/1801350 [08:38<10:43, 1558.04 examples/s]Running tokenizer on dataset:  44%|████▍     | 799000/1801350 [08:38<10:34, 1579.66 examples/s]Running tokenizer on dataset:  44%|████▍     | 799000/1801350 [08:38<10:36, 1573.59 examples/s]Running tokenizer on dataset:  44%|████▍     | 800000/1801350 [08:38<10:22, 1609.69 examples/s]Running tokenizer on dataset:  44%|████▍     | 801000/1801350 [08:38<10:51, 1535.81 examples/s]Running tokenizer on dataset:  44%|████▍     | 800000/1801350 [08:38<10:27, 1594.76 examples/s]Running tokenizer on dataset:  44%|████▍     | 800000/1801350 [08:39<10:27, 1595.92 examples/s]Running tokenizer on dataset:  45%|████▍     | 802000/1801350 [08:39<10:19, 1612.12 examples/s]Running tokenizer on dataset:  44%|████▍     | 801000/1801350 [08:39<10:51, 1534.35 examples/s]Running tokenizer on dataset:  44%|████▍     | 801000/1801350 [08:39<10:39, 1563.29 examples/s]Running tokenizer on dataset:  44%|████▍     | 801000/1801350 [08:39<10:47, 1544.37 examples/s]Running tokenizer on dataset:  45%|████▍     | 802000/1801350 [08:40<10:20, 1611.16 examples/s]Running tokenizer on dataset:  45%|████▍     | 803000/1801350 [08:40<11:13, 1481.41 examples/s]Running tokenizer on dataset:  45%|████▍     | 802000/1801350 [08:40<10:25, 1597.72 examples/s]Running tokenizer on dataset:  45%|████▍     | 802000/1801350 [08:40<10:25, 1598.87 examples/s]Running tokenizer on dataset:  45%|████▍     | 804000/1801350 [08:40<10:42, 1552.09 examples/s]Running tokenizer on dataset:  45%|████▍     | 803000/1801350 [08:40<11:07, 1496.65 examples/s]Running tokenizer on dataset:  45%|████▍     | 803000/1801350 [08:41<11:04, 1501.87 examples/s]Running tokenizer on dataset:  45%|████▍     | 803000/1801350 [08:41<10:58, 1515.46 examples/s]Running tokenizer on dataset:  45%|████▍     | 804000/1801350 [08:41<10:51, 1529.86 examples/s]Running tokenizer on dataset:  45%|████▍     | 804000/1801350 [08:41<10:52, 1527.50 examples/s]Running tokenizer on dataset:  45%|████▍     | 805000/1801350 [08:41<12:20, 1345.65 examples/s]Running tokenizer on dataset:  45%|████▍     | 804000/1801350 [08:41<10:53, 1526.23 examples/s]Running tokenizer on dataset:  45%|████▍     | 806000/1801350 [08:42<11:45, 1409.94 examples/s]Running tokenizer on dataset:  45%|████▍     | 805000/1801350 [08:42<12:50, 1293.32 examples/s]Running tokenizer on dataset:  45%|████▍     | 805000/1801350 [08:42<12:23, 1340.13 examples/s]Running tokenizer on dataset:  45%|████▍     | 805000/1801350 [08:42<12:10, 1363.90 examples/s]Running tokenizer on dataset:  45%|████▍     | 807000/1801350 [08:43<11:11, 1480.02 examples/s]Running tokenizer on dataset:  45%|████▍     | 806000/1801350 [08:43<12:06, 1369.12 examples/s]Running tokenizer on dataset:  45%|████▍     | 806000/1801350 [08:43<11:52, 1396.97 examples/s]Running tokenizer on dataset:  45%|████▍     | 806000/1801350 [08:43<11:46, 1409.17 examples/s]Running tokenizer on dataset:  45%|████▍     | 807000/1801350 [08:43<11:26, 1447.58 examples/s]Running tokenizer on dataset:  45%|████▍     | 808000/1801350 [08:43<11:40, 1417.19 examples/s]Running tokenizer on dataset:  45%|████▍     | 807000/1801350 [08:43<11:21, 1458.67 examples/s]Running tokenizer on dataset:  45%|████▍     | 807000/1801350 [08:44<11:22, 1456.37 examples/s]Running tokenizer on dataset:  45%|████▍     | 809000/1801350 [08:44<11:07, 1486.39 examples/s]Running tokenizer on dataset:  45%|████▍     | 808000/1801350 [08:44<11:45, 1407.99 examples/s]Running tokenizer on dataset:  45%|████▍     | 808000/1801350 [08:44<11:35, 1427.99 examples/s]Running tokenizer on dataset:  45%|████▍     | 808000/1801350 [08:44<11:39, 1419.39 examples/s]Running tokenizer on dataset:  45%|████▍     | 810000/1801350 [08:45<10:56, 1508.97 examples/s]Running tokenizer on dataset:  45%|████▍     | 809000/1801350 [08:45<11:18, 1463.37 examples/s]Running tokenizer on dataset:  45%|████▍     | 809000/1801350 [08:45<11:12, 1474.90 examples/s]Running tokenizer on dataset:  45%|████▍     | 809000/1801350 [08:45<11:18, 1462.34 examples/s]Running tokenizer on dataset:  45%|████▍     | 810000/1801350 [08:45<11:01, 1498.47 examples/s]Running tokenizer on dataset:  45%|████▌     | 811000/1801350 [08:45<11:35, 1423.88 examples/s]Running tokenizer on dataset:  45%|████▍     | 810000/1801350 [08:45<11:05, 1489.11 examples/s]Running tokenizer on dataset:  45%|████▍     | 810000/1801350 [08:46<11:07, 1485.27 examples/s]Running tokenizer on dataset:  45%|████▌     | 812000/1801350 [08:46<11:05, 1487.09 examples/s]Running tokenizer on dataset:  45%|████▌     | 811000/1801350 [08:46<11:33, 1427.97 examples/s]Running tokenizer on dataset:  45%|████▌     | 811000/1801350 [08:46<11:24, 1447.34 examples/s]Running tokenizer on dataset:  45%|████▌     | 811000/1801350 [08:46<11:31, 1432.21 examples/s]Running tokenizer on dataset:  45%|████▌     | 813000/1801350 [08:47<11:00, 1495.43 examples/s]Running tokenizer on dataset:  45%|████▌     | 812000/1801350 [08:47<11:09, 1478.61 examples/s]Running tokenizer on dataset:  45%|████▌     | 812000/1801350 [08:47<11:05, 1486.29 examples/s]Running tokenizer on dataset:  45%|████▌     | 812000/1801350 [08:47<11:12, 1472.17 examples/s]Running tokenizer on dataset:  45%|████▌     | 814000/1801350 [08:47<10:28, 1570.71 examples/s]Running tokenizer on dataset:  45%|████▌     | 813000/1801350 [08:47<11:06, 1483.16 examples/s]Running tokenizer on dataset:  45%|████▌     | 813000/1801350 [08:47<11:00, 1497.33 examples/s]Running tokenizer on dataset:  45%|████▌     | 815000/1801350 [08:48<10:06, 1625.24 examples/s]Running tokenizer on dataset:  45%|████▌     | 813000/1801350 [08:48<11:08, 1478.70 examples/s]Running tokenizer on dataset:  45%|████▌     | 814000/1801350 [08:48<10:33, 1559.49 examples/s]Running tokenizer on dataset:  45%|████▌     | 814000/1801350 [08:48<10:31, 1563.48 examples/s]Running tokenizer on dataset:  45%|████▌     | 816000/1801350 [08:48<09:54, 1657.86 examples/s]Running tokenizer on dataset:  45%|████▌     | 814000/1801350 [08:48<10:36, 1552.34 examples/s]Running tokenizer on dataset:  45%|████▌     | 815000/1801350 [08:49<10:17, 1597.55 examples/s]Running tokenizer on dataset:  45%|████▌     | 815000/1801350 [08:49<10:12, 1611.21 examples/s]Running tokenizer on dataset:  45%|████▌     | 817000/1801350 [08:49<09:24, 1743.40 examples/s]Running tokenizer on dataset:  45%|████▌     | 815000/1801350 [08:49<10:15, 1601.44 examples/s]Running tokenizer on dataset:  45%|████▌     | 816000/1801350 [08:49<10:05, 1626.73 examples/s]Running tokenizer on dataset:  45%|████▌     | 816000/1801350 [08:49<10:01, 1636.98 examples/s]Running tokenizer on dataset:  45%|████▌     | 818000/1801350 [08:49<09:19, 1758.51 examples/s]Running tokenizer on dataset:  45%|████▌     | 816000/1801350 [08:49<09:58, 1646.07 examples/s]Running tokenizer on dataset:  45%|████▌     | 817000/1801350 [08:50<09:27, 1734.99 examples/s]Running tokenizer on dataset:  45%|████▌     | 817000/1801350 [08:50<09:29, 1729.31 examples/s]Running tokenizer on dataset:  45%|████▌     | 817000/1801350 [08:50<09:18, 1762.94 examples/s]Running tokenizer on dataset:  45%|████▌     | 819000/1801350 [08:50<09:55, 1648.52 examples/s]Running tokenizer on dataset:  45%|████▌     | 818000/1801350 [08:50<09:20, 1753.98 examples/s]Running tokenizer on dataset:  45%|████▌     | 818000/1801350 [08:50<09:16, 1766.87 examples/s]Running tokenizer on dataset:  45%|████▌     | 818000/1801350 [08:50<09:17, 1762.53 examples/s]Running tokenizer on dataset:  46%|████▌     | 820000/1801350 [08:51<09:46, 1674.65 examples/s]Running tokenizer on dataset:  45%|████▌     | 819000/1801350 [08:51<09:50, 1663.12 examples/s]Running tokenizer on dataset:  45%|████▌     | 819000/1801350 [08:51<09:48, 1669.19 examples/s]Running tokenizer on dataset:  45%|████▌     | 819000/1801350 [08:51<09:50, 1664.51 examples/s]Running tokenizer on dataset:  46%|████▌     | 821000/1801350 [08:51<09:45, 1672.99 examples/s]Running tokenizer on dataset:  46%|████▌     | 820000/1801350 [08:51<09:47, 1670.58 examples/s]Running tokenizer on dataset:  46%|████▌     | 820000/1801350 [08:51<09:44, 1678.77 examples/s]Running tokenizer on dataset:  46%|████▌     | 820000/1801350 [08:52<09:45, 1675.95 examples/s]Running tokenizer on dataset:  46%|████▌     | 822000/1801350 [08:52<10:12, 1597.91 examples/s]Running tokenizer on dataset:  46%|████▌     | 821000/1801350 [08:52<09:44, 1676.03 examples/s]Running tokenizer on dataset:  46%|████▌     | 821000/1801350 [08:52<09:43, 1681.51 examples/s]Running tokenizer on dataset:  46%|████▌     | 821000/1801350 [08:52<09:43, 1679.24 examples/s]Running tokenizer on dataset:  46%|████▌     | 823000/1801350 [08:53<10:07, 1610.42 examples/s]Running tokenizer on dataset:  46%|████▌     | 822000/1801350 [08:53<10:18, 1583.77 examples/s]Running tokenizer on dataset:  46%|████▌     | 822000/1801350 [08:53<10:06, 1613.76 examples/s]Running tokenizer on dataset:  46%|████▌     | 822000/1801350 [08:53<10:17, 1587.13 examples/s]Running tokenizer on dataset:  46%|████▌     | 824000/1801350 [08:53<09:59, 1630.78 examples/s]Running tokenizer on dataset:  46%|████▌     | 823000/1801350 [08:53<10:05, 1616.28 examples/s]Running tokenizer on dataset:  46%|████▌     | 823000/1801350 [08:53<10:13, 1595.52 examples/s]Running tokenizer on dataset:  46%|████▌     | 823000/1801350 [08:54<10:08, 1608.67 examples/s]Running tokenizer on dataset:  46%|████▌     | 825000/1801350 [08:54<10:29, 1550.79 examples/s]Running tokenizer on dataset:  46%|████▌     | 824000/1801350 [08:54<09:59, 1629.27 examples/s]Running tokenizer on dataset:  46%|████▌     | 824000/1801350 [08:54<10:00, 1627.95 examples/s]Running tokenizer on dataset:  46%|████▌     | 824000/1801350 [08:54<10:00, 1628.40 examples/s]Running tokenizer on dataset:  46%|████▌     | 825000/1801350 [08:55<10:23, 1566.09 examples/s]Running tokenizer on dataset:  46%|████▌     | 825000/1801350 [08:55<10:29, 1551.25 examples/s]Running tokenizer on dataset:  46%|████▌     | 826000/1801350 [08:55<12:33, 1295.16 examples/s]Running tokenizer on dataset:  46%|████▌     | 825000/1801350 [08:55<10:31, 1545.95 examples/s]Running tokenizer on dataset:  46%|████▌     | 827000/1801350 [08:56<11:39, 1393.22 examples/s]Running tokenizer on dataset:  46%|████▌     | 826000/1801350 [08:56<12:38, 1286.00 examples/s]Running tokenizer on dataset:  46%|████▌     | 826000/1801350 [08:56<12:54, 1259.91 examples/s]Running tokenizer on dataset:  46%|████▌     | 826000/1801350 [08:56<12:26, 1305.94 examples/s]Running tokenizer on dataset:  46%|████▌     | 828000/1801350 [08:56<10:57, 1481.24 examples/s]Running tokenizer on dataset:  46%|████▌     | 827000/1801350 [08:56<11:45, 1381.25 examples/s]Running tokenizer on dataset:  46%|████▌     | 827000/1801350 [08:56<11:54, 1364.56 examples/s]Running tokenizer on dataset:  46%|████▌     | 827000/1801350 [08:57<11:39, 1393.06 examples/s]Running tokenizer on dataset:  46%|████▌     | 829000/1801350 [08:57<11:26, 1416.64 examples/s]Running tokenizer on dataset:  46%|████▌     | 828000/1801350 [08:57<11:11, 1448.97 examples/s]Running tokenizer on dataset:  46%|████▌     | 828000/1801350 [08:57<11:17, 1437.64 examples/s]Running tokenizer on dataset:  46%|████▌     | 828000/1801350 [08:57<11:07, 1458.64 examples/s]Running tokenizer on dataset:  46%|████▌     | 830000/1801350 [08:58<11:03, 1463.96 examples/s]Running tokenizer on dataset:  46%|████▌     | 829000/1801350 [08:58<11:34, 1399.21 examples/s]Running tokenizer on dataset:  46%|████▌     | 829000/1801350 [08:58<11:38, 1392.02 examples/s]Running tokenizer on dataset:  46%|████▌     | 829000/1801350 [08:58<11:25, 1418.30 examples/s]Running tokenizer on dataset:  46%|████▌     | 831000/1801350 [08:58<11:11, 1445.39 examples/s]Running tokenizer on dataset:  46%|████▌     | 830000/1801350 [08:58<11:10, 1449.11 examples/s]Running tokenizer on dataset:  46%|████▌     | 830000/1801350 [08:58<11:15, 1437.57 examples/s]Running tokenizer on dataset:  46%|████▌     | 830000/1801350 [08:59<11:09, 1451.76 examples/s]Running tokenizer on dataset:  46%|████▌     | 832000/1801350 [08:59<10:42, 1507.68 examples/s]Running tokenizer on dataset:  46%|████▌     | 831000/1801350 [08:59<11:16, 1433.60 examples/s]Running tokenizer on dataset:  46%|████▌     | 831000/1801350 [08:59<11:15, 1437.55 examples/s]Running tokenizer on dataset:  46%|████▌     | 831000/1801350 [08:59<11:21, 1422.95 examples/s]Running tokenizer on dataset:  46%|████▌     | 833000/1801350 [08:59<10:30, 1535.55 examples/s]Running tokenizer on dataset:  46%|████▌     | 832000/1801350 [09:00<10:49, 1491.64 examples/s]Running tokenizer on dataset:  46%|████▌     | 832000/1801350 [09:00<10:49, 1492.93 examples/s]Running tokenizer on dataset:  46%|████▌     | 832000/1801350 [09:00<10:48, 1493.84 examples/s]Running tokenizer on dataset:  46%|████▋     | 834000/1801350 [09:00<10:18, 1563.27 examples/s]Running tokenizer on dataset:  46%|████▌     | 833000/1801350 [09:00<10:50, 1488.69 examples/s]Running tokenizer on dataset:  46%|████▌     | 833000/1801350 [09:00<10:47, 1496.04 examples/s]Running tokenizer on dataset:  46%|████▌     | 833000/1801350 [09:01<10:50, 1487.67 examples/s]Running tokenizer on dataset:  46%|████▋     | 835000/1801350 [09:01<10:15, 1569.52 examples/s]Running tokenizer on dataset:  46%|████▋     | 834000/1801350 [09:01<10:24, 1548.61 examples/s]Running tokenizer on dataset:  46%|████▋     | 834000/1801350 [09:01<10:32, 1529.19 examples/s]Running tokenizer on dataset:  46%|████▋     | 834000/1801350 [09:01<10:24, 1550.18 examples/s]Running tokenizer on dataset:  46%|████▋     | 836000/1801350 [09:01<10:17, 1564.14 examples/s]Running tokenizer on dataset:  46%|████▋     | 835000/1801350 [09:02<10:26, 1542.54 examples/s]Running tokenizer on dataset:  46%|████▋     | 835000/1801350 [09:02<10:19, 1559.91 examples/s]Running tokenizer on dataset:  46%|████▋     | 835000/1801350 [09:02<10:21, 1553.99 examples/s]Running tokenizer on dataset:  46%|████▋     | 837000/1801350 [09:02<10:09, 1581.79 examples/s]Running tokenizer on dataset:  46%|████▋     | 836000/1801350 [09:02<10:16, 1565.84 examples/s]Running tokenizer on dataset:  46%|████▋     | 836000/1801350 [09:02<10:17, 1563.88 examples/s]Running tokenizer on dataset:  46%|████▋     | 836000/1801350 [09:03<10:22, 1550.97 examples/s]Running tokenizer on dataset:  47%|████▋     | 838000/1801350 [09:03<10:08, 1584.26 examples/s]Running tokenizer on dataset:  46%|████▋     | 837000/1801350 [09:03<10:11, 1576.02 examples/s]Running tokenizer on dataset:  46%|████▋     | 837000/1801350 [09:03<10:10, 1578.81 examples/s]Running tokenizer on dataset:  46%|████▋     | 837000/1801350 [09:03<10:06, 1589.93 examples/s]Running tokenizer on dataset:  47%|████▋     | 839000/1801350 [09:03<10:12, 1571.07 examples/s]Running tokenizer on dataset:  47%|████▋     | 838000/1801350 [09:03<10:08, 1583.45 examples/s]Running tokenizer on dataset:  47%|████▋     | 838000/1801350 [09:04<10:08, 1583.96 examples/s]Running tokenizer on dataset:  47%|████▋     | 838000/1801350 [09:04<10:13, 1571.45 examples/s]Running tokenizer on dataset:  47%|████▋     | 840000/1801350 [09:04<10:29, 1528.28 examples/s]Running tokenizer on dataset:  47%|████▋     | 839000/1801350 [09:04<10:06, 1587.94 examples/s]Running tokenizer on dataset:  47%|████▋     | 839000/1801350 [09:04<10:17, 1557.71 examples/s]Running tokenizer on dataset:  47%|████▋     | 839000/1801350 [09:04<10:05, 1590.59 examples/s]Running tokenizer on dataset:  47%|████▋     | 841000/1801350 [09:04<10:00, 1599.53 examples/s]Running tokenizer on dataset:  47%|████▋     | 840000/1801350 [09:05<10:24, 1538.42 examples/s]Running tokenizer on dataset:  47%|████▋     | 840000/1801350 [09:05<10:35, 1513.24 examples/s]Running tokenizer on dataset:  47%|████▋     | 842000/1801350 [09:05<09:44, 1641.17 examples/s]Running tokenizer on dataset:  47%|████▋     | 840000/1801350 [09:05<10:33, 1518.24 examples/s]Running tokenizer on dataset:  47%|████▋     | 841000/1801350 [09:05<10:02, 1594.06 examples/s]Running tokenizer on dataset:  47%|████▋     | 841000/1801350 [09:05<10:01, 1596.06 examples/s]Running tokenizer on dataset:  47%|████▋     | 841000/1801350 [09:06<09:57, 1608.16 examples/s]Running tokenizer on dataset:  47%|████▋     | 843000/1801350 [09:06<10:17, 1553.03 examples/s]Running tokenizer on dataset:  47%|████▋     | 842000/1801350 [09:06<09:52, 1618.88 examples/s]Running tokenizer on dataset:  47%|████▋     | 842000/1801350 [09:06<09:55, 1611.22 examples/s]Running tokenizer on dataset:  47%|████▋     | 842000/1801350 [09:06<09:59, 1601.05 examples/s]Running tokenizer on dataset:  47%|████▋     | 844000/1801350 [09:07<10:58, 1452.88 examples/s]Running tokenizer on dataset:  47%|████▋     | 843000/1801350 [09:07<10:19, 1546.06 examples/s]Running tokenizer on dataset:  47%|████▋     | 843000/1801350 [09:07<10:22, 1540.24 examples/s]Running tokenizer on dataset:  47%|████▋     | 843000/1801350 [09:07<10:23, 1536.25 examples/s]Running tokenizer on dataset:  47%|████▋     | 845000/1801350 [09:07<11:06, 1435.22 examples/s]Running tokenizer on dataset:  47%|████▋     | 844000/1801350 [09:07<10:58, 1453.20 examples/s]Running tokenizer on dataset:  47%|████▋     | 844000/1801350 [09:08<11:00, 1449.79 examples/s]Running tokenizer on dataset:  47%|████▋     | 844000/1801350 [09:08<10:58, 1453.12 examples/s]Running tokenizer on dataset:  47%|████▋     | 846000/1801350 [09:08<10:44, 1481.58 examples/s]Running tokenizer on dataset:  47%|████▋     | 845000/1801350 [09:08<11:14, 1417.98 examples/s]Running tokenizer on dataset:  47%|████▋     | 845000/1801350 [09:08<11:13, 1420.50 examples/s]Running tokenizer on dataset:  47%|████▋     | 845000/1801350 [09:08<11:13, 1420.88 examples/s]Running tokenizer on dataset:  47%|████▋     | 846000/1801350 [09:09<10:41, 1489.77 examples/s]Running tokenizer on dataset:  47%|████▋     | 846000/1801350 [09:09<10:42, 1486.14 examples/s]Running tokenizer on dataset:  47%|████▋     | 847000/1801350 [09:09<12:36, 1262.20 examples/s]Running tokenizer on dataset:  47%|████▋     | 846000/1801350 [09:09<10:48, 1473.72 examples/s]Running tokenizer on dataset:  47%|████▋     | 848000/1801350 [09:10<11:33, 1375.59 examples/s]Running tokenizer on dataset:  47%|████▋     | 847000/1801350 [09:10<12:36, 1261.35 examples/s]Running tokenizer on dataset:  47%|████▋     | 847000/1801350 [09:10<12:41, 1252.64 examples/s]Running tokenizer on dataset:  47%|████▋     | 849000/1801350 [09:10<11:03, 1436.11 examples/s]Running tokenizer on dataset:  47%|████▋     | 847000/1801350 [09:10<12:40, 1254.98 examples/s]Running tokenizer on dataset:  47%|████▋     | 848000/1801350 [09:10<11:41, 1359.00 examples/s]Running tokenizer on dataset:  47%|████▋     | 848000/1801350 [09:11<11:46, 1350.33 examples/s]Running tokenizer on dataset:  47%|████▋     | 848000/1801350 [09:11<11:40, 1361.66 examples/s]Running tokenizer on dataset:  47%|████▋     | 850000/1801350 [09:11<10:49, 1463.80 examples/s]Running tokenizer on dataset:  47%|████▋     | 849000/1801350 [09:11<11:01, 1440.34 examples/s]Running tokenizer on dataset:  47%|████▋     | 849000/1801350 [09:11<11:12, 1417.09 examples/s]Running tokenizer on dataset:  47%|████▋     | 849000/1801350 [09:11<11:00, 1441.09 examples/s]Running tokenizer on dataset:  47%|████▋     | 851000/1801350 [09:12<10:55, 1450.32 examples/s]Running tokenizer on dataset:  47%|████▋     | 850000/1801350 [09:12<10:49, 1464.88 examples/s]Running tokenizer on dataset:  47%|████▋     | 850000/1801350 [09:12<10:52, 1457.96 examples/s]Running tokenizer on dataset:  47%|████▋     | 850000/1801350 [09:12<10:53, 1455.33 examples/s]Running tokenizer on dataset:  47%|████▋     | 852000/1801350 [09:12<10:30, 1505.55 examples/s]Running tokenizer on dataset:  47%|████▋     | 851000/1801350 [09:12<10:52, 1456.68 examples/s]Running tokenizer on dataset:  47%|████▋     | 851000/1801350 [09:13<10:54, 1451.11 examples/s]Running tokenizer on dataset:  47%|████▋     | 851000/1801350 [09:13<10:53, 1455.07 examples/s]Running tokenizer on dataset:  47%|████▋     | 853000/1801350 [09:13<10:29, 1505.83 examples/s]Running tokenizer on dataset:  47%|████▋     | 852000/1801350 [09:13<10:27, 1511.90 examples/s]Running tokenizer on dataset:  47%|████▋     | 852000/1801350 [09:13<10:28, 1509.67 examples/s]Running tokenizer on dataset:  47%|████▋     | 852000/1801350 [09:13<10:37, 1489.27 examples/s]Running tokenizer on dataset:  47%|████▋     | 854000/1801350 [09:14<10:41, 1477.06 examples/s]Running tokenizer on dataset:  47%|████▋     | 853000/1801350 [09:14<10:40, 1479.82 examples/s]Running tokenizer on dataset:  47%|████▋     | 853000/1801350 [09:14<10:42, 1476.56 examples/s]Running tokenizer on dataset:  47%|████▋     | 855000/1801350 [09:14<10:13, 1541.54 examples/s]Running tokenizer on dataset:  47%|████▋     | 853000/1801350 [09:14<10:45, 1469.71 examples/s]Running tokenizer on dataset:  47%|████▋     | 854000/1801350 [09:14<10:32, 1496.94 examples/s]Running tokenizer on dataset:  47%|████▋     | 854000/1801350 [09:14<10:34, 1493.38 examples/s]Running tokenizer on dataset:  48%|████▊     | 856000/1801350 [09:15<10:11, 1544.89 examples/s]Running tokenizer on dataset:  47%|████▋     | 854000/1801350 [09:15<10:46, 1465.32 examples/s]Running tokenizer on dataset:  47%|████▋     | 855000/1801350 [09:15<10:19, 1528.52 examples/s]Running tokenizer on dataset:  47%|████▋     | 855000/1801350 [09:15<10:21, 1523.36 examples/s]Running tokenizer on dataset:  48%|████▊     | 857000/1801350 [09:15<09:59, 1575.87 examples/s]Running tokenizer on dataset:  47%|████▋     | 855000/1801350 [09:15<10:31, 1498.09 examples/s]Running tokenizer on dataset:  48%|████▊     | 856000/1801350 [09:16<10:19, 1525.21 examples/s]Running tokenizer on dataset:  48%|████▊     | 856000/1801350 [09:16<10:15, 1535.68 examples/s]Running tokenizer on dataset:  48%|████▊     | 858000/1801350 [09:16<10:02, 1565.78 examples/s]Running tokenizer on dataset:  48%|████▊     | 856000/1801350 [09:16<10:25, 1511.06 examples/s]Running tokenizer on dataset:  48%|████▊     | 857000/1801350 [09:16<10:07, 1554.10 examples/s]Running tokenizer on dataset:  48%|████▊     | 857000/1801350 [09:16<10:10, 1546.98 examples/s]Running tokenizer on dataset:  48%|████▊     | 857000/1801350 [09:17<10:04, 1563.18 examples/s]Running tokenizer on dataset:  48%|████▊     | 859000/1801350 [09:17<10:25, 1505.60 examples/s]Running tokenizer on dataset:  48%|████▊     | 858000/1801350 [09:17<10:00, 1572.17 examples/s]Running tokenizer on dataset:  48%|████▊     | 858000/1801350 [09:17<10:02, 1564.67 examples/s]Running tokenizer on dataset:  48%|████▊     | 858000/1801350 [09:17<10:02, 1565.40 examples/s]Running tokenizer on dataset:  48%|████▊     | 860000/1801350 [09:17<10:11, 1538.34 examples/s]Running tokenizer on dataset:  48%|████▊     | 859000/1801350 [09:18<10:20, 1518.09 examples/s]Running tokenizer on dataset:  48%|████▊     | 859000/1801350 [09:18<10:23, 1510.28 examples/s]Running tokenizer on dataset:  48%|████▊     | 861000/1801350 [09:18<09:19, 1681.53 examples/s]Running tokenizer on dataset:  48%|████▊     | 859000/1801350 [09:18<10:28, 1499.97 examples/s]Running tokenizer on dataset:  48%|████▊     | 860000/1801350 [09:18<10:10, 1543.02 examples/s]Running tokenizer on dataset:  48%|████▊     | 860000/1801350 [09:18<10:18, 1523.05 examples/s]Running tokenizer on dataset:  48%|████▊     | 862000/1801350 [09:18<09:41, 1616.25 examples/s]Running tokenizer on dataset:  48%|████▊     | 861000/1801350 [09:19<09:17, 1688.07 examples/s]Running tokenizer on dataset:  48%|████▊     | 860000/1801350 [09:19<10:33, 1484.91 examples/s]Running tokenizer on dataset:  48%|████▊     | 861000/1801350 [09:19<09:20, 1677.37 examples/s]Running tokenizer on dataset:  48%|████▊     | 863000/1801350 [09:19<09:17, 1684.62 examples/s]Running tokenizer on dataset:  48%|████▊     | 861000/1801350 [09:19<09:25, 1663.51 examples/s]Running tokenizer on dataset:  48%|████▊     | 862000/1801350 [09:19<09:42, 1613.16 examples/s]Running tokenizer on dataset:  48%|████▊     | 862000/1801350 [09:19<09:36, 1628.19 examples/s]Running tokenizer on dataset:  48%|████▊     | 864000/1801350 [09:20<09:38, 1619.15 examples/s]Running tokenizer on dataset:  48%|████▊     | 862000/1801350 [09:20<09:48, 1595.42 examples/s]Running tokenizer on dataset:  48%|████▊     | 863000/1801350 [09:20<09:24, 1662.64 examples/s]Running tokenizer on dataset:  48%|████▊     | 863000/1801350 [09:20<09:24, 1663.25 examples/s]Running tokenizer on dataset:  48%|████▊     | 865000/1801350 [09:20<09:39, 1617.07 examples/s]Running tokenizer on dataset:  48%|████▊     | 863000/1801350 [09:20<09:23, 1665.22 examples/s]Running tokenizer on dataset:  48%|████▊     | 864000/1801350 [09:21<09:41, 1610.85 examples/s]Running tokenizer on dataset:  48%|████▊     | 864000/1801350 [09:21<09:50, 1588.32 examples/s]Running tokenizer on dataset:  48%|████▊     | 866000/1801350 [09:21<10:01, 1554.28 examples/s]Running tokenizer on dataset:  48%|████▊     | 864000/1801350 [09:21<09:53, 1580.12 examples/s]Running tokenizer on dataset:  48%|████▊     | 865000/1801350 [09:21<09:47, 1593.45 examples/s]Running tokenizer on dataset:  48%|████▊     | 865000/1801350 [09:21<09:51, 1583.10 examples/s]Running tokenizer on dataset:  48%|████▊     | 867000/1801350 [09:22<09:45, 1595.07 examples/s]Running tokenizer on dataset:  48%|████▊     | 865000/1801350 [09:22<09:50, 1586.22 examples/s]Running tokenizer on dataset:  48%|████▊     | 866000/1801350 [09:22<10:08, 1538.05 examples/s]Running tokenizer on dataset:  48%|████▊     | 866000/1801350 [09:22<10:05, 1545.07 examples/s]Running tokenizer on dataset:  48%|████▊     | 866000/1801350 [09:22<10:00, 1557.37 examples/s]Running tokenizer on dataset:  48%|████▊     | 867000/1801350 [09:22<09:49, 1585.53 examples/s]Running tokenizer on dataset:  48%|████▊     | 868000/1801350 [09:23<11:38, 1337.00 examples/s]Running tokenizer on dataset:  48%|████▊     | 867000/1801350 [09:23<09:54, 1571.62 examples/s]Running tokenizer on dataset:  48%|████▊     | 867000/1801350 [09:23<09:51, 1580.22 examples/s]Running tokenizer on dataset:  48%|████▊     | 869000/1801350 [09:23<11:03, 1405.53 examples/s]Running tokenizer on dataset:  48%|████▊     | 868000/1801350 [09:23<11:31, 1349.16 examples/s]Running tokenizer on dataset:  48%|████▊     | 868000/1801350 [09:24<11:28, 1356.58 examples/s]Running tokenizer on dataset:  48%|████▊     | 870000/1801350 [09:24<10:25, 1490.08 examples/s]Running tokenizer on dataset:  48%|████▊     | 868000/1801350 [09:24<11:51, 1311.92 examples/s]Running tokenizer on dataset:  48%|████▊     | 869000/1801350 [09:24<11:05, 1399.95 examples/s]Running tokenizer on dataset:  48%|████▊     | 869000/1801350 [09:24<11:05, 1399.98 examples/s]Running tokenizer on dataset:  48%|████▊     | 871000/1801350 [09:24<10:03, 1541.02 examples/s]Running tokenizer on dataset:  48%|████▊     | 869000/1801350 [09:25<11:24, 1362.00 examples/s]Running tokenizer on dataset:  48%|████▊     | 870000/1801350 [09:25<10:33, 1470.19 examples/s]Running tokenizer on dataset:  48%|████▊     | 870000/1801350 [09:25<10:33, 1469.19 examples/s]Running tokenizer on dataset:  48%|████▊     | 872000/1801350 [09:25<09:51, 1572.25 examples/s]Running tokenizer on dataset:  48%|████▊     | 870000/1801350 [09:25<10:42, 1449.68 examples/s]Running tokenizer on dataset:  48%|████▊     | 871000/1801350 [09:25<10:09, 1526.95 examples/s]Running tokenizer on dataset:  48%|████▊     | 871000/1801350 [09:25<10:06, 1534.62 examples/s]Running tokenizer on dataset:  48%|████▊     | 873000/1801350 [09:26<09:49, 1575.88 examples/s]Running tokenizer on dataset:  48%|████▊     | 871000/1801350 [09:26<10:15, 1511.22 examples/s]Running tokenizer on dataset:  48%|████▊     | 872000/1801350 [09:26<10:00, 1547.57 examples/s]Running tokenizer on dataset:  48%|████▊     | 872000/1801350 [09:26<10:01, 1544.17 examples/s]Running tokenizer on dataset:  49%|████▊     | 874000/1801350 [09:26<09:36, 1609.17 examples/s]Running tokenizer on dataset:  48%|████▊     | 872000/1801350 [09:26<10:04, 1538.39 examples/s]Running tokenizer on dataset:  48%|████▊     | 873000/1801350 [09:27<09:54, 1562.78 examples/s]Running tokenizer on dataset:  48%|████▊     | 873000/1801350 [09:27<09:51, 1570.22 examples/s]Running tokenizer on dataset:  49%|████▊     | 875000/1801350 [09:27<09:34, 1611.64 examples/s]Running tokenizer on dataset:  48%|████▊     | 873000/1801350 [09:27<09:58, 1552.21 examples/s]Running tokenizer on dataset:  49%|████▊     | 874000/1801350 [09:27<09:43, 1590.40 examples/s]Running tokenizer on dataset:  49%|████▊     | 874000/1801350 [09:27<09:44, 1585.58 examples/s]Running tokenizer on dataset:  49%|████▊     | 876000/1801350 [09:27<09:33, 1614.10 examples/s]Running tokenizer on dataset:  49%|████▊     | 874000/1801350 [09:28<09:52, 1565.62 examples/s]Running tokenizer on dataset:  49%|████▊     | 875000/1801350 [09:28<09:37, 1604.33 examples/s]Running tokenizer on dataset:  49%|████▊     | 875000/1801350 [09:28<09:41, 1592.64 examples/s]Running tokenizer on dataset:  49%|████▊     | 877000/1801350 [09:28<09:40, 1592.00 examples/s]Running tokenizer on dataset:  49%|████▊     | 876000/1801350 [09:28<09:25, 1637.35 examples/s]Running tokenizer on dataset:  49%|████▊     | 875000/1801350 [09:28<09:52, 1563.06 examples/s]Running tokenizer on dataset:  49%|████▊     | 876000/1801350 [09:29<09:39, 1597.39 examples/s]Running tokenizer on dataset:  49%|████▊     | 878000/1801350 [09:29<09:39, 1593.12 examples/s]Running tokenizer on dataset:  49%|████▊     | 876000/1801350 [09:29<09:36, 1605.96 examples/s]Running tokenizer on dataset:  49%|████▊     | 877000/1801350 [09:29<09:36, 1602.03 examples/s]Running tokenizer on dataset:  49%|████▊     | 877000/1801350 [09:29<09:40, 1592.43 examples/s]Running tokenizer on dataset:  49%|████▉     | 879000/1801350 [09:29<09:41, 1585.94 examples/s]Running tokenizer on dataset:  49%|████▊     | 877000/1801350 [09:30<09:42, 1585.84 examples/s]Running tokenizer on dataset:  49%|████▊     | 878000/1801350 [09:30<09:46, 1573.70 examples/s]Running tokenizer on dataset:  49%|████▊     | 878000/1801350 [09:30<09:49, 1566.24 examples/s]Running tokenizer on dataset:  49%|████▉     | 880000/1801350 [09:30<09:55, 1546.12 examples/s]Running tokenizer on dataset:  49%|████▊     | 878000/1801350 [09:30<09:52, 1558.28 examples/s]Running tokenizer on dataset:  49%|████▉     | 879000/1801350 [09:30<09:39, 1591.33 examples/s]Running tokenizer on dataset:  49%|████▉     | 879000/1801350 [09:31<09:46, 1571.71 examples/s]Running tokenizer on dataset:  49%|████▉     | 881000/1801350 [09:31<09:55, 1545.31 examples/s]Running tokenizer on dataset:  49%|████▉     | 879000/1801350 [09:31<09:45, 1576.52 examples/s]Running tokenizer on dataset:  49%|████▉     | 880000/1801350 [09:31<09:56, 1545.23 examples/s]Running tokenizer on dataset:  49%|████▉     | 880000/1801350 [09:31<10:02, 1528.47 examples/s]Running tokenizer on dataset:  49%|████▉     | 882000/1801350 [09:31<10:29, 1460.69 examples/s]Running tokenizer on dataset:  49%|████▉     | 880000/1801350 [09:32<10:00, 1534.88 examples/s]Running tokenizer on dataset:  49%|████▉     | 881000/1801350 [09:32<10:00, 1532.56 examples/s]Running tokenizer on dataset:  49%|████▉     | 881000/1801350 [09:32<10:03, 1524.41 examples/s]Running tokenizer on dataset:  49%|████▉     | 883000/1801350 [09:32<10:04, 1519.41 examples/s]Running tokenizer on dataset:  49%|████▉     | 881000/1801350 [09:32<10:02, 1527.10 examples/s]Running tokenizer on dataset:  49%|████▉     | 882000/1801350 [09:32<10:31, 1456.62 examples/s]Running tokenizer on dataset:  49%|████▉     | 882000/1801350 [09:33<10:28, 1461.82 examples/s]Running tokenizer on dataset:  49%|████▉     | 884000/1801350 [09:33<10:00, 1526.48 examples/s]Running tokenizer on dataset:  49%|████▉     | 883000/1801350 [09:33<10:02, 1523.06 examples/s]Running tokenizer on dataset:  49%|████▉     | 882000/1801350 [09:33<10:31, 1455.67 examples/s]Running tokenizer on dataset:  49%|████▉     | 883000/1801350 [09:33<10:11, 1501.64 examples/s]Running tokenizer on dataset:  49%|████▉     | 885000/1801350 [09:33<10:02, 1521.38 examples/s]Running tokenizer on dataset:  49%|████▉     | 884000/1801350 [09:34<09:55, 1540.26 examples/s]Running tokenizer on dataset:  49%|████▉     | 883000/1801350 [09:34<10:16, 1488.87 examples/s]Running tokenizer on dataset:  49%|████▉     | 884000/1801350 [09:34<09:59, 1529.26 examples/s]Running tokenizer on dataset:  49%|████▉     | 886000/1801350 [09:34<09:38, 1582.50 examples/s]Running tokenizer on dataset:  49%|████▉     | 884000/1801350 [09:34<10:00, 1526.52 examples/s]Running tokenizer on dataset:  49%|████▉     | 885000/1801350 [09:34<10:00, 1524.80 examples/s]Running tokenizer on dataset:  49%|████▉     | 887000/1801350 [09:35<09:11, 1658.63 examples/s]Running tokenizer on dataset:  49%|████▉     | 885000/1801350 [09:35<10:13, 1493.25 examples/s]Running tokenizer on dataset:  49%|████▉     | 886000/1801350 [09:35<09:36, 1588.93 examples/s]Running tokenizer on dataset:  49%|████▉     | 885000/1801350 [09:35<10:11, 1498.72 examples/s]Running tokenizer on dataset:  49%|████▉     | 886000/1801350 [09:35<09:37, 1585.07 examples/s]Running tokenizer on dataset:  49%|████▉     | 888000/1801350 [09:35<09:47, 1553.51 examples/s]Running tokenizer on dataset:  49%|████▉     | 887000/1801350 [09:35<09:17, 1641.43 examples/s]Running tokenizer on dataset:  49%|████▉     | 886000/1801350 [09:36<09:43, 1569.86 examples/s]Running tokenizer on dataset:  49%|████▉     | 887000/1801350 [09:36<09:17, 1640.96 examples/s]Running tokenizer on dataset:  49%|████▉     | 887000/1801350 [09:36<09:13, 1653.32 examples/s]Running tokenizer on dataset:  49%|████▉     | 888000/1801350 [09:36<09:51, 1544.66 examples/s]Running tokenizer on dataset:  49%|████▉     | 889000/1801350 [09:36<11:21, 1339.71 examples/s]Running tokenizer on dataset:  49%|████▉     | 888000/1801350 [09:36<09:46, 1557.64 examples/s]Running tokenizer on dataset:  49%|████▉     | 888000/1801350 [09:37<09:50, 1545.58 examples/s]Running tokenizer on dataset:  49%|████▉     | 890000/1801350 [09:37<10:42, 1418.12 examples/s]Running tokenizer on dataset:  49%|████▉     | 889000/1801350 [09:37<11:25, 1331.62 examples/s]Running tokenizer on dataset:  49%|████▉     | 891000/1801350 [09:37<09:58, 1520.13 examples/s]Running tokenizer on dataset:  49%|████▉     | 889000/1801350 [09:37<11:21, 1338.36 examples/s]Running tokenizer on dataset:  49%|████▉     | 890000/1801350 [09:38<10:45, 1412.93 examples/s]Running tokenizer on dataset:  49%|████▉     | 889000/1801350 [09:38<11:32, 1317.32 examples/s]Running tokenizer on dataset:  49%|████▉     | 890000/1801350 [09:38<10:38, 1428.40 examples/s]Running tokenizer on dataset:  50%|████▉     | 892000/1801350 [09:38<10:15, 1476.40 examples/s]Running tokenizer on dataset:  49%|████▉     | 891000/1801350 [09:38<10:04, 1504.89 examples/s]Running tokenizer on dataset:  49%|████▉     | 890000/1801350 [09:38<10:57, 1385.95 examples/s]Running tokenizer on dataset:  49%|████▉     | 891000/1801350 [09:39<10:08, 1495.42 examples/s]Running tokenizer on dataset:  50%|████▉     | 893000/1801350 [09:39<10:16, 1474.05 examples/s]Running tokenizer on dataset:  49%|████▉     | 891000/1801350 [09:39<10:10, 1490.20 examples/s]Running tokenizer on dataset:  50%|████▉     | 892000/1801350 [09:39<10:15, 1477.15 examples/s]Running tokenizer on dataset:  50%|████▉     | 892000/1801350 [09:39<10:10, 1488.50 examples/s]Running tokenizer on dataset:  50%|████▉     | 894000/1801350 [09:39<10:18, 1467.28 examples/s]Running tokenizer on dataset:  50%|████▉     | 893000/1801350 [09:40<10:11, 1484.55 examples/s]Running tokenizer on dataset:  50%|████▉     | 892000/1801350 [09:40<10:23, 1458.93 examples/s]Running tokenizer on dataset:  50%|████▉     | 893000/1801350 [09:40<10:19, 1467.24 examples/s]Running tokenizer on dataset:  50%|████▉     | 895000/1801350 [09:40<10:31, 1435.14 examples/s]Running tokenizer on dataset:  50%|████▉     | 894000/1801350 [09:40<10:22, 1457.15 examples/s]Running tokenizer on dataset:  50%|████▉     | 893000/1801350 [09:40<10:28, 1444.74 examples/s]Running tokenizer on dataset:  50%|████▉     | 894000/1801350 [09:41<10:26, 1449.02 examples/s]Running tokenizer on dataset:  50%|████▉     | 896000/1801350 [09:41<10:05, 1496.41 examples/s]Running tokenizer on dataset:  50%|████▉     | 894000/1801350 [09:41<10:26, 1447.98 examples/s]Running tokenizer on dataset:  50%|████▉     | 895000/1801350 [09:41<10:27, 1445.03 examples/s]Running tokenizer on dataset:  50%|████▉     | 895000/1801350 [09:41<10:32, 1432.90 examples/s]Running tokenizer on dataset:  50%|████▉     | 897000/1801350 [09:41<09:46, 1540.87 examples/s]Running tokenizer on dataset:  50%|████▉     | 896000/1801350 [09:42<10:03, 1498.97 examples/s]Running tokenizer on dataset:  50%|████▉     | 895000/1801350 [09:42<10:37, 1422.43 examples/s]Running tokenizer on dataset:  50%|████▉     | 898000/1801350 [09:42<09:29, 1587.23 examples/s]Running tokenizer on dataset:  50%|████▉     | 896000/1801350 [09:42<10:11, 1479.36 examples/s]Running tokenizer on dataset:  50%|████▉     | 897000/1801350 [09:42<09:47, 1539.10 examples/s]Running tokenizer on dataset:  50%|████▉     | 896000/1801350 [09:42<10:07, 1489.14 examples/s]Running tokenizer on dataset:  50%|████▉     | 899000/1801350 [09:43<09:23, 1601.42 examples/s]Running tokenizer on dataset:  50%|████▉     | 897000/1801350 [09:43<09:42, 1552.23 examples/s]Running tokenizer on dataset:  50%|████▉     | 898000/1801350 [09:43<09:34, 1573.43 examples/s]Running tokenizer on dataset:  50%|████▉     | 897000/1801350 [09:43<09:52, 1525.04 examples/s]Running tokenizer on dataset:  50%|████▉     | 898000/1801350 [09:43<09:25, 1597.77 examples/s]Running tokenizer on dataset:  50%|████▉     | 900000/1801350 [09:43<09:17, 1616.91 examples/s]Running tokenizer on dataset:  50%|████▉     | 899000/1801350 [09:44<09:23, 1601.79 examples/s]Running tokenizer on dataset:  50%|████▉     | 898000/1801350 [09:44<09:38, 1561.35 examples/s]Running tokenizer on dataset:  50%|████▉     | 899000/1801350 [09:44<09:18, 1615.58 examples/s]Running tokenizer on dataset:  50%|█████     | 901000/1801350 [09:44<09:25, 1591.41 examples/s]Running tokenizer on dataset:  50%|████▉     | 900000/1801350 [09:44<09:17, 1617.09 examples/s]Running tokenizer on dataset:  50%|████▉     | 899000/1801350 [09:44<09:27, 1590.08 examples/s]Running tokenizer on dataset:  50%|████▉     | 900000/1801350 [09:44<09:16, 1618.66 examples/s]Running tokenizer on dataset:  50%|█████     | 902000/1801350 [09:45<09:39, 1551.48 examples/s]Running tokenizer on dataset:  50%|█████     | 901000/1801350 [09:45<09:27, 1585.98 examples/s]Running tokenizer on dataset:  50%|████▉     | 900000/1801350 [09:45<09:19, 1612.29 examples/s]Running tokenizer on dataset:  50%|█████     | 901000/1801350 [09:45<09:27, 1585.39 examples/s]Running tokenizer on dataset:  50%|█████     | 903000/1801350 [09:45<10:05, 1484.15 examples/s]Running tokenizer on dataset:  50%|█████     | 902000/1801350 [09:46<09:40, 1550.53 examples/s]Running tokenizer on dataset:  50%|█████     | 901000/1801350 [09:46<09:30, 1579.02 examples/s]Running tokenizer on dataset:  50%|█████     | 902000/1801350 [09:46<09:41, 1547.22 examples/s]Running tokenizer on dataset:  50%|█████     | 904000/1801350 [09:46<09:52, 1515.18 examples/s]Running tokenizer on dataset:  50%|█████     | 902000/1801350 [09:46<09:34, 1565.84 examples/s]Running tokenizer on dataset:  50%|█████     | 903000/1801350 [09:46<10:12, 1466.23 examples/s]Running tokenizer on dataset:  50%|█████     | 903000/1801350 [09:46<10:05, 1483.13 examples/s]Running tokenizer on dataset:  50%|█████     | 905000/1801350 [09:47<10:22, 1439.97 examples/s]Running tokenizer on dataset:  50%|█████     | 904000/1801350 [09:47<09:48, 1524.56 examples/s]Running tokenizer on dataset:  50%|█████     | 903000/1801350 [09:47<10:03, 1487.99 examples/s]Running tokenizer on dataset:  50%|█████     | 904000/1801350 [09:47<09:52, 1515.34 examples/s]Running tokenizer on dataset:  50%|█████     | 906000/1801350 [09:47<09:46, 1526.47 examples/s]Running tokenizer on dataset:  50%|█████     | 904000/1801350 [09:48<09:52, 1514.04 examples/s]Running tokenizer on dataset:  50%|█████     | 905000/1801350 [09:48<10:35, 1410.90 examples/s]Running tokenizer on dataset:  50%|█████     | 907000/1801350 [09:48<09:28, 1573.34 examples/s]Running tokenizer on dataset:  50%|█████     | 905000/1801350 [09:48<10:28, 1426.96 examples/s]Running tokenizer on dataset:  50%|█████     | 906000/1801350 [09:48<09:48, 1522.00 examples/s]Running tokenizer on dataset:  50%|█████     | 905000/1801350 [09:48<10:22, 1441.00 examples/s]Running tokenizer on dataset:  50%|█████     | 906000/1801350 [09:48<09:48, 1522.07 examples/s]Running tokenizer on dataset:  50%|█████     | 908000/1801350 [09:49<10:02, 1481.82 examples/s]Running tokenizer on dataset:  50%|█████     | 907000/1801350 [09:49<09:29, 1569.55 examples/s]Running tokenizer on dataset:  50%|█████     | 906000/1801350 [09:49<09:52, 1510.27 examples/s]Running tokenizer on dataset:  50%|█████     | 907000/1801350 [09:49<09:31, 1564.64 examples/s]Running tokenizer on dataset:  50%|█████     | 909000/1801350 [09:49<09:45, 1524.70 examples/s]Running tokenizer on dataset:  50%|█████     | 907000/1801350 [09:49<09:24, 1584.59 examples/s]Running tokenizer on dataset:  50%|█████     | 908000/1801350 [09:50<10:00, 1487.98 examples/s]Running tokenizer on dataset:  50%|█████     | 908000/1801350 [09:50<09:59, 1490.76 examples/s]Running tokenizer on dataset:  50%|█████     | 909000/1801350 [09:50<09:37, 1545.23 examples/s]Running tokenizer on dataset:  50%|█████     | 908000/1801350 [09:50<10:00, 1488.88 examples/s]Running tokenizer on dataset:  51%|█████     | 910000/1801350 [09:50<11:38, 1276.50 examples/s]Running tokenizer on dataset:  50%|█████     | 909000/1801350 [09:50<09:44, 1525.91 examples/s]Running tokenizer on dataset:  50%|█████     | 909000/1801350 [09:51<09:36, 1548.76 examples/s]Running tokenizer on dataset:  51%|█████     | 911000/1801350 [09:51<10:59, 1350.80 examples/s]Running tokenizer on dataset:  51%|█████     | 910000/1801350 [09:51<11:22, 1305.39 examples/s]Running tokenizer on dataset:  51%|█████     | 910000/1801350 [09:51<11:19, 1310.88 examples/s]Running tokenizer on dataset:  51%|█████     | 912000/1801350 [09:51<09:57, 1488.01 examples/s]Running tokenizer on dataset:  51%|█████     | 911000/1801350 [09:52<10:40, 1390.92 examples/s]Running tokenizer on dataset:  51%|█████     | 910000/1801350 [09:52<11:21, 1307.83 examples/s]Running tokenizer on dataset:  51%|█████     | 911000/1801350 [09:52<10:41, 1387.79 examples/s]Running tokenizer on dataset:  51%|█████     | 913000/1801350 [09:52<09:50, 1505.08 examples/s]Running tokenizer on dataset:  51%|█████     | 912000/1801350 [09:52<09:52, 1501.11 examples/s]Running tokenizer on dataset:  51%|█████     | 911000/1801350 [09:53<10:39, 1392.37 examples/s]Running tokenizer on dataset:  51%|█████     | 912000/1801350 [09:53<09:54, 1496.46 examples/s]Running tokenizer on dataset:  51%|█████     | 914000/1801350 [09:53<09:55, 1489.32 examples/s]Running tokenizer on dataset:  51%|█████     | 913000/1801350 [09:53<09:43, 1522.17 examples/s]Running tokenizer on dataset:  51%|█████     | 912000/1801350 [09:53<09:59, 1484.25 examples/s]Running tokenizer on dataset:  51%|█████     | 913000/1801350 [09:53<09:44, 1521.06 examples/s]Running tokenizer on dataset:  51%|█████     | 915000/1801350 [09:54<10:18, 1433.05 examples/s]Running tokenizer on dataset:  51%|█████     | 913000/1801350 [09:54<09:43, 1522.36 examples/s]Running tokenizer on dataset:  51%|█████     | 914000/1801350 [09:54<09:55, 1490.37 examples/s]Running tokenizer on dataset:  51%|█████     | 914000/1801350 [09:54<09:51, 1498.98 examples/s]Running tokenizer on dataset:  51%|█████     | 916000/1801350 [09:54<09:51, 1497.74 examples/s]Running tokenizer on dataset:  51%|█████     | 914000/1801350 [09:54<09:52, 1498.41 examples/s]Running tokenizer on dataset:  51%|█████     | 915000/1801350 [09:54<10:21, 1426.95 examples/s]Running tokenizer on dataset:  51%|█████     | 917000/1801350 [09:55<09:06, 1619.21 examples/s]Running tokenizer on dataset:  51%|█████     | 915000/1801350 [09:55<10:18, 1432.59 examples/s]Running tokenizer on dataset:  51%|█████     | 916000/1801350 [09:55<09:47, 1507.20 examples/s]Running tokenizer on dataset:  51%|█████     | 915000/1801350 [09:55<10:24, 1418.88 examples/s]Running tokenizer on dataset:  51%|█████     | 918000/1801350 [09:55<09:09, 1608.23 examples/s]Running tokenizer on dataset:  51%|█████     | 916000/1801350 [09:55<09:52, 1493.19 examples/s]Running tokenizer on dataset:  51%|█████     | 917000/1801350 [09:56<09:07, 1616.42 examples/s]Running tokenizer on dataset:  51%|█████     | 917000/1801350 [09:56<09:04, 1623.97 examples/s]Running tokenizer on dataset:  51%|█████     | 916000/1801350 [09:56<09:58, 1480.45 examples/s]Running tokenizer on dataset:  51%|█████     | 919000/1801350 [09:56<09:11, 1598.67 examples/s]Running tokenizer on dataset:  51%|█████     | 918000/1801350 [09:56<09:10, 1604.69 examples/s]Running tokenizer on dataset:  51%|█████     | 917000/1801350 [09:56<09:14, 1594.69 examples/s]Running tokenizer on dataset:  51%|█████     | 918000/1801350 [09:56<09:18, 1581.85 examples/s]Running tokenizer on dataset:  51%|█████     | 920000/1801350 [09:57<09:12, 1594.32 examples/s]Running tokenizer on dataset:  51%|█████     | 919000/1801350 [09:57<09:10, 1602.47 examples/s]Running tokenizer on dataset:  51%|█████     | 921000/1801350 [09:57<08:20, 1759.01 examples/s]Running tokenizer on dataset:  51%|█████     | 918000/1801350 [09:57<09:23, 1568.99 examples/s]Running tokenizer on dataset:  51%|█████     | 919000/1801350 [09:57<09:14, 1591.08 examples/s]Running tokenizer on dataset:  51%|█████     | 920000/1801350 [09:57<09:07, 1610.91 examples/s]Running tokenizer on dataset:  51%|█████     | 919000/1801350 [09:58<09:06, 1615.18 examples/s]Running tokenizer on dataset:  51%|█████     | 922000/1801350 [09:58<08:45, 1672.42 examples/s]Running tokenizer on dataset:  51%|█████     | 920000/1801350 [09:58<09:17, 1580.14 examples/s]Running tokenizer on dataset:  51%|█████     | 921000/1801350 [09:58<08:36, 1703.39 examples/s]Running tokenizer on dataset:  51%|█████     | 921000/1801350 [09:58<08:21, 1754.55 examples/s]Running tokenizer on dataset:  51%|█████     | 923000/1801350 [09:58<08:43, 1677.53 examples/s]Running tokenizer on dataset:  51%|█████     | 920000/1801350 [09:58<09:21, 1570.65 examples/s]Running tokenizer on dataset:  51%|█████     | 922000/1801350 [09:59<08:52, 1652.03 examples/s]Running tokenizer on dataset:  51%|█████     | 921000/1801350 [09:59<08:25, 1740.68 examples/s]Running tokenizer on dataset:  51%|█████     | 922000/1801350 [09:59<08:48, 1665.36 examples/s]Running tokenizer on dataset:  51%|█████▏    | 924000/1801350 [09:59<09:09, 1597.00 examples/s]Running tokenizer on dataset:  51%|█████     | 923000/1801350 [09:59<08:41, 1683.76 examples/s]Running tokenizer on dataset:  51%|█████     | 922000/1801350 [09:59<08:47, 1666.17 examples/s]Running tokenizer on dataset:  51%|█████     | 923000/1801350 [09:59<08:42, 1679.55 examples/s]Running tokenizer on dataset:  51%|█████▏    | 925000/1801350 [10:00<08:56, 1634.30 examples/s]Running tokenizer on dataset:  51%|█████     | 923000/1801350 [10:00<08:41, 1685.22 examples/s]Running tokenizer on dataset:  51%|█████▏    | 924000/1801350 [10:00<09:24, 1553.47 examples/s]Running tokenizer on dataset:  51%|█████▏    | 926000/1801350 [10:00<08:49, 1651.85 examples/s]Running tokenizer on dataset:  51%|█████▏    | 924000/1801350 [10:00<09:10, 1592.50 examples/s]Running tokenizer on dataset:  51%|█████▏    | 925000/1801350 [10:00<09:01, 1618.19 examples/s]Running tokenizer on dataset:  51%|█████▏    | 924000/1801350 [10:01<09:04, 1610.43 examples/s]Running tokenizer on dataset:  51%|█████▏    | 925000/1801350 [10:01<08:55, 1637.32 examples/s]Running tokenizer on dataset:  51%|█████▏    | 927000/1801350 [10:01<09:21, 1556.26 examples/s]Running tokenizer on dataset:  51%|█████▏    | 926000/1801350 [10:01<08:57, 1627.57 examples/s]Running tokenizer on dataset:  51%|█████▏    | 925000/1801350 [10:01<08:57, 1629.70 examples/s]Running tokenizer on dataset:  51%|█████▏    | 926000/1801350 [10:01<08:53, 1641.10 examples/s]Running tokenizer on dataset:  52%|█████▏    | 928000/1801350 [10:01<09:23, 1549.10 examples/s]Running tokenizer on dataset:  51%|█████▏    | 926000/1801350 [10:02<08:45, 1665.28 examples/s]Running tokenizer on dataset:  51%|█████▏    | 927000/1801350 [10:02<09:26, 1542.72 examples/s]Running tokenizer on dataset:  51%|█████▏    | 927000/1801350 [10:02<09:16, 1571.48 examples/s]Running tokenizer on dataset:  52%|█████▏    | 929000/1801350 [10:02<09:11, 1582.86 examples/s]Running tokenizer on dataset:  52%|█████▏    | 928000/1801350 [10:02<09:24, 1547.98 examples/s]Running tokenizer on dataset:  51%|█████▏    | 927000/1801350 [10:02<09:17, 1569.44 examples/s]Running tokenizer on dataset:  52%|█████▏    | 928000/1801350 [10:03<09:27, 1537.69 examples/s]Running tokenizer on dataset:  52%|█████▏    | 930000/1801350 [10:03<09:14, 1571.40 examples/s]Running tokenizer on dataset:  52%|█████▏    | 929000/1801350 [10:03<09:13, 1576.56 examples/s]Running tokenizer on dataset:  52%|█████▏    | 928000/1801350 [10:03<09:25, 1544.09 examples/s]Running tokenizer on dataset:  52%|█████▏    | 929000/1801350 [10:03<09:14, 1572.96 examples/s]Running tokenizer on dataset:  52%|█████▏    | 931000/1801350 [10:04<10:37, 1364.65 examples/s]Running tokenizer on dataset:  52%|█████▏    | 930000/1801350 [10:04<09:10, 1582.60 examples/s]Running tokenizer on dataset:  52%|█████▏    | 929000/1801350 [10:04<09:20, 1556.00 examples/s]Running tokenizer on dataset:  52%|█████▏    | 930000/1801350 [10:04<09:18, 1560.18 examples/s]Running tokenizer on dataset:  52%|█████▏    | 932000/1801350 [10:04<10:02, 1443.80 examples/s]Running tokenizer on dataset:  52%|█████▏    | 930000/1801350 [10:04<09:13, 1575.16 examples/s]Running tokenizer on dataset:  52%|█████▏    | 931000/1801350 [10:05<11:08, 1302.30 examples/s]Running tokenizer on dataset:  52%|█████▏    | 931000/1801350 [10:05<10:39, 1360.78 examples/s]Running tokenizer on dataset:  52%|█████▏    | 933000/1801350 [10:05<09:55, 1457.28 examples/s]Running tokenizer on dataset:  52%|█████▏    | 931000/1801350 [10:05<10:31, 1377.64 examples/s]Running tokenizer on dataset:  52%|█████▏    | 932000/1801350 [10:05<10:18, 1406.54 examples/s]Running tokenizer on dataset:  52%|█████▏    | 932000/1801350 [10:05<10:05, 1435.86 examples/s]Running tokenizer on dataset:  52%|█████▏    | 934000/1801350 [10:06<09:57, 1451.52 examples/s]Running tokenizer on dataset:  52%|█████▏    | 932000/1801350 [10:06<10:04, 1438.72 examples/s]Running tokenizer on dataset:  52%|█████▏    | 933000/1801350 [10:06<10:13, 1415.36 examples/s]Running tokenizer on dataset:  52%|█████▏    | 933000/1801350 [10:06<10:00, 1445.67 examples/s]Running tokenizer on dataset:  52%|█████▏    | 935000/1801350 [10:06<09:43, 1485.65 examples/s]Running tokenizer on dataset:  52%|█████▏    | 933000/1801350 [10:07<09:58, 1450.60 examples/s]Running tokenizer on dataset:  52%|█████▏    | 934000/1801350 [10:07<10:07, 1427.12 examples/s]Running tokenizer on dataset:  52%|█████▏    | 936000/1801350 [10:07<09:17, 1550.84 examples/s]Running tokenizer on dataset:  52%|█████▏    | 934000/1801350 [10:07<10:02, 1438.78 examples/s]Running tokenizer on dataset:  52%|█████▏    | 934000/1801350 [10:07<09:58, 1449.87 examples/s]Running tokenizer on dataset:  52%|█████▏    | 935000/1801350 [10:07<09:51, 1464.28 examples/s]Running tokenizer on dataset:  52%|█████▏    | 935000/1801350 [10:07<09:43, 1485.97 examples/s]Running tokenizer on dataset:  52%|█████▏    | 937000/1801350 [10:08<09:31, 1511.94 examples/s]Running tokenizer on dataset:  52%|█████▏    | 935000/1801350 [10:08<09:49, 1470.29 examples/s]Running tokenizer on dataset:  52%|█████▏    | 936000/1801350 [10:08<09:28, 1521.62 examples/s]Running tokenizer on dataset:  52%|█████▏    | 936000/1801350 [10:08<09:24, 1533.54 examples/s]Running tokenizer on dataset:  52%|█████▏    | 938000/1801350 [10:08<09:48, 1468.07 examples/s]Running tokenizer on dataset:  52%|█████▏    | 936000/1801350 [10:09<09:21, 1542.17 examples/s]Running tokenizer on dataset:  52%|█████▏    | 937000/1801350 [10:09<09:36, 1499.15 examples/s]Running tokenizer on dataset:  52%|█████▏    | 937000/1801350 [10:09<09:27, 1522.98 examples/s]Running tokenizer on dataset:  52%|█████▏    | 939000/1801350 [10:09<09:25, 1523.95 examples/s]Running tokenizer on dataset:  52%|█████▏    | 937000/1801350 [10:09<09:34, 1505.11 examples/s]Running tokenizer on dataset:  52%|█████▏    | 938000/1801350 [10:09<09:46, 1470.93 examples/s]Running tokenizer on dataset:  52%|█████▏    | 938000/1801350 [10:09<09:39, 1489.73 examples/s]Running tokenizer on dataset:  52%|█████▏    | 940000/1801350 [10:10<09:36, 1494.77 examples/s]Running tokenizer on dataset:  52%|█████▏    | 938000/1801350 [10:10<09:46, 1473.18 examples/s]Running tokenizer on dataset:  52%|█████▏    | 939000/1801350 [10:10<09:38, 1491.94 examples/s]Running tokenizer on dataset:  52%|█████▏    | 939000/1801350 [10:10<09:30, 1511.58 examples/s]Running tokenizer on dataset:  52%|█████▏    | 941000/1801350 [10:10<09:10, 1562.76 examples/s]Running tokenizer on dataset:  52%|█████▏    | 939000/1801350 [10:11<09:33, 1504.85 examples/s]Running tokenizer on dataset:  52%|█████▏    | 940000/1801350 [10:11<09:38, 1488.06 examples/s]Running tokenizer on dataset:  52%|█████▏    | 942000/1801350 [10:11<09:02, 1583.03 examples/s]Running tokenizer on dataset:  52%|█████▏    | 940000/1801350 [10:11<09:37, 1490.29 examples/s]Running tokenizer on dataset:  52%|█████▏    | 941000/1801350 [10:11<09:08, 1569.59 examples/s]Running tokenizer on dataset:  52%|█████▏    | 940000/1801350 [10:11<09:44, 1472.72 examples/s]Running tokenizer on dataset:  52%|█████▏    | 941000/1801350 [10:11<09:10, 1563.89 examples/s]Running tokenizer on dataset:  52%|█████▏    | 943000/1801350 [10:12<09:24, 1520.75 examples/s]Running tokenizer on dataset:  52%|█████▏    | 941000/1801350 [10:12<09:06, 1575.44 examples/s]Running tokenizer on dataset:  52%|█████▏    | 942000/1801350 [10:12<09:14, 1550.05 examples/s]Running tokenizer on dataset:  52%|█████▏    | 942000/1801350 [10:12<09:04, 1576.85 examples/s]Running tokenizer on dataset:  52%|█████▏    | 944000/1801350 [10:12<09:31, 1500.91 examples/s]Running tokenizer on dataset:  52%|█████▏    | 942000/1801350 [10:12<09:11, 1558.37 examples/s]Running tokenizer on dataset:  52%|█████▏    | 943000/1801350 [10:13<09:24, 1519.42 examples/s]Running tokenizer on dataset:  52%|█████▏    | 943000/1801350 [10:13<09:24, 1520.32 examples/s]Running tokenizer on dataset:  52%|█████▏    | 945000/1801350 [10:13<09:37, 1483.59 examples/s]Running tokenizer on dataset:  52%|█████▏    | 943000/1801350 [10:13<09:26, 1516.16 examples/s]Running tokenizer on dataset:  52%|█████▏    | 944000/1801350 [10:13<09:27, 1510.71 examples/s]Running tokenizer on dataset:  52%|█████▏    | 944000/1801350 [10:13<09:26, 1513.05 examples/s]Running tokenizer on dataset:  53%|█████▎    | 946000/1801350 [10:14<09:25, 1513.81 examples/s]Running tokenizer on dataset:  52%|█████▏    | 944000/1801350 [10:14<09:28, 1507.88 examples/s]Running tokenizer on dataset:  52%|█████▏    | 945000/1801350 [10:14<09:34, 1490.08 examples/s]Running tokenizer on dataset:  52%|█████▏    | 945000/1801350 [10:14<09:39, 1477.98 examples/s]Running tokenizer on dataset:  53%|█████▎    | 947000/1801350 [10:14<09:06, 1562.44 examples/s]Running tokenizer on dataset:  53%|█████▎    | 946000/1801350 [10:15<09:16, 1537.94 examples/s]Running tokenizer on dataset:  52%|█████▏    | 945000/1801350 [10:15<09:43, 1467.35 examples/s]Running tokenizer on dataset:  53%|█████▎    | 946000/1801350 [10:15<09:23, 1517.38 examples/s]Running tokenizer on dataset:  53%|█████▎    | 948000/1801350 [10:15<09:04, 1567.46 examples/s]Running tokenizer on dataset:  53%|█████▎    | 949000/1801350 [10:15<08:00, 1772.27 examples/s]Running tokenizer on dataset:  53%|█████▎    | 947000/1801350 [10:15<09:09, 1556.00 examples/s]Running tokenizer on dataset:  53%|█████▎    | 946000/1801350 [10:15<09:25, 1513.05 examples/s]Running tokenizer on dataset:  53%|█████▎    | 947000/1801350 [10:15<09:10, 1552.24 examples/s]Running tokenizer on dataset:  53%|█████▎    | 950000/1801350 [10:16<08:21, 1696.51 examples/s]Running tokenizer on dataset:  53%|█████▎    | 947000/1801350 [10:16<09:11, 1549.43 examples/s]Running tokenizer on dataset:  53%|█████▎    | 948000/1801350 [10:16<09:04, 1565.83 examples/s]Running tokenizer on dataset:  53%|█████▎    | 948000/1801350 [10:16<09:07, 1558.07 examples/s]Running tokenizer on dataset:  53%|█████▎    | 949000/1801350 [10:16<08:11, 1734.87 examples/s]Running tokenizer on dataset:  53%|█████▎    | 949000/1801350 [10:16<08:07, 1748.36 examples/s]Running tokenizer on dataset:  53%|█████▎    | 951000/1801350 [10:16<08:41, 1629.36 examples/s]Running tokenizer on dataset:  53%|█████▎    | 948000/1801350 [10:16<09:15, 1536.17 examples/s]Running tokenizer on dataset:  53%|█████▎    | 949000/1801350 [10:17<08:14, 1723.02 examples/s]Running tokenizer on dataset:  53%|█████▎    | 950000/1801350 [10:17<08:30, 1667.04 examples/s]Running tokenizer on dataset:  53%|█████▎    | 950000/1801350 [10:17<08:32, 1660.33 examples/s]Running tokenizer on dataset:  53%|█████▎    | 952000/1801350 [10:17<10:18, 1372.61 examples/s]Running tokenizer on dataset:  53%|█████▎    | 951000/1801350 [10:18<08:40, 1632.15 examples/s]Running tokenizer on dataset:  53%|█████▎    | 950000/1801350 [10:18<08:35, 1651.00 examples/s]Running tokenizer on dataset:  53%|█████▎    | 951000/1801350 [10:18<08:47, 1612.32 examples/s]Running tokenizer on dataset:  53%|█████▎    | 953000/1801350 [10:18<10:08, 1394.01 examples/s]Running tokenizer on dataset:  53%|█████▎    | 951000/1801350 [10:18<08:47, 1611.10 examples/s]Running tokenizer on dataset:  53%|█████▎    | 952000/1801350 [10:19<10:10, 1390.80 examples/s]Running tokenizer on dataset:  53%|█████▎    | 952000/1801350 [10:19<10:10, 1391.53 examples/s]Running tokenizer on dataset:  53%|█████▎    | 954000/1801350 [10:19<09:37, 1468.40 examples/s]Running tokenizer on dataset:  53%|█████▎    | 952000/1801350 [10:19<10:03, 1408.04 examples/s]Running tokenizer on dataset:  53%|█████▎    | 953000/1801350 [10:19<09:57, 1420.67 examples/s]Running tokenizer on dataset:  53%|█████▎    | 955000/1801350 [10:19<09:05, 1552.47 examples/s]Running tokenizer on dataset:  53%|█████▎    | 953000/1801350 [10:19<10:03, 1404.88 examples/s]Running tokenizer on dataset:  53%|█████▎    | 954000/1801350 [10:20<09:21, 1508.12 examples/s]Running tokenizer on dataset:  53%|█████▎    | 956000/1801350 [10:20<08:51, 1589.02 examples/s]Running tokenizer on dataset:  53%|█████▎    | 953000/1801350 [10:20<10:07, 1396.33 examples/s]Running tokenizer on dataset:  53%|█████▎    | 954000/1801350 [10:20<09:38, 1464.05 examples/s]Running tokenizer on dataset:  53%|█████▎    | 955000/1801350 [10:20<09:01, 1564.13 examples/s]Running tokenizer on dataset:  53%|█████▎    | 954000/1801350 [10:20<09:40, 1459.49 examples/s]Running tokenizer on dataset:  53%|█████▎    | 957000/1801350 [10:21<08:49, 1595.53 examples/s]Running tokenizer on dataset:  53%|█████▎    | 955000/1801350 [10:20<09:02, 1559.09 examples/s]Running tokenizer on dataset:  53%|█████▎    | 958000/1801350 [10:21<08:10, 1720.93 examples/s]Running tokenizer on dataset:  53%|█████▎    | 956000/1801350 [10:21<08:54, 1582.28 examples/s]Running tokenizer on dataset:  53%|█████▎    | 955000/1801350 [10:21<09:10, 1537.37 examples/s]Running tokenizer on dataset:  53%|█████▎    | 956000/1801350 [10:21<09:02, 1558.37 examples/s]Running tokenizer on dataset:  53%|█████▎    | 957000/1801350 [10:22<08:46, 1604.70 examples/s]Running tokenizer on dataset:  53%|█████▎    | 956000/1801350 [10:22<08:56, 1574.43 examples/s]Running tokenizer on dataset:  53%|█████▎    | 959000/1801350 [10:22<08:55, 1572.29 examples/s]Running tokenizer on dataset:  53%|█████▎    | 957000/1801350 [10:22<08:50, 1591.17 examples/s]Running tokenizer on dataset:  53%|█████▎    | 958000/1801350 [10:22<08:23, 1675.95 examples/s]Running tokenizer on dataset:  53%|█████▎    | 958000/1801350 [10:22<08:10, 1720.16 examples/s]Running tokenizer on dataset:  53%|█████▎    | 957000/1801350 [10:22<08:53, 1583.31 examples/s]Running tokenizer on dataset:  53%|█████▎    | 960000/1801350 [10:22<08:49, 1587.68 examples/s]Running tokenizer on dataset:  53%|█████▎    | 958000/1801350 [10:23<08:15, 1700.31 examples/s]Running tokenizer on dataset:  53%|█████▎    | 959000/1801350 [10:23<08:57, 1565.71 examples/s]Running tokenizer on dataset:  53%|█████▎    | 961000/1801350 [10:23<08:31, 1642.57 examples/s]Running tokenizer on dataset:  53%|█████▎    | 959000/1801350 [10:23<08:51, 1585.89 examples/s]Running tokenizer on dataset:  53%|█████▎    | 962000/1801350 [10:23<08:14, 1698.80 examples/s]Running tokenizer on dataset:  53%|█████▎    | 960000/1801350 [10:23<08:50, 1585.34 examples/s]Running tokenizer on dataset:  53%|█████▎    | 959000/1801350 [10:23<08:55, 1573.64 examples/s]Running tokenizer on dataset:  53%|█████▎    | 960000/1801350 [10:24<08:48, 1592.68 examples/s]Running tokenizer on dataset:  53%|█████▎    | 961000/1801350 [10:24<08:37, 1624.47 examples/s]Running tokenizer on dataset:  53%|█████▎    | 960000/1801350 [10:24<08:51, 1583.97 examples/s]Running tokenizer on dataset:  53%|█████▎    | 961000/1801350 [10:24<08:32, 1638.28 examples/s]Running tokenizer on dataset:  53%|█████▎    | 963000/1801350 [10:24<08:42, 1605.23 examples/s]Running tokenizer on dataset:  53%|█████▎    | 962000/1801350 [10:25<08:34, 1632.27 examples/s]Running tokenizer on dataset:  53%|█████▎    | 961000/1801350 [10:25<08:38, 1619.84 examples/s]Running tokenizer on dataset:  53%|█████▎    | 962000/1801350 [10:25<08:23, 1666.33 examples/s]Running tokenizer on dataset:  54%|█████▎    | 964000/1801350 [10:25<08:45, 1594.44 examples/s]Running tokenizer on dataset:  53%|█████▎    | 963000/1801350 [10:25<08:31, 1637.49 examples/s]Running tokenizer on dataset:  53%|█████▎    | 962000/1801350 [10:25<08:23, 1665.81 examples/s]Running tokenizer on dataset:  53%|█████▎    | 963000/1801350 [10:25<08:32, 1636.99 examples/s]Running tokenizer on dataset:  54%|█████▎    | 965000/1801350 [10:25<08:44, 1594.98 examples/s]Running tokenizer on dataset:  54%|█████▎    | 964000/1801350 [10:26<08:43, 1600.70 examples/s]Running tokenizer on dataset:  53%|█████▎    | 963000/1801350 [10:26<08:32, 1635.75 examples/s]Running tokenizer on dataset:  54%|█████▎    | 964000/1801350 [10:26<08:40, 1610.16 examples/s]Running tokenizer on dataset:  54%|█████▎    | 966000/1801350 [10:26<08:36, 1617.71 examples/s]Running tokenizer on dataset:  54%|█████▎    | 965000/1801350 [10:27<08:43, 1598.51 examples/s]Running tokenizer on dataset:  54%|█████▎    | 964000/1801350 [10:27<08:34, 1626.61 examples/s]Running tokenizer on dataset:  54%|█████▎    | 965000/1801350 [10:27<08:50, 1577.89 examples/s]Running tokenizer on dataset:  54%|█████▎    | 967000/1801350 [10:27<08:47, 1581.74 examples/s]Running tokenizer on dataset:  54%|█████▎    | 966000/1801350 [10:27<08:37, 1613.01 examples/s]Running tokenizer on dataset:  54%|█████▎    | 965000/1801350 [10:27<08:45, 1592.05 examples/s]Running tokenizer on dataset:  54%|█████▎    | 966000/1801350 [10:27<08:38, 1610.22 examples/s]Running tokenizer on dataset:  54%|█████▎    | 968000/1801350 [10:27<08:49, 1573.43 examples/s]Running tokenizer on dataset:  54%|█████▎    | 966000/1801350 [10:28<08:30, 1634.93 examples/s]Running tokenizer on dataset:  54%|█████▎    | 967000/1801350 [10:28<08:54, 1561.93 examples/s]Running tokenizer on dataset:  54%|█████▍    | 969000/1801350 [10:28<08:43, 1589.07 examples/s]Running tokenizer on dataset:  54%|█████▎    | 967000/1801350 [10:28<08:53, 1565.23 examples/s]Running tokenizer on dataset:  54%|█████▎    | 967000/1801350 [10:28<08:47, 1580.80 examples/s]Running tokenizer on dataset:  54%|█████▎    | 968000/1801350 [10:28<08:51, 1568.59 examples/s]Running tokenizer on dataset:  54%|█████▎    | 968000/1801350 [10:29<08:53, 1560.78 examples/s]Running tokenizer on dataset:  54%|█████▍    | 970000/1801350 [10:29<08:49, 1570.67 examples/s]Running tokenizer on dataset:  54%|█████▎    | 968000/1801350 [10:29<08:47, 1578.78 examples/s]Running tokenizer on dataset:  54%|█████▍    | 969000/1801350 [10:29<08:49, 1572.40 examples/s]Running tokenizer on dataset:  54%|█████▍    | 969000/1801350 [10:29<08:49, 1571.83 examples/s]Running tokenizer on dataset:  54%|█████▍    | 971000/1801350 [10:29<08:45, 1578.93 examples/s]Running tokenizer on dataset:  54%|█████▍    | 970000/1801350 [10:30<08:46, 1579.47 examples/s]Running tokenizer on dataset:  54%|█████▍    | 969000/1801350 [10:30<08:47, 1577.28 examples/s]Running tokenizer on dataset:  54%|█████▍    | 972000/1801350 [10:30<08:35, 1609.29 examples/s]Running tokenizer on dataset:  54%|█████▍    | 970000/1801350 [10:30<08:50, 1567.69 examples/s]Running tokenizer on dataset:  54%|█████▍    | 970000/1801350 [10:30<08:52, 1560.34 examples/s]Running tokenizer on dataset:  54%|█████▍    | 971000/1801350 [10:30<08:55, 1549.67 examples/s]Running tokenizer on dataset:  54%|█████▍    | 971000/1801350 [10:30<08:45, 1580.20 examples/s]Running tokenizer on dataset:  54%|█████▍    | 973000/1801350 [10:31<09:19, 1481.61 examples/s]Running tokenizer on dataset:  54%|█████▍    | 972000/1801350 [10:31<08:42, 1587.10 examples/s]Running tokenizer on dataset:  54%|█████▍    | 971000/1801350 [10:31<08:46, 1578.52 examples/s]Running tokenizer on dataset:  54%|█████▍    | 972000/1801350 [10:31<08:37, 1601.53 examples/s]Running tokenizer on dataset:  54%|█████▍    | 974000/1801350 [10:31<08:46, 1571.26 examples/s]Running tokenizer on dataset:  54%|█████▍    | 972000/1801350 [10:32<08:48, 1568.64 examples/s]Running tokenizer on dataset:  54%|█████▍    | 975000/1801350 [10:32<08:47, 1566.86 examples/s]Running tokenizer on dataset:  54%|█████▍    | 973000/1801350 [10:32<09:37, 1433.82 examples/s]Running tokenizer on dataset:  54%|█████▍    | 973000/1801350 [10:32<09:36, 1436.46 examples/s]Running tokenizer on dataset:  54%|█████▍    | 976000/1801350 [10:32<08:12, 1676.65 examples/s]Running tokenizer on dataset:  54%|█████▍    | 974000/1801350 [10:32<08:55, 1543.96 examples/s]Running tokenizer on dataset:  54%|█████▍    | 973000/1801350 [10:32<09:20, 1477.82 examples/s]Running tokenizer on dataset:  54%|█████▍    | 974000/1801350 [10:32<08:57, 1540.39 examples/s]Running tokenizer on dataset:  54%|█████▍    | 974000/1801350 [10:33<08:35, 1606.28 examples/s]Running tokenizer on dataset:  54%|█████▍    | 977000/1801350 [10:33<08:21, 1643.64 examples/s]Running tokenizer on dataset:  54%|█████▍    | 975000/1801350 [10:33<08:56, 1539.10 examples/s]Running tokenizer on dataset:  54%|█████▍    | 975000/1801350 [10:33<09:00, 1529.01 examples/s]Running tokenizer on dataset:  54%|█████▍    | 978000/1801350 [10:34<08:14, 1664.13 examples/s]Running tokenizer on dataset:  54%|█████▍    | 976000/1801350 [10:34<08:34, 1604.71 examples/s]Running tokenizer on dataset:  54%|█████▍    | 975000/1801350 [10:34<08:49, 1560.07 examples/s]Running tokenizer on dataset:  54%|█████▍    | 976000/1801350 [10:34<08:31, 1612.05 examples/s]Running tokenizer on dataset:  54%|█████▍    | 976000/1801350 [10:34<08:24, 1635.38 examples/s]Running tokenizer on dataset:  54%|█████▍    | 979000/1801350 [10:34<08:19, 1645.09 examples/s]Running tokenizer on dataset:  54%|█████▍    | 977000/1801350 [10:34<08:32, 1609.03 examples/s]Running tokenizer on dataset:  54%|█████▍    | 977000/1801350 [10:34<08:29, 1618.22 examples/s]Running tokenizer on dataset:  54%|█████▍    | 980000/1801350 [10:35<07:58, 1715.34 examples/s]Running tokenizer on dataset:  54%|█████▍    | 977000/1801350 [10:35<08:25, 1629.46 examples/s]Running tokenizer on dataset:  54%|█████▍    | 978000/1801350 [10:35<08:30, 1613.78 examples/s]Running tokenizer on dataset:  54%|█████▍    | 978000/1801350 [10:35<08:30, 1611.49 examples/s]Running tokenizer on dataset:  54%|█████▍    | 981000/1801350 [10:35<08:12, 1666.23 examples/s]Running tokenizer on dataset:  54%|█████▍    | 978000/1801350 [10:35<08:30, 1612.98 examples/s]Running tokenizer on dataset:  54%|█████▍    | 979000/1801350 [10:35<08:31, 1606.59 examples/s]Running tokenizer on dataset:  54%|█████▍    | 979000/1801350 [10:36<08:26, 1622.45 examples/s]Running tokenizer on dataset:  55%|█████▍    | 982000/1801350 [10:36<08:03, 1696.14 examples/s]Running tokenizer on dataset:  54%|█████▍    | 980000/1801350 [10:36<08:04, 1694.22 examples/s]Running tokenizer on dataset:  54%|█████▍    | 979000/1801350 [10:36<08:29, 1613.43 examples/s]Running tokenizer on dataset:  54%|█████▍    | 980000/1801350 [10:36<08:08, 1682.28 examples/s]Running tokenizer on dataset:  54%|█████▍    | 980000/1801350 [10:36<08:01, 1706.78 examples/s]Running tokenizer on dataset:  55%|█████▍    | 983000/1801350 [10:37<08:37, 1582.40 examples/s]Running tokenizer on dataset:  54%|█████▍    | 981000/1801350 [10:37<08:19, 1643.40 examples/s]Running tokenizer on dataset:  54%|█████▍    | 981000/1801350 [10:37<08:18, 1644.38 examples/s]Running tokenizer on dataset:  55%|█████▍    | 982000/1801350 [10:37<08:02, 1696.98 examples/s]Running tokenizer on dataset:  54%|█████▍    | 981000/1801350 [10:37<08:20, 1639.25 examples/s]Running tokenizer on dataset:  55%|█████▍    | 982000/1801350 [10:37<08:04, 1690.86 examples/s]Running tokenizer on dataset:  55%|█████▍    | 984000/1801350 [10:37<08:52, 1535.29 examples/s]Running tokenizer on dataset:  55%|█████▍    | 982000/1801350 [10:38<08:05, 1689.33 examples/s]Running tokenizer on dataset:  55%|█████▍    | 985000/1801350 [10:38<08:20, 1631.79 examples/s]Running tokenizer on dataset:  55%|█████▍    | 983000/1801350 [10:38<08:32, 1597.83 examples/s]Running tokenizer on dataset:  55%|█████▍    | 983000/1801350 [10:38<08:32, 1597.04 examples/s]Running tokenizer on dataset:  55%|█████▍    | 986000/1801350 [10:38<08:18, 1634.33 examples/s]Running tokenizer on dataset:  55%|█████▍    | 983000/1801350 [10:38<08:34, 1589.55 examples/s]Running tokenizer on dataset:  55%|█████▍    | 984000/1801350 [10:39<08:53, 1532.10 examples/s]Running tokenizer on dataset:  55%|█████▍    | 984000/1801350 [10:39<08:49, 1542.74 examples/s]Running tokenizer on dataset:  55%|█████▍    | 987000/1801350 [10:39<08:20, 1626.77 examples/s]Running tokenizer on dataset:  55%|█████▍    | 985000/1801350 [10:39<08:25, 1614.79 examples/s]Running tokenizer on dataset:  55%|█████▍    | 984000/1801350 [10:39<08:54, 1529.20 examples/s]Running tokenizer on dataset:  55%|█████▍    | 985000/1801350 [10:39<08:27, 1609.12 examples/s]Running tokenizer on dataset:  55%|█████▍    | 985000/1801350 [10:40<08:19, 1635.92 examples/s]Running tokenizer on dataset:  55%|█████▍    | 988000/1801350 [10:40<08:39, 1564.91 examples/s]Running tokenizer on dataset:  55%|█████▍    | 986000/1801350 [10:40<08:25, 1614.39 examples/s]Running tokenizer on dataset:  55%|█████▍    | 986000/1801350 [10:40<08:27, 1606.22 examples/s]Running tokenizer on dataset:  55%|█████▍    | 986000/1801350 [10:40<08:31, 1592.67 examples/s]Running tokenizer on dataset:  55%|█████▍    | 987000/1801350 [10:40<08:18, 1634.68 examples/s]Running tokenizer on dataset:  55%|█████▍    | 987000/1801350 [10:40<08:20, 1626.65 examples/s]Running tokenizer on dataset:  55%|█████▍    | 989000/1801350 [10:40<08:57, 1510.47 examples/s]Running tokenizer on dataset:  55%|█████▍    | 987000/1801350 [10:41<08:27, 1603.20 examples/s]Running tokenizer on dataset:  55%|█████▍    | 990000/1801350 [10:41<08:30, 1589.71 examples/s]Running tokenizer on dataset:  55%|█████▍    | 988000/1801350 [10:41<08:45, 1546.99 examples/s]Running tokenizer on dataset:  55%|█████▍    | 988000/1801350 [10:41<08:41, 1560.92 examples/s]Running tokenizer on dataset:  55%|█████▌    | 991000/1801350 [10:42<08:29, 1591.64 examples/s]Running tokenizer on dataset:  55%|█████▍    | 988000/1801350 [10:42<08:46, 1545.05 examples/s]Running tokenizer on dataset:  55%|█████▍    | 989000/1801350 [10:42<08:51, 1529.36 examples/s]Running tokenizer on dataset:  55%|█████▍    | 989000/1801350 [10:42<08:47, 1541.28 examples/s]Running tokenizer on dataset:  55%|█████▌    | 992000/1801350 [10:42<08:19, 1619.87 examples/s]Running tokenizer on dataset:  55%|█████▍    | 990000/1801350 [10:42<08:35, 1575.34 examples/s]Running tokenizer on dataset:  55%|█████▍    | 989000/1801350 [10:42<08:54, 1519.83 examples/s]Running tokenizer on dataset:  55%|█████▍    | 990000/1801350 [10:42<08:33, 1578.64 examples/s]Running tokenizer on dataset:  55%|█████▌    | 993000/1801350 [10:43<08:06, 1662.31 examples/s]Running tokenizer on dataset:  55%|█████▍    | 990000/1801350 [10:43<08:35, 1575.33 examples/s]Running tokenizer on dataset:  55%|█████▌    | 991000/1801350 [10:43<08:35, 1572.63 examples/s]Running tokenizer on dataset:  55%|█████▌    | 991000/1801350 [10:43<08:30, 1586.91 examples/s]Running tokenizer on dataset:  55%|█████▌    | 991000/1801350 [10:44<08:34, 1575.98 examples/s]Running tokenizer on dataset:  55%|█████▌    | 992000/1801350 [10:44<08:24, 1605.30 examples/s]Running tokenizer on dataset:  55%|█████▌    | 992000/1801350 [10:44<08:21, 1613.83 examples/s]Running tokenizer on dataset:  55%|█████▌    | 994000/1801350 [10:44<09:27, 1423.20 examples/s]Running tokenizer on dataset:  55%|█████▌    | 993000/1801350 [10:44<08:00, 1680.64 examples/s]Running tokenizer on dataset:  55%|█████▌    | 993000/1801350 [10:44<07:58, 1687.87 examples/s]Running tokenizer on dataset:  55%|█████▌    | 992000/1801350 [10:44<08:31, 1581.75 examples/s]Running tokenizer on dataset:  55%|█████▌    | 995000/1801350 [10:44<09:03, 1483.53 examples/s]Running tokenizer on dataset:  55%|█████▌    | 993000/1801350 [10:45<08:11, 1645.85 examples/s]Running tokenizer on dataset:  55%|█████▌    | 996000/1801350 [10:45<08:34, 1565.72 examples/s]Running tokenizer on dataset:  55%|█████▌    | 994000/1801350 [10:45<09:27, 1421.55 examples/s]Running tokenizer on dataset:  55%|█████▌    | 994000/1801350 [10:45<09:28, 1421.00 examples/s]Running tokenizer on dataset:  55%|█████▌    | 995000/1801350 [10:46<08:46, 1530.65 examples/s]Running tokenizer on dataset:  55%|█████▌    | 994000/1801350 [10:46<09:12, 1461.09 examples/s]Running tokenizer on dataset:  55%|█████▌    | 997000/1801350 [10:46<08:50, 1516.20 examples/s]Running tokenizer on dataset:  55%|█████▌    | 995000/1801350 [10:46<08:59, 1494.61 examples/s]Running tokenizer on dataset:  55%|█████▌    | 996000/1801350 [10:46<08:29, 1579.99 examples/s]Running tokenizer on dataset:  55%|█████▌    | 995000/1801350 [10:46<08:47, 1527.93 examples/s]Running tokenizer on dataset:  55%|█████▌    | 998000/1801350 [10:46<08:45, 1527.38 examples/s]Running tokenizer on dataset:  55%|█████▌    | 996000/1801350 [10:46<08:34, 1565.95 examples/s]Running tokenizer on dataset:  55%|█████▌    | 996000/1801350 [10:47<08:25, 1592.21 examples/s]Running tokenizer on dataset:  55%|█████▌    | 999000/1801350 [10:47<08:30, 1570.59 examples/s]Running tokenizer on dataset:  55%|█████▌    | 997000/1801350 [10:47<08:56, 1499.12 examples/s]Running tokenizer on dataset:  55%|█████▌    | 997000/1801350 [10:47<08:52, 1510.26 examples/s]Running tokenizer on dataset:  55%|█████▌    | 997000/1801350 [10:47<08:48, 1521.86 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1000000/1801350 [10:48<08:33, 1561.46 examples/s]Running tokenizer on dataset:  55%|█████▌    | 998000/1801350 [10:48<08:50, 1515.02 examples/s]Running tokenizer on dataset:  55%|█████▌    | 998000/1801350 [10:48<08:38, 1549.58 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1001000/1801350 [10:48<08:22, 1593.46 examples/s]Running tokenizer on dataset:  55%|█████▌    | 998000/1801350 [10:48<08:41, 1539.44 examples/s]Running tokenizer on dataset:  55%|█████▌    | 999000/1801350 [10:48<08:40, 1540.44 examples/s]Running tokenizer on dataset:  55%|█████▌    | 999000/1801350 [10:48<08:37, 1550.37 examples/s]Running tokenizer on dataset:  55%|█████▌    | 999000/1801350 [10:49<08:39, 1544.45 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1002000/1801350 [10:49<08:24, 1585.07 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1000000/1801350 [10:49<08:46, 1522.96 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1000000/1801350 [10:49<08:38, 1545.88 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1003000/1801350 [10:49<08:09, 1629.92 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1000000/1801350 [10:49<08:39, 1542.19 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1001000/1801350 [10:49<08:27, 1576.26 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1001000/1801350 [10:49<08:23, 1588.09 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1004000/1801350 [10:50<08:15, 1610.79 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1001000/1801350 [10:50<08:28, 1572.40 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1002000/1801350 [10:50<08:26, 1577.06 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1002000/1801350 [10:50<08:27, 1576.01 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1005000/1801350 [10:51<08:32, 1555.14 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1002000/1801350 [10:51<08:29, 1567.72 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1003000/1801350 [10:51<08:16, 1607.92 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1003000/1801350 [10:51<08:17, 1606.10 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1003000/1801350 [10:51<08:11, 1624.26 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1006000/1801350 [10:51<08:15, 1605.26 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1004000/1801350 [10:51<08:17, 1603.85 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1004000/1801350 [10:51<08:17, 1601.17 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1004000/1801350 [10:52<08:13, 1616.10 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1007000/1801350 [10:52<08:28, 1562.36 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1005000/1801350 [10:52<08:32, 1552.89 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1005000/1801350 [10:52<08:21, 1589.15 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1005000/1801350 [10:52<08:20, 1592.29 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1006000/1801350 [10:53<08:14, 1607.90 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1006000/1801350 [10:53<08:08, 1626.49 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1008000/1801350 [10:53<08:41, 1520.31 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1006000/1801350 [10:53<08:18, 1597.09 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1007000/1801350 [10:53<08:23, 1576.64 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1009000/1801350 [10:53<08:36, 1533.78 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1007000/1801350 [10:53<08:18, 1592.67 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1007000/1801350 [10:54<08:27, 1566.46 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1010000/1801350 [10:54<08:13, 1602.46 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1008000/1801350 [10:54<08:32, 1547.30 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1008000/1801350 [10:54<08:24, 1571.86 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1008000/1801350 [10:54<08:32, 1547.00 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1011000/1801350 [10:55<08:30, 1549.26 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1009000/1801350 [10:55<08:33, 1543.11 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1009000/1801350 [10:55<08:30, 1551.65 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1012000/1801350 [10:55<08:18, 1581.86 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1009000/1801350 [10:55<08:37, 1529.86 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1010000/1801350 [10:55<08:18, 1588.31 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1010000/1801350 [10:55<08:27, 1558.77 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1013000/1801350 [10:56<08:14, 1595.22 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1010000/1801350 [10:56<08:27, 1560.80 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1011000/1801350 [10:56<08:29, 1550.61 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1011000/1801350 [10:56<08:31, 1545.93 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1014000/1801350 [10:56<08:10, 1603.73 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1011000/1801350 [10:56<08:34, 1536.28 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1012000/1801350 [10:56<08:24, 1565.80 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1012000/1801350 [10:56<08:25, 1562.12 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1013000/1801350 [10:57<08:10, 1608.57 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1012000/1801350 [10:57<08:33, 1535.84 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1013000/1801350 [10:57<08:16, 1586.80 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1015000/1801350 [10:57<09:31, 1376.20 examples/s]Running tokenizer on dataset:  56%|█████▌    | 1013000/1801350 [10:58<08:17, 1585.63 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1014000/1801350 [10:58<08:07, 1615.19 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1014000/1801350 [10:58<07:59, 1643.50 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1016000/1801350 [10:58<09:19, 1402.69 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1014000/1801350 [10:58<08:12, 1597.19 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1015000/1801350 [10:59<09:07, 1435.18 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1015000/1801350 [10:59<09:18, 1408.78 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1017000/1801350 [10:59<09:06, 1436.34 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1015000/1801350 [10:59<09:35, 1366.78 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1016000/1801350 [10:59<09:09, 1429.06 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1016000/1801350 [10:59<09:08, 1431.43 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1018000/1801350 [10:59<09:06, 1433.75 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1019000/1801350 [11:00<08:19, 1566.87 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1017000/1801350 [11:00<09:05, 1438.60 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1017000/1801350 [11:00<08:59, 1453.79 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1016000/1801350 [11:00<09:28, 1382.12 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1020000/1801350 [11:01<08:26, 1542.31 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1018000/1801350 [11:01<09:06, 1434.32 examples/s]Running tokenizer on dataset:  56%|█████▋    | 1017000/1801350 [11:01<09:22, 1393.57 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1018000/1801350 [11:01<09:04, 1439.91 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1021000/1801350 [11:01<08:15, 1574.96 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1019000/1801350 [11:01<08:30, 1532.98 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1019000/1801350 [11:01<08:26, 1543.78 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1018000/1801350 [11:01<09:12, 1418.64 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1020000/1801350 [11:02<08:22, 1554.05 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1020000/1801350 [11:02<08:20, 1561.10 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1019000/1801350 [11:02<08:33, 1522.52 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1022000/1801350 [11:02<09:08, 1421.92 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1021000/1801350 [11:02<08:13, 1579.85 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1021000/1801350 [11:02<08:13, 1580.48 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1020000/1801350 [11:02<08:31, 1527.01 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1023000/1801350 [11:03<08:48, 1472.49 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1021000/1801350 [11:03<08:08, 1598.12 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1024000/1801350 [11:03<08:34, 1510.42 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1022000/1801350 [11:03<09:02, 1436.48 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1022000/1801350 [11:03<09:02, 1435.83 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1023000/1801350 [11:04<08:35, 1508.48 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1023000/1801350 [11:04<08:33, 1516.46 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1022000/1801350 [11:04<09:00, 1440.98 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1025000/1801350 [11:04<09:11, 1406.85 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1024000/1801350 [11:04<08:27, 1531.68 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1024000/1801350 [11:04<08:26, 1535.57 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1023000/1801350 [11:05<08:44, 1483.13 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1026000/1801350 [11:05<09:14, 1399.06 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1024000/1801350 [11:05<08:19, 1557.35 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1025000/1801350 [11:05<09:08, 1415.97 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1025000/1801350 [11:05<09:07, 1417.94 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1027000/1801350 [11:05<08:52, 1455.48 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1025000/1801350 [11:06<08:58, 1441.60 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1026000/1801350 [11:06<09:08, 1412.73 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1026000/1801350 [11:06<09:10, 1407.57 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1028000/1801350 [11:06<09:01, 1428.39 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1027000/1801350 [11:07<08:49, 1463.34 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1027000/1801350 [11:07<08:47, 1468.76 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1026000/1801350 [11:07<09:09, 1411.22 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1029000/1801350 [11:07<08:46, 1466.79 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1030000/1801350 [11:07<08:06, 1583.97 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1027000/1801350 [11:07<08:46, 1470.59 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1028000/1801350 [11:07<09:03, 1423.50 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1028000/1801350 [11:07<09:08, 1410.08 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1031000/1801350 [11:08<08:02, 1595.46 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1029000/1801350 [11:08<08:47, 1463.54 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1029000/1801350 [11:08<08:49, 1458.28 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1028000/1801350 [11:08<09:03, 1422.53 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1032000/1801350 [11:09<08:00, 1601.78 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1030000/1801350 [11:09<08:20, 1540.22 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1030000/1801350 [11:09<08:19, 1542.90 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1029000/1801350 [11:09<08:52, 1451.77 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1033000/1801350 [11:09<07:52, 1627.24 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1031000/1801350 [11:09<08:12, 1565.14 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1031000/1801350 [11:09<08:11, 1566.97 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1030000/1801350 [11:09<08:23, 1532.55 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1034000/1801350 [11:10<07:57, 1608.42 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1032000/1801350 [11:10<08:11, 1563.83 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1032000/1801350 [11:10<08:11, 1564.77 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1031000/1801350 [11:10<08:13, 1559.72 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1035000/1801350 [11:10<07:49, 1632.96 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1033000/1801350 [11:10<07:58, 1605.05 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1033000/1801350 [11:10<08:01, 1597.25 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1032000/1801350 [11:10<08:16, 1549.97 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1034000/1801350 [11:11<07:59, 1599.91 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1034000/1801350 [11:11<08:01, 1592.10 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1033000/1801350 [11:11<07:53, 1623.06 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1036000/1801350 [11:11<09:02, 1410.05 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1035000/1801350 [11:12<07:42, 1657.37 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1035000/1801350 [11:12<07:43, 1653.96 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1034000/1801350 [11:12<07:56, 1608.73 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1037000/1801350 [11:12<08:45, 1453.19 examples/s]Running tokenizer on dataset:  57%|█████▋    | 1035000/1801350 [11:12<07:41, 1661.47 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1038000/1801350 [11:12<08:11, 1552.03 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1036000/1801350 [11:13<08:52, 1436.29 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1036000/1801350 [11:13<08:54, 1431.89 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1039000/1801350 [11:13<07:41, 1652.52 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1037000/1801350 [11:13<08:32, 1492.25 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1037000/1801350 [11:13<08:33, 1488.59 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1036000/1801350 [11:13<08:53, 1434.32 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1040000/1801350 [11:14<07:47, 1629.38 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1038000/1801350 [11:14<08:08, 1562.54 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1038000/1801350 [11:14<08:09, 1560.24 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1037000/1801350 [11:14<08:35, 1482.77 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1039000/1801350 [11:14<07:37, 1666.13 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1039000/1801350 [11:14<07:38, 1661.79 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1041000/1801350 [11:14<08:11, 1547.96 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1038000/1801350 [11:14<08:10, 1557.47 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1039000/1801350 [11:15<07:29, 1697.02 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1040000/1801350 [11:15<07:50, 1616.79 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1040000/1801350 [11:15<07:54, 1603.99 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1042000/1801350 [11:15<08:19, 1521.20 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1040000/1801350 [11:15<07:43, 1644.26 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1041000/1801350 [11:16<08:04, 1569.57 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1041000/1801350 [11:16<08:14, 1537.77 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1043000/1801350 [11:16<08:10, 1544.61 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1044000/1801350 [11:16<07:32, 1675.12 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1042000/1801350 [11:16<08:07, 1558.75 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1041000/1801350 [11:16<08:10, 1550.30 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1042000/1801350 [11:16<08:17, 1524.88 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1045000/1801350 [11:17<07:31, 1677.05 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1043000/1801350 [11:17<08:03, 1567.65 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1042000/1801350 [11:17<08:15, 1533.73 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1043000/1801350 [11:17<08:13, 1537.92 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1046000/1801350 [11:17<07:40, 1638.54 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1044000/1801350 [11:17<07:43, 1632.59 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1044000/1801350 [11:17<07:44, 1632.18 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1043000/1801350 [11:18<08:15, 1530.53 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1047000/1801350 [11:18<07:41, 1636.15 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1045000/1801350 [11:18<07:30, 1679.52 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1045000/1801350 [11:18<07:38, 1648.81 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1044000/1801350 [11:18<07:49, 1613.40 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1048000/1801350 [11:19<07:34, 1658.22 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1046000/1801350 [11:19<07:48, 1611.00 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1046000/1801350 [11:19<07:43, 1631.38 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1045000/1801350 [11:19<07:38, 1649.92 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1049000/1801350 [11:19<07:28, 1677.65 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1047000/1801350 [11:19<07:38, 1646.40 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1046000/1801350 [11:19<07:40, 1640.21 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1047000/1801350 [11:19<07:44, 1623.25 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1050000/1801350 [11:20<07:26, 1684.12 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1048000/1801350 [11:20<07:36, 1648.76 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1048000/1801350 [11:20<07:34, 1656.80 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1047000/1801350 [11:20<07:47, 1614.79 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1051000/1801350 [11:20<07:36, 1644.45 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1049000/1801350 [11:20<07:36, 1647.95 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1049000/1801350 [11:20<07:28, 1676.90 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1048000/1801350 [11:20<07:35, 1652.93 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1050000/1801350 [11:21<07:20, 1705.30 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1050000/1801350 [11:21<07:29, 1673.26 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1049000/1801350 [11:21<07:29, 1673.31 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1052000/1801350 [11:21<08:05, 1543.38 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1051000/1801350 [11:22<07:32, 1656.56 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1050000/1801350 [11:22<07:20, 1705.62 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1051000/1801350 [11:22<07:36, 1643.19 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1053000/1801350 [11:22<07:54, 1577.82 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1054000/1801350 [11:22<07:27, 1670.64 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1051000/1801350 [11:22<07:26, 1679.08 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1052000/1801350 [11:22<07:59, 1561.80 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1052000/1801350 [11:22<08:01, 1555.17 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1053000/1801350 [11:23<07:49, 1593.81 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1055000/1801350 [11:23<07:59, 1557.69 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1052000/1801350 [11:23<07:47, 1602.70 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1053000/1801350 [11:23<07:55, 1575.36 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1054000/1801350 [11:23<07:35, 1639.88 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1056000/1801350 [11:24<07:55, 1567.85 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1054000/1801350 [11:24<07:37, 1634.55 examples/s]Running tokenizer on dataset:  58%|█████▊    | 1053000/1801350 [11:24<07:48, 1596.94 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1054000/1801350 [11:24<07:28, 1666.84 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1055000/1801350 [11:24<07:59, 1554.90 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1055000/1801350 [11:24<07:54, 1571.74 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1057000/1801350 [11:25<09:22, 1322.97 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1055000/1801350 [11:25<07:52, 1580.95 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1056000/1801350 [11:25<07:56, 1564.78 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1056000/1801350 [11:25<07:50, 1583.09 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1058000/1801350 [11:25<08:37, 1435.75 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1056000/1801350 [11:25<07:47, 1595.93 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1059000/1801350 [11:26<08:27, 1462.09 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1057000/1801350 [11:26<09:29, 1307.28 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1057000/1801350 [11:26<09:18, 1333.45 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1060000/1801350 [11:26<08:01, 1540.43 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1058000/1801350 [11:26<08:28, 1460.60 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1058000/1801350 [11:26<08:39, 1431.22 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1057000/1801350 [11:27<09:37, 1288.91 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1061000/1801350 [11:27<07:45, 1589.91 examples/s]Running tokenizer on dataset:  59%|█████▊    | 1058000/1801350 [11:27<08:43, 1418.65 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1059000/1801350 [11:27<08:30, 1453.33 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1059000/1801350 [11:27<08:38, 1432.66 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1062000/1801350 [11:27<07:22, 1670.15 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1060000/1801350 [11:28<08:04, 1529.84 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1060000/1801350 [11:28<08:00, 1541.84 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1059000/1801350 [11:28<08:42, 1419.50 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1063000/1801350 [11:28<07:24, 1662.74 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1061000/1801350 [11:28<07:54, 1561.48 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1061000/1801350 [11:28<07:51, 1569.29 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1060000/1801350 [11:28<08:12, 1506.47 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1064000/1801350 [11:29<07:25, 1656.14 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1062000/1801350 [11:29<07:24, 1664.93 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1062000/1801350 [11:29<07:29, 1645.33 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1061000/1801350 [11:29<08:02, 1535.77 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1065000/1801350 [11:29<07:37, 1609.25 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1063000/1801350 [11:29<07:29, 1642.46 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1063000/1801350 [11:29<07:29, 1643.15 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1062000/1801350 [11:29<07:30, 1640.16 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1066000/1801350 [11:30<07:34, 1619.36 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1064000/1801350 [11:30<07:25, 1653.54 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1064000/1801350 [11:30<07:28, 1645.04 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1063000/1801350 [11:30<07:28, 1646.83 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1067000/1801350 [11:31<07:31, 1624.76 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1064000/1801350 [11:31<07:16, 1690.97 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1065000/1801350 [11:31<07:44, 1585.48 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1065000/1801350 [11:31<07:47, 1575.67 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1068000/1801350 [11:31<07:17, 1676.69 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1066000/1801350 [11:31<07:30, 1630.95 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1066000/1801350 [11:31<07:32, 1625.27 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1065000/1801350 [11:31<07:43, 1589.97 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1069000/1801350 [11:32<07:16, 1678.86 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1066000/1801350 [11:32<07:28, 1640.63 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1067000/1801350 [11:32<07:37, 1605.18 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1067000/1801350 [11:32<07:38, 1602.64 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1070000/1801350 [11:32<07:24, 1644.17 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1068000/1801350 [11:32<07:15, 1684.84 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1068000/1801350 [11:32<07:16, 1679.58 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1067000/1801350 [11:33<07:38, 1602.96 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1071000/1801350 [11:33<07:34, 1606.20 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1069000/1801350 [11:33<07:12, 1691.69 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1069000/1801350 [11:33<07:14, 1684.00 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1068000/1801350 [11:33<07:20, 1665.31 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1072000/1801350 [11:34<07:29, 1621.18 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1069000/1801350 [11:34<07:10, 1699.75 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1070000/1801350 [11:34<07:23, 1650.62 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1070000/1801350 [11:34<07:23, 1647.79 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1070000/1801350 [11:34<07:06, 1713.84 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1071000/1801350 [11:34<07:33, 1608.86 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1071000/1801350 [11:34<07:36, 1598.34 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1073000/1801350 [11:34<07:58, 1521.99 examples/s]Running tokenizer on dataset:  59%|█████▉    | 1071000/1801350 [11:35<07:22, 1651.38 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1072000/1801350 [11:35<07:21, 1651.89 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1072000/1801350 [11:35<07:27, 1628.74 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1074000/1801350 [11:35<08:01, 1510.91 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1072000/1801350 [11:36<07:24, 1639.13 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1075000/1801350 [11:36<07:53, 1535.38 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1073000/1801350 [11:36<07:50, 1547.61 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1073000/1801350 [11:36<07:53, 1539.70 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1076000/1801350 [11:36<07:37, 1585.56 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1073000/1801350 [11:36<07:43, 1570.82 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1074000/1801350 [11:36<07:58, 1518.93 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1074000/1801350 [11:36<07:58, 1518.67 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1077000/1801350 [11:37<07:34, 1592.91 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1074000/1801350 [11:37<07:55, 1528.39 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1075000/1801350 [11:37<07:57, 1520.85 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1075000/1801350 [11:37<07:57, 1521.17 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1075000/1801350 [11:38<07:53, 1532.91 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1076000/1801350 [11:38<07:43, 1565.54 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1076000/1801350 [11:38<07:43, 1565.28 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1078000/1801350 [11:38<08:58, 1343.28 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1076000/1801350 [11:38<07:37, 1586.50 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1077000/1801350 [11:38<07:39, 1575.37 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1077000/1801350 [11:38<07:41, 1567.89 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1079000/1801350 [11:39<08:38, 1393.85 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1077000/1801350 [11:39<07:47, 1550.82 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1078000/1801350 [11:39<08:41, 1387.21 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1078000/1801350 [11:39<08:45, 1376.35 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1080000/1801350 [11:39<08:43, 1377.93 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1078000/1801350 [11:40<08:37, 1396.97 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1079000/1801350 [11:40<08:29, 1418.70 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1079000/1801350 [11:40<08:33, 1405.98 examples/s]Running tokenizer on dataset:  60%|██████    | 1081000/1801350 [11:40<08:25, 1425.22 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1079000/1801350 [11:40<08:31, 1411.89 examples/s]Running tokenizer on dataset:  60%|██████    | 1082000/1801350 [11:41<08:01, 1493.22 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1080000/1801350 [11:41<08:46, 1369.70 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1080000/1801350 [11:41<08:48, 1366.01 examples/s]Running tokenizer on dataset:  60%|██████    | 1083000/1801350 [11:41<07:54, 1514.58 examples/s]Running tokenizer on dataset:  60%|█████▉    | 1080000/1801350 [11:41<08:55, 1346.58 examples/s]Running tokenizer on dataset:  60%|██████    | 1081000/1801350 [11:41<08:22, 1434.39 examples/s]Running tokenizer on dataset:  60%|██████    | 1081000/1801350 [11:41<08:22, 1432.97 examples/s]Running tokenizer on dataset:  60%|██████    | 1084000/1801350 [11:42<07:37, 1568.17 examples/s]Running tokenizer on dataset:  60%|██████    | 1081000/1801350 [11:42<08:26, 1423.53 examples/s]Running tokenizer on dataset:  60%|██████    | 1082000/1801350 [11:42<08:07, 1475.09 examples/s]Running tokenizer on dataset:  60%|██████    | 1082000/1801350 [11:42<08:11, 1463.63 examples/s]Running tokenizer on dataset:  60%|██████    | 1082000/1801350 [11:42<07:59, 1498.78 examples/s]Running tokenizer on dataset:  60%|██████    | 1085000/1801350 [11:43<08:03, 1480.81 examples/s]Running tokenizer on dataset:  60%|██████    | 1083000/1801350 [11:43<08:00, 1495.88 examples/s]Running tokenizer on dataset:  60%|██████    | 1083000/1801350 [11:43<07:59, 1497.34 examples/s]Running tokenizer on dataset:  60%|██████    | 1084000/1801350 [11:43<07:37, 1566.86 examples/s]Running tokenizer on dataset:  60%|██████    | 1084000/1801350 [11:43<07:39, 1560.84 examples/s]Running tokenizer on dataset:  60%|██████    | 1083000/1801350 [11:43<08:04, 1481.16 examples/s]Running tokenizer on dataset:  60%|██████    | 1086000/1801350 [11:43<08:15, 1443.10 examples/s]Running tokenizer on dataset:  60%|██████    | 1084000/1801350 [11:44<07:35, 1575.75 examples/s]Running tokenizer on dataset:  60%|██████    | 1087000/1801350 [11:44<07:47, 1529.16 examples/s]Running tokenizer on dataset:  60%|██████    | 1085000/1801350 [11:44<07:57, 1500.90 examples/s]Running tokenizer on dataset:  60%|██████    | 1085000/1801350 [11:44<07:58, 1497.16 examples/s]Running tokenizer on dataset:  60%|██████    | 1085000/1801350 [11:44<07:47, 1530.93 examples/s]Running tokenizer on dataset:  60%|██████    | 1088000/1801350 [11:45<07:49, 1520.39 examples/s]Running tokenizer on dataset:  60%|██████    | 1086000/1801350 [11:45<08:08, 1464.73 examples/s]Running tokenizer on dataset:  60%|██████    | 1086000/1801350 [11:45<08:11, 1453.99 examples/s]Running tokenizer on dataset:  60%|██████    | 1087000/1801350 [11:45<07:41, 1548.07 examples/s]Running tokenizer on dataset:  60%|██████    | 1086000/1801350 [11:45<08:09, 1462.06 examples/s]Running tokenizer on dataset:  60%|██████    | 1087000/1801350 [11:45<07:46, 1532.83 examples/s]Running tokenizer on dataset:  60%|██████    | 1089000/1801350 [11:45<08:00, 1481.48 examples/s]Running tokenizer on dataset:  60%|██████    | 1087000/1801350 [11:46<07:42, 1543.05 examples/s]Running tokenizer on dataset:  61%|██████    | 1090000/1801350 [11:46<07:31, 1575.12 examples/s]Running tokenizer on dataset:  60%|██████    | 1088000/1801350 [11:46<08:01, 1481.60 examples/s]Running tokenizer on dataset:  60%|██████    | 1088000/1801350 [11:46<08:00, 1485.71 examples/s]Running tokenizer on dataset:  61%|██████    | 1091000/1801350 [11:46<07:37, 1553.97 examples/s]Running tokenizer on dataset:  60%|██████    | 1088000/1801350 [11:46<07:58, 1492.23 examples/s]Running tokenizer on dataset:  60%|██████    | 1089000/1801350 [11:47<07:57, 1490.32 examples/s]Running tokenizer on dataset:  60%|██████    | 1089000/1801350 [11:47<08:09, 1455.70 examples/s]Running tokenizer on dataset:  61%|██████    | 1090000/1801350 [11:47<07:21, 1611.39 examples/s]Running tokenizer on dataset:  61%|██████    | 1092000/1801350 [11:47<07:41, 1536.84 examples/s]Running tokenizer on dataset:  60%|██████    | 1089000/1801350 [11:47<08:00, 1481.89 examples/s]Running tokenizer on dataset:  61%|██████    | 1090000/1801350 [11:47<07:34, 1565.77 examples/s]Running tokenizer on dataset:  61%|██████    | 1090000/1801350 [11:48<07:26, 1592.56 examples/s]Running tokenizer on dataset:  61%|██████    | 1093000/1801350 [11:48<07:41, 1534.51 examples/s]Running tokenizer on dataset:  61%|██████    | 1091000/1801350 [11:48<07:44, 1529.78 examples/s]Running tokenizer on dataset:  61%|██████    | 1091000/1801350 [11:48<07:42, 1534.46 examples/s]Running tokenizer on dataset:  61%|██████    | 1091000/1801350 [11:48<07:36, 1557.23 examples/s]Running tokenizer on dataset:  61%|██████    | 1092000/1801350 [11:48<07:34, 1559.02 examples/s]Running tokenizer on dataset:  61%|██████    | 1092000/1801350 [11:48<07:40, 1538.85 examples/s]Running tokenizer on dataset:  61%|██████    | 1094000/1801350 [11:48<07:46, 1515.00 examples/s]Running tokenizer on dataset:  61%|██████    | 1092000/1801350 [11:49<07:36, 1555.19 examples/s]Running tokenizer on dataset:  61%|██████    | 1093000/1801350 [11:49<07:44, 1524.38 examples/s]Running tokenizer on dataset:  61%|██████    | 1093000/1801350 [11:49<07:42, 1532.56 examples/s]Running tokenizer on dataset:  61%|██████    | 1095000/1801350 [11:49<07:53, 1492.67 examples/s]Running tokenizer on dataset:  61%|██████    | 1093000/1801350 [11:50<07:36, 1551.20 examples/s]Running tokenizer on dataset:  61%|██████    | 1096000/1801350 [11:50<07:32, 1558.72 examples/s]Running tokenizer on dataset:  61%|██████    | 1094000/1801350 [11:50<07:45, 1520.02 examples/s]Running tokenizer on dataset:  61%|██████    | 1094000/1801350 [11:50<07:49, 1506.57 examples/s]Running tokenizer on dataset:  61%|██████    | 1097000/1801350 [11:50<07:17, 1608.31 examples/s]Running tokenizer on dataset:  61%|██████    | 1094000/1801350 [11:50<07:47, 1513.69 examples/s]Running tokenizer on dataset:  61%|██████    | 1095000/1801350 [11:50<07:53, 1491.14 examples/s]Running tokenizer on dataset:  61%|██████    | 1095000/1801350 [11:50<07:54, 1489.29 examples/s]Running tokenizer on dataset:  61%|██████    | 1098000/1801350 [11:51<07:32, 1554.86 examples/s]Running tokenizer on dataset:  61%|██████    | 1095000/1801350 [11:51<07:48, 1508.35 examples/s]Running tokenizer on dataset:  61%|██████    | 1096000/1801350 [11:51<07:37, 1541.64 examples/s]Running tokenizer on dataset:  61%|██████    | 1096000/1801350 [11:51<07:48, 1506.72 examples/s]Running tokenizer on dataset:  61%|██████    | 1096000/1801350 [11:52<07:30, 1564.80 examples/s]Running tokenizer on dataset:  61%|██████    | 1097000/1801350 [11:52<07:18, 1607.91 examples/s]Running tokenizer on dataset:  61%|██████    | 1097000/1801350 [11:52<07:23, 1589.76 examples/s]Running tokenizer on dataset:  61%|██████    | 1099000/1801350 [11:52<08:51, 1321.93 examples/s]Running tokenizer on dataset:  61%|██████    | 1097000/1801350 [11:52<07:21, 1594.52 examples/s]Running tokenizer on dataset:  61%|██████    | 1098000/1801350 [11:52<07:29, 1564.87 examples/s]Running tokenizer on dataset:  61%|██████    | 1098000/1801350 [11:52<07:35, 1544.19 examples/s]Running tokenizer on dataset:  61%|██████    | 1100000/1801350 [11:53<08:15, 1415.99 examples/s]Running tokenizer on dataset:  61%|██████    | 1098000/1801350 [11:53<07:28, 1566.99 examples/s]Running tokenizer on dataset:  61%|██████    | 1101000/1801350 [11:53<07:54, 1474.89 examples/s]Running tokenizer on dataset:  61%|██████    | 1099000/1801350 [11:53<08:56, 1308.78 examples/s]Running tokenizer on dataset:  61%|██████    | 1099000/1801350 [11:53<09:02, 1294.59 examples/s]Running tokenizer on dataset:  61%|██████    | 1099000/1801350 [11:54<08:44, 1339.66 examples/s]Running tokenizer on dataset:  61%|██████    | 1102000/1801350 [11:54<07:46, 1500.17 examples/s]Running tokenizer on dataset:  61%|██████    | 1100000/1801350 [11:54<08:21, 1398.95 examples/s]Running tokenizer on dataset:  61%|██████    | 1100000/1801350 [11:54<08:25, 1388.49 examples/s]Running tokenizer on dataset:  61%|██████    | 1100000/1801350 [11:54<08:11, 1426.91 examples/s]Running tokenizer on dataset:  61%|██████    | 1103000/1801350 [11:54<07:39, 1520.06 examples/s]Running tokenizer on dataset:  61%|██████    | 1101000/1801350 [11:55<08:03, 1449.32 examples/s]Running tokenizer on dataset:  61%|██████    | 1101000/1801350 [11:55<08:02, 1451.58 examples/s]Running tokenizer on dataset:  61%|██████    | 1101000/1801350 [11:55<07:55, 1473.58 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1104000/1801350 [11:55<07:38, 1522.23 examples/s]Running tokenizer on dataset:  61%|██████    | 1102000/1801350 [11:55<07:57, 1464.19 examples/s]Running tokenizer on dataset:  61%|██████    | 1102000/1801350 [11:55<08:02, 1449.41 examples/s]Running tokenizer on dataset:  61%|██████    | 1102000/1801350 [11:56<07:51, 1484.33 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1105000/1801350 [11:56<07:41, 1507.60 examples/s]Running tokenizer on dataset:  61%|██████    | 1103000/1801350 [11:56<07:44, 1503.35 examples/s]Running tokenizer on dataset:  61%|██████    | 1103000/1801350 [11:56<07:45, 1499.04 examples/s]Running tokenizer on dataset:  61%|██████    | 1103000/1801350 [11:56<07:40, 1517.20 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1106000/1801350 [11:56<07:37, 1520.64 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1104000/1801350 [11:57<07:43, 1505.37 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1104000/1801350 [11:57<07:44, 1501.81 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1104000/1801350 [11:57<07:39, 1518.08 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1107000/1801350 [11:57<07:25, 1558.93 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1105000/1801350 [11:57<07:42, 1506.30 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1105000/1801350 [11:57<07:42, 1504.01 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1105000/1801350 [11:58<07:40, 1512.22 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1108000/1801350 [11:58<07:32, 1532.87 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1106000/1801350 [11:58<07:43, 1500.13 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1106000/1801350 [11:58<07:44, 1497.46 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1106000/1801350 [11:58<07:37, 1520.87 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1109000/1801350 [11:58<07:30, 1536.91 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1107000/1801350 [11:58<07:30, 1542.51 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1107000/1801350 [11:58<07:30, 1541.08 examples/s]Running tokenizer on dataset:  61%|██████▏   | 1107000/1801350 [11:59<07:29, 1543.28 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1110000/1801350 [11:59<07:24, 1555.19 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1108000/1801350 [11:59<07:28, 1546.48 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1108000/1801350 [11:59<07:31, 1537.02 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1108000/1801350 [12:00<07:27, 1549.95 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1111000/1801350 [12:00<07:15, 1584.88 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1109000/1801350 [12:00<07:26, 1551.57 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1109000/1801350 [12:00<07:27, 1547.40 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1112000/1801350 [12:00<07:08, 1607.43 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1109000/1801350 [12:00<07:27, 1546.08 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1110000/1801350 [12:00<07:22, 1563.56 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1110000/1801350 [12:00<07:23, 1559.86 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1113000/1801350 [12:01<07:09, 1601.45 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1110000/1801350 [12:01<07:22, 1562.90 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1111000/1801350 [12:01<07:20, 1568.81 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1111000/1801350 [12:01<07:19, 1569.25 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1114000/1801350 [12:01<06:56, 1649.45 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1111000/1801350 [12:01<07:23, 1558.10 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1112000/1801350 [12:02<07:10, 1599.96 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1112000/1801350 [12:02<07:13, 1591.29 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1115000/1801350 [12:02<07:06, 1610.63 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1112000/1801350 [12:02<07:08, 1608.57 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1113000/1801350 [12:02<07:10, 1599.88 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1113000/1801350 [12:02<07:12, 1590.74 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1113000/1801350 [12:03<07:08, 1604.61 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1116000/1801350 [12:03<07:11, 1588.67 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1114000/1801350 [12:03<06:54, 1656.71 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1114000/1801350 [12:03<06:55, 1653.28 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1117000/1801350 [12:03<06:48, 1674.80 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1114000/1801350 [12:03<06:56, 1649.24 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1115000/1801350 [12:03<07:06, 1610.42 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1115000/1801350 [12:03<07:08, 1601.98 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1118000/1801350 [12:04<07:01, 1619.41 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1115000/1801350 [12:04<07:06, 1610.81 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1116000/1801350 [12:04<07:08, 1597.59 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1116000/1801350 [12:04<07:12, 1586.00 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1119000/1801350 [12:05<07:09, 1587.82 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1116000/1801350 [12:05<07:10, 1591.08 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1117000/1801350 [12:05<06:52, 1659.38 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1117000/1801350 [12:05<06:54, 1652.41 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1117000/1801350 [12:05<06:46, 1683.45 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1118000/1801350 [12:05<07:00, 1625.18 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1118000/1801350 [12:05<07:01, 1620.72 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1120000/1801350 [12:06<08:37, 1317.20 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1118000/1801350 [12:06<06:57, 1636.97 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1119000/1801350 [12:06<07:05, 1602.01 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1119000/1801350 [12:06<07:07, 1594.34 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1121000/1801350 [12:06<08:05, 1401.35 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1119000/1801350 [12:06<07:05, 1602.45 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1122000/1801350 [12:07<07:31, 1504.09 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1120000/1801350 [12:07<08:19, 1365.41 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1120000/1801350 [12:07<08:27, 1342.33 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1123000/1801350 [12:07<07:14, 1562.72 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1120000/1801350 [12:07<08:17, 1370.87 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1121000/1801350 [12:08<07:46, 1457.36 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1121000/1801350 [12:08<07:48, 1452.88 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1124000/1801350 [12:08<07:00, 1611.06 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1121000/1801350 [12:08<07:47, 1455.32 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1122000/1801350 [12:08<07:25, 1523.25 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1122000/1801350 [12:08<07:25, 1526.30 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1122000/1801350 [12:08<07:19, 1546.66 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1125000/1801350 [12:09<07:01, 1604.15 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1123000/1801350 [12:09<07:09, 1579.82 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1123000/1801350 [12:09<07:17, 1549.43 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1123000/1801350 [12:09<07:10, 1574.33 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1126000/1801350 [12:09<07:13, 1559.13 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1124000/1801350 [12:09<06:58, 1617.43 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1124000/1801350 [12:09<07:09, 1576.09 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1124000/1801350 [12:10<07:02, 1604.57 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1127000/1801350 [12:10<07:15, 1548.93 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1125000/1801350 [12:10<06:54, 1632.45 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1125000/1801350 [12:10<07:01, 1604.10 examples/s]Running tokenizer on dataset:  62%|██████▏   | 1125000/1801350 [12:10<06:55, 1628.77 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1128000/1801350 [12:10<07:06, 1577.50 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1126000/1801350 [12:11<07:09, 1571.40 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1126000/1801350 [12:11<07:10, 1567.33 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1126000/1801350 [12:11<07:05, 1588.08 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1129000/1801350 [12:11<07:22, 1518.26 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1127000/1801350 [12:11<07:15, 1549.21 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1127000/1801350 [12:11<07:15, 1549.84 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1127000/1801350 [12:12<07:07, 1576.13 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1130000/1801350 [12:12<07:18, 1530.27 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1128000/1801350 [12:12<07:06, 1578.43 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1128000/1801350 [12:12<07:07, 1573.95 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1128000/1801350 [12:12<07:06, 1579.82 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1131000/1801350 [12:12<07:07, 1566.83 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1129000/1801350 [12:13<07:25, 1508.41 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1129000/1801350 [12:13<07:17, 1535.22 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1129000/1801350 [12:13<07:11, 1557.11 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1132000/1801350 [12:13<06:51, 1627.17 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1130000/1801350 [12:13<07:20, 1525.36 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1130000/1801350 [12:13<07:14, 1543.55 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1130000/1801350 [12:13<07:09, 1562.98 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1133000/1801350 [12:14<06:58, 1595.96 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1131000/1801350 [12:14<07:06, 1573.39 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1131000/1801350 [12:14<07:15, 1540.98 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1131000/1801350 [12:14<07:04, 1579.44 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1132000/1801350 [12:14<06:46, 1645.23 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1132000/1801350 [12:14<06:51, 1626.38 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1134000/1801350 [12:14<07:23, 1504.89 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1132000/1801350 [12:15<06:50, 1631.91 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1133000/1801350 [12:15<06:49, 1631.91 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1133000/1801350 [12:15<06:55, 1608.39 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1135000/1801350 [12:15<07:43, 1438.53 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1133000/1801350 [12:15<06:55, 1610.43 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1134000/1801350 [12:16<07:10, 1550.11 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1134000/1801350 [12:16<07:16, 1530.46 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1136000/1801350 [12:16<07:30, 1477.07 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1134000/1801350 [12:16<07:12, 1543.90 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1137000/1801350 [12:16<07:11, 1538.34 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1135000/1801350 [12:17<07:41, 1442.82 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1135000/1801350 [12:17<07:45, 1430.29 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1135000/1801350 [12:17<07:42, 1440.21 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1138000/1801350 [12:17<07:14, 1526.99 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1136000/1801350 [12:17<07:29, 1479.49 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1136000/1801350 [12:17<07:28, 1481.95 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1136000/1801350 [12:17<07:24, 1495.23 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1139000/1801350 [12:18<07:11, 1535.00 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1137000/1801350 [12:18<07:20, 1508.96 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1137000/1801350 [12:18<07:19, 1511.82 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1137000/1801350 [12:18<07:19, 1510.36 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1140000/1801350 [12:18<07:07, 1548.80 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1138000/1801350 [12:18<07:20, 1506.99 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1138000/1801350 [12:18<07:20, 1507.50 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1138000/1801350 [12:19<07:22, 1498.63 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1139000/1801350 [12:19<07:16, 1518.61 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1139000/1801350 [12:19<07:16, 1517.51 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1141000/1801350 [12:19<08:28, 1299.31 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1139000/1801350 [12:19<07:13, 1527.38 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1140000/1801350 [12:20<07:05, 1553.68 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1140000/1801350 [12:20<07:06, 1552.16 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1140000/1801350 [12:20<07:06, 1552.35 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1142000/1801350 [12:20<08:02, 1366.59 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1143000/1801350 [12:21<07:28, 1466.55 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1141000/1801350 [12:21<08:25, 1306.00 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1141000/1801350 [12:21<08:27, 1300.77 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1141000/1801350 [12:21<08:17, 1327.64 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1144000/1801350 [12:21<07:19, 1494.31 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1142000/1801350 [12:21<07:53, 1392.26 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1142000/1801350 [12:21<07:55, 1387.06 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1142000/1801350 [12:22<07:49, 1403.48 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1145000/1801350 [12:22<07:30, 1457.12 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1143000/1801350 [12:22<07:27, 1470.01 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1143000/1801350 [12:22<07:33, 1452.49 examples/s]Running tokenizer on dataset:  63%|██████▎   | 1143000/1801350 [12:22<07:29, 1465.28 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1146000/1801350 [12:23<07:17, 1499.34 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1144000/1801350 [12:23<07:29, 1463.61 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1144000/1801350 [12:23<07:30, 1460.21 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1144000/1801350 [12:23<07:25, 1473.97 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1147000/1801350 [12:23<07:28, 1457.66 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1145000/1801350 [12:23<07:25, 1473.13 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1145000/1801350 [12:23<07:25, 1472.40 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1145000/1801350 [12:24<07:28, 1463.66 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1148000/1801350 [12:24<07:03, 1540.95 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1146000/1801350 [12:24<07:24, 1474.03 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1146000/1801350 [12:24<07:27, 1463.14 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1146000/1801350 [12:24<07:19, 1489.85 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1149000/1801350 [12:25<07:10, 1514.06 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1147000/1801350 [12:25<07:29, 1455.74 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1147000/1801350 [12:25<07:31, 1447.79 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1147000/1801350 [12:25<07:25, 1468.42 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1150000/1801350 [12:25<07:07, 1523.61 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1148000/1801350 [12:25<07:10, 1517.03 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1148000/1801350 [12:25<07:11, 1515.83 examples/s]Running tokenizer on dataset:  64%|██████▎   | 1148000/1801350 [12:26<07:04, 1537.35 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1151000/1801350 [12:26<06:53, 1572.67 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1149000/1801350 [12:26<07:10, 1513.73 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1149000/1801350 [12:26<07:11, 1511.50 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1149000/1801350 [12:26<07:11, 1513.11 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1152000/1801350 [12:26<06:40, 1619.51 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1150000/1801350 [12:27<07:06, 1528.05 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1150000/1801350 [12:27<07:07, 1523.86 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1150000/1801350 [12:27<07:09, 1517.11 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1153000/1801350 [12:27<06:53, 1568.14 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1151000/1801350 [12:27<06:54, 1569.29 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1151000/1801350 [12:27<06:55, 1566.34 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1151000/1801350 [12:27<06:59, 1549.42 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1152000/1801350 [12:28<06:32, 1653.17 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1152000/1801350 [12:28<06:36, 1637.72 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1154000/1801350 [12:28<07:24, 1456.32 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1152000/1801350 [12:28<06:43, 1608.40 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1153000/1801350 [12:28<06:49, 1582.86 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1153000/1801350 [12:28<06:55, 1562.27 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1155000/1801350 [12:29<07:19, 1469.63 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1153000/1801350 [12:29<06:57, 1551.85 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1156000/1801350 [12:29<06:57, 1546.00 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1154000/1801350 [12:29<07:17, 1479.58 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1154000/1801350 [12:29<07:22, 1462.42 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1154000/1801350 [12:29<07:20, 1469.56 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1157000/1801350 [12:30<07:02, 1526.56 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1155000/1801350 [12:30<07:12, 1494.15 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1155000/1801350 [12:30<07:16, 1481.95 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1155000/1801350 [12:30<07:12, 1493.19 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1158000/1801350 [12:30<06:57, 1539.51 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1156000/1801350 [12:30<07:04, 1520.54 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1156000/1801350 [12:31<07:05, 1516.98 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1156000/1801350 [12:31<07:04, 1519.67 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1159000/1801350 [12:31<06:58, 1533.63 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1157000/1801350 [12:31<07:10, 1498.38 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1157000/1801350 [12:31<07:08, 1504.52 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1157000/1801350 [12:31<07:05, 1513.46 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1160000/1801350 [12:32<06:57, 1536.87 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1158000/1801350 [12:32<06:57, 1539.56 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1158000/1801350 [12:32<06:56, 1544.66 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1158000/1801350 [12:32<06:58, 1536.13 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1161000/1801350 [12:32<06:41, 1594.38 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1159000/1801350 [12:32<07:02, 1521.02 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1159000/1801350 [12:32<07:06, 1507.69 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1159000/1801350 [12:33<07:03, 1517.89 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1160000/1801350 [12:33<06:54, 1546.10 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1160000/1801350 [12:33<06:54, 1545.50 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1160000/1801350 [12:33<06:52, 1553.51 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1162000/1801350 [12:33<08:21, 1274.56 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1161000/1801350 [12:34<06:39, 1601.42 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1161000/1801350 [12:34<06:43, 1586.92 examples/s]Running tokenizer on dataset:  64%|██████▍   | 1161000/1801350 [12:34<06:38, 1606.20 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1163000/1801350 [12:34<08:01, 1326.17 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1164000/1801350 [12:35<07:30, 1413.76 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1162000/1801350 [12:35<08:03, 1322.34 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1162000/1801350 [12:35<08:06, 1315.25 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1162000/1801350 [12:35<08:20, 1278.40 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1165000/1801350 [12:35<07:16, 1457.18 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1163000/1801350 [12:35<07:49, 1359.70 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1163000/1801350 [12:35<07:51, 1352.75 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1163000/1801350 [12:36<07:57, 1338.12 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1166000/1801350 [12:36<07:04, 1495.16 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1164000/1801350 [12:36<07:26, 1426.01 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1164000/1801350 [12:36<07:28, 1421.54 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1164000/1801350 [12:36<07:35, 1399.18 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1167000/1801350 [12:37<06:49, 1549.51 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1165000/1801350 [12:37<07:19, 1447.06 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1165000/1801350 [12:37<07:20, 1445.13 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1165000/1801350 [12:37<07:25, 1429.32 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1168000/1801350 [12:37<06:48, 1550.24 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1166000/1801350 [12:37<07:07, 1487.86 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1166000/1801350 [12:37<07:07, 1485.18 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1166000/1801350 [12:38<07:09, 1479.85 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1169000/1801350 [12:38<06:38, 1585.74 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1167000/1801350 [12:38<06:49, 1548.05 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1167000/1801350 [12:38<06:51, 1539.88 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1167000/1801350 [12:38<06:53, 1533.72 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1170000/1801350 [12:38<06:18, 1668.74 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1168000/1801350 [12:39<06:47, 1555.96 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1168000/1801350 [12:39<06:49, 1547.80 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1168000/1801350 [12:39<06:49, 1547.23 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1171000/1801350 [12:39<06:27, 1626.05 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1169000/1801350 [12:39<06:36, 1593.86 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1169000/1801350 [12:39<06:38, 1588.70 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1169000/1801350 [12:39<06:37, 1590.73 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1172000/1801350 [12:40<06:19, 1657.11 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1170000/1801350 [12:40<06:17, 1673.40 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1170000/1801350 [12:40<06:18, 1667.81 examples/s]Running tokenizer on dataset:  65%|██████▍   | 1170000/1801350 [12:40<06:17, 1671.19 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1173000/1801350 [12:40<06:37, 1582.43 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1171000/1801350 [12:40<06:24, 1641.32 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1171000/1801350 [12:40<06:24, 1638.48 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1171000/1801350 [12:41<06:26, 1629.82 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1172000/1801350 [12:41<06:17, 1666.94 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1172000/1801350 [12:41<06:16, 1670.37 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1174000/1801350 [12:41<06:40, 1565.79 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1172000/1801350 [12:41<06:22, 1645.16 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1175000/1801350 [12:42<06:36, 1580.28 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1173000/1801350 [12:42<06:40, 1570.64 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1173000/1801350 [12:42<06:39, 1573.17 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1173000/1801350 [12:42<06:34, 1593.73 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1176000/1801350 [12:42<06:24, 1624.58 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1174000/1801350 [12:42<06:36, 1583.39 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1174000/1801350 [12:42<06:36, 1582.91 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1174000/1801350 [12:43<06:35, 1584.36 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1177000/1801350 [12:43<06:24, 1624.55 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1175000/1801350 [12:43<06:38, 1570.76 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1175000/1801350 [12:43<06:38, 1571.44 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1175000/1801350 [12:43<06:41, 1561.74 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1178000/1801350 [12:43<06:14, 1665.84 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1176000/1801350 [12:43<06:27, 1614.27 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1176000/1801350 [12:43<06:28, 1608.67 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1176000/1801350 [12:44<06:25, 1620.12 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1179000/1801350 [12:44<06:34, 1579.21 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1177000/1801350 [12:44<06:23, 1629.24 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1177000/1801350 [12:44<06:25, 1618.21 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1177000/1801350 [12:44<06:23, 1626.23 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1180000/1801350 [12:45<06:12, 1669.80 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1178000/1801350 [12:45<06:12, 1673.02 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1178000/1801350 [12:45<06:13, 1669.32 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1178000/1801350 [12:45<06:10, 1682.62 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1181000/1801350 [12:45<06:13, 1661.53 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1179000/1801350 [12:45<06:31, 1588.39 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1179000/1801350 [12:45<06:33, 1582.90 examples/s]Running tokenizer on dataset:  65%|██████▌   | 1179000/1801350 [12:46<06:31, 1589.38 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1182000/1801350 [12:46<06:30, 1584.87 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1180000/1801350 [12:46<06:09, 1682.58 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1180000/1801350 [12:46<06:14, 1659.49 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1180000/1801350 [12:46<06:07, 1690.90 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1181000/1801350 [12:46<06:10, 1672.75 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1181000/1801350 [12:46<06:12, 1665.90 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1181000/1801350 [12:47<06:13, 1662.04 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1183000/1801350 [12:47<07:54, 1303.49 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1182000/1801350 [12:47<06:29, 1589.95 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1182000/1801350 [12:47<06:31, 1583.89 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1182000/1801350 [12:47<06:28, 1592.82 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1184000/1801350 [12:48<07:33, 1361.77 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1183000/1801350 [12:48<07:45, 1327.45 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1183000/1801350 [12:48<07:50, 1313.56 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1185000/1801350 [12:48<07:30, 1367.11 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1183000/1801350 [12:49<07:44, 1332.40 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1184000/1801350 [12:49<07:21, 1398.20 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1184000/1801350 [12:49<07:22, 1394.92 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1186000/1801350 [12:49<07:12, 1423.04 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1184000/1801350 [12:49<07:27, 1378.68 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1187000/1801350 [12:50<06:55, 1479.50 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1185000/1801350 [12:50<07:29, 1369.94 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1185000/1801350 [12:50<07:29, 1370.98 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1185000/1801350 [12:50<07:26, 1381.31 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1188000/1801350 [12:50<06:50, 1493.55 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1186000/1801350 [12:50<07:13, 1418.40 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1186000/1801350 [12:50<07:18, 1404.01 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1186000/1801350 [12:51<07:13, 1419.71 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1187000/1801350 [12:51<07:02, 1455.02 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1187000/1801350 [12:51<07:06, 1441.96 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1189000/1801350 [12:51<07:14, 1410.47 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1187000/1801350 [12:51<07:06, 1440.86 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1188000/1801350 [12:52<06:56, 1472.62 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1188000/1801350 [12:52<06:57, 1470.32 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1190000/1801350 [12:52<07:09, 1423.93 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1188000/1801350 [12:52<06:59, 1463.76 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1191000/1801350 [12:52<06:45, 1506.03 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1189000/1801350 [12:52<07:09, 1426.54 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1189000/1801350 [12:52<07:12, 1414.80 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1189000/1801350 [12:53<07:06, 1435.73 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1192000/1801350 [12:53<06:49, 1487.98 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1190000/1801350 [12:53<07:09, 1424.42 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1190000/1801350 [12:53<07:12, 1414.64 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1190000/1801350 [12:53<07:06, 1433.97 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1193000/1801350 [12:54<06:31, 1552.56 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1191000/1801350 [12:54<06:50, 1486.67 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1191000/1801350 [12:54<06:52, 1479.45 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1191000/1801350 [12:54<06:51, 1484.79 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1194000/1801350 [12:54<06:26, 1569.50 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1192000/1801350 [12:54<06:55, 1465.14 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1192000/1801350 [12:54<06:57, 1459.89 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1192000/1801350 [12:55<06:56, 1462.30 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1193000/1801350 [12:55<06:24, 1581.98 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1195000/1801350 [12:55<06:47, 1486.17 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1193000/1801350 [12:55<06:34, 1540.86 examples/s]Running tokenizer on dataset:  66%|██████▌   | 1193000/1801350 [12:55<06:33, 1546.84 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1194000/1801350 [12:55<06:23, 1583.08 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1194000/1801350 [12:56<06:23, 1584.84 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1196000/1801350 [12:56<06:49, 1479.10 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1194000/1801350 [12:56<06:25, 1576.29 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1195000/1801350 [12:56<06:38, 1520.69 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1195000/1801350 [12:56<06:42, 1506.21 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1197000/1801350 [12:56<07:01, 1433.85 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1195000/1801350 [12:57<06:42, 1504.60 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1198000/1801350 [12:57<06:23, 1571.56 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1196000/1801350 [12:57<06:46, 1488.90 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1196000/1801350 [12:57<06:48, 1483.58 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1196000/1801350 [12:57<06:41, 1505.95 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1199000/1801350 [12:58<06:33, 1532.23 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1197000/1801350 [12:58<06:54, 1458.27 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1197000/1801350 [12:58<06:57, 1447.28 examples/s]Running tokenizer on dataset:  66%|██████▋   | 1197000/1801350 [12:58<06:54, 1459.72 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1198000/1801350 [12:58<06:27, 1558.11 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1198000/1801350 [12:58<06:30, 1546.25 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1200000/1801350 [12:58<06:41, 1498.68 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1198000/1801350 [12:58<06:26, 1561.34 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1201000/1801350 [12:59<06:16, 1594.98 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1199000/1801350 [12:59<06:33, 1531.93 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1199000/1801350 [12:59<06:34, 1526.54 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1199000/1801350 [12:59<06:32, 1536.38 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1202000/1801350 [12:59<06:11, 1612.49 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1200000/1801350 [13:00<06:37, 1513.44 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1200000/1801350 [13:00<06:38, 1510.35 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1200000/1801350 [13:00<06:33, 1528.80 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1203000/1801350 [13:00<06:00, 1659.55 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1201000/1801350 [13:00<06:22, 1569.69 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1201000/1801350 [13:00<06:23, 1567.22 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1201000/1801350 [13:00<06:22, 1570.46 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1202000/1801350 [13:01<06:19, 1579.12 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1202000/1801350 [13:01<06:20, 1575.32 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1204000/1801350 [13:01<07:10, 1388.37 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1202000/1801350 [13:01<06:18, 1584.12 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1203000/1801350 [13:01<06:03, 1645.77 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1203000/1801350 [13:01<06:03, 1644.16 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1205000/1801350 [13:02<06:48, 1459.47 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1203000/1801350 [13:02<06:01, 1656.64 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1206000/1801350 [13:02<06:33, 1512.10 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1204000/1801350 [13:02<07:05, 1402.65 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1204000/1801350 [13:02<07:08, 1393.28 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1204000/1801350 [13:03<07:08, 1394.20 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1207000/1801350 [13:03<06:30, 1521.31 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1205000/1801350 [13:03<06:44, 1475.43 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1205000/1801350 [13:03<06:46, 1468.10 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1205000/1801350 [13:03<06:46, 1467.75 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1206000/1801350 [13:03<06:32, 1518.30 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1206000/1801350 [13:03<06:32, 1515.98 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1208000/1801350 [13:04<07:01, 1406.10 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1206000/1801350 [13:04<06:37, 1498.92 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1207000/1801350 [13:04<06:34, 1505.66 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1207000/1801350 [13:04<06:35, 1501.39 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1209000/1801350 [13:04<06:47, 1454.89 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1207000/1801350 [13:04<06:35, 1501.64 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1210000/1801350 [13:05<06:21, 1550.28 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1208000/1801350 [13:05<06:56, 1425.28 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1208000/1801350 [13:05<06:57, 1420.82 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1208000/1801350 [13:05<06:56, 1424.12 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1211000/1801350 [13:05<06:14, 1578.30 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1209000/1801350 [13:06<06:43, 1466.78 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1209000/1801350 [13:06<06:44, 1462.99 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1209000/1801350 [13:06<06:41, 1476.51 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1212000/1801350 [13:06<06:36, 1484.94 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1210000/1801350 [13:06<06:24, 1539.33 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1210000/1801350 [13:06<06:25, 1533.06 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1210000/1801350 [13:06<06:24, 1539.82 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1213000/1801350 [13:07<06:10, 1588.21 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1211000/1801350 [13:07<06:16, 1566.52 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1211000/1801350 [13:07<06:19, 1556.76 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1211000/1801350 [13:07<06:17, 1563.57 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1214000/1801350 [13:07<05:55, 1652.93 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1212000/1801350 [13:07<06:30, 1508.18 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1212000/1801350 [13:08<06:33, 1499.39 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1215000/1801350 [13:08<05:35, 1748.76 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1212000/1801350 [13:08<06:35, 1488.73 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1213000/1801350 [13:08<06:12, 1578.54 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1213000/1801350 [13:08<06:12, 1578.89 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1213000/1801350 [13:08<06:11, 1582.48 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1216000/1801350 [13:08<06:01, 1618.12 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1214000/1801350 [13:09<05:57, 1642.47 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1214000/1801350 [13:09<05:58, 1636.94 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1214000/1801350 [13:09<05:53, 1661.02 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1217000/1801350 [13:09<05:52, 1656.95 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1215000/1801350 [13:09<05:40, 1724.43 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1215000/1801350 [13:09<05:46, 1692.07 examples/s]Running tokenizer on dataset:  67%|██████▋   | 1215000/1801350 [13:09<05:38, 1731.43 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1218000/1801350 [13:10<05:54, 1647.17 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1216000/1801350 [13:10<05:56, 1642.66 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1216000/1801350 [13:10<05:59, 1627.59 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1216000/1801350 [13:10<05:56, 1640.42 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1219000/1801350 [13:10<05:59, 1620.98 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1217000/1801350 [13:10<05:52, 1659.17 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1217000/1801350 [13:10<06:00, 1621.56 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1217000/1801350 [13:11<05:55, 1642.83 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1220000/1801350 [13:11<05:52, 1649.21 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1218000/1801350 [13:11<05:52, 1656.67 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1218000/1801350 [13:11<05:52, 1656.91 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1218000/1801350 [13:11<05:51, 1658.10 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1221000/1801350 [13:12<06:00, 1611.58 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1219000/1801350 [13:12<06:00, 1616.13 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1219000/1801350 [13:12<06:02, 1607.54 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1219000/1801350 [13:12<05:59, 1619.47 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1222000/1801350 [13:12<05:57, 1619.46 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1220000/1801350 [13:12<05:49, 1661.65 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1220000/1801350 [13:12<05:51, 1655.55 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1220000/1801350 [13:12<05:49, 1662.76 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1223000/1801350 [13:13<06:17, 1531.12 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1221000/1801350 [13:13<05:59, 1612.37 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1221000/1801350 [13:13<06:03, 1596.71 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1221000/1801350 [13:13<06:02, 1601.27 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1224000/1801350 [13:13<06:09, 1562.62 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1222000/1801350 [13:13<05:56, 1627.26 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1222000/1801350 [13:14<05:58, 1615.56 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1222000/1801350 [13:14<05:57, 1621.47 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1223000/1801350 [13:14<06:19, 1525.54 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1223000/1801350 [13:14<06:13, 1549.16 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1225000/1801350 [13:14<07:11, 1336.25 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1223000/1801350 [13:15<06:19, 1523.89 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1224000/1801350 [13:15<06:04, 1584.08 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1224000/1801350 [13:15<06:09, 1560.58 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1226000/1801350 [13:15<06:45, 1418.41 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1224000/1801350 [13:15<06:08, 1565.34 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1227000/1801350 [13:16<06:22, 1500.47 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1225000/1801350 [13:16<07:11, 1335.22 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1225000/1801350 [13:16<07:10, 1338.02 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1225000/1801350 [13:16<07:04, 1357.78 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1228000/1801350 [13:16<06:12, 1540.14 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1226000/1801350 [13:16<06:42, 1427.97 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1226000/1801350 [13:16<06:44, 1423.29 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1226000/1801350 [13:17<06:43, 1425.85 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1229000/1801350 [13:17<06:17, 1514.60 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1227000/1801350 [13:17<06:24, 1495.49 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1227000/1801350 [13:17<06:25, 1490.92 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1227000/1801350 [13:17<06:24, 1495.53 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1230000/1801350 [13:18<06:18, 1510.59 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1228000/1801350 [13:18<06:18, 1515.00 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1228000/1801350 [13:18<06:12, 1539.29 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1228000/1801350 [13:18<06:15, 1526.78 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1231000/1801350 [13:18<06:08, 1548.64 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1229000/1801350 [13:18<06:24, 1487.84 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1229000/1801350 [13:18<06:19, 1507.80 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1229000/1801350 [13:19<06:23, 1491.95 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1232000/1801350 [13:19<05:54, 1604.39 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1230000/1801350 [13:19<06:17, 1512.08 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1230000/1801350 [13:19<06:18, 1510.84 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1230000/1801350 [13:19<06:14, 1523.94 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1233000/1801350 [13:19<05:50, 1620.48 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1231000/1801350 [13:20<06:08, 1547.76 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1231000/1801350 [13:20<06:12, 1533.12 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1231000/1801350 [13:20<06:07, 1550.02 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1234000/1801350 [13:20<05:57, 1588.22 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1232000/1801350 [13:20<05:54, 1604.45 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1232000/1801350 [13:20<05:57, 1592.77 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1232000/1801350 [13:20<05:54, 1604.84 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1235000/1801350 [13:21<05:53, 1604.19 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1233000/1801350 [13:21<05:52, 1611.16 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1233000/1801350 [13:21<05:50, 1621.73 examples/s]Running tokenizer on dataset:  68%|██████▊   | 1233000/1801350 [13:21<05:52, 1613.54 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1236000/1801350 [13:21<05:53, 1598.64 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1234000/1801350 [13:21<05:51, 1613.21 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1234000/1801350 [13:21<05:57, 1588.38 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1234000/1801350 [13:22<05:54, 1600.34 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1237000/1801350 [13:22<05:50, 1611.76 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1235000/1801350 [13:22<05:54, 1598.82 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1235000/1801350 [13:22<05:58, 1580.53 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1235000/1801350 [13:22<05:52, 1604.54 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1238000/1801350 [13:23<05:52, 1597.42 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1236000/1801350 [13:23<05:59, 1570.67 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1236000/1801350 [13:23<05:51, 1608.40 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1236000/1801350 [13:23<05:53, 1598.78 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1239000/1801350 [13:23<05:52, 1594.83 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1237000/1801350 [13:23<05:54, 1591.45 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1237000/1801350 [13:23<05:54, 1591.02 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1237000/1801350 [13:24<05:50, 1607.97 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1240000/1801350 [13:24<05:52, 1592.29 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1238000/1801350 [13:24<05:56, 1580.42 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1238000/1801350 [13:24<05:52, 1598.34 examples/s]Running tokenizer on dataset:  69%|██████▊   | 1238000/1801350 [13:24<05:50, 1607.34 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1241000/1801350 [13:24<05:57, 1567.64 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1239000/1801350 [13:25<05:52, 1594.78 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1239000/1801350 [13:25<05:47, 1617.52 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1239000/1801350 [13:25<05:49, 1608.87 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1242000/1801350 [13:25<06:06, 1527.69 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1240000/1801350 [13:25<05:55, 1580.95 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1240000/1801350 [13:25<05:47, 1615.19 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1240000/1801350 [13:25<05:49, 1604.49 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1243000/1801350 [13:26<06:04, 1530.31 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1241000/1801350 [13:26<05:59, 1560.15 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1241000/1801350 [13:26<05:58, 1562.36 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1241000/1801350 [13:26<05:55, 1575.81 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1244000/1801350 [13:26<06:01, 1543.84 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1242000/1801350 [13:27<06:06, 1527.47 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1242000/1801350 [13:27<06:08, 1516.23 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1242000/1801350 [13:27<06:05, 1528.61 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1245000/1801350 [13:27<05:55, 1564.55 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1243000/1801350 [13:27<06:06, 1522.69 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1243000/1801350 [13:27<06:08, 1515.44 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1243000/1801350 [13:27<06:08, 1514.97 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1244000/1801350 [13:28<05:59, 1548.62 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1244000/1801350 [13:28<06:00, 1544.31 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1246000/1801350 [13:28<06:54, 1339.68 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1244000/1801350 [13:28<05:58, 1553.93 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1245000/1801350 [13:28<05:51, 1584.62 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1245000/1801350 [13:28<05:51, 1581.47 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1245000/1801350 [13:29<05:48, 1598.14 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1247000/1801350 [13:29<06:53, 1342.14 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1248000/1801350 [13:29<06:26, 1430.06 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1246000/1801350 [13:29<06:49, 1355.04 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1246000/1801350 [13:29<06:50, 1352.58 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1246000/1801350 [13:30<06:48, 1359.85 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1249000/1801350 [13:30<06:09, 1492.91 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1247000/1801350 [13:30<06:41, 1379.56 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1247000/1801350 [13:30<06:53, 1341.01 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1247000/1801350 [13:30<06:47, 1359.48 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1250000/1801350 [13:31<05:52, 1564.27 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1248000/1801350 [13:31<06:25, 1437.10 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1248000/1801350 [13:31<06:28, 1424.33 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1248000/1801350 [13:31<06:25, 1434.52 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1251000/1801350 [13:31<05:59, 1530.56 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1249000/1801350 [13:31<06:15, 1472.70 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1249000/1801350 [13:31<06:19, 1453.74 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1249000/1801350 [13:32<06:13, 1479.20 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1252000/1801350 [13:32<05:48, 1578.35 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1250000/1801350 [13:32<05:52, 1565.43 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1250000/1801350 [13:32<05:55, 1550.36 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1250000/1801350 [13:32<05:52, 1566.03 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1253000/1801350 [13:32<05:39, 1614.33 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1251000/1801350 [13:33<05:56, 1541.87 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1251000/1801350 [13:33<06:01, 1521.67 examples/s]Running tokenizer on dataset:  69%|██████▉   | 1251000/1801350 [13:33<05:59, 1531.97 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1254000/1801350 [13:33<05:45, 1585.89 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1252000/1801350 [13:33<05:51, 1564.24 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1252000/1801350 [13:33<05:52, 1556.47 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1252000/1801350 [13:33<05:49, 1571.04 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1255000/1801350 [13:34<05:40, 1606.80 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1253000/1801350 [13:34<05:39, 1615.23 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1253000/1801350 [13:34<05:41, 1607.12 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1253000/1801350 [13:34<05:37, 1622.65 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1256000/1801350 [13:34<05:41, 1595.23 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1254000/1801350 [13:34<05:45, 1582.74 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1254000/1801350 [13:35<05:46, 1579.50 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1254000/1801350 [13:35<05:44, 1588.65 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1257000/1801350 [13:35<05:42, 1590.36 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1255000/1801350 [13:35<05:42, 1594.59 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1255000/1801350 [13:35<05:41, 1600.55 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1255000/1801350 [13:35<05:41, 1601.61 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1258000/1801350 [13:36<05:39, 1598.45 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1256000/1801350 [13:36<05:44, 1585.05 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1256000/1801350 [13:36<05:45, 1577.90 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1256000/1801350 [13:36<05:44, 1581.47 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1259000/1801350 [13:36<05:40, 1593.31 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1257000/1801350 [13:36<05:42, 1587.32 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1257000/1801350 [13:36<05:40, 1600.88 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1257000/1801350 [13:37<05:39, 1601.08 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1260000/1801350 [13:37<05:35, 1611.71 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1258000/1801350 [13:37<05:41, 1590.75 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1258000/1801350 [13:37<05:41, 1592.51 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1258000/1801350 [13:37<05:41, 1590.83 examples/s]Running tokenizer on dataset:  70%|███████   | 1261000/1801350 [13:37<05:24, 1667.65 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1259000/1801350 [13:38<05:39, 1598.32 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1259000/1801350 [13:38<05:40, 1592.66 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1259000/1801350 [13:38<05:40, 1594.33 examples/s]Running tokenizer on dataset:  70%|███████   | 1262000/1801350 [13:38<05:26, 1650.46 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1260000/1801350 [13:38<05:39, 1596.33 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1260000/1801350 [13:38<05:33, 1622.34 examples/s]Running tokenizer on dataset:  70%|██████▉   | 1260000/1801350 [13:38<05:32, 1628.86 examples/s]Running tokenizer on dataset:  70%|███████   | 1263000/1801350 [13:39<05:31, 1624.12 examples/s]Running tokenizer on dataset:  70%|███████   | 1261000/1801350 [13:39<05:19, 1693.87 examples/s]Running tokenizer on dataset:  70%|███████   | 1261000/1801350 [13:39<05:27, 1651.20 examples/s]Running tokenizer on dataset:  70%|███████   | 1261000/1801350 [13:39<05:19, 1693.17 examples/s]Running tokenizer on dataset:  70%|███████   | 1264000/1801350 [13:39<05:22, 1667.20 examples/s]Running tokenizer on dataset:  70%|███████   | 1262000/1801350 [13:39<05:22, 1674.31 examples/s]Running tokenizer on dataset:  70%|███████   | 1262000/1801350 [13:39<05:28, 1641.83 examples/s]Running tokenizer on dataset:  70%|███████   | 1262000/1801350 [13:40<05:22, 1674.57 examples/s]Running tokenizer on dataset:  70%|███████   | 1265000/1801350 [13:40<05:45, 1553.32 examples/s]Running tokenizer on dataset:  70%|███████   | 1263000/1801350 [13:40<05:34, 1610.80 examples/s]Running tokenizer on dataset:  70%|███████   | 1263000/1801350 [13:40<05:31, 1622.87 examples/s]Running tokenizer on dataset:  70%|███████   | 1263000/1801350 [13:40<05:28, 1636.69 examples/s]Running tokenizer on dataset:  70%|███████   | 1266000/1801350 [13:41<05:33, 1604.44 examples/s]Running tokenizer on dataset:  70%|███████   | 1264000/1801350 [13:41<05:25, 1650.75 examples/s]Running tokenizer on dataset:  70%|███████   | 1264000/1801350 [13:41<05:28, 1637.46 examples/s]Running tokenizer on dataset:  70%|███████   | 1264000/1801350 [13:41<05:21, 1668.90 examples/s]Running tokenizer on dataset:  70%|███████   | 1265000/1801350 [13:41<05:46, 1549.69 examples/s]Running tokenizer on dataset:  70%|███████   | 1265000/1801350 [13:41<05:43, 1561.73 examples/s]Running tokenizer on dataset:  70%|███████   | 1265000/1801350 [13:41<05:43, 1560.64 examples/s]Running tokenizer on dataset:  70%|███████   | 1267000/1801350 [13:42<06:40, 1334.83 examples/s]Running tokenizer on dataset:  70%|███████   | 1266000/1801350 [13:42<05:29, 1622.43 examples/s]Running tokenizer on dataset:  70%|███████   | 1266000/1801350 [13:42<05:30, 1619.71 examples/s]Running tokenizer on dataset:  70%|███████   | 1266000/1801350 [13:42<05:27, 1636.30 examples/s]Running tokenizer on dataset:  70%|███████   | 1268000/1801350 [13:42<06:22, 1395.52 examples/s]Running tokenizer on dataset:  70%|███████   | 1269000/1801350 [13:43<05:57, 1489.86 examples/s]Running tokenizer on dataset:  70%|███████   | 1267000/1801350 [13:43<06:45, 1317.55 examples/s]Running tokenizer on dataset:  70%|███████   | 1267000/1801350 [13:43<06:43, 1323.42 examples/s]Running tokenizer on dataset:  70%|███████   | 1267000/1801350 [13:43<06:23, 1394.15 examples/s]Running tokenizer on dataset:  71%|███████   | 1270000/1801350 [13:43<05:48, 1523.17 examples/s]Running tokenizer on dataset:  70%|███████   | 1268000/1801350 [13:44<06:24, 1387.30 examples/s]Running tokenizer on dataset:  70%|███████   | 1268000/1801350 [13:44<06:25, 1383.40 examples/s]Running tokenizer on dataset:  70%|███████   | 1268000/1801350 [13:44<06:19, 1406.36 examples/s]Running tokenizer on dataset:  71%|███████   | 1271000/1801350 [13:44<05:39, 1561.23 examples/s]Running tokenizer on dataset:  70%|███████   | 1269000/1801350 [13:44<06:09, 1442.58 examples/s]Running tokenizer on dataset:  70%|███████   | 1269000/1801350 [13:44<06:11, 1434.48 examples/s]Running tokenizer on dataset:  70%|███████   | 1269000/1801350 [13:44<06:01, 1471.69 examples/s]Running tokenizer on dataset:  71%|███████   | 1272000/1801350 [13:45<05:39, 1558.60 examples/s]Running tokenizer on dataset:  71%|███████   | 1270000/1801350 [13:45<05:59, 1476.74 examples/s]Running tokenizer on dataset:  71%|███████   | 1270000/1801350 [13:45<05:59, 1476.21 examples/s]Running tokenizer on dataset:  71%|███████   | 1270000/1801350 [13:45<05:49, 1518.33 examples/s]Running tokenizer on dataset:  71%|███████   | 1273000/1801350 [13:45<05:39, 1555.57 examples/s]Running tokenizer on dataset:  71%|███████   | 1271000/1801350 [13:46<05:50, 1513.52 examples/s]Running tokenizer on dataset:  71%|███████   | 1271000/1801350 [13:46<05:49, 1518.39 examples/s]Running tokenizer on dataset:  71%|███████   | 1271000/1801350 [13:46<05:41, 1551.09 examples/s]Running tokenizer on dataset:  71%|███████   | 1274000/1801350 [13:46<05:43, 1533.65 examples/s]Running tokenizer on dataset:  71%|███████   | 1272000/1801350 [13:46<05:45, 1533.50 examples/s]Running tokenizer on dataset:  71%|███████   | 1272000/1801350 [13:46<05:45, 1533.88 examples/s]Running tokenizer on dataset:  71%|███████   | 1272000/1801350 [13:46<05:39, 1557.76 examples/s]Running tokenizer on dataset:  71%|███████   | 1275000/1801350 [13:47<05:57, 1471.34 examples/s]Running tokenizer on dataset:  71%|███████   | 1273000/1801350 [13:47<05:40, 1552.61 examples/s]Running tokenizer on dataset:  71%|███████   | 1273000/1801350 [13:47<05:46, 1526.11 examples/s]Running tokenizer on dataset:  71%|███████   | 1273000/1801350 [13:47<05:45, 1530.13 examples/s]Running tokenizer on dataset:  71%|███████   | 1276000/1801350 [13:47<05:47, 1513.44 examples/s]Running tokenizer on dataset:  71%|███████   | 1274000/1801350 [13:47<05:43, 1534.32 examples/s]Running tokenizer on dataset:  71%|███████   | 1274000/1801350 [13:47<05:45, 1526.30 examples/s]Running tokenizer on dataset:  71%|███████   | 1274000/1801350 [13:47<05:50, 1506.07 examples/s]Running tokenizer on dataset:  71%|███████   | 1277000/1801350 [13:48<05:38, 1551.26 examples/s]Running tokenizer on dataset:  71%|███████   | 1275000/1801350 [13:48<05:50, 1500.00 examples/s]Running tokenizer on dataset:  71%|███████   | 1275000/1801350 [13:48<05:58, 1468.87 examples/s]Running tokenizer on dataset:  71%|███████   | 1275000/1801350 [13:48<05:59, 1463.63 examples/s]Running tokenizer on dataset:  71%|███████   | 1278000/1801350 [13:49<05:28, 1591.32 examples/s]Running tokenizer on dataset:  71%|███████   | 1276000/1801350 [13:49<05:48, 1509.40 examples/s]Running tokenizer on dataset:  71%|███████   | 1276000/1801350 [13:49<05:48, 1509.48 examples/s]Running tokenizer on dataset:  71%|███████   | 1276000/1801350 [13:49<05:50, 1499.25 examples/s]Running tokenizer on dataset:  71%|███████   | 1279000/1801350 [13:49<05:22, 1621.77 examples/s]Running tokenizer on dataset:  71%|███████   | 1277000/1801350 [13:49<05:37, 1554.45 examples/s]Running tokenizer on dataset:  71%|███████   | 1277000/1801350 [13:49<05:37, 1554.38 examples/s]Running tokenizer on dataset:  71%|███████   | 1277000/1801350 [13:49<05:36, 1556.07 examples/s]Running tokenizer on dataset:  71%|███████   | 1280000/1801350 [13:50<05:20, 1626.36 examples/s]Running tokenizer on dataset:  71%|███████   | 1278000/1801350 [13:50<05:29, 1587.57 examples/s]Running tokenizer on dataset:  71%|███████   | 1278000/1801350 [13:50<05:31, 1580.17 examples/s]Running tokenizer on dataset:  71%|███████   | 1278000/1801350 [13:50<05:30, 1582.98 examples/s]Running tokenizer on dataset:  71%|███████   | 1281000/1801350 [13:50<05:14, 1651.95 examples/s]Running tokenizer on dataset:  71%|███████   | 1279000/1801350 [13:51<05:22, 1617.83 examples/s]Running tokenizer on dataset:  71%|███████   | 1279000/1801350 [13:51<05:24, 1611.75 examples/s]Running tokenizer on dataset:  71%|███████   | 1279000/1801350 [13:51<05:22, 1618.36 examples/s]Running tokenizer on dataset:  71%|███████   | 1282000/1801350 [13:51<05:21, 1616.68 examples/s]Running tokenizer on dataset:  71%|███████   | 1280000/1801350 [13:51<05:18, 1636.02 examples/s]Running tokenizer on dataset:  71%|███████   | 1280000/1801350 [13:51<05:18, 1634.86 examples/s]Running tokenizer on dataset:  71%|███████   | 1280000/1801350 [13:51<05:18, 1634.54 examples/s]Running tokenizer on dataset:  71%|███████   | 1283000/1801350 [13:52<05:29, 1573.24 examples/s]Running tokenizer on dataset:  71%|███████   | 1281000/1801350 [13:52<05:15, 1651.60 examples/s]Running tokenizer on dataset:  71%|███████   | 1281000/1801350 [13:52<05:15, 1648.01 examples/s]Running tokenizer on dataset:  71%|███████   | 1281000/1801350 [13:52<05:16, 1646.62 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1284000/1801350 [13:52<05:10, 1663.63 examples/s]Running tokenizer on dataset:  71%|███████   | 1282000/1801350 [13:52<05:18, 1629.11 examples/s]Running tokenizer on dataset:  71%|███████   | 1282000/1801350 [13:52<05:20, 1619.69 examples/s]Running tokenizer on dataset:  71%|███████   | 1282000/1801350 [13:52<05:19, 1627.66 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1285000/1801350 [13:53<05:20, 1612.70 examples/s]Running tokenizer on dataset:  71%|███████   | 1283000/1801350 [13:53<05:29, 1575.08 examples/s]Running tokenizer on dataset:  71%|███████   | 1283000/1801350 [13:53<05:31, 1561.34 examples/s]Running tokenizer on dataset:  71%|███████   | 1283000/1801350 [13:53<05:32, 1559.29 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1286000/1801350 [13:53<05:21, 1603.86 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1284000/1801350 [13:54<05:07, 1683.99 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1284000/1801350 [13:54<05:03, 1703.14 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1284000/1801350 [13:54<05:12, 1656.12 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1287000/1801350 [13:54<05:25, 1579.77 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1285000/1801350 [13:54<05:16, 1633.81 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1285000/1801350 [13:54<05:20, 1609.57 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1285000/1801350 [13:54<05:23, 1598.13 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1286000/1801350 [13:55<05:20, 1606.62 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1286000/1801350 [13:55<05:25, 1581.57 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1286000/1801350 [13:55<05:27, 1574.58 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1288000/1801350 [13:55<06:27, 1326.11 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1287000/1801350 [13:56<05:25, 1579.45 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1287000/1801350 [13:56<05:23, 1590.90 examples/s]Running tokenizer on dataset:  71%|███████▏  | 1287000/1801350 [13:56<05:22, 1592.94 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1289000/1801350 [13:56<06:16, 1360.69 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1290000/1801350 [13:56<05:53, 1446.85 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1288000/1801350 [13:57<06:22, 1343.79 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1288000/1801350 [13:57<06:22, 1340.71 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1288000/1801350 [13:57<06:27, 1326.33 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1291000/1801350 [13:57<05:51, 1450.83 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1289000/1801350 [13:57<06:07, 1392.35 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1289000/1801350 [13:57<06:14, 1366.42 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1289000/1801350 [13:57<06:14, 1368.89 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1292000/1801350 [13:58<05:42, 1488.99 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1290000/1801350 [13:58<05:51, 1452.74 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1290000/1801350 [13:58<05:52, 1450.60 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1290000/1801350 [13:58<05:56, 1436.27 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1293000/1801350 [13:58<05:36, 1512.13 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1291000/1801350 [13:59<05:55, 1437.41 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1291000/1801350 [13:59<05:55, 1434.92 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1291000/1801350 [13:59<06:02, 1406.65 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1294000/1801350 [13:59<05:16, 1603.71 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1292000/1801350 [13:59<05:46, 1467.87 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1292000/1801350 [13:59<05:51, 1450.96 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1292000/1801350 [13:59<05:46, 1468.66 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1295000/1801350 [13:59<05:08, 1642.94 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1293000/1801350 [14:00<05:40, 1492.92 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1293000/1801350 [14:00<05:42, 1486.00 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1293000/1801350 [14:00<05:45, 1470.05 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1296000/1801350 [14:00<05:12, 1614.71 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1294000/1801350 [14:00<05:20, 1583.15 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1294000/1801350 [14:00<05:20, 1583.67 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1294000/1801350 [14:00<05:21, 1578.54 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1297000/1801350 [14:01<05:05, 1652.45 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1295000/1801350 [14:01<05:07, 1646.90 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1295000/1801350 [14:01<05:08, 1641.83 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1295000/1801350 [14:01<05:10, 1632.45 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1298000/1801350 [14:01<05:04, 1655.39 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1296000/1801350 [14:02<05:12, 1616.36 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1296000/1801350 [14:02<05:13, 1612.08 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1296000/1801350 [14:02<05:15, 1600.68 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1299000/1801350 [14:02<05:16, 1589.25 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1297000/1801350 [14:02<05:05, 1650.03 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1297000/1801350 [14:02<05:06, 1646.75 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1297000/1801350 [14:02<05:07, 1642.62 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1300000/1801350 [14:03<05:04, 1645.39 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1298000/1801350 [14:03<05:04, 1650.85 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1298000/1801350 [14:03<05:05, 1645.82 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1298000/1801350 [14:03<05:06, 1639.70 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1301000/1801350 [14:03<05:12, 1600.18 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1299000/1801350 [14:04<05:17, 1584.63 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1299000/1801350 [14:04<05:17, 1581.12 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1299000/1801350 [14:04<05:17, 1581.74 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1302000/1801350 [14:04<05:10, 1608.44 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1300000/1801350 [14:04<05:06, 1635.61 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1300000/1801350 [14:04<05:07, 1629.47 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1300000/1801350 [14:04<05:07, 1628.75 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1303000/1801350 [14:04<05:04, 1636.47 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1301000/1801350 [14:05<05:12, 1600.72 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1301000/1801350 [14:05<05:14, 1589.76 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1301000/1801350 [14:05<05:14, 1589.14 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1304000/1801350 [14:05<05:15, 1578.37 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1302000/1801350 [14:05<05:09, 1612.93 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1302000/1801350 [14:05<05:11, 1600.80 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1302000/1801350 [14:05<05:11, 1601.77 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1305000/1801350 [14:06<05:19, 1552.77 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1303000/1801350 [14:06<05:07, 1620.48 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1303000/1801350 [14:06<05:07, 1618.14 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1303000/1801350 [14:06<05:07, 1619.18 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1306000/1801350 [14:06<05:14, 1574.37 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1304000/1801350 [14:07<05:14, 1578.94 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1304000/1801350 [14:07<05:15, 1578.58 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1304000/1801350 [14:07<05:15, 1574.67 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1307000/1801350 [14:07<05:25, 1519.83 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1305000/1801350 [14:07<05:16, 1568.78 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1305000/1801350 [14:07<05:17, 1563.40 examples/s]Running tokenizer on dataset:  72%|███████▏  | 1305000/1801350 [14:07<05:20, 1547.99 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1308000/1801350 [14:08<05:08, 1596.83 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1306000/1801350 [14:08<05:13, 1580.49 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1306000/1801350 [14:08<05:13, 1578.02 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1306000/1801350 [14:08<05:21, 1541.98 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1309000/1801350 [14:09<06:03, 1355.54 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1307000/1801350 [14:09<05:21, 1539.37 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1307000/1801350 [14:09<05:25, 1520.62 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1307000/1801350 [14:09<05:29, 1499.43 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1308000/1801350 [14:09<05:01, 1636.98 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1308000/1801350 [14:09<05:03, 1626.68 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1308000/1801350 [14:09<05:05, 1615.15 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1310000/1801350 [14:09<06:08, 1331.74 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1311000/1801350 [14:10<05:43, 1425.77 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1309000/1801350 [14:10<05:52, 1395.79 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1309000/1801350 [14:10<05:54, 1390.28 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1309000/1801350 [14:10<05:54, 1388.96 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1312000/1801350 [14:11<05:33, 1465.46 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1310000/1801350 [14:11<05:55, 1382.41 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1310000/1801350 [14:11<05:57, 1375.80 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1310000/1801350 [14:11<05:55, 1381.27 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1313000/1801350 [14:11<05:34, 1458.91 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1311000/1801350 [14:11<05:38, 1447.87 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1311000/1801350 [14:11<05:39, 1443.08 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1311000/1801350 [14:12<05:37, 1451.00 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1314000/1801350 [14:12<05:24, 1501.31 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1312000/1801350 [14:12<05:39, 1442.25 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1312000/1801350 [14:12<05:39, 1439.40 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1312000/1801350 [14:12<05:33, 1465.75 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1315000/1801350 [14:13<05:19, 1524.48 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1313000/1801350 [14:13<05:38, 1442.57 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1313000/1801350 [14:13<05:34, 1460.70 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1313000/1801350 [14:13<05:39, 1437.88 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1316000/1801350 [14:13<04:59, 1618.17 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1314000/1801350 [14:13<05:25, 1498.60 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1314000/1801350 [14:13<05:24, 1500.35 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1314000/1801350 [14:13<05:22, 1511.48 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1317000/1801350 [14:14<04:55, 1637.71 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1315000/1801350 [14:14<05:16, 1538.43 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1315000/1801350 [14:14<05:16, 1534.74 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1315000/1801350 [14:14<05:14, 1544.97 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1318000/1801350 [14:14<04:50, 1664.09 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1316000/1801350 [14:15<04:55, 1645.08 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1316000/1801350 [14:15<04:59, 1622.67 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1316000/1801350 [14:15<04:57, 1634.01 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1319000/1801350 [14:15<04:51, 1656.15 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1317000/1801350 [14:15<04:56, 1634.19 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1317000/1801350 [14:15<04:54, 1645.06 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1317000/1801350 [14:15<04:57, 1630.71 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1320000/1801350 [14:15<04:47, 1672.54 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1318000/1801350 [14:16<04:46, 1684.92 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1318000/1801350 [14:16<04:46, 1687.84 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1318000/1801350 [14:16<04:53, 1646.10 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1321000/1801350 [14:16<04:44, 1685.72 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1319000/1801350 [14:16<04:49, 1663.95 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1319000/1801350 [14:16<04:50, 1660.94 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1319000/1801350 [14:16<04:56, 1627.58 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1322000/1801350 [14:17<05:03, 1578.11 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1320000/1801350 [14:17<04:46, 1682.99 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1320000/1801350 [14:17<04:51, 1650.97 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1320000/1801350 [14:17<04:49, 1662.96 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1323000/1801350 [14:17<04:53, 1628.88 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1321000/1801350 [14:18<04:47, 1671.81 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1321000/1801350 [14:18<04:49, 1657.55 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1321000/1801350 [14:18<04:45, 1680.37 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1324000/1801350 [14:18<04:47, 1663.20 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1322000/1801350 [14:18<04:59, 1599.65 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1322000/1801350 [14:18<05:00, 1597.42 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1322000/1801350 [14:18<05:07, 1556.97 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1325000/1801350 [14:19<04:49, 1645.47 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1323000/1801350 [14:19<04:53, 1627.58 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1323000/1801350 [14:19<04:58, 1603.91 examples/s]Running tokenizer on dataset:  73%|███████▎  | 1323000/1801350 [14:19<04:57, 1605.68 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1326000/1801350 [14:19<05:01, 1574.38 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1324000/1801350 [14:19<04:46, 1664.99 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1324000/1801350 [14:19<04:47, 1657.51 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1324000/1801350 [14:19<04:50, 1644.79 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1327000/1801350 [14:20<04:58, 1587.50 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1325000/1801350 [14:20<04:47, 1657.62 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1325000/1801350 [14:20<04:49, 1647.89 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1325000/1801350 [14:20<04:52, 1629.29 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1328000/1801350 [14:21<04:57, 1589.32 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1326000/1801350 [14:21<04:59, 1587.36 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1326000/1801350 [14:21<05:03, 1566.95 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1326000/1801350 [14:21<05:04, 1563.05 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1329000/1801350 [14:21<05:00, 1570.92 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1327000/1801350 [14:21<05:01, 1574.98 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1327000/1801350 [14:21<05:03, 1563.10 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1327000/1801350 [14:21<05:04, 1558.04 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1328000/1801350 [14:22<04:56, 1595.22 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1328000/1801350 [14:22<04:57, 1588.75 examples/s]Running tokenizer on dataset:  74%|███████▎  | 1328000/1801350 [14:22<05:00, 1575.09 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1330000/1801350 [14:22<05:54, 1327.88 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1329000/1801350 [14:23<04:58, 1582.56 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1329000/1801350 [14:23<04:59, 1575.81 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1329000/1801350 [14:23<05:00, 1572.69 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1331000/1801350 [14:23<05:38, 1389.40 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1332000/1801350 [14:23<05:18, 1471.75 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1330000/1801350 [14:24<05:50, 1345.29 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1330000/1801350 [14:24<05:45, 1362.96 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1330000/1801350 [14:24<05:53, 1333.46 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1333000/1801350 [14:24<05:15, 1484.62 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1331000/1801350 [14:24<05:31, 1418.17 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1331000/1801350 [14:24<05:30, 1422.21 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1331000/1801350 [14:24<05:37, 1393.01 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1334000/1801350 [14:25<05:14, 1484.89 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1332000/1801350 [14:25<05:16, 1485.28 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1332000/1801350 [14:25<05:26, 1436.05 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1332000/1801350 [14:25<05:20, 1463.08 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1335000/1801350 [14:25<05:09, 1507.88 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1333000/1801350 [14:26<05:18, 1469.17 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1333000/1801350 [14:26<05:26, 1435.56 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1333000/1801350 [14:26<05:23, 1449.23 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1336000/1801350 [14:26<05:05, 1521.52 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1334000/1801350 [14:26<05:20, 1460.13 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1334000/1801350 [14:26<05:17, 1471.66 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1334000/1801350 [14:26<05:17, 1471.97 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1337000/1801350 [14:27<04:52, 1584.88 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1335000/1801350 [14:27<05:11, 1495.93 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1335000/1801350 [14:27<05:10, 1501.47 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1335000/1801350 [14:27<05:10, 1501.87 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1338000/1801350 [14:27<04:50, 1594.23 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1336000/1801350 [14:28<05:08, 1508.12 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1336000/1801350 [14:28<05:07, 1515.77 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1336000/1801350 [14:28<05:10, 1498.13 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1339000/1801350 [14:28<04:44, 1624.90 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1337000/1801350 [14:28<04:50, 1599.29 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1337000/1801350 [14:28<04:53, 1581.40 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1337000/1801350 [14:28<04:51, 1592.34 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1340000/1801350 [14:28<04:48, 1597.86 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1338000/1801350 [14:29<04:52, 1584.86 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1338000/1801350 [14:29<04:53, 1576.22 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1338000/1801350 [14:29<04:53, 1581.11 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1341000/1801350 [14:29<04:42, 1629.80 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1339000/1801350 [14:29<04:44, 1624.60 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1339000/1801350 [14:29<04:49, 1595.31 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1339000/1801350 [14:29<04:41, 1640.84 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1342000/1801350 [14:30<04:46, 1604.51 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1340000/1801350 [14:30<04:48, 1598.13 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1340000/1801350 [14:30<04:48, 1601.07 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1340000/1801350 [14:30<04:54, 1564.24 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1343000/1801350 [14:30<04:43, 1616.40 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1341000/1801350 [14:31<04:45, 1614.54 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1341000/1801350 [14:31<04:38, 1653.30 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1341000/1801350 [14:31<04:46, 1606.01 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1344000/1801350 [14:31<04:40, 1632.34 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1342000/1801350 [14:31<04:44, 1615.61 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1342000/1801350 [14:31<04:44, 1615.09 examples/s]Running tokenizer on dataset:  74%|███████▍  | 1342000/1801350 [14:31<04:43, 1622.08 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1345000/1801350 [14:32<04:42, 1616.07 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1343000/1801350 [14:32<04:46, 1601.54 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1343000/1801350 [14:32<04:42, 1623.45 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1343000/1801350 [14:32<04:46, 1601.92 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1346000/1801350 [14:32<04:41, 1615.45 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1344000/1801350 [14:32<04:38, 1643.30 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1344000/1801350 [14:32<04:45, 1602.82 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1344000/1801350 [14:32<04:39, 1634.44 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1347000/1801350 [14:33<04:43, 1601.42 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1345000/1801350 [14:33<04:42, 1615.54 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1345000/1801350 [14:33<04:45, 1597.47 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1345000/1801350 [14:33<04:45, 1597.94 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1348000/1801350 [14:33<04:38, 1626.17 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1346000/1801350 [14:34<04:37, 1641.69 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1346000/1801350 [14:34<04:38, 1634.55 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1346000/1801350 [14:34<04:44, 1600.49 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1349000/1801350 [14:34<04:35, 1641.33 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1347000/1801350 [14:34<04:42, 1605.94 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1347000/1801350 [14:34<04:39, 1625.83 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1347000/1801350 [14:34<04:49, 1570.79 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1350000/1801350 [14:35<04:39, 1612.56 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1348000/1801350 [14:35<04:33, 1658.90 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1348000/1801350 [14:35<04:37, 1632.72 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1348000/1801350 [14:35<04:39, 1623.36 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1349000/1801350 [14:35<04:33, 1651.24 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1349000/1801350 [14:35<04:32, 1657.07 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1349000/1801350 [14:36<04:37, 1631.41 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1351000/1801350 [14:36<05:30, 1364.57 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1350000/1801350 [14:36<04:34, 1644.40 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1350000/1801350 [14:36<04:37, 1626.32 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1350000/1801350 [14:36<04:37, 1628.82 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1352000/1801350 [14:36<05:21, 1395.99 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1353000/1801350 [14:37<05:10, 1444.74 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1351000/1801350 [14:37<05:20, 1406.03 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1351000/1801350 [14:37<05:19, 1411.10 examples/s]Running tokenizer on dataset:  75%|███████▍  | 1351000/1801350 [14:37<05:34, 1346.62 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1354000/1801350 [14:38<05:04, 1468.34 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1352000/1801350 [14:38<05:12, 1437.28 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1352000/1801350 [14:38<05:11, 1443.40 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1352000/1801350 [14:38<05:24, 1386.20 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1355000/1801350 [14:38<04:53, 1519.92 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1353000/1801350 [14:38<05:08, 1453.58 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1353000/1801350 [14:38<05:03, 1478.45 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1353000/1801350 [14:38<05:15, 1422.48 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1356000/1801350 [14:39<04:44, 1566.79 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1354000/1801350 [14:39<05:08, 1447.92 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1354000/1801350 [14:39<05:08, 1450.90 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1354000/1801350 [14:39<05:13, 1426.70 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1357000/1801350 [14:39<04:42, 1570.91 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1355000/1801350 [14:40<04:57, 1501.50 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1355000/1801350 [14:40<04:55, 1510.28 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1355000/1801350 [14:40<04:58, 1493.73 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1358000/1801350 [14:40<04:42, 1571.90 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1356000/1801350 [14:40<04:48, 1543.46 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1356000/1801350 [14:40<04:45, 1558.49 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1356000/1801350 [14:40<04:51, 1527.56 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1359000/1801350 [14:41<04:43, 1562.40 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1357000/1801350 [14:41<04:44, 1560.58 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1357000/1801350 [14:41<04:45, 1555.35 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1357000/1801350 [14:41<04:44, 1562.04 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1360000/1801350 [14:41<04:57, 1482.70 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1358000/1801350 [14:42<04:42, 1569.48 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1358000/1801350 [14:42<04:43, 1562.41 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1358000/1801350 [14:42<04:43, 1561.40 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1361000/1801350 [14:42<04:48, 1525.23 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1359000/1801350 [14:42<04:44, 1555.91 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1359000/1801350 [14:42<04:40, 1577.77 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1359000/1801350 [14:42<04:44, 1553.50 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1362000/1801350 [14:43<04:37, 1581.17 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1360000/1801350 [14:43<04:54, 1499.88 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1360000/1801350 [14:43<04:59, 1473.26 examples/s]Running tokenizer on dataset:  75%|███████▌  | 1360000/1801350 [14:43<04:58, 1480.49 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1363000/1801350 [14:43<04:37, 1576.93 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1361000/1801350 [14:44<04:46, 1536.73 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1361000/1801350 [14:44<04:50, 1517.75 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1361000/1801350 [14:44<04:50, 1517.03 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1364000/1801350 [14:44<04:52, 1496.81 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1362000/1801350 [14:44<04:37, 1582.57 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1362000/1801350 [14:44<04:37, 1585.29 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1362000/1801350 [14:44<04:40, 1564.75 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1365000/1801350 [14:45<04:50, 1502.13 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1363000/1801350 [14:45<04:36, 1583.18 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1363000/1801350 [14:45<04:38, 1574.41 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1363000/1801350 [14:45<04:38, 1572.99 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1366000/1801350 [14:45<04:49, 1503.96 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1364000/1801350 [14:46<04:52, 1493.61 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1364000/1801350 [14:46<04:53, 1488.59 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1364000/1801350 [14:46<04:53, 1490.19 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1367000/1801350 [14:46<04:46, 1517.36 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1365000/1801350 [14:46<04:51, 1495.36 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1365000/1801350 [14:46<04:52, 1494.34 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1365000/1801350 [14:46<04:53, 1487.21 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1368000/1801350 [14:47<04:43, 1527.52 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1366000/1801350 [14:47<04:52, 1489.48 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1366000/1801350 [14:47<04:53, 1484.01 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1366000/1801350 [14:47<04:53, 1485.29 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1369000/1801350 [14:47<04:37, 1558.78 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1367000/1801350 [14:48<04:46, 1514.41 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1367000/1801350 [14:48<04:47, 1513.02 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1367000/1801350 [14:48<04:46, 1516.51 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1370000/1801350 [14:48<04:57, 1450.53 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1368000/1801350 [14:48<04:43, 1531.12 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1368000/1801350 [14:48<04:44, 1524.32 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1368000/1801350 [14:48<04:45, 1519.09 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1371000/1801350 [14:49<04:47, 1496.84 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1369000/1801350 [14:49<04:35, 1569.93 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1369000/1801350 [14:49<04:36, 1566.44 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1369000/1801350 [14:49<04:38, 1555.15 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1370000/1801350 [14:50<04:56, 1454.30 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1370000/1801350 [14:50<04:58, 1446.77 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1372000/1801350 [14:50<05:29, 1301.78 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1370000/1801350 [14:50<05:00, 1435.69 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1371000/1801350 [14:50<04:45, 1507.12 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1371000/1801350 [14:50<04:45, 1506.91 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1371000/1801350 [14:50<04:43, 1519.73 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1373000/1801350 [14:50<05:29, 1301.32 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1374000/1801350 [14:51<05:19, 1335.60 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1372000/1801350 [14:51<05:26, 1314.20 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1372000/1801350 [14:51<05:26, 1313.34 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1372000/1801350 [14:51<05:28, 1308.35 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1375000/1801350 [14:52<04:42, 1506.76 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1373000/1801350 [14:52<05:21, 1333.27 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1373000/1801350 [14:52<05:24, 1321.51 examples/s]Running tokenizer on dataset:  76%|███████▌  | 1373000/1801350 [14:52<05:28, 1305.77 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1376000/1801350 [14:52<04:42, 1504.70 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1374000/1801350 [14:53<05:19, 1337.63 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1374000/1801350 [14:53<05:21, 1328.84 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1374000/1801350 [14:53<05:21, 1327.97 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1377000/1801350 [14:53<04:37, 1527.68 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1375000/1801350 [14:53<04:48, 1479.51 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1375000/1801350 [14:53<04:49, 1473.84 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1375000/1801350 [14:53<04:48, 1475.92 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1378000/1801350 [14:53<04:29, 1572.28 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1376000/1801350 [14:54<04:46, 1483.69 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1376000/1801350 [14:54<04:47, 1481.34 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1376000/1801350 [14:54<04:45, 1488.94 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1379000/1801350 [14:54<04:39, 1513.50 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1377000/1801350 [14:54<04:40, 1512.15 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1377000/1801350 [14:54<04:41, 1507.15 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1377000/1801350 [14:55<04:42, 1504.31 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1380000/1801350 [14:55<04:33, 1542.19 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1378000/1801350 [14:55<04:31, 1561.33 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1378000/1801350 [14:55<04:33, 1546.00 examples/s]Running tokenizer on dataset:  76%|███████▋  | 1378000/1801350 [14:55<04:31, 1561.01 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1381000/1801350 [14:56<04:37, 1517.48 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1379000/1801350 [14:56<04:38, 1517.18 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1379000/1801350 [14:56<04:38, 1515.47 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1379000/1801350 [14:56<04:37, 1521.19 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1382000/1801350 [14:56<04:34, 1528.59 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1380000/1801350 [14:56<04:32, 1548.96 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1380000/1801350 [14:56<04:33, 1543.06 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1380000/1801350 [14:56<04:33, 1542.33 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1383000/1801350 [14:57<04:28, 1556.87 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1381000/1801350 [14:57<04:36, 1519.80 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1381000/1801350 [14:57<04:39, 1505.88 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1381000/1801350 [14:57<04:37, 1516.13 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1384000/1801350 [14:57<04:29, 1551.02 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1382000/1801350 [14:58<04:34, 1526.27 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1382000/1801350 [14:58<04:36, 1517.26 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1382000/1801350 [14:58<04:32, 1539.61 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1385000/1801350 [14:58<04:18, 1609.54 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1383000/1801350 [14:58<04:29, 1550.30 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1383000/1801350 [14:58<04:33, 1531.85 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1383000/1801350 [14:58<04:30, 1547.31 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1386000/1801350 [14:59<04:28, 1545.72 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1384000/1801350 [14:59<04:29, 1548.35 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1384000/1801350 [14:59<04:30, 1541.74 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1384000/1801350 [14:59<04:27, 1559.63 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1387000/1801350 [14:59<04:27, 1547.54 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1385000/1801350 [15:00<04:19, 1605.81 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1385000/1801350 [15:00<04:20, 1596.39 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1385000/1801350 [15:00<04:18, 1609.96 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1388000/1801350 [15:00<04:15, 1618.27 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1386000/1801350 [15:00<04:27, 1554.70 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1386000/1801350 [15:00<04:28, 1547.87 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1386000/1801350 [15:00<04:26, 1558.53 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1389000/1801350 [15:01<04:19, 1590.87 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1387000/1801350 [15:01<04:28, 1541.78 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1387000/1801350 [15:01<04:30, 1530.77 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1387000/1801350 [15:01<04:33, 1514.10 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1390000/1801350 [15:01<04:22, 1566.38 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1388000/1801350 [15:01<04:19, 1595.05 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1388000/1801350 [15:01<04:19, 1591.45 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1388000/1801350 [15:02<04:19, 1595.12 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1391000/1801350 [15:02<04:23, 1555.49 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1389000/1801350 [15:02<04:18, 1598.15 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1389000/1801350 [15:02<04:19, 1588.84 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1389000/1801350 [15:02<04:19, 1586.98 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1392000/1801350 [15:02<04:20, 1573.43 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1390000/1801350 [15:03<04:20, 1578.30 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1390000/1801350 [15:03<04:21, 1571.55 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1390000/1801350 [15:03<04:20, 1581.08 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1391000/1801350 [15:03<04:21, 1571.65 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1391000/1801350 [15:03<04:22, 1565.13 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1391000/1801350 [15:03<04:19, 1583.62 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1393000/1801350 [15:04<05:16, 1292.06 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1392000/1801350 [15:04<04:16, 1597.48 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1392000/1801350 [15:04<04:19, 1580.27 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1392000/1801350 [15:04<04:17, 1589.79 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1394000/1801350 [15:04<04:58, 1362.69 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1395000/1801350 [15:05<04:44, 1429.34 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1393000/1801350 [15:05<05:12, 1306.50 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1393000/1801350 [15:05<05:19, 1279.16 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1393000/1801350 [15:05<05:08, 1324.59 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1396000/1801350 [15:05<04:35, 1473.22 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1394000/1801350 [15:06<04:55, 1380.72 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1394000/1801350 [15:06<04:54, 1385.14 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1394000/1801350 [15:06<05:04, 1336.03 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1397000/1801350 [15:06<04:30, 1494.28 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1395000/1801350 [15:06<04:45, 1424.92 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1395000/1801350 [15:06<04:49, 1402.58 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1395000/1801350 [15:06<04:44, 1427.29 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1398000/1801350 [15:07<04:29, 1496.05 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1396000/1801350 [15:07<04:42, 1435.62 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1396000/1801350 [15:07<04:49, 1401.52 examples/s]Running tokenizer on dataset:  77%|███████▋  | 1396000/1801350 [15:07<04:39, 1449.20 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1399000/1801350 [15:07<04:12, 1595.56 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1397000/1801350 [15:08<04:37, 1458.28 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1397000/1801350 [15:08<04:34, 1472.55 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1397000/1801350 [15:08<04:31, 1487.56 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1400000/1801350 [15:08<04:12, 1592.47 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1398000/1801350 [15:08<04:32, 1482.54 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1398000/1801350 [15:08<04:38, 1446.19 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1398000/1801350 [15:08<04:36, 1460.36 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1401000/1801350 [15:09<04:15, 1567.01 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1399000/1801350 [15:09<04:14, 1582.84 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1399000/1801350 [15:09<04:12, 1591.42 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1399000/1801350 [15:09<04:14, 1579.69 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1402000/1801350 [15:09<04:04, 1635.94 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1400000/1801350 [15:10<04:12, 1586.44 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1400000/1801350 [15:10<04:16, 1564.23 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1400000/1801350 [15:10<04:14, 1579.40 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1403000/1801350 [15:10<04:05, 1621.89 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1401000/1801350 [15:10<04:15, 1565.51 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1401000/1801350 [15:10<04:17, 1553.15 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1401000/1801350 [15:10<04:16, 1561.51 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1404000/1801350 [15:10<04:07, 1607.38 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1402000/1801350 [15:11<04:04, 1632.79 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1402000/1801350 [15:11<04:06, 1618.44 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1402000/1801350 [15:11<04:05, 1625.67 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1405000/1801350 [15:11<04:01, 1641.07 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1403000/1801350 [15:11<04:10, 1592.29 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1403000/1801350 [15:11<04:09, 1597.11 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1403000/1801350 [15:11<04:09, 1594.85 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1406000/1801350 [15:12<04:12, 1566.63 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1404000/1801350 [15:12<04:09, 1594.20 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1404000/1801350 [15:12<04:07, 1607.23 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1404000/1801350 [15:12<04:08, 1596.88 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1407000/1801350 [15:12<04:18, 1524.27 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1405000/1801350 [15:13<04:00, 1647.91 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1405000/1801350 [15:13<04:00, 1650.30 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1405000/1801350 [15:13<04:02, 1637.40 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1408000/1801350 [15:13<04:13, 1548.71 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1406000/1801350 [15:13<04:13, 1556.57 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1406000/1801350 [15:13<04:15, 1549.71 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1406000/1801350 [15:13<04:15, 1544.51 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1409000/1801350 [15:14<04:05, 1599.74 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1407000/1801350 [15:14<04:19, 1519.30 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1407000/1801350 [15:14<04:19, 1517.45 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1407000/1801350 [15:14<04:21, 1508.11 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1410000/1801350 [15:14<04:13, 1545.94 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1408000/1801350 [15:15<04:14, 1548.02 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1408000/1801350 [15:15<04:15, 1540.54 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1408000/1801350 [15:15<04:15, 1540.74 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1411000/1801350 [15:15<04:10, 1558.71 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1409000/1801350 [15:15<04:05, 1595.90 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1409000/1801350 [15:15<04:06, 1592.26 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1409000/1801350 [15:15<04:06, 1590.51 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1412000/1801350 [15:16<04:08, 1567.45 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1410000/1801350 [15:16<04:11, 1557.60 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1410000/1801350 [15:16<04:11, 1556.32 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1410000/1801350 [15:16<04:12, 1549.92 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1413000/1801350 [15:16<04:07, 1571.52 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1411000/1801350 [15:17<04:10, 1555.31 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1411000/1801350 [15:17<04:11, 1553.50 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1411000/1801350 [15:17<04:11, 1551.31 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1414000/1801350 [15:17<04:42, 1373.01 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1412000/1801350 [15:17<04:10, 1551.70 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1412000/1801350 [15:17<04:10, 1551.37 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1412000/1801350 [15:17<04:11, 1546.56 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1415000/1801350 [15:18<04:29, 1434.32 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1413000/1801350 [15:18<04:04, 1586.26 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1413000/1801350 [15:18<04:05, 1584.15 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1413000/1801350 [15:18<04:06, 1576.32 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1416000/1801350 [15:18<04:34, 1406.11 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1414000/1801350 [15:19<04:42, 1369.96 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1414000/1801350 [15:19<04:43, 1368.26 examples/s]Running tokenizer on dataset:  78%|███████▊  | 1414000/1801350 [15:19<04:53, 1318.02 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1417000/1801350 [15:19<04:10, 1533.89 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1415000/1801350 [15:19<04:27, 1443.35 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1415000/1801350 [15:19<04:27, 1442.38 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1415000/1801350 [15:20<04:37, 1394.22 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1418000/1801350 [15:20<04:09, 1536.63 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1416000/1801350 [15:20<04:25, 1449.93 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1416000/1801350 [15:20<04:27, 1439.98 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1416000/1801350 [15:20<04:32, 1416.47 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1419000/1801350 [15:20<04:08, 1538.27 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1417000/1801350 [15:21<04:09, 1539.95 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1417000/1801350 [15:21<04:11, 1527.41 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1417000/1801350 [15:21<04:14, 1511.49 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1420000/1801350 [15:21<04:03, 1564.39 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1418000/1801350 [15:21<04:09, 1536.66 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1418000/1801350 [15:21<04:11, 1523.69 examples/s]Running tokenizer on dataset:  79%|███████▊  | 1418000/1801350 [15:21<04:12, 1515.68 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1421000/1801350 [15:22<04:03, 1559.34 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1419000/1801350 [15:22<04:08, 1538.38 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1419000/1801350 [15:22<04:10, 1524.23 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1419000/1801350 [15:22<04:12, 1516.90 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1422000/1801350 [15:22<04:14, 1492.44 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1420000/1801350 [15:23<04:05, 1552.02 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1420000/1801350 [15:23<04:06, 1547.15 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1420000/1801350 [15:23<04:07, 1540.72 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1423000/1801350 [15:23<04:08, 1524.87 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1421000/1801350 [15:23<04:03, 1561.84 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1421000/1801350 [15:23<04:05, 1548.46 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1421000/1801350 [15:23<04:04, 1556.24 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1424000/1801350 [15:24<04:01, 1563.26 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1422000/1801350 [15:24<04:13, 1495.83 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1422000/1801350 [15:24<04:14, 1493.00 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1425000/1801350 [15:24<03:53, 1613.64 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1422000/1801350 [15:24<04:15, 1483.67 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1423000/1801350 [15:25<04:08, 1524.90 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1423000/1801350 [15:25<04:09, 1515.59 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1426000/1801350 [15:25<03:49, 1635.36 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1423000/1801350 [15:25<04:13, 1490.49 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1424000/1801350 [15:25<04:01, 1565.70 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1424000/1801350 [15:25<04:01, 1561.05 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1424000/1801350 [15:25<04:01, 1564.56 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1427000/1801350 [15:25<03:53, 1601.71 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1425000/1801350 [15:26<03:53, 1613.92 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1425000/1801350 [15:26<03:53, 1611.43 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1425000/1801350 [15:26<03:55, 1601.12 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1428000/1801350 [15:26<03:59, 1558.81 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1426000/1801350 [15:26<03:51, 1622.60 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1426000/1801350 [15:26<03:51, 1618.92 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1426000/1801350 [15:26<03:51, 1623.90 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1429000/1801350 [15:27<04:02, 1535.51 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1427000/1801350 [15:27<03:50, 1621.82 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1427000/1801350 [15:27<03:52, 1612.74 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1427000/1801350 [15:27<03:54, 1594.81 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1430000/1801350 [15:27<04:03, 1522.90 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1428000/1801350 [15:28<03:57, 1572.89 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1428000/1801350 [15:28<03:59, 1561.67 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1428000/1801350 [15:28<03:58, 1568.53 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1431000/1801350 [15:28<03:54, 1576.35 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1429000/1801350 [15:28<04:02, 1536.32 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1429000/1801350 [15:28<04:03, 1530.62 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1429000/1801350 [15:28<04:02, 1534.46 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1432000/1801350 [15:29<03:59, 1540.40 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1430000/1801350 [15:29<04:03, 1522.95 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1430000/1801350 [15:29<04:03, 1522.50 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1430000/1801350 [15:29<04:03, 1525.42 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1433000/1801350 [15:29<03:57, 1549.66 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1431000/1801350 [15:30<03:55, 1570.06 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1431000/1801350 [15:30<03:57, 1562.08 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1431000/1801350 [15:30<03:59, 1549.50 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1434000/1801350 [15:30<03:56, 1553.69 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1432000/1801350 [15:30<04:00, 1535.98 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1432000/1801350 [15:30<04:00, 1536.64 examples/s]Running tokenizer on dataset:  79%|███████▉  | 1432000/1801350 [15:30<03:59, 1539.80 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1435000/1801350 [15:31<04:06, 1485.18 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1433000/1801350 [15:31<03:55, 1561.03 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1433000/1801350 [15:31<03:57, 1552.14 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1433000/1801350 [15:31<03:59, 1539.42 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1436000/1801350 [15:31<03:57, 1538.33 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1434000/1801350 [15:32<03:56, 1554.34 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1434000/1801350 [15:32<03:56, 1552.98 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1434000/1801350 [15:32<03:56, 1551.86 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1437000/1801350 [15:32<03:57, 1535.54 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1435000/1801350 [15:32<04:09, 1467.14 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1435000/1801350 [15:32<04:10, 1459.77 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1438000/1801350 [15:33<03:52, 1560.07 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1435000/1801350 [15:33<04:15, 1433.37 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1436000/1801350 [15:33<03:52, 1570.31 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1436000/1801350 [15:33<03:59, 1523.68 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1436000/1801350 [15:33<03:57, 1535.37 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1439000/1801350 [15:33<03:51, 1564.49 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1437000/1801350 [15:34<03:54, 1552.25 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1437000/1801350 [15:34<03:58, 1526.88 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1437000/1801350 [15:34<03:58, 1525.34 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1440000/1801350 [15:34<03:49, 1572.29 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1438000/1801350 [15:34<03:51, 1570.28 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1438000/1801350 [15:34<03:55, 1542.86 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1438000/1801350 [15:34<03:53, 1559.24 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1441000/1801350 [15:34<03:51, 1558.12 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1439000/1801350 [15:35<03:50, 1569.37 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1439000/1801350 [15:35<03:53, 1554.18 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1439000/1801350 [15:35<03:50, 1569.76 examples/s]Running tokenizer on dataset:  80%|████████  | 1442000/1801350 [15:35<03:59, 1499.77 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1440000/1801350 [15:35<03:48, 1584.26 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1440000/1801350 [15:35<03:46, 1593.68 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1440000/1801350 [15:36<03:48, 1584.46 examples/s]Running tokenizer on dataset:  80%|████████  | 1443000/1801350 [15:36<03:48, 1571.08 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1441000/1801350 [15:36<03:54, 1539.60 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1441000/1801350 [15:36<03:50, 1564.88 examples/s]Running tokenizer on dataset:  80%|███████▉  | 1441000/1801350 [15:36<03:50, 1562.59 examples/s]Running tokenizer on dataset:  80%|████████  | 1444000/1801350 [15:36<03:48, 1561.69 examples/s]Running tokenizer on dataset:  80%|████████  | 1442000/1801350 [15:37<03:59, 1501.67 examples/s]Running tokenizer on dataset:  80%|████████  | 1442000/1801350 [15:37<04:02, 1484.38 examples/s]Running tokenizer on dataset:  80%|████████  | 1445000/1801350 [15:37<03:39, 1625.20 examples/s]Running tokenizer on dataset:  80%|████████  | 1442000/1801350 [15:37<04:03, 1477.46 examples/s]Running tokenizer on dataset:  80%|████████  | 1443000/1801350 [15:37<03:45, 1586.96 examples/s]Running tokenizer on dataset:  80%|████████  | 1443000/1801350 [15:37<03:50, 1557.29 examples/s]Running tokenizer on dataset:  80%|████████  | 1443000/1801350 [15:38<03:46, 1584.46 examples/s]Running tokenizer on dataset:  80%|████████  | 1446000/1801350 [15:38<03:50, 1538.49 examples/s]Running tokenizer on dataset:  80%|████████  | 1444000/1801350 [15:38<03:47, 1568.15 examples/s]Running tokenizer on dataset:  80%|████████  | 1444000/1801350 [15:38<03:51, 1545.45 examples/s]Running tokenizer on dataset:  80%|████████  | 1444000/1801350 [15:38<03:50, 1550.90 examples/s]Running tokenizer on dataset:  80%|████████  | 1447000/1801350 [15:38<03:50, 1535.97 examples/s]Running tokenizer on dataset:  80%|████████  | 1445000/1801350 [15:39<03:42, 1598.54 examples/s]Running tokenizer on dataset:  80%|████████  | 1445000/1801350 [15:39<03:44, 1584.23 examples/s]Running tokenizer on dataset:  80%|████████  | 1445000/1801350 [15:39<03:43, 1592.45 examples/s]Running tokenizer on dataset:  80%|████████  | 1448000/1801350 [15:39<03:41, 1597.52 examples/s]Running tokenizer on dataset:  80%|████████  | 1446000/1801350 [15:39<03:49, 1545.80 examples/s]Running tokenizer on dataset:  80%|████████  | 1446000/1801350 [15:39<03:49, 1545.76 examples/s]Running tokenizer on dataset:  80%|████████  | 1446000/1801350 [15:39<03:49, 1550.65 examples/s]Running tokenizer on dataset:  80%|████████  | 1449000/1801350 [15:40<03:42, 1585.32 examples/s]Running tokenizer on dataset:  80%|████████  | 1447000/1801350 [15:40<03:50, 1537.23 examples/s]Running tokenizer on dataset:  80%|████████  | 1450000/1801350 [15:40<03:32, 1650.26 examples/s]Running tokenizer on dataset:  80%|████████  | 1447000/1801350 [15:40<03:53, 1520.20 examples/s]Running tokenizer on dataset:  80%|████████  | 1447000/1801350 [15:40<03:51, 1527.46 examples/s]Running tokenizer on dataset:  80%|████████  | 1448000/1801350 [15:41<03:42, 1586.09 examples/s]Running tokenizer on dataset:  80%|████████  | 1448000/1801350 [15:41<03:41, 1597.16 examples/s]Running tokenizer on dataset:  80%|████████  | 1448000/1801350 [15:41<03:41, 1593.73 examples/s]Running tokenizer on dataset:  81%|████████  | 1451000/1801350 [15:41<03:49, 1528.81 examples/s]Running tokenizer on dataset:  80%|████████  | 1449000/1801350 [15:41<03:44, 1569.46 examples/s]Running tokenizer on dataset:  80%|████████  | 1449000/1801350 [15:41<03:43, 1577.93 examples/s]Running tokenizer on dataset:  80%|████████  | 1449000/1801350 [15:41<03:44, 1569.95 examples/s]Running tokenizer on dataset:  81%|████████  | 1452000/1801350 [15:42<03:49, 1519.96 examples/s]Running tokenizer on dataset:  80%|████████  | 1450000/1801350 [15:42<03:38, 1611.30 examples/s]Running tokenizer on dataset:  80%|████████  | 1450000/1801350 [15:42<03:37, 1612.25 examples/s]Running tokenizer on dataset:  80%|████████  | 1450000/1801350 [15:42<03:39, 1603.77 examples/s]Running tokenizer on dataset:  81%|████████  | 1453000/1801350 [15:42<03:49, 1517.41 examples/s]Running tokenizer on dataset:  81%|████████  | 1451000/1801350 [15:42<03:47, 1539.26 examples/s]Running tokenizer on dataset:  81%|████████  | 1451000/1801350 [15:43<03:46, 1547.37 examples/s]Running tokenizer on dataset:  81%|████████  | 1451000/1801350 [15:43<03:48, 1529.95 examples/s]Running tokenizer on dataset:  81%|████████  | 1454000/1801350 [15:43<03:50, 1508.47 examples/s]Running tokenizer on dataset:  81%|████████  | 1452000/1801350 [15:43<03:46, 1544.39 examples/s]Running tokenizer on dataset:  81%|████████  | 1452000/1801350 [15:43<03:48, 1527.28 examples/s]Running tokenizer on dataset:  81%|████████  | 1452000/1801350 [15:43<03:46, 1539.72 examples/s]Running tokenizer on dataset:  81%|████████  | 1455000/1801350 [15:44<03:49, 1510.72 examples/s]Running tokenizer on dataset:  81%|████████  | 1453000/1801350 [15:44<03:49, 1517.75 examples/s]Running tokenizer on dataset:  81%|████████  | 1453000/1801350 [15:44<03:48, 1523.74 examples/s]Running tokenizer on dataset:  81%|████████  | 1453000/1801350 [15:44<03:51, 1502.70 examples/s]Running tokenizer on dataset:  81%|████████  | 1456000/1801350 [15:44<04:15, 1353.07 examples/s]Running tokenizer on dataset:  81%|████████  | 1454000/1801350 [15:45<03:51, 1499.91 examples/s]Running tokenizer on dataset:  81%|████████  | 1454000/1801350 [15:45<03:52, 1496.21 examples/s]Running tokenizer on dataset:  81%|████████  | 1454000/1801350 [15:45<03:50, 1507.94 examples/s]Running tokenizer on dataset:  81%|████████  | 1457000/1801350 [15:45<04:11, 1369.49 examples/s]Running tokenizer on dataset:  81%|████████  | 1455000/1801350 [15:45<03:47, 1520.64 examples/s]Running tokenizer on dataset:  81%|████████  | 1455000/1801350 [15:45<03:49, 1506.51 examples/s]Running tokenizer on dataset:  81%|████████  | 1455000/1801350 [15:45<03:48, 1515.34 examples/s]Running tokenizer on dataset:  81%|████████  | 1458000/1801350 [15:46<03:58, 1436.68 examples/s]Running tokenizer on dataset:  81%|████████  | 1456000/1801350 [15:46<04:18, 1333.45 examples/s]Running tokenizer on dataset:  81%|████████  | 1456000/1801350 [15:46<04:18, 1337.67 examples/s]Running tokenizer on dataset:  81%|████████  | 1456000/1801350 [15:46<04:16, 1346.68 examples/s]Running tokenizer on dataset:  81%|████████  | 1459000/1801350 [15:46<03:54, 1457.39 examples/s]Running tokenizer on dataset:  81%|████████  | 1457000/1801350 [15:47<04:11, 1368.00 examples/s]Running tokenizer on dataset:  81%|████████  | 1457000/1801350 [15:47<04:11, 1369.57 examples/s]Running tokenizer on dataset:  81%|████████  | 1460000/1801350 [15:47<03:42, 1532.46 examples/s]Running tokenizer on dataset:  81%|████████  | 1457000/1801350 [15:47<04:15, 1350.28 examples/s]Running tokenizer on dataset:  81%|████████  | 1458000/1801350 [15:47<03:59, 1433.44 examples/s]Running tokenizer on dataset:  81%|████████  | 1461000/1801350 [15:48<03:33, 1594.05 examples/s]Running tokenizer on dataset:  81%|████████  | 1458000/1801350 [15:48<04:01, 1419.03 examples/s]Running tokenizer on dataset:  81%|████████  | 1458000/1801350 [15:48<04:00, 1427.81 examples/s]Running tokenizer on dataset:  81%|████████  | 1462000/1801350 [15:48<03:24, 1659.16 examples/s]Running tokenizer on dataset:  81%|████████  | 1459000/1801350 [15:48<03:56, 1449.80 examples/s]Running tokenizer on dataset:  81%|████████  | 1459000/1801350 [15:48<03:57, 1441.83 examples/s]Running tokenizer on dataset:  81%|████████  | 1459000/1801350 [15:48<03:55, 1455.85 examples/s]Running tokenizer on dataset:  81%|████████  | 1463000/1801350 [15:49<03:23, 1660.60 examples/s]Running tokenizer on dataset:  81%|████████  | 1460000/1801350 [15:49<03:44, 1523.54 examples/s]Running tokenizer on dataset:  81%|████████  | 1460000/1801350 [15:49<03:44, 1522.57 examples/s]Running tokenizer on dataset:  81%|████████  | 1460000/1801350 [15:49<03:42, 1535.69 examples/s]Running tokenizer on dataset:  81%|████████  | 1461000/1801350 [15:49<03:32, 1601.65 examples/s]Running tokenizer on dataset:  81%|████████  | 1461000/1801350 [15:49<03:33, 1595.74 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1464000/1801350 [15:49<03:35, 1568.48 examples/s]Running tokenizer on dataset:  81%|████████  | 1461000/1801350 [15:49<03:34, 1586.37 examples/s]Running tokenizer on dataset:  81%|████████  | 1462000/1801350 [15:50<03:29, 1621.77 examples/s]Running tokenizer on dataset:  81%|████████  | 1462000/1801350 [15:50<03:27, 1638.13 examples/s]Running tokenizer on dataset:  81%|████████  | 1462000/1801350 [15:50<03:26, 1646.69 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1465000/1801350 [15:50<03:46, 1482.79 examples/s]Running tokenizer on dataset:  81%|████████  | 1463000/1801350 [15:50<03:28, 1620.14 examples/s]Running tokenizer on dataset:  81%|████████  | 1463000/1801350 [15:51<03:28, 1626.04 examples/s]Running tokenizer on dataset:  81%|████████  | 1463000/1801350 [15:51<03:25, 1642.55 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1466000/1801350 [15:51<03:52, 1441.57 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1464000/1801350 [15:51<03:30, 1606.06 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1464000/1801350 [15:51<03:31, 1595.39 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1464000/1801350 [15:51<03:29, 1611.63 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1467000/1801350 [15:52<03:41, 1511.13 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1465000/1801350 [15:52<03:42, 1510.10 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1465000/1801350 [15:52<03:42, 1514.01 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1465000/1801350 [15:52<03:43, 1503.77 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1468000/1801350 [15:52<03:40, 1513.09 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1466000/1801350 [15:53<03:50, 1454.19 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1466000/1801350 [15:53<03:50, 1454.70 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1466000/1801350 [15:53<03:52, 1440.76 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1469000/1801350 [15:53<03:39, 1514.95 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1467000/1801350 [15:53<03:40, 1517.87 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1467000/1801350 [15:53<03:40, 1519.28 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1467000/1801350 [15:53<03:40, 1516.65 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1470000/1801350 [15:53<03:39, 1512.72 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1468000/1801350 [15:54<03:40, 1513.47 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1468000/1801350 [15:54<03:39, 1521.52 examples/s]Running tokenizer on dataset:  81%|████████▏ | 1468000/1801350 [15:54<03:39, 1516.89 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1471000/1801350 [15:54<03:38, 1512.21 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1469000/1801350 [15:54<03:37, 1529.11 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1469000/1801350 [15:55<03:38, 1523.04 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1469000/1801350 [15:55<03:37, 1528.11 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1472000/1801350 [15:55<03:36, 1522.54 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1470000/1801350 [15:55<03:39, 1512.76 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1470000/1801350 [15:55<03:39, 1513.00 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1473000/1801350 [15:55<03:24, 1609.50 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1470000/1801350 [15:55<03:42, 1488.21 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1471000/1801350 [15:56<03:38, 1513.87 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1471000/1801350 [15:56<03:40, 1495.38 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1474000/1801350 [15:56<03:23, 1611.01 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1471000/1801350 [15:56<03:39, 1505.31 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1472000/1801350 [15:56<03:33, 1543.81 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1472000/1801350 [15:57<03:35, 1530.89 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1475000/1801350 [15:57<03:27, 1569.69 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1472000/1801350 [15:57<03:34, 1532.48 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1473000/1801350 [15:57<03:25, 1597.98 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1473000/1801350 [15:57<03:26, 1592.32 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1476000/1801350 [15:57<03:25, 1586.88 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1473000/1801350 [15:57<03:25, 1600.05 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1474000/1801350 [15:58<03:26, 1586.52 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1474000/1801350 [15:58<03:28, 1570.91 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1474000/1801350 [15:58<03:27, 1574.41 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1477000/1801350 [15:58<03:57, 1364.34 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1475000/1801350 [15:58<03:27, 1570.71 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1475000/1801350 [15:58<03:28, 1564.15 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1475000/1801350 [15:59<03:26, 1581.26 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1478000/1801350 [15:59<03:51, 1394.36 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1476000/1801350 [15:59<03:24, 1593.83 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1476000/1801350 [15:59<03:26, 1573.61 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1476000/1801350 [15:59<03:22, 1604.25 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1479000/1801350 [16:00<03:52, 1385.61 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1477000/1801350 [16:00<04:01, 1344.96 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1477000/1801350 [16:00<03:57, 1364.99 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1477000/1801350 [16:00<03:57, 1366.55 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1480000/1801350 [16:00<03:45, 1422.65 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1478000/1801350 [16:01<03:52, 1393.20 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1478000/1801350 [16:01<03:52, 1391.57 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1478000/1801350 [16:01<03:51, 1395.11 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1481000/1801350 [16:01<03:36, 1481.45 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1479000/1801350 [16:01<03:51, 1392.17 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1479000/1801350 [16:01<03:49, 1405.22 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1479000/1801350 [16:01<03:49, 1407.33 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1482000/1801350 [16:02<03:31, 1508.24 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1480000/1801350 [16:02<03:46, 1420.40 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1480000/1801350 [16:02<03:45, 1425.45 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1483000/1801350 [16:02<03:23, 1560.71 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1480000/1801350 [16:02<03:49, 1400.66 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1481000/1801350 [16:03<03:36, 1482.10 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1481000/1801350 [16:03<03:36, 1478.51 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1484000/1801350 [16:03<03:28, 1522.73 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1481000/1801350 [16:03<03:35, 1483.88 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1482000/1801350 [16:03<03:33, 1495.27 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1482000/1801350 [16:03<03:34, 1491.98 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1485000/1801350 [16:03<03:22, 1564.75 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1482000/1801350 [16:03<03:35, 1480.93 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1483000/1801350 [16:04<03:27, 1536.49 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1483000/1801350 [16:04<03:27, 1536.17 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1483000/1801350 [16:04<03:27, 1531.98 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1486000/1801350 [16:04<03:25, 1535.67 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1484000/1801350 [16:05<03:28, 1522.24 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1484000/1801350 [16:05<03:26, 1538.33 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1484000/1801350 [16:05<03:27, 1533.07 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1487000/1801350 [16:05<03:24, 1534.78 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1485000/1801350 [16:05<03:23, 1555.94 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1485000/1801350 [16:05<03:23, 1556.02 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1488000/1801350 [16:05<03:14, 1614.84 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1485000/1801350 [16:05<03:26, 1533.05 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1486000/1801350 [16:06<03:23, 1549.02 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1486000/1801350 [16:06<03:22, 1559.25 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1489000/1801350 [16:06<03:15, 1594.98 examples/s]Running tokenizer on dataset:  82%|████████▏ | 1486000/1801350 [16:06<03:22, 1559.78 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1487000/1801350 [16:06<03:20, 1571.51 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1490000/1801350 [16:07<03:12, 1616.92 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1487000/1801350 [16:07<03:24, 1538.77 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1487000/1801350 [16:07<03:22, 1552.17 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1488000/1801350 [16:07<03:14, 1614.42 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1488000/1801350 [16:07<03:15, 1603.45 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1491000/1801350 [16:07<03:12, 1610.31 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1488000/1801350 [16:07<03:15, 1599.86 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1489000/1801350 [16:08<03:16, 1593.11 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1489000/1801350 [16:08<03:17, 1579.11 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1492000/1801350 [16:08<03:13, 1600.07 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1489000/1801350 [16:08<03:17, 1581.67 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1490000/1801350 [16:08<03:14, 1602.76 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1490000/1801350 [16:08<03:13, 1609.67 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1490000/1801350 [16:08<03:12, 1616.94 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1493000/1801350 [16:08<03:17, 1563.74 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1491000/1801350 [16:09<03:12, 1610.95 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1494000/1801350 [16:09<03:04, 1663.85 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1491000/1801350 [16:09<03:15, 1584.61 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1491000/1801350 [16:09<03:13, 1604.36 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1492000/1801350 [16:09<03:12, 1604.73 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1495000/1801350 [16:10<03:04, 1660.33 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1492000/1801350 [16:10<03:14, 1591.73 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1492000/1801350 [16:10<03:13, 1599.42 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1496000/1801350 [16:10<03:02, 1669.14 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1493000/1801350 [16:10<03:18, 1554.50 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1493000/1801350 [16:10<03:16, 1566.83 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1493000/1801350 [16:10<03:16, 1569.87 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1494000/1801350 [16:11<03:05, 1657.63 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1494000/1801350 [16:11<03:04, 1667.52 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1497000/1801350 [16:11<03:06, 1633.58 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1494000/1801350 [16:11<03:05, 1654.68 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1495000/1801350 [16:11<03:06, 1642.37 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1495000/1801350 [16:11<03:04, 1663.76 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1495000/1801350 [16:11<03:04, 1658.27 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1498000/1801350 [16:12<03:40, 1377.14 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1496000/1801350 [16:12<03:05, 1647.30 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1496000/1801350 [16:12<03:04, 1654.48 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1496000/1801350 [16:12<03:02, 1671.66 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1499000/1801350 [16:12<03:27, 1457.30 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1497000/1801350 [16:12<03:05, 1643.54 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1497000/1801350 [16:13<03:04, 1652.98 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1497000/1801350 [16:13<03:03, 1661.79 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1500000/1801350 [16:13<03:15, 1538.78 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1498000/1801350 [16:13<03:40, 1378.62 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1501000/1801350 [16:14<03:08, 1591.00 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1498000/1801350 [16:14<03:40, 1378.02 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1498000/1801350 [16:14<03:39, 1384.50 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1499000/1801350 [16:14<03:24, 1475.32 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1502000/1801350 [16:14<03:09, 1583.77 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1499000/1801350 [16:14<03:26, 1466.95 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1499000/1801350 [16:14<03:24, 1475.41 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1500000/1801350 [16:15<03:13, 1553.47 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1500000/1801350 [16:15<03:13, 1560.29 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1503000/1801350 [16:15<03:11, 1555.08 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1500000/1801350 [16:15<03:14, 1551.51 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1501000/1801350 [16:15<03:09, 1584.48 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1501000/1801350 [16:15<03:08, 1591.66 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1504000/1801350 [16:15<03:03, 1616.51 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1501000/1801350 [16:15<03:10, 1576.31 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1502000/1801350 [16:16<03:09, 1579.32 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1502000/1801350 [16:16<03:10, 1567.85 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1502000/1801350 [16:16<03:09, 1575.70 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1505000/1801350 [16:16<03:10, 1556.03 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1503000/1801350 [16:17<03:09, 1570.50 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1503000/1801350 [16:17<03:08, 1580.13 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1503000/1801350 [16:17<03:08, 1584.35 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1506000/1801350 [16:17<03:11, 1543.57 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1504000/1801350 [16:17<03:04, 1609.47 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1504000/1801350 [16:17<03:03, 1620.22 examples/s]Running tokenizer on dataset:  83%|████████▎ | 1504000/1801350 [16:17<03:03, 1620.42 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1507000/1801350 [16:17<03:15, 1505.93 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1505000/1801350 [16:18<03:07, 1578.19 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1505000/1801350 [16:18<03:09, 1562.15 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1505000/1801350 [16:18<03:07, 1579.54 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1508000/1801350 [16:18<03:14, 1508.88 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1506000/1801350 [16:18<03:08, 1563.59 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1506000/1801350 [16:19<03:08, 1563.62 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1506000/1801350 [16:19<03:07, 1574.67 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1509000/1801350 [16:19<03:06, 1568.73 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1507000/1801350 [16:19<03:12, 1530.76 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1507000/1801350 [16:19<03:13, 1521.75 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1507000/1801350 [16:19<03:11, 1537.39 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1510000/1801350 [16:19<03:06, 1562.87 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1508000/1801350 [16:20<03:12, 1524.39 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1508000/1801350 [16:20<03:14, 1504.87 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1511000/1801350 [16:20<03:02, 1590.28 examples/s]Running tokenizer on dataset:  84%|████████▎ | 1508000/1801350 [16:20<03:12, 1522.45 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1509000/1801350 [16:20<03:05, 1573.10 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1509000/1801350 [16:20<03:04, 1583.21 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1509000/1801350 [16:21<03:03, 1593.08 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1512000/1801350 [16:21<03:09, 1530.92 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1510000/1801350 [16:21<03:05, 1568.16 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1510000/1801350 [16:21<03:05, 1572.74 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1510000/1801350 [16:21<03:06, 1564.52 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1513000/1801350 [16:21<03:06, 1545.75 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1511000/1801350 [16:22<03:03, 1581.46 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1511000/1801350 [16:22<03:02, 1587.91 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1514000/1801350 [16:22<02:56, 1625.32 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1511000/1801350 [16:22<03:05, 1563.16 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1512000/1801350 [16:22<03:08, 1531.72 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1512000/1801350 [16:22<03:06, 1549.85 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1512000/1801350 [16:22<03:08, 1535.92 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1515000/1801350 [16:23<03:05, 1539.73 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1513000/1801350 [16:23<03:07, 1541.59 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1513000/1801350 [16:23<03:05, 1554.16 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1513000/1801350 [16:23<03:05, 1552.56 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1516000/1801350 [16:23<02:59, 1589.40 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1514000/1801350 [16:24<02:58, 1611.34 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1517000/1801350 [16:24<02:45, 1719.64 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1514000/1801350 [16:24<02:58, 1613.19 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1514000/1801350 [16:24<02:57, 1615.26 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1515000/1801350 [16:24<03:05, 1539.78 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1518000/1801350 [16:24<02:55, 1612.65 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1515000/1801350 [16:24<03:06, 1537.29 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1515000/1801350 [16:24<03:08, 1521.20 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1516000/1801350 [16:25<03:00, 1581.48 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1516000/1801350 [16:25<03:00, 1578.59 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1516000/1801350 [16:25<02:59, 1592.42 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1517000/1801350 [16:25<02:48, 1683.84 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1517000/1801350 [16:25<02:46, 1706.48 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1519000/1801350 [16:25<03:38, 1294.19 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1517000/1801350 [16:25<02:47, 1699.51 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1518000/1801350 [16:26<02:55, 1610.37 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1518000/1801350 [16:26<02:55, 1610.34 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1520000/1801350 [16:26<03:28, 1347.37 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1518000/1801350 [16:26<02:58, 1586.67 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1521000/1801350 [16:27<03:11, 1463.75 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1519000/1801350 [16:27<03:28, 1355.84 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1519000/1801350 [16:27<03:36, 1301.73 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1522000/1801350 [16:27<03:07, 1492.04 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1519000/1801350 [16:27<03:36, 1301.42 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1520000/1801350 [16:28<03:29, 1344.76 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1520000/1801350 [16:28<03:24, 1373.32 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1523000/1801350 [16:28<03:02, 1528.13 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1520000/1801350 [16:28<03:31, 1332.86 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1521000/1801350 [16:28<03:08, 1485.54 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1521000/1801350 [16:28<03:15, 1430.36 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1524000/1801350 [16:29<02:56, 1571.35 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1521000/1801350 [16:29<03:15, 1434.86 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1522000/1801350 [16:29<03:07, 1487.51 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1522000/1801350 [16:29<03:11, 1456.08 examples/s]Running tokenizer on dataset:  84%|████████▍ | 1522000/1801350 [16:29<03:09, 1476.65 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1525000/1801350 [16:29<03:02, 1510.14 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1523000/1801350 [16:30<03:04, 1508.86 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1523000/1801350 [16:30<03:05, 1504.53 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1523000/1801350 [16:30<03:02, 1524.43 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1526000/1801350 [16:30<03:03, 1503.21 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1524000/1801350 [16:30<02:58, 1557.84 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1524000/1801350 [16:30<02:58, 1553.48 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1524000/1801350 [16:30<02:57, 1563.71 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1527000/1801350 [16:31<03:04, 1487.68 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1525000/1801350 [16:31<03:03, 1504.81 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1525000/1801350 [16:31<03:03, 1503.64 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1525000/1801350 [16:31<03:02, 1513.68 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1528000/1801350 [16:31<03:02, 1493.84 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1526000/1801350 [16:32<03:04, 1495.02 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1526000/1801350 [16:32<03:05, 1484.38 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1526000/1801350 [16:32<03:03, 1498.20 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1529000/1801350 [16:32<03:04, 1476.25 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1527000/1801350 [16:32<03:04, 1486.29 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1527000/1801350 [16:32<03:05, 1482.11 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1527000/1801350 [16:33<03:04, 1488.84 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1530000/1801350 [16:33<03:04, 1474.49 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1528000/1801350 [16:33<03:03, 1491.35 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1528000/1801350 [16:33<03:02, 1495.53 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1528000/1801350 [16:33<03:04, 1484.27 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1531000/1801350 [16:33<03:02, 1484.53 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1529000/1801350 [16:34<03:04, 1473.61 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1529000/1801350 [16:34<03:05, 1465.42 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1532000/1801350 [16:34<02:52, 1565.84 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1529000/1801350 [16:34<03:07, 1455.15 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1530000/1801350 [16:34<03:05, 1459.66 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1530000/1801350 [16:34<03:06, 1454.70 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1533000/1801350 [16:34<02:46, 1613.04 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1530000/1801350 [16:35<03:08, 1443.15 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1534000/1801350 [16:35<02:41, 1655.55 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1531000/1801350 [16:35<03:04, 1464.55 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1531000/1801350 [16:35<03:04, 1461.60 examples/s]Running tokenizer on dataset:  85%|████████▍ | 1531000/1801350 [16:35<03:03, 1475.45 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1532000/1801350 [16:36<02:50, 1575.85 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1535000/1801350 [16:36<02:44, 1622.81 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1532000/1801350 [16:36<02:53, 1551.40 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1532000/1801350 [16:36<02:53, 1552.12 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1536000/1801350 [16:36<02:38, 1672.18 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1533000/1801350 [16:36<02:50, 1577.34 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1533000/1801350 [16:36<02:51, 1567.46 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1533000/1801350 [16:36<02:50, 1573.95 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1534000/1801350 [16:37<02:44, 1622.93 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1534000/1801350 [16:37<02:46, 1603.16 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1537000/1801350 [16:37<02:45, 1595.40 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1534000/1801350 [16:37<02:46, 1606.44 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1535000/1801350 [16:37<02:42, 1638.42 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1535000/1801350 [16:37<02:44, 1617.03 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1538000/1801350 [16:37<02:41, 1632.60 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1535000/1801350 [16:38<02:45, 1611.65 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1536000/1801350 [16:38<02:40, 1658.00 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1536000/1801350 [16:38<02:40, 1655.76 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1539000/1801350 [16:38<02:45, 1585.22 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1536000/1801350 [16:38<02:41, 1644.15 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1537000/1801350 [16:39<02:42, 1628.75 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1537000/1801350 [16:39<02:43, 1617.50 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1537000/1801350 [16:39<02:42, 1631.73 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1540000/1801350 [16:39<03:16, 1327.25 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1538000/1801350 [16:39<02:39, 1656.14 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1538000/1801350 [16:39<02:41, 1627.37 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1538000/1801350 [16:39<02:41, 1630.47 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1541000/1801350 [16:40<03:01, 1435.27 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1539000/1801350 [16:40<02:42, 1619.16 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1539000/1801350 [16:40<02:42, 1617.09 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1539000/1801350 [16:40<02:42, 1616.61 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1542000/1801350 [16:40<02:51, 1516.48 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1543000/1801350 [16:41<02:44, 1572.54 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1540000/1801350 [16:41<03:15, 1339.65 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1540000/1801350 [16:41<03:24, 1278.74 examples/s]Running tokenizer on dataset:  85%|████████▌ | 1540000/1801350 [16:41<03:13, 1348.82 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1541000/1801350 [16:41<02:57, 1468.70 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1544000/1801350 [16:42<02:41, 1595.18 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1541000/1801350 [16:42<02:56, 1473.70 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1541000/1801350 [16:42<03:07, 1385.61 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1545000/1801350 [16:42<02:25, 1755.85 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1542000/1801350 [16:42<02:47, 1548.41 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1542000/1801350 [16:42<02:47, 1548.76 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1542000/1801350 [16:42<02:55, 1480.12 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1546000/1801350 [16:43<02:29, 1712.73 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1543000/1801350 [16:43<02:43, 1583.10 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1543000/1801350 [16:43<02:48, 1537.75 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1543000/1801350 [16:43<02:45, 1560.39 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1547000/1801350 [16:43<02:29, 1706.39 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1544000/1801350 [16:43<02:39, 1610.42 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1544000/1801350 [16:43<02:44, 1565.65 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1544000/1801350 [16:43<02:40, 1607.84 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1545000/1801350 [16:44<02:24, 1772.28 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1545000/1801350 [16:44<02:26, 1754.58 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1545000/1801350 [16:44<02:29, 1716.26 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1548000/1801350 [16:44<02:41, 1564.91 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1546000/1801350 [16:44<02:27, 1728.67 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1546000/1801350 [16:44<02:29, 1710.20 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1546000/1801350 [16:44<02:27, 1733.05 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1549000/1801350 [16:45<02:39, 1584.49 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1547000/1801350 [16:45<02:27, 1723.36 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1547000/1801350 [16:45<02:29, 1701.98 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1547000/1801350 [16:45<02:28, 1713.07 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1550000/1801350 [16:45<02:38, 1589.90 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1548000/1801350 [16:46<02:37, 1606.56 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1551000/1801350 [16:46<02:25, 1721.87 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1548000/1801350 [16:46<02:37, 1604.95 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1548000/1801350 [16:46<02:39, 1588.69 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1549000/1801350 [16:46<02:35, 1621.96 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1552000/1801350 [16:46<02:27, 1686.24 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1549000/1801350 [16:46<02:36, 1611.80 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1549000/1801350 [16:46<02:38, 1592.16 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1550000/1801350 [16:47<02:34, 1621.69 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1553000/1801350 [16:47<02:24, 1716.03 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1550000/1801350 [16:47<02:35, 1611.50 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1550000/1801350 [16:47<02:36, 1606.92 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1551000/1801350 [16:47<02:26, 1713.16 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1554000/1801350 [16:47<02:29, 1652.04 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1551000/1801350 [16:48<02:27, 1698.45 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1551000/1801350 [16:48<02:27, 1692.15 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1552000/1801350 [16:48<02:27, 1685.29 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1555000/1801350 [16:48<02:23, 1716.56 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1552000/1801350 [16:48<02:29, 1669.17 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1552000/1801350 [16:48<02:29, 1668.12 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1553000/1801350 [16:48<02:26, 1698.21 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1556000/1801350 [16:49<02:22, 1717.63 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1553000/1801350 [16:49<02:25, 1712.49 examples/s]Running tokenizer on dataset:  86%|████████▌ | 1553000/1801350 [16:49<02:28, 1673.34 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1557000/1801350 [16:49<02:20, 1738.79 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1554000/1801350 [16:49<02:28, 1660.43 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1554000/1801350 [16:49<02:29, 1650.73 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1554000/1801350 [16:49<02:29, 1656.80 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1555000/1801350 [16:50<02:21, 1743.13 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1555000/1801350 [16:50<02:20, 1751.21 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1555000/1801350 [16:50<02:22, 1722.90 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1558000/1801350 [16:50<02:39, 1526.96 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1556000/1801350 [16:50<02:19, 1752.57 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1556000/1801350 [16:50<02:19, 1753.87 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1556000/1801350 [16:50<02:21, 1731.84 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1559000/1801350 [16:51<02:33, 1575.84 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1557000/1801350 [16:51<02:21, 1721.11 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1557000/1801350 [16:51<02:21, 1729.76 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1557000/1801350 [16:51<02:21, 1724.46 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1560000/1801350 [16:51<02:37, 1535.21 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1558000/1801350 [16:52<02:35, 1565.07 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1558000/1801350 [16:52<02:36, 1557.99 examples/s]Running tokenizer on dataset:  86%|████████▋ | 1558000/1801350 [16:52<02:37, 1543.87 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1559000/1801350 [16:52<02:30, 1610.81 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1561000/1801350 [16:52<03:02, 1318.37 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1559000/1801350 [16:52<02:30, 1605.68 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1559000/1801350 [16:52<02:33, 1583.10 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1560000/1801350 [16:53<02:35, 1552.20 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1562000/1801350 [16:53<02:50, 1399.81 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1560000/1801350 [16:53<02:37, 1536.33 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1560000/1801350 [16:53<02:37, 1536.83 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1563000/1801350 [16:54<02:46, 1433.56 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1561000/1801350 [16:54<03:03, 1311.21 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1561000/1801350 [16:54<03:00, 1331.06 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1561000/1801350 [16:54<03:03, 1308.67 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1564000/1801350 [16:54<02:41, 1465.54 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1562000/1801350 [16:55<02:53, 1383.09 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1565000/1801350 [16:55<02:32, 1547.93 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1562000/1801350 [16:55<02:51, 1398.71 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1562000/1801350 [16:55<02:55, 1366.83 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1563000/1801350 [16:55<02:47, 1419.66 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1563000/1801350 [16:55<02:46, 1430.08 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1566000/1801350 [16:55<02:34, 1522.44 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1563000/1801350 [16:55<02:49, 1407.59 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1564000/1801350 [16:56<02:42, 1456.30 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1567000/1801350 [16:56<02:25, 1609.23 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1564000/1801350 [16:56<02:43, 1448.11 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1564000/1801350 [16:56<02:43, 1447.83 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1565000/1801350 [16:56<02:34, 1530.11 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1568000/1801350 [16:57<02:22, 1637.06 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1565000/1801350 [16:57<02:33, 1536.13 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1565000/1801350 [16:57<02:34, 1525.03 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1569000/1801350 [16:57<02:15, 1717.15 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1566000/1801350 [16:57<02:37, 1494.07 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1566000/1801350 [16:57<02:34, 1520.64 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1566000/1801350 [16:57<02:34, 1525.91 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1567000/1801350 [16:58<02:27, 1593.59 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1570000/1801350 [16:58<02:18, 1668.66 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1567000/1801350 [16:58<02:26, 1594.75 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1567000/1801350 [16:58<02:27, 1585.24 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1568000/1801350 [16:58<02:24, 1619.52 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1571000/1801350 [16:58<02:22, 1616.67 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1568000/1801350 [16:58<02:23, 1621.92 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1568000/1801350 [16:58<02:23, 1623.66 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1569000/1801350 [16:59<02:17, 1687.59 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1569000/1801350 [16:59<02:15, 1714.65 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1569000/1801350 [16:59<02:15, 1711.07 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1572000/1801350 [16:59<02:27, 1550.29 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1570000/1801350 [16:59<02:18, 1671.22 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1570000/1801350 [17:00<02:18, 1668.14 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1570000/1801350 [17:00<02:17, 1678.76 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1573000/1801350 [17:00<02:27, 1545.96 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1571000/1801350 [17:00<02:21, 1631.02 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1571000/1801350 [17:00<02:21, 1626.12 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1571000/1801350 [17:00<02:21, 1631.59 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1574000/1801350 [17:00<02:24, 1568.24 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1572000/1801350 [17:01<02:25, 1573.28 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1575000/1801350 [17:01<02:17, 1640.74 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1572000/1801350 [17:01<02:26, 1560.69 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1572000/1801350 [17:01<02:26, 1562.04 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1573000/1801350 [17:01<02:27, 1545.57 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1576000/1801350 [17:02<02:19, 1617.24 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1573000/1801350 [17:02<02:27, 1551.45 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1573000/1801350 [17:02<02:28, 1541.12 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1574000/1801350 [17:02<02:26, 1551.85 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1577000/1801350 [17:02<02:19, 1612.83 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1574000/1801350 [17:02<02:26, 1553.83 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1574000/1801350 [17:02<02:26, 1547.51 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1575000/1801350 [17:03<02:19, 1616.82 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1575000/1801350 [17:03<02:19, 1627.01 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1575000/1801350 [17:03<02:17, 1650.24 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1578000/1801350 [17:03<02:22, 1570.08 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1576000/1801350 [17:03<02:20, 1604.07 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1576000/1801350 [17:03<02:21, 1587.21 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1579000/1801350 [17:03<02:21, 1566.32 examples/s]Running tokenizer on dataset:  87%|████████▋ | 1576000/1801350 [17:03<02:21, 1593.66 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1577000/1801350 [17:04<02:20, 1595.52 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1577000/1801350 [17:04<02:21, 1581.99 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1580000/1801350 [17:04<02:20, 1576.83 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1577000/1801350 [17:04<02:22, 1578.07 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1578000/1801350 [17:04<02:21, 1582.53 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1581000/1801350 [17:05<02:14, 1638.00 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1578000/1801350 [17:05<02:20, 1589.77 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1578000/1801350 [17:05<02:24, 1545.93 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1579000/1801350 [17:05<02:22, 1562.19 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1579000/1801350 [17:05<02:19, 1593.73 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1579000/1801350 [17:05<02:21, 1569.33 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1582000/1801350 [17:06<02:41, 1355.54 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1580000/1801350 [17:06<02:20, 1573.96 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1580000/1801350 [17:06<02:19, 1587.70 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1580000/1801350 [17:06<02:19, 1588.31 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1581000/1801350 [17:06<02:14, 1635.62 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1583000/1801350 [17:06<02:40, 1358.79 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1581000/1801350 [17:07<02:14, 1638.99 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1581000/1801350 [17:07<02:16, 1609.44 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1584000/1801350 [17:07<02:33, 1417.99 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1582000/1801350 [17:07<02:42, 1352.60 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1582000/1801350 [17:08<02:40, 1368.95 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1582000/1801350 [17:08<02:39, 1372.51 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1585000/1801350 [17:08<02:22, 1515.58 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1583000/1801350 [17:08<02:36, 1399.39 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1586000/1801350 [17:08<02:13, 1607.32 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1583000/1801350 [17:08<02:37, 1387.67 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1583000/1801350 [17:08<02:37, 1386.69 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1584000/1801350 [17:09<02:32, 1429.08 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1587000/1801350 [17:09<02:16, 1575.12 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1584000/1801350 [17:09<02:31, 1436.32 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1584000/1801350 [17:09<02:31, 1435.00 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1585000/1801350 [17:09<02:23, 1511.18 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1588000/1801350 [17:09<02:13, 1596.91 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1585000/1801350 [17:09<02:22, 1515.41 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1585000/1801350 [17:10<02:23, 1506.48 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1586000/1801350 [17:10<02:17, 1570.66 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1589000/1801350 [17:10<02:09, 1637.38 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1586000/1801350 [17:10<02:16, 1576.36 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1586000/1801350 [17:10<02:16, 1578.22 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1587000/1801350 [17:11<02:18, 1551.86 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1590000/1801350 [17:11<02:14, 1571.82 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1587000/1801350 [17:11<02:16, 1564.86 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1587000/1801350 [17:11<02:18, 1550.62 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1588000/1801350 [17:11<02:15, 1577.05 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1588000/1801350 [17:11<02:14, 1585.44 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1588000/1801350 [17:11<02:14, 1591.08 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1591000/1801350 [17:11<02:16, 1543.68 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1589000/1801350 [17:12<02:10, 1621.21 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1589000/1801350 [17:12<02:09, 1636.96 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1589000/1801350 [17:12<02:10, 1621.95 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1592000/1801350 [17:12<02:12, 1574.50 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1590000/1801350 [17:12<02:16, 1547.69 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1590000/1801350 [17:13<02:15, 1563.74 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1590000/1801350 [17:13<02:15, 1556.59 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1593000/1801350 [17:13<02:17, 1519.43 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1591000/1801350 [17:13<02:14, 1567.52 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1591000/1801350 [17:13<02:11, 1600.57 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1594000/1801350 [17:13<02:09, 1596.15 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1591000/1801350 [17:13<02:13, 1578.26 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1592000/1801350 [17:14<02:10, 1609.11 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1595000/1801350 [17:14<02:08, 1605.11 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1592000/1801350 [17:14<02:11, 1596.01 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1592000/1801350 [17:14<02:11, 1590.74 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1596000/1801350 [17:14<02:02, 1679.69 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1593000/1801350 [17:14<02:16, 1524.01 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1593000/1801350 [17:15<02:16, 1528.35 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1593000/1801350 [17:15<02:15, 1532.66 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1594000/1801350 [17:15<02:10, 1592.66 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1597000/1801350 [17:15<02:07, 1602.96 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1594000/1801350 [17:15<02:11, 1581.64 examples/s]Running tokenizer on dataset:  88%|████████▊ | 1594000/1801350 [17:15<02:10, 1586.19 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1595000/1801350 [17:15<02:07, 1619.63 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1598000/1801350 [17:16<02:06, 1601.99 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1595000/1801350 [17:16<02:08, 1602.00 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1595000/1801350 [17:16<02:08, 1600.59 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1596000/1801350 [17:16<02:03, 1663.79 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1596000/1801350 [17:16<02:02, 1673.05 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1596000/1801350 [17:16<02:03, 1663.49 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1599000/1801350 [17:16<02:09, 1562.56 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1597000/1801350 [17:17<02:06, 1620.43 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1600000/1801350 [17:17<02:01, 1660.06 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1597000/1801350 [17:17<02:07, 1604.75 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1597000/1801350 [17:17<02:07, 1602.75 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1598000/1801350 [17:17<02:07, 1600.10 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1601000/1801350 [17:18<02:02, 1636.29 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1598000/1801350 [17:18<02:08, 1586.10 examples/s]Running tokenizer on dataset:  89%|████████▊ | 1598000/1801350 [17:18<02:08, 1577.78 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1599000/1801350 [17:18<02:08, 1576.72 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1602000/1801350 [17:18<02:01, 1639.35 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1599000/1801350 [17:18<02:07, 1589.49 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1599000/1801350 [17:18<02:08, 1578.34 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1600000/1801350 [17:19<02:02, 1638.83 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1600000/1801350 [17:19<02:01, 1650.59 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1600000/1801350 [17:19<02:01, 1651.24 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1603000/1801350 [17:19<02:25, 1359.40 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1601000/1801350 [17:19<02:02, 1632.91 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1601000/1801350 [17:19<02:01, 1650.45 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1601000/1801350 [17:19<02:02, 1639.66 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1604000/1801350 [17:20<02:14, 1470.20 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1602000/1801350 [17:20<02:01, 1634.13 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1602000/1801350 [17:20<02:00, 1651.59 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1602000/1801350 [17:20<02:01, 1637.94 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1605000/1801350 [17:20<02:12, 1481.28 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1603000/1801350 [17:21<02:25, 1365.06 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1603000/1801350 [17:21<02:23, 1379.94 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1603000/1801350 [17:21<02:23, 1381.53 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1606000/1801350 [17:21<02:19, 1405.08 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1604000/1801350 [17:21<02:12, 1487.46 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1604000/1801350 [17:22<02:12, 1485.03 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1604000/1801350 [17:22<02:12, 1485.95 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1607000/1801350 [17:22<02:13, 1460.87 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1605000/1801350 [17:22<02:11, 1498.73 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1605000/1801350 [17:22<02:09, 1512.31 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1605000/1801350 [17:22<02:10, 1506.06 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1608000/1801350 [17:22<02:05, 1544.58 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1606000/1801350 [17:23<02:17, 1422.42 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1609000/1801350 [17:23<02:00, 1593.62 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1606000/1801350 [17:23<02:18, 1408.30 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1606000/1801350 [17:23<02:19, 1403.89 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1607000/1801350 [17:23<02:11, 1476.37 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1610000/1801350 [17:24<02:00, 1586.99 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1607000/1801350 [17:24<02:13, 1455.93 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1607000/1801350 [17:24<02:13, 1457.70 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1608000/1801350 [17:24<02:05, 1541.90 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1608000/1801350 [17:24<02:04, 1556.88 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1611000/1801350 [17:24<02:03, 1540.75 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1608000/1801350 [17:24<02:06, 1528.42 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1609000/1801350 [17:25<02:03, 1562.58 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1612000/1801350 [17:25<02:00, 1573.67 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1609000/1801350 [17:25<02:04, 1550.50 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1609000/1801350 [17:25<02:03, 1559.24 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1610000/1801350 [17:25<02:01, 1575.76 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1610000/1801350 [17:25<02:01, 1571.48 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1613000/1801350 [17:25<01:58, 1583.67 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1610000/1801350 [17:25<02:01, 1574.48 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1611000/1801350 [17:26<02:02, 1548.01 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1614000/1801350 [17:26<01:57, 1595.86 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1611000/1801350 [17:26<02:04, 1534.80 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1611000/1801350 [17:26<02:05, 1520.74 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1612000/1801350 [17:27<02:00, 1568.64 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1612000/1801350 [17:27<01:57, 1606.56 examples/s]Running tokenizer on dataset:  89%|████████▉ | 1612000/1801350 [17:27<02:00, 1575.56 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1615000/1801350 [17:27<02:07, 1464.99 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1613000/1801350 [17:27<01:57, 1596.33 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1613000/1801350 [17:27<01:58, 1589.74 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1613000/1801350 [17:27<01:57, 1596.74 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1616000/1801350 [17:28<02:06, 1461.85 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1614000/1801350 [17:28<01:59, 1569.25 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1614000/1801350 [17:28<01:57, 1592.24 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1614000/1801350 [17:28<02:00, 1554.97 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1617000/1801350 [17:28<02:08, 1430.37 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1615000/1801350 [17:29<02:06, 1470.67 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1615000/1801350 [17:29<02:05, 1489.09 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1615000/1801350 [17:29<02:07, 1456.40 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1618000/1801350 [17:29<02:04, 1467.73 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1616000/1801350 [17:29<02:05, 1478.50 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1616000/1801350 [17:29<02:06, 1463.53 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1616000/1801350 [17:29<02:08, 1447.53 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1619000/1801350 [17:30<01:57, 1554.50 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1620000/1801350 [17:30<01:45, 1718.36 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1617000/1801350 [17:30<02:08, 1435.39 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1617000/1801350 [17:30<02:08, 1437.84 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1617000/1801350 [17:30<02:09, 1427.92 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1621000/1801350 [17:31<01:45, 1701.42 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1618000/1801350 [17:31<02:04, 1472.26 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1618000/1801350 [17:31<02:04, 1474.91 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1618000/1801350 [17:31<02:04, 1475.90 examples/s]Running tokenizer on dataset:  90%|█████████ | 1622000/1801350 [17:31<01:46, 1681.72 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1619000/1801350 [17:31<01:59, 1529.41 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1619000/1801350 [17:31<01:59, 1529.87 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1619000/1801350 [17:31<01:59, 1524.35 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1620000/1801350 [17:32<01:47, 1681.92 examples/s]Running tokenizer on dataset:  90%|█████████ | 1623000/1801350 [17:32<01:52, 1591.34 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1620000/1801350 [17:32<01:48, 1669.58 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1620000/1801350 [17:32<01:46, 1696.42 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1621000/1801350 [17:32<01:47, 1681.01 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1621000/1801350 [17:32<01:46, 1690.06 examples/s]Running tokenizer on dataset:  90%|████████▉ | 1621000/1801350 [17:32<01:47, 1671.69 examples/s]Running tokenizer on dataset:  90%|█████████ | 1622000/1801350 [17:33<01:45, 1695.68 examples/s]Running tokenizer on dataset:  90%|█████████ | 1624000/1801350 [17:33<02:13, 1331.07 examples/s]Running tokenizer on dataset:  90%|█████████ | 1622000/1801350 [17:33<01:45, 1698.23 examples/s]Running tokenizer on dataset:  90%|█████████ | 1622000/1801350 [17:33<01:46, 1687.17 examples/s]Running tokenizer on dataset:  90%|█████████ | 1625000/1801350 [17:34<02:03, 1428.86 examples/s]Running tokenizer on dataset:  90%|█████████ | 1623000/1801350 [17:34<01:51, 1603.30 examples/s]Running tokenizer on dataset:  90%|█████████ | 1623000/1801350 [17:34<01:50, 1608.53 examples/s]Running tokenizer on dataset:  90%|█████████ | 1623000/1801350 [17:34<01:51, 1598.01 examples/s]Running tokenizer on dataset:  90%|█████████ | 1626000/1801350 [17:34<02:04, 1403.92 examples/s]Running tokenizer on dataset:  90%|█████████ | 1624000/1801350 [17:35<02:12, 1342.09 examples/s]Running tokenizer on dataset:  90%|█████████ | 1627000/1801350 [17:35<01:54, 1528.53 examples/s]Running tokenizer on dataset:  90%|█████████ | 1624000/1801350 [17:35<02:12, 1340.66 examples/s]Running tokenizer on dataset:  90%|█████████ | 1624000/1801350 [17:35<02:12, 1337.51 examples/s]Running tokenizer on dataset:  90%|█████████ | 1625000/1801350 [17:35<02:02, 1433.79 examples/s]Running tokenizer on dataset:  90%|█████████ | 1628000/1801350 [17:35<01:50, 1568.16 examples/s]Running tokenizer on dataset:  90%|█████████ | 1625000/1801350 [17:35<02:03, 1424.94 examples/s]Running tokenizer on dataset:  90%|█████████ | 1625000/1801350 [17:35<02:04, 1418.79 examples/s]Running tokenizer on dataset:  90%|█████████ | 1626000/1801350 [17:36<02:02, 1427.61 examples/s]Running tokenizer on dataset:  90%|█████████ | 1629000/1801350 [17:36<01:50, 1554.21 examples/s]Running tokenizer on dataset:  90%|█████████ | 1626000/1801350 [17:36<02:04, 1412.31 examples/s]Running tokenizer on dataset:  90%|█████████ | 1626000/1801350 [17:36<02:04, 1410.08 examples/s]Running tokenizer on dataset:  90%|█████████ | 1627000/1801350 [17:36<01:53, 1532.47 examples/s]Running tokenizer on dataset:  90%|█████████ | 1627000/1801350 [17:37<01:53, 1538.10 examples/s]Running tokenizer on dataset:  90%|█████████ | 1630000/1801350 [17:37<01:51, 1542.21 examples/s]Running tokenizer on dataset:  90%|█████████ | 1627000/1801350 [17:37<01:53, 1532.47 examples/s]Running tokenizer on dataset:  90%|█████████ | 1628000/1801350 [17:37<01:50, 1571.77 examples/s]Running tokenizer on dataset:  90%|█████████ | 1628000/1801350 [17:37<01:49, 1580.51 examples/s]Running tokenizer on dataset:  90%|█████████ | 1628000/1801350 [17:37<01:50, 1573.71 examples/s]Running tokenizer on dataset:  91%|█████████ | 1631000/1801350 [17:37<01:55, 1481.08 examples/s]Running tokenizer on dataset:  90%|█████████ | 1629000/1801350 [17:38<01:53, 1523.97 examples/s]Running tokenizer on dataset:  90%|█████████ | 1629000/1801350 [17:38<01:52, 1532.07 examples/s]Running tokenizer on dataset:  90%|█████████ | 1629000/1801350 [17:38<01:52, 1529.23 examples/s]Running tokenizer on dataset:  91%|█████████ | 1632000/1801350 [17:38<01:52, 1501.56 examples/s]Running tokenizer on dataset:  90%|█████████ | 1630000/1801350 [17:38<01:50, 1555.22 examples/s]Running tokenizer on dataset:  90%|█████████ | 1630000/1801350 [17:39<01:50, 1547.76 examples/s]Running tokenizer on dataset:  90%|█████████ | 1630000/1801350 [17:39<01:52, 1525.39 examples/s]Running tokenizer on dataset:  91%|█████████ | 1633000/1801350 [17:39<01:52, 1493.15 examples/s]Running tokenizer on dataset:  91%|█████████ | 1631000/1801350 [17:39<01:53, 1499.63 examples/s]Running tokenizer on dataset:  91%|█████████ | 1634000/1801350 [17:39<01:45, 1589.89 examples/s]Running tokenizer on dataset:  91%|█████████ | 1631000/1801350 [17:39<01:55, 1481.26 examples/s]Running tokenizer on dataset:  91%|█████████ | 1631000/1801350 [17:39<01:55, 1471.12 examples/s]Running tokenizer on dataset:  91%|█████████ | 1632000/1801350 [17:40<01:51, 1516.23 examples/s]Running tokenizer on dataset:  91%|█████████ | 1635000/1801350 [17:40<01:43, 1607.01 examples/s]Running tokenizer on dataset:  91%|█████████ | 1632000/1801350 [17:40<01:52, 1499.83 examples/s]Running tokenizer on dataset:  91%|█████████ | 1632000/1801350 [17:40<01:53, 1490.09 examples/s]Running tokenizer on dataset:  91%|█████████ | 1633000/1801350 [17:40<01:52, 1501.06 examples/s]Running tokenizer on dataset:  91%|█████████ | 1636000/1801350 [17:40<01:39, 1662.25 examples/s]Running tokenizer on dataset:  91%|█████████ | 1633000/1801350 [17:41<01:52, 1490.66 examples/s]Running tokenizer on dataset:  91%|█████████ | 1633000/1801350 [17:41<01:53, 1487.56 examples/s]Running tokenizer on dataset:  91%|█████████ | 1634000/1801350 [17:41<01:48, 1537.93 examples/s]Running tokenizer on dataset:  91%|█████████ | 1637000/1801350 [17:41<01:38, 1669.70 examples/s]Running tokenizer on dataset:  91%|█████████ | 1634000/1801350 [17:41<01:48, 1547.20 examples/s]Running tokenizer on dataset:  91%|█████████ | 1634000/1801350 [17:41<01:50, 1521.06 examples/s]Running tokenizer on dataset:  91%|█████████ | 1638000/1801350 [17:42<01:37, 1679.59 examples/s]Running tokenizer on dataset:  91%|█████████ | 1635000/1801350 [17:42<01:46, 1565.74 examples/s]Running tokenizer on dataset:  91%|█████████ | 1635000/1801350 [17:42<01:45, 1575.47 examples/s]Running tokenizer on dataset:  91%|█████████ | 1635000/1801350 [17:42<01:44, 1594.81 examples/s]Running tokenizer on dataset:  91%|█████████ | 1636000/1801350 [17:42<01:41, 1624.01 examples/s]Running tokenizer on dataset:  91%|█████████ | 1639000/1801350 [17:42<01:41, 1600.53 examples/s]Running tokenizer on dataset:  91%|█████████ | 1636000/1801350 [17:42<01:41, 1636.24 examples/s]Running tokenizer on dataset:  91%|█████████ | 1636000/1801350 [17:42<01:41, 1628.31 examples/s]Running tokenizer on dataset:  91%|█████████ | 1637000/1801350 [17:43<01:39, 1658.24 examples/s]Running tokenizer on dataset:  91%|█████████ | 1640000/1801350 [17:43<01:40, 1602.62 examples/s]Running tokenizer on dataset:  91%|█████████ | 1637000/1801350 [17:43<01:38, 1665.07 examples/s]Running tokenizer on dataset:  91%|█████████ | 1637000/1801350 [17:43<01:38, 1664.62 examples/s]Running tokenizer on dataset:  91%|█████████ | 1638000/1801350 [17:43<01:37, 1676.19 examples/s]Running tokenizer on dataset:  91%|█████████ | 1638000/1801350 [17:44<01:37, 1668.33 examples/s]Running tokenizer on dataset:  91%|█████████ | 1638000/1801350 [17:44<01:38, 1666.54 examples/s]Running tokenizer on dataset:  91%|█████████ | 1641000/1801350 [17:44<01:43, 1554.50 examples/s]Running tokenizer on dataset:  91%|█████████ | 1639000/1801350 [17:44<01:41, 1605.83 examples/s]Running tokenizer on dataset:  91%|█████████ | 1642000/1801350 [17:44<01:40, 1591.52 examples/s]Running tokenizer on dataset:  91%|█████████ | 1639000/1801350 [17:44<01:41, 1600.43 examples/s]Running tokenizer on dataset:  91%|█████████ | 1639000/1801350 [17:44<01:41, 1592.36 examples/s]Running tokenizer on dataset:  91%|█████████ | 1640000/1801350 [17:45<01:41, 1588.15 examples/s]Running tokenizer on dataset:  91%|█████████ | 1640000/1801350 [17:45<01:40, 1611.36 examples/s]Running tokenizer on dataset:  91%|█████████ | 1640000/1801350 [17:45<01:40, 1603.02 examples/s]Running tokenizer on dataset:  91%|█████████ | 1643000/1801350 [17:45<01:48, 1461.13 examples/s]Running tokenizer on dataset:  91%|█████████ | 1641000/1801350 [17:45<01:42, 1570.03 examples/s]Running tokenizer on dataset:  91%|█████████ | 1641000/1801350 [17:46<01:41, 1574.35 examples/s]Running tokenizer on dataset:  91%|█████████ | 1641000/1801350 [17:46<01:41, 1572.49 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1644000/1801350 [17:46<01:48, 1455.92 examples/s]Running tokenizer on dataset:  91%|█████████ | 1642000/1801350 [17:46<01:41, 1570.73 examples/s]Running tokenizer on dataset:  91%|█████████ | 1642000/1801350 [17:46<01:41, 1577.72 examples/s]Running tokenizer on dataset:  91%|█████████ | 1642000/1801350 [17:46<01:41, 1576.17 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1645000/1801350 [17:47<01:56, 1337.63 examples/s]Running tokenizer on dataset:  91%|█████████ | 1643000/1801350 [17:47<01:46, 1482.36 examples/s]Running tokenizer on dataset:  91%|█████████ | 1643000/1801350 [17:47<01:46, 1484.11 examples/s]Running tokenizer on dataset:  91%|█████████ | 1643000/1801350 [17:47<01:46, 1481.84 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1646000/1801350 [17:47<01:51, 1392.75 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1644000/1801350 [17:47<01:46, 1473.78 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1644000/1801350 [17:48<01:47, 1470.48 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1644000/1801350 [17:48<01:47, 1465.13 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1647000/1801350 [17:48<01:47, 1438.69 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1645000/1801350 [17:48<01:57, 1336.03 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1648000/1801350 [17:49<01:42, 1498.86 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1645000/1801350 [17:49<01:57, 1329.99 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1645000/1801350 [17:49<01:57, 1327.50 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1646000/1801350 [17:49<01:50, 1412.18 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1649000/1801350 [17:49<01:37, 1554.93 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1646000/1801350 [17:49<01:51, 1392.80 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1646000/1801350 [17:49<01:52, 1379.43 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1647000/1801350 [17:50<01:47, 1441.24 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1650000/1801350 [17:50<01:42, 1475.70 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1647000/1801350 [17:50<01:48, 1425.29 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1647000/1801350 [17:50<01:48, 1427.38 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1648000/1801350 [17:50<01:42, 1491.87 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1648000/1801350 [17:50<01:42, 1503.17 examples/s]Running tokenizer on dataset:  91%|█████████▏| 1648000/1801350 [17:50<01:42, 1496.50 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1651000/1801350 [17:51<01:42, 1461.28 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1649000/1801350 [17:51<01:39, 1526.46 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1652000/1801350 [17:51<01:36, 1543.34 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1649000/1801350 [17:51<01:39, 1531.91 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1649000/1801350 [17:51<01:40, 1522.97 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1650000/1801350 [17:52<01:41, 1488.09 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1653000/1801350 [17:52<01:31, 1625.06 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1650000/1801350 [17:52<01:43, 1469.32 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1650000/1801350 [17:52<01:42, 1469.83 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1651000/1801350 [17:52<01:40, 1489.35 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1654000/1801350 [17:52<01:35, 1547.54 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1651000/1801350 [17:53<01:42, 1461.92 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1651000/1801350 [17:53<01:43, 1453.72 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1652000/1801350 [17:53<01:37, 1538.87 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1655000/1801350 [17:53<01:36, 1512.04 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1652000/1801350 [17:53<01:37, 1531.55 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1652000/1801350 [17:53<01:37, 1526.69 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1653000/1801350 [17:53<01:32, 1597.07 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1656000/1801350 [17:54<01:33, 1548.34 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1653000/1801350 [17:54<01:32, 1608.73 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1653000/1801350 [17:54<01:32, 1602.23 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1654000/1801350 [17:54<01:36, 1527.35 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1657000/1801350 [17:54<01:34, 1532.12 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1654000/1801350 [17:54<01:36, 1519.27 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1654000/1801350 [17:54<01:37, 1518.42 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1655000/1801350 [17:55<01:36, 1513.77 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1658000/1801350 [17:55<01:31, 1563.43 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1655000/1801350 [17:55<01:36, 1513.23 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1655000/1801350 [17:55<01:37, 1508.62 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1656000/1801350 [17:55<01:32, 1565.62 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1659000/1801350 [17:56<01:31, 1558.11 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1656000/1801350 [17:56<01:32, 1564.80 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1656000/1801350 [17:56<01:33, 1548.83 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1657000/1801350 [17:56<01:35, 1513.32 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1660000/1801350 [17:56<01:31, 1552.43 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1657000/1801350 [17:56<01:35, 1508.39 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1657000/1801350 [17:56<01:35, 1504.75 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1658000/1801350 [17:57<01:31, 1565.98 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1661000/1801350 [17:57<01:29, 1573.63 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1658000/1801350 [17:57<01:31, 1568.71 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1658000/1801350 [17:57<01:33, 1526.66 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1659000/1801350 [17:57<01:31, 1554.69 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1662000/1801350 [17:57<01:25, 1629.37 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1659000/1801350 [17:58<01:30, 1574.75 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1659000/1801350 [17:58<01:32, 1539.07 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1660000/1801350 [17:58<01:30, 1564.73 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1663000/1801350 [17:58<01:24, 1637.84 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1660000/1801350 [17:58<01:30, 1553.43 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1660000/1801350 [17:58<01:30, 1556.23 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1661000/1801350 [17:59<01:29, 1568.60 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1664000/1801350 [17:59<01:24, 1624.26 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1661000/1801350 [17:59<01:29, 1575.97 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1661000/1801350 [17:59<01:29, 1564.24 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1662000/1801350 [17:59<01:24, 1644.96 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1665000/1801350 [17:59<01:27, 1563.53 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1662000/1801350 [17:59<01:25, 1625.31 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1662000/1801350 [17:59<01:25, 1634.33 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1663000/1801350 [18:00<01:23, 1655.27 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1663000/1801350 [18:00<01:21, 1687.97 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1663000/1801350 [18:00<01:22, 1679.10 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1664000/1801350 [18:00<01:23, 1646.40 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1666000/1801350 [18:00<01:41, 1328.57 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1664000/1801350 [18:01<01:23, 1642.10 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1664000/1801350 [18:01<01:22, 1671.10 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1667000/1801350 [18:01<01:31, 1464.69 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1665000/1801350 [18:01<01:27, 1549.80 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1665000/1801350 [18:01<01:26, 1577.61 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1665000/1801350 [18:01<01:27, 1563.11 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1668000/1801350 [18:02<01:29, 1497.93 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1669000/1801350 [18:02<01:23, 1579.21 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1666000/1801350 [18:02<01:43, 1309.33 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1666000/1801350 [18:02<01:43, 1313.90 examples/s]Running tokenizer on dataset:  92%|█████████▏| 1666000/1801350 [18:02<01:42, 1321.05 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1667000/1801350 [18:03<01:34, 1423.81 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1670000/1801350 [18:03<01:22, 1590.34 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1667000/1801350 [18:03<01:34, 1418.19 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1667000/1801350 [18:03<01:34, 1415.50 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1668000/1801350 [18:03<01:29, 1496.28 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1671000/1801350 [18:03<01:22, 1573.55 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1668000/1801350 [18:04<01:29, 1489.10 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1668000/1801350 [18:04<01:29, 1491.89 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1669000/1801350 [18:04<01:25, 1545.45 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1672000/1801350 [18:04<01:22, 1562.27 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1669000/1801350 [18:04<01:26, 1538.06 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1669000/1801350 [18:04<01:26, 1527.52 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1670000/1801350 [18:04<01:23, 1568.46 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1673000/1801350 [18:05<01:22, 1558.50 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1670000/1801350 [18:05<01:24, 1546.50 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1670000/1801350 [18:05<01:23, 1567.04 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1671000/1801350 [18:05<01:23, 1563.26 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1674000/1801350 [18:05<01:21, 1558.38 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1671000/1801350 [18:05<01:24, 1541.65 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1671000/1801350 [18:05<01:23, 1561.30 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1672000/1801350 [18:06<01:23, 1552.57 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1675000/1801350 [18:06<01:20, 1561.47 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1672000/1801350 [18:06<01:24, 1536.05 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1672000/1801350 [18:06<01:23, 1547.73 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1673000/1801350 [18:06<01:22, 1561.19 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1676000/1801350 [18:07<01:20, 1548.46 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1673000/1801350 [18:07<01:22, 1546.75 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1673000/1801350 [18:07<01:22, 1551.55 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1674000/1801350 [18:07<01:21, 1555.05 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1677000/1801350 [18:07<01:17, 1613.22 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1674000/1801350 [18:07<01:22, 1540.07 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1674000/1801350 [18:07<01:22, 1544.57 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1675000/1801350 [18:08<01:21, 1550.78 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1678000/1801350 [18:08<01:18, 1565.11 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1675000/1801350 [18:08<01:21, 1554.00 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1675000/1801350 [18:08<01:21, 1556.24 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1676000/1801350 [18:08<01:20, 1560.15 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1679000/1801350 [18:08<01:16, 1600.43 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1676000/1801350 [18:09<01:20, 1554.17 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1676000/1801350 [18:09<01:20, 1560.39 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1677000/1801350 [18:09<01:17, 1597.48 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1680000/1801350 [18:09<01:17, 1572.23 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1677000/1801350 [18:09<01:18, 1594.12 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1677000/1801350 [18:09<01:17, 1598.64 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1678000/1801350 [18:10<01:19, 1548.57 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1681000/1801350 [18:10<01:17, 1550.18 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1678000/1801350 [18:10<01:19, 1559.32 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1678000/1801350 [18:10<01:18, 1564.59 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1679000/1801350 [18:10<01:16, 1596.28 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1682000/1801350 [18:10<01:18, 1511.97 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1679000/1801350 [18:11<01:16, 1594.08 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1679000/1801350 [18:11<01:17, 1582.13 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1680000/1801350 [18:11<01:17, 1556.02 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1683000/1801350 [18:11<01:19, 1494.36 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1680000/1801350 [18:11<01:17, 1555.87 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1680000/1801350 [18:11<01:18, 1552.28 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1681000/1801350 [18:11<01:17, 1559.69 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1681000/1801350 [18:12<01:16, 1572.93 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1681000/1801350 [18:12<01:16, 1565.62 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1684000/1801350 [18:12<01:20, 1463.30 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1682000/1801350 [18:12<01:18, 1527.33 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1685000/1801350 [18:12<01:17, 1508.77 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1682000/1801350 [18:13<01:18, 1524.25 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1682000/1801350 [18:13<01:18, 1520.68 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1683000/1801350 [18:13<01:19, 1483.71 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1686000/1801350 [18:13<01:16, 1501.88 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1683000/1801350 [18:13<01:19, 1492.98 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1683000/1801350 [18:13<01:19, 1489.99 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1684000/1801350 [18:14<01:18, 1494.95 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1684000/1801350 [18:14<01:17, 1510.89 examples/s]Running tokenizer on dataset:  93%|█████████▎| 1684000/1801350 [18:14<01:18, 1504.44 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1687000/1801350 [18:14<01:27, 1304.65 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1685000/1801350 [18:14<01:17, 1493.75 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1685000/1801350 [18:15<01:16, 1513.33 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1685000/1801350 [18:15<01:16, 1513.61 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1688000/1801350 [18:15<01:20, 1408.97 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1686000/1801350 [18:15<01:16, 1506.56 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1686000/1801350 [18:15<01:15, 1520.03 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1686000/1801350 [18:15<01:16, 1513.22 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1689000/1801350 [18:15<01:18, 1437.39 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1687000/1801350 [18:16<01:23, 1365.25 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1690000/1801350 [18:16<01:15, 1471.37 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1687000/1801350 [18:16<01:24, 1346.01 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1687000/1801350 [18:16<01:25, 1334.43 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1688000/1801350 [18:16<01:17, 1462.73 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1691000/1801350 [18:17<01:10, 1561.02 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1688000/1801350 [18:17<01:17, 1453.90 examples/s]Running tokenizer on dataset:  94%|█████████▎| 1688000/1801350 [18:17<01:18, 1437.46 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1689000/1801350 [18:17<01:16, 1469.07 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1692000/1801350 [18:17<01:09, 1579.17 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1689000/1801350 [18:17<01:17, 1458.97 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1689000/1801350 [18:17<01:17, 1449.72 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1690000/1801350 [18:18<01:14, 1493.84 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1693000/1801350 [18:18<01:13, 1474.00 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1690000/1801350 [18:18<01:15, 1471.37 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1690000/1801350 [18:18<01:15, 1467.24 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1691000/1801350 [18:18<01:11, 1551.82 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1691000/1801350 [18:19<01:11, 1547.41 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1691000/1801350 [18:19<01:11, 1552.60 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1694000/1801350 [18:19<01:13, 1453.75 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1692000/1801350 [18:19<01:09, 1567.13 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1692000/1801350 [18:19<01:09, 1564.89 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1692000/1801350 [18:19<01:09, 1568.93 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1695000/1801350 [18:19<01:11, 1486.00 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1693000/1801350 [18:20<01:13, 1473.53 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1696000/1801350 [18:20<01:08, 1541.39 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1693000/1801350 [18:20<01:14, 1455.49 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1693000/1801350 [18:20<01:14, 1451.39 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1694000/1801350 [18:20<01:11, 1491.33 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1697000/1801350 [18:21<01:09, 1509.98 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1694000/1801350 [18:21<01:13, 1469.65 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1694000/1801350 [18:21<01:13, 1457.66 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1695000/1801350 [18:21<01:10, 1508.04 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1698000/1801350 [18:21<01:08, 1505.06 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1695000/1801350 [18:21<01:11, 1496.71 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1695000/1801350 [18:21<01:11, 1493.59 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1696000/1801350 [18:22<01:09, 1517.34 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1699000/1801350 [18:22<01:07, 1508.18 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1696000/1801350 [18:22<01:09, 1515.37 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1696000/1801350 [18:22<01:09, 1507.94 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1697000/1801350 [18:22<01:10, 1488.84 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1697000/1801350 [18:23<01:09, 1503.72 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1697000/1801350 [18:23<01:09, 1502.92 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1700000/1801350 [18:23<01:12, 1402.35 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1698000/1801350 [18:23<01:08, 1501.38 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1698000/1801350 [18:23<01:08, 1509.02 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1698000/1801350 [18:23<01:08, 1510.05 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1701000/1801350 [18:23<01:09, 1437.68 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1699000/1801350 [18:24<01:07, 1509.87 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1699000/1801350 [18:24<01:07, 1518.90 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1699000/1801350 [18:24<01:07, 1518.45 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1702000/1801350 [18:24<01:07, 1482.56 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1700000/1801350 [18:24<01:10, 1436.64 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1703000/1801350 [18:25<01:04, 1534.93 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1700000/1801350 [18:25<01:10, 1434.29 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1700000/1801350 [18:25<01:10, 1433.54 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1701000/1801350 [18:25<01:08, 1461.51 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1704000/1801350 [18:25<01:03, 1538.02 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1701000/1801350 [18:25<01:09, 1450.85 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1701000/1801350 [18:25<01:09, 1447.10 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1702000/1801350 [18:26<01:06, 1502.96 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1705000/1801350 [18:26<01:03, 1526.28 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1702000/1801350 [18:26<01:06, 1497.02 examples/s]Running tokenizer on dataset:  94%|█████████▍| 1702000/1801350 [18:26<01:06, 1490.85 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1703000/1801350 [18:26<01:04, 1514.98 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1706000/1801350 [18:27<01:00, 1568.69 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1703000/1801350 [18:27<01:04, 1515.32 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1703000/1801350 [18:27<01:05, 1510.48 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1704000/1801350 [18:27<01:03, 1524.42 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1707000/1801350 [18:27<01:00, 1552.40 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1704000/1801350 [18:27<01:03, 1528.49 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1704000/1801350 [18:27<01:03, 1524.93 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1705000/1801350 [18:28<01:03, 1524.50 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1705000/1801350 [18:28<01:02, 1542.15 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1705000/1801350 [18:28<01:02, 1530.67 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1706000/1801350 [18:28<01:01, 1553.81 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1708000/1801350 [18:28<01:12, 1294.99 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1706000/1801350 [18:29<01:00, 1569.15 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1706000/1801350 [18:29<01:01, 1559.00 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1709000/1801350 [18:29<01:06, 1396.45 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1707000/1801350 [18:29<01:00, 1555.78 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1707000/1801350 [18:29<01:00, 1568.03 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1707000/1801350 [18:29<01:00, 1558.85 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1710000/1801350 [18:29<01:02, 1458.36 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1708000/1801350 [18:30<01:10, 1320.70 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1711000/1801350 [18:30<00:59, 1510.85 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1708000/1801350 [18:30<01:09, 1340.42 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1708000/1801350 [18:30<01:09, 1335.85 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1709000/1801350 [18:30<01:05, 1415.38 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1712000/1801350 [18:31<00:57, 1549.56 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1709000/1801350 [18:31<01:05, 1420.37 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1709000/1801350 [18:31<01:05, 1413.16 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1710000/1801350 [18:31<01:02, 1461.27 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1713000/1801350 [18:31<00:55, 1582.84 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1710000/1801350 [18:31<01:02, 1468.43 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1710000/1801350 [18:31<01:02, 1458.51 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1711000/1801350 [18:32<00:59, 1514.32 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1714000/1801350 [18:32<00:53, 1618.85 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1711000/1801350 [18:32<00:59, 1514.86 examples/s]Running tokenizer on dataset:  95%|█████████▍| 1711000/1801350 [18:32<00:59, 1512.29 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1712000/1801350 [18:32<00:58, 1523.56 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1715000/1801350 [18:32<00:52, 1645.97 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1712000/1801350 [18:33<00:58, 1536.61 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1712000/1801350 [18:33<00:58, 1535.57 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1713000/1801350 [18:33<00:56, 1567.41 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1716000/1801350 [18:33<00:53, 1609.94 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1713000/1801350 [18:33<00:56, 1569.04 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1713000/1801350 [18:33<00:56, 1568.53 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1714000/1801350 [18:34<00:54, 1608.54 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1717000/1801350 [18:34<00:52, 1600.89 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1714000/1801350 [18:34<00:54, 1616.99 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1714000/1801350 [18:34<00:53, 1622.90 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1715000/1801350 [18:34<00:52, 1651.44 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1718000/1801350 [18:34<00:49, 1676.32 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1715000/1801350 [18:34<00:52, 1642.71 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1715000/1801350 [18:34<00:52, 1641.14 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1716000/1801350 [18:35<00:52, 1615.63 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1719000/1801350 [18:35<00:52, 1571.51 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1716000/1801350 [18:35<00:52, 1619.02 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1716000/1801350 [18:35<00:53, 1600.24 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1717000/1801350 [18:35<00:52, 1621.35 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1720000/1801350 [18:36<00:52, 1550.84 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1717000/1801350 [18:36<00:52, 1613.54 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1717000/1801350 [18:36<00:52, 1608.92 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1718000/1801350 [18:36<00:50, 1659.40 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1718000/1801350 [18:36<00:49, 1682.69 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1718000/1801350 [18:36<00:49, 1680.26 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1721000/1801350 [18:36<00:53, 1494.49 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1719000/1801350 [18:37<00:52, 1571.15 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1722000/1801350 [18:37<00:52, 1525.88 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1719000/1801350 [18:37<00:52, 1561.13 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1719000/1801350 [18:37<00:52, 1556.27 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1720000/1801350 [18:37<00:52, 1549.80 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1720000/1801350 [18:38<00:52, 1554.56 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1723000/1801350 [18:38<00:51, 1520.01 examples/s]Running tokenizer on dataset:  95%|█████████▌| 1720000/1801350 [18:38<00:52, 1546.82 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1721000/1801350 [18:38<00:52, 1530.55 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1724000/1801350 [18:38<00:51, 1513.89 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1721000/1801350 [18:38<00:52, 1529.71 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1721000/1801350 [18:38<00:52, 1527.80 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1722000/1801350 [18:39<00:51, 1530.30 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1725000/1801350 [18:39<00:48, 1570.51 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1722000/1801350 [18:39<00:51, 1528.75 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1722000/1801350 [18:39<00:51, 1527.87 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1723000/1801350 [18:39<00:51, 1527.40 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1726000/1801350 [18:39<00:46, 1629.10 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1723000/1801350 [18:40<00:51, 1526.10 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1723000/1801350 [18:40<00:51, 1509.92 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1724000/1801350 [18:40<00:50, 1526.35 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1727000/1801350 [18:40<00:45, 1645.86 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1724000/1801350 [18:40<00:50, 1528.95 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1724000/1801350 [18:40<00:50, 1518.01 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1725000/1801350 [18:41<00:49, 1546.26 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1728000/1801350 [18:41<00:43, 1667.26 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1725000/1801350 [18:41<00:49, 1547.17 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1725000/1801350 [18:41<00:49, 1546.12 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1726000/1801350 [18:41<00:46, 1621.00 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1726000/1801350 [18:41<00:46, 1634.37 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1726000/1801350 [18:41<00:46, 1628.68 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1729000/1801350 [18:42<00:51, 1395.69 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1727000/1801350 [18:42<00:45, 1644.13 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1727000/1801350 [18:42<00:44, 1663.47 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1727000/1801350 [18:42<00:45, 1650.28 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1728000/1801350 [18:42<00:43, 1698.78 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1730000/1801350 [18:42<00:49, 1453.48 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1728000/1801350 [18:43<00:43, 1705.33 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1728000/1801350 [18:43<00:43, 1694.28 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1731000/1801350 [18:43<00:46, 1514.29 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1729000/1801350 [18:43<00:51, 1412.78 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1732000/1801350 [18:44<00:45, 1512.45 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1729000/1801350 [18:44<00:50, 1418.63 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1729000/1801350 [18:44<00:51, 1413.27 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1730000/1801350 [18:44<00:47, 1491.07 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1733000/1801350 [18:44<00:43, 1573.42 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1730000/1801350 [18:44<00:48, 1483.76 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1730000/1801350 [18:44<00:48, 1479.53 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1731000/1801350 [18:44<00:46, 1518.13 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1734000/1801350 [18:45<00:41, 1634.82 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1731000/1801350 [18:45<00:46, 1522.83 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1731000/1801350 [18:45<00:46, 1519.18 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1732000/1801350 [18:45<00:45, 1514.42 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1735000/1801350 [18:45<00:40, 1649.00 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1732000/1801350 [18:45<00:46, 1505.41 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1732000/1801350 [18:45<00:46, 1504.13 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1733000/1801350 [18:46<00:43, 1571.15 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1736000/1801350 [18:46<00:39, 1674.58 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1733000/1801350 [18:46<00:43, 1557.23 examples/s]Running tokenizer on dataset:  96%|█████████▌| 1733000/1801350 [18:46<00:43, 1555.98 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1734000/1801350 [18:46<00:41, 1625.87 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1737000/1801350 [18:46<00:37, 1708.96 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1734000/1801350 [18:47<00:40, 1642.79 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1734000/1801350 [18:47<00:41, 1632.49 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1735000/1801350 [18:47<00:39, 1667.63 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1738000/1801350 [18:47<00:38, 1658.12 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1735000/1801350 [18:47<00:40, 1657.69 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1735000/1801350 [18:47<00:40, 1650.92 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1736000/1801350 [18:47<00:38, 1693.93 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1739000/1801350 [18:48<00:38, 1606.91 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1736000/1801350 [18:48<00:38, 1687.96 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1736000/1801350 [18:48<00:38, 1680.48 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1737000/1801350 [18:48<00:37, 1708.15 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1740000/1801350 [18:48<00:37, 1627.78 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1737000/1801350 [18:48<00:37, 1702.35 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1737000/1801350 [18:48<00:37, 1701.81 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1738000/1801350 [18:49<00:38, 1651.02 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1741000/1801350 [18:49<00:37, 1607.69 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1738000/1801350 [18:49<00:38, 1643.69 examples/s]Running tokenizer on dataset:  96%|█████████▋| 1738000/1801350 [18:49<00:38, 1644.12 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1739000/1801350 [18:49<00:38, 1599.89 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1742000/1801350 [18:50<00:37, 1596.09 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1739000/1801350 [18:50<00:38, 1608.75 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1739000/1801350 [18:50<00:38, 1604.19 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1740000/1801350 [18:50<00:37, 1624.57 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1740000/1801350 [18:50<00:37, 1620.72 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1740000/1801350 [18:50<00:37, 1617.45 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1743000/1801350 [18:50<00:37, 1535.82 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1741000/1801350 [18:51<00:38, 1587.60 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1744000/1801350 [18:51<00:36, 1579.39 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1741000/1801350 [18:51<00:37, 1590.77 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1741000/1801350 [18:51<00:38, 1580.35 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1742000/1801350 [18:51<00:37, 1595.78 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1745000/1801350 [18:52<00:35, 1580.92 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1742000/1801350 [18:52<00:37, 1587.13 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1742000/1801350 [18:52<00:37, 1583.53 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1743000/1801350 [18:52<00:37, 1549.73 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1746000/1801350 [18:52<00:34, 1609.42 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1743000/1801350 [18:52<00:37, 1559.66 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1743000/1801350 [18:52<00:37, 1552.65 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1744000/1801350 [18:52<00:36, 1579.03 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1747000/1801350 [18:53<00:33, 1620.56 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1744000/1801350 [18:53<00:36, 1582.21 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1744000/1801350 [18:53<00:36, 1571.43 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1745000/1801350 [18:53<00:35, 1575.34 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1748000/1801350 [18:53<00:32, 1623.95 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1745000/1801350 [18:53<00:35, 1570.19 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1745000/1801350 [18:53<00:36, 1562.24 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1746000/1801350 [18:54<00:34, 1605.96 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1749000/1801350 [18:54<00:32, 1592.30 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1746000/1801350 [18:54<00:34, 1598.70 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1746000/1801350 [18:54<00:34, 1597.99 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1747000/1801350 [18:54<00:33, 1606.34 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1747000/1801350 [18:55<00:33, 1641.49 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1747000/1801350 [18:55<00:33, 1633.52 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1748000/1801350 [18:55<00:32, 1640.84 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1750000/1801350 [18:55<00:41, 1248.95 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1748000/1801350 [18:55<00:32, 1643.39 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1748000/1801350 [18:55<00:33, 1611.81 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1749000/1801350 [18:56<00:32, 1618.69 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1751000/1801350 [18:56<00:38, 1309.58 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1749000/1801350 [18:56<00:32, 1607.79 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1749000/1801350 [18:56<00:32, 1615.29 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1752000/1801350 [18:56<00:35, 1400.77 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1750000/1801350 [18:57<00:40, 1256.31 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1750000/1801350 [18:57<00:39, 1290.25 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1753000/1801350 [18:57<00:33, 1455.11 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1750000/1801350 [18:57<00:40, 1277.31 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1751000/1801350 [18:57<00:38, 1319.45 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1754000/1801350 [18:58<00:30, 1541.66 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1751000/1801350 [18:58<00:38, 1323.62 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1751000/1801350 [18:58<00:38, 1322.71 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1752000/1801350 [18:58<00:34, 1414.07 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1755000/1801350 [18:58<00:30, 1537.24 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1752000/1801350 [18:58<00:35, 1407.48 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1752000/1801350 [18:58<00:35, 1404.16 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1753000/1801350 [18:59<00:33, 1451.76 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1756000/1801350 [18:59<00:29, 1549.61 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1753000/1801350 [18:59<00:33, 1449.93 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1753000/1801350 [18:59<00:33, 1440.46 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1754000/1801350 [18:59<00:31, 1507.74 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1757000/1801350 [19:00<00:27, 1597.20 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1754000/1801350 [19:00<00:31, 1520.58 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1754000/1801350 [19:00<00:31, 1509.17 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1755000/1801350 [19:00<00:30, 1523.23 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1758000/1801350 [19:00<00:26, 1611.76 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1755000/1801350 [19:00<00:30, 1528.78 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1755000/1801350 [19:00<00:30, 1526.48 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1756000/1801350 [19:00<00:29, 1550.95 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1759000/1801350 [19:01<00:26, 1625.29 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1756000/1801350 [19:01<00:29, 1543.54 examples/s]Running tokenizer on dataset:  97%|█████████▋| 1756000/1801350 [19:01<00:29, 1529.57 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1757000/1801350 [19:01<00:27, 1587.88 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1760000/1801350 [19:01<00:25, 1595.25 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1757000/1801350 [19:01<00:28, 1577.56 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1757000/1801350 [19:01<00:28, 1579.12 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1758000/1801350 [19:02<00:27, 1581.41 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1761000/1801350 [19:02<00:25, 1585.31 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1758000/1801350 [19:02<00:27, 1584.03 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1758000/1801350 [19:02<00:27, 1587.07 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1759000/1801350 [19:02<00:26, 1598.25 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1759000/1801350 [19:03<00:25, 1633.19 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1762000/1801350 [19:03<00:25, 1547.10 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1759000/1801350 [19:03<00:26, 1584.29 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1760000/1801350 [19:03<00:25, 1612.40 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1763000/1801350 [19:03<00:24, 1591.18 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1760000/1801350 [19:03<00:25, 1618.90 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1760000/1801350 [19:03<00:26, 1584.81 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1761000/1801350 [19:04<00:25, 1605.55 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1764000/1801350 [19:04<00:23, 1592.88 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1761000/1801350 [19:04<00:25, 1591.41 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1761000/1801350 [19:04<00:25, 1596.62 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1762000/1801350 [19:04<00:25, 1572.30 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1765000/1801350 [19:04<00:22, 1634.90 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1762000/1801350 [19:05<00:25, 1555.12 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1762000/1801350 [19:05<00:25, 1545.16 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1763000/1801350 [19:05<00:23, 1618.30 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1766000/1801350 [19:05<00:21, 1649.25 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1763000/1801350 [19:05<00:23, 1598.71 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1763000/1801350 [19:05<00:24, 1590.77 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1764000/1801350 [19:05<00:23, 1606.87 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1767000/1801350 [19:06<00:21, 1614.87 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1764000/1801350 [19:06<00:23, 1596.19 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1764000/1801350 [19:06<00:23, 1591.48 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1765000/1801350 [19:06<00:22, 1623.88 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1765000/1801350 [19:06<00:22, 1650.09 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1768000/1801350 [19:06<00:21, 1533.05 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1765000/1801350 [19:06<00:22, 1629.86 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1766000/1801350 [19:07<00:21, 1644.61 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1766000/1801350 [19:07<00:21, 1671.20 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1766000/1801350 [19:07<00:21, 1666.39 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1769000/1801350 [19:07<00:21, 1539.90 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1767000/1801350 [19:07<00:21, 1631.67 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1770000/1801350 [19:08<00:19, 1573.23 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1767000/1801350 [19:08<00:21, 1612.68 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1767000/1801350 [19:08<00:21, 1607.83 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1768000/1801350 [19:08<00:21, 1550.51 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1768000/1801350 [19:08<00:21, 1545.04 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1768000/1801350 [19:08<00:21, 1550.24 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1769000/1801350 [19:09<00:20, 1579.84 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1771000/1801350 [19:09<00:22, 1334.64 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1769000/1801350 [19:09<00:20, 1579.00 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1769000/1801350 [19:09<00:20, 1573.80 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1770000/1801350 [19:09<00:19, 1600.98 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1772000/1801350 [19:09<00:20, 1420.27 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1770000/1801350 [19:10<00:19, 1582.74 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1770000/1801350 [19:10<00:19, 1579.90 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1773000/1801350 [19:10<00:18, 1493.01 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1771000/1801350 [19:10<00:22, 1368.08 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1774000/1801350 [19:10<00:17, 1607.50 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1771000/1801350 [19:11<00:22, 1356.67 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1771000/1801350 [19:11<00:22, 1349.53 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1772000/1801350 [19:11<00:20, 1440.32 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1775000/1801350 [19:11<00:16, 1620.16 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1772000/1801350 [19:11<00:20, 1430.29 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1772000/1801350 [19:11<00:20, 1424.52 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1773000/1801350 [19:11<00:18, 1495.13 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1776000/1801350 [19:12<00:15, 1636.44 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1773000/1801350 [19:12<00:18, 1501.88 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1773000/1801350 [19:12<00:18, 1493.36 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1774000/1801350 [19:12<00:17, 1595.38 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1774000/1801350 [19:12<00:16, 1616.70 examples/s]Running tokenizer on dataset:  98%|█████████▊| 1774000/1801350 [19:12<00:17, 1608.18 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1777000/1801350 [19:12<00:16, 1471.66 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1775000/1801350 [19:13<00:16, 1598.73 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1775000/1801350 [19:13<00:16, 1611.59 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1775000/1801350 [19:13<00:16, 1608.37 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1778000/1801350 [19:13<00:15, 1503.26 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1776000/1801350 [19:13<00:15, 1635.72 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1776000/1801350 [19:14<00:15, 1639.45 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1776000/1801350 [19:14<00:15, 1631.16 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1779000/1801350 [19:14<00:14, 1519.55 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1777000/1801350 [19:14<00:16, 1487.21 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1780000/1801350 [19:14<00:13, 1535.83 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1777000/1801350 [19:14<00:16, 1485.08 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1777000/1801350 [19:14<00:16, 1479.22 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1778000/1801350 [19:15<00:15, 1513.60 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1778000/1801350 [19:15<00:15, 1503.36 examples/s]Running tokenizer on dataset:  99%|█████████▊| 1778000/1801350 [19:15<00:15, 1492.47 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1781000/1801350 [19:15<00:13, 1489.07 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1779000/1801350 [19:15<00:14, 1524.10 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1779000/1801350 [19:16<00:14, 1512.86 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1782000/1801350 [19:16<00:12, 1536.93 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1779000/1801350 [19:16<00:14, 1499.92 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1780000/1801350 [19:16<00:14, 1506.66 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1783000/1801350 [19:16<00:11, 1655.97 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1780000/1801350 [19:16<00:14, 1500.27 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1780000/1801350 [19:16<00:14, 1493.14 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1781000/1801350 [19:17<00:13, 1497.66 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1784000/1801350 [19:17<00:10, 1642.52 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1781000/1801350 [19:17<00:13, 1479.76 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1781000/1801350 [19:17<00:13, 1470.47 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1782000/1801350 [19:17<00:12, 1514.97 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1785000/1801350 [19:17<00:10, 1604.11 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1782000/1801350 [19:18<00:12, 1509.49 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1782000/1801350 [19:18<00:12, 1509.09 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1783000/1801350 [19:18<00:11, 1630.76 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1786000/1801350 [19:18<00:09, 1577.28 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1783000/1801350 [19:18<00:11, 1624.63 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1783000/1801350 [19:18<00:11, 1623.83 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1784000/1801350 [19:18<00:10, 1639.18 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1787000/1801350 [19:19<00:08, 1598.44 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1784000/1801350 [19:19<00:10, 1634.02 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1784000/1801350 [19:19<00:10, 1625.34 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1785000/1801350 [19:19<00:10, 1606.62 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1788000/1801350 [19:19<00:08, 1572.71 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1785000/1801350 [19:19<00:10, 1603.14 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1785000/1801350 [19:19<00:10, 1580.46 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1786000/1801350 [19:20<00:09, 1576.26 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1789000/1801350 [19:20<00:07, 1556.03 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1786000/1801350 [19:20<00:09, 1580.20 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1786000/1801350 [19:20<00:09, 1536.67 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1787000/1801350 [19:20<00:09, 1590.55 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1787000/1801350 [19:21<00:09, 1586.11 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1787000/1801350 [19:21<00:09, 1578.80 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1790000/1801350 [19:21<00:07, 1496.01 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1788000/1801350 [19:21<00:08, 1557.39 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1788000/1801350 [19:21<00:08, 1589.45 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1788000/1801350 [19:21<00:08, 1559.05 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1791000/1801350 [19:21<00:06, 1500.47 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1789000/1801350 [19:22<00:07, 1554.47 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1789000/1801350 [19:22<00:07, 1558.97 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1789000/1801350 [19:22<00:07, 1584.72 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1790000/1801350 [19:22<00:07, 1545.44 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1792000/1801350 [19:22<00:07, 1295.88 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1790000/1801350 [19:23<00:07, 1516.64 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1790000/1801350 [19:23<00:07, 1517.03 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1791000/1801350 [19:23<00:06, 1541.05 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1793000/1801350 [19:23<00:05, 1393.13 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1791000/1801350 [19:23<00:06, 1537.37 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1791000/1801350 [19:23<00:06, 1505.84 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1794000/1801350 [19:24<00:04, 1480.22 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1792000/1801350 [19:24<00:07, 1308.02 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1795000/1801350 [19:24<00:04, 1457.49 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1792000/1801350 [19:24<00:07, 1312.72 examples/s]Running tokenizer on dataset:  99%|█████████▉| 1792000/1801350 [19:24<00:07, 1266.59 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1793000/1801350 [19:25<00:05, 1395.44 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1793000/1801350 [19:25<00:05, 1422.35 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1796000/1801350 [19:25<00:03, 1479.08 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1793000/1801350 [19:25<00:06, 1378.24 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1794000/1801350 [19:25<00:05, 1468.43 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1794000/1801350 [19:26<00:04, 1495.90 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1797000/1801350 [19:26<00:02, 1544.70 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1794000/1801350 [19:26<00:05, 1463.03 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1795000/1801350 [19:26<00:04, 1454.29 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1798000/1801350 [19:26<00:02, 1561.27 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1795000/1801350 [19:26<00:04, 1450.91 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1795000/1801350 [19:26<00:04, 1434.53 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1796000/1801350 [19:26<00:03, 1465.44 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1799000/1801350 [19:27<00:01, 1574.42 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1796000/1801350 [19:27<00:03, 1466.16 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1796000/1801350 [19:27<00:03, 1443.40 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1797000/1801350 [19:27<00:02, 1520.15 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1800000/1801350 [19:27<00:00, 1617.43 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1797000/1801350 [19:28<00:02, 1515.88 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1797000/1801350 [19:28<00:02, 1508.71 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1798000/1801350 [19:28<00:02, 1538.63 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1801000/1801350 [19:28<00:00, 1643.88 examples/s]Running tokenizer on dataset: 100%|██████████| 1801350/1801350 [19:28<00:00, 1711.65 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1798000/1801350 [19:28<00:02, 1536.06 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1798000/1801350 [19:28<00:02, 1533.04 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1799000/1801350 [19:28<00:01, 1570.23 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1799000/1801350 [19:29<00:01, 1651.72 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1799000/1801350 [19:29<00:01, 1639.51 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1800000/1801350 [19:29<00:00, 1712.78 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1800000/1801350 [19:29<00:00, 1773.11 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1800000/1801350 [19:29<00:00, 1794.77 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1801000/1801350 [19:29<00:00, 1826.46 examples/s]Running tokenizer on dataset: 100%|██████████| 1801350/1801350 [19:29<00:00, 1916.35 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1801000/1801350 [19:30<00:00, 1914.74 examples/s]Running tokenizer on dataset: 100%|█████████▉| 1801000/1801350 [19:30<00:00, 1935.60 examples/s]Running tokenizer on dataset: 100%|██████████| 1801350/1801350 [19:30<00:00, 2008.94 examples/s]                                                                                                Running tokenizer on dataset:   0%|          | 0/3760 [00:00<?, ? examples/s]Running tokenizer on dataset:  27%|██▋       | 1000/3760 [00:00<00:00, 6771.56 examples/s]Running tokenizer on dataset:  53%|█████▎    | 2000/3760 [00:00<00:00, 5627.85 examples/s]Running tokenizer on dataset:  80%|███████▉  | 3000/3760 [00:00<00:00, 5341.84 examples/s]Running tokenizer on dataset: 100%|██████████| 3760/3760 [00:00<00:00, 5401.29 examples/s]                                                                                          Grouping texts in chunks of 1024:   0%|          | 0/1801350 [00:00<?, ? examples/s]Grouping texts in chunks of 1024:   0%|          | 2000/1801350 [00:00<02:02, 14745.70 examples/s]Grouping texts in chunks of 1024:   0%|          | 4000/1801350 [00:00<01:58, 15216.22 examples/s]Grouping texts in chunks of 1024:   0%|          | 6000/1801350 [00:00<01:52, 15936.54 examples/s]                                                                                                                                                                                                                                                                                                Grouping texts in chunks of 1024:   0%|          | 0/1801350 [00:00<?, ? examples/s]Grouping texts in chunks of 1024:   0%|          | 0/1801350 [00:00<?, ? examples/s]Grouping texts in chunks of 1024:   0%|          | 0/1801350 [00:00<?, ? examples/s]Grouping texts in chunks of 1024:   0%|          | 1000/1801350 [00:00<06:32, 4592.28 examples/s]Grouping texts in chunks of 1024:   0%|          | 1000/1801350 [00:00<07:15, 4131.55 examples/s]Grouping texts in chunks of 1024:   0%|          | 1000/1801350 [00:00<06:32, 4587.82 examples/s]Grouping texts in chunks of 1024:   0%|          | 8000/1801350 [00:00<03:51, 7758.47 examples/s] Grouping texts in chunks of 1024:   0%|          | 2000/1801350 [00:00<07:15, 4128.78 examples/s]Grouping texts in chunks of 1024:   0%|          | 2000/1801350 [00:00<07:15, 4133.72 examples/s]Grouping texts in chunks of 1024:   0%|          | 2000/1801350 [00:00<07:34, 3962.12 examples/s]Grouping texts in chunks of 1024:   0%|          | 3000/1801350 [00:00<06:51, 4366.75 examples/s]Grouping texts in chunks of 1024:   0%|          | 3000/1801350 [00:00<06:55, 4325.59 examples/s]Grouping texts in chunks of 1024:   0%|          | 3000/1801350 [00:00<07:07, 4208.30 examples/s]Grouping texts in chunks of 1024:   1%|          | 10000/1801350 [00:01<04:51, 6137.66 examples/s]Grouping texts in chunks of 1024:   0%|          | 4000/1801350 [00:00<06:49, 4393.41 examples/s]Grouping texts in chunks of 1024:   0%|          | 4000/1801350 [00:00<07:00, 4271.97 examples/s]Grouping texts in chunks of 1024:   0%|          | 4000/1801350 [00:00<06:57, 4302.15 examples/s]Grouping texts in chunks of 1024:   1%|          | 11000/1801350 [00:01<05:19, 5599.19 examples/s]Grouping texts in chunks of 1024:   0%|          | 5000/1801350 [00:01<06:26, 4650.58 examples/s]Grouping texts in chunks of 1024:   0%|          | 5000/1801350 [00:01<06:26, 4642.76 examples/s]Grouping texts in chunks of 1024:   0%|          | 5000/1801350 [00:01<06:27, 4635.08 examples/s]Grouping texts in chunks of 1024:   1%|          | 12000/1801350 [00:01<05:32, 5375.47 examples/s]Grouping texts in chunks of 1024:   0%|          | 6000/1801350 [00:01<06:06, 4901.76 examples/s]Grouping texts in chunks of 1024:   0%|          | 6000/1801350 [00:01<06:18, 4746.85 examples/s]Grouping texts in chunks of 1024:   0%|          | 6000/1801350 [00:01<06:24, 4668.57 examples/s]Grouping texts in chunks of 1024:   1%|          | 13000/1801350 [00:01<05:58, 4986.82 examples/s]Grouping texts in chunks of 1024:   0%|          | 7000/1801350 [00:01<06:40, 4481.08 examples/s]Grouping texts in chunks of 1024:   0%|          | 7000/1801350 [00:01<06:46, 4411.89 examples/s]Grouping texts in chunks of 1024:   0%|          | 7000/1801350 [00:01<06:56, 4310.95 examples/s]Grouping texts in chunks of 1024:   1%|          | 14000/1801350 [00:02<06:10, 4825.52 examples/s]Grouping texts in chunks of 1024:   0%|          | 8000/1801350 [00:01<06:49, 4381.29 examples/s]Grouping texts in chunks of 1024:   0%|          | 8000/1801350 [00:01<06:49, 4376.47 examples/s]Grouping texts in chunks of 1024:   0%|          | 8000/1801350 [00:01<06:57, 4292.77 examples/s]Grouping texts in chunks of 1024:   1%|          | 15000/1801350 [00:02<06:08, 4842.06 examples/s]Grouping texts in chunks of 1024:   0%|          | 9000/1801350 [00:02<06:46, 4414.22 examples/s]Grouping texts in chunks of 1024:   0%|          | 9000/1801350 [00:02<06:52, 4342.70 examples/s]Grouping texts in chunks of 1024:   0%|          | 9000/1801350 [00:02<06:49, 4376.40 examples/s]Grouping texts in chunks of 1024:   1%|          | 16000/1801350 [00:02<06:39, 4464.85 examples/s]Grouping texts in chunks of 1024:   1%|          | 10000/1801350 [00:02<06:39, 4479.70 examples/s]Grouping texts in chunks of 1024:   1%|          | 10000/1801350 [00:02<06:47, 4395.33 examples/s]Grouping texts in chunks of 1024:   1%|          | 10000/1801350 [00:02<06:48, 4383.41 examples/s]Grouping texts in chunks of 1024:   1%|          | 17000/1801350 [00:02<06:44, 4406.49 examples/s]Grouping texts in chunks of 1024:   1%|          | 11000/1801350 [00:02<06:44, 4421.72 examples/s]Grouping texts in chunks of 1024:   1%|          | 11000/1801350 [00:02<06:55, 4312.46 examples/s]Grouping texts in chunks of 1024:   1%|          | 11000/1801350 [00:02<06:50, 4356.97 examples/s]Grouping texts in chunks of 1024:   1%|          | 18000/1801350 [00:03<06:34, 4514.89 examples/s]Grouping texts in chunks of 1024:   1%|          | 12000/1801350 [00:02<06:47, 4388.33 examples/s]Grouping texts in chunks of 1024:   1%|          | 12000/1801350 [00:02<06:52, 4334.10 examples/s]Grouping texts in chunks of 1024:   1%|          | 12000/1801350 [00:02<06:47, 4395.88 examples/s]Grouping texts in chunks of 1024:   1%|          | 19000/1801350 [00:03<06:38, 4469.96 examples/s]Grouping texts in chunks of 1024:   1%|          | 13000/1801350 [00:02<06:46, 4394.68 examples/s]Grouping texts in chunks of 1024:   1%|          | 13000/1801350 [00:02<07:05, 4203.56 examples/s]Grouping texts in chunks of 1024:   1%|          | 13000/1801350 [00:02<07:03, 4218.74 examples/s]Grouping texts in chunks of 1024:   1%|          | 20000/1801350 [00:03<06:37, 4479.07 examples/s]Grouping texts in chunks of 1024:   1%|          | 14000/1801350 [00:03<06:38, 4482.54 examples/s]Grouping texts in chunks of 1024:   1%|          | 14000/1801350 [00:03<06:48, 4372.30 examples/s]Grouping texts in chunks of 1024:   1%|          | 14000/1801350 [00:03<06:43, 4432.63 examples/s]Grouping texts in chunks of 1024:   1%|          | 21000/1801350 [00:03<06:42, 4418.25 examples/s]Grouping texts in chunks of 1024:   1%|          | 15000/1801350 [00:03<06:35, 4516.13 examples/s]Grouping texts in chunks of 1024:   1%|          | 15000/1801350 [00:03<06:39, 4469.19 examples/s]Grouping texts in chunks of 1024:   1%|          | 15000/1801350 [00:03<06:36, 4505.44 examples/s]Grouping texts in chunks of 1024:   1%|          | 22000/1801350 [00:04<06:56, 4274.60 examples/s]Grouping texts in chunks of 1024:   1%|          | 16000/1801350 [00:03<06:54, 4307.85 examples/s]Grouping texts in chunks of 1024:   1%|          | 16000/1801350 [00:03<06:54, 4309.02 examples/s]Grouping texts in chunks of 1024:   1%|          | 16000/1801350 [00:03<06:58, 4269.70 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 23000/1801350 [00:04<06:45, 4388.03 examples/s]Grouping texts in chunks of 1024:   1%|          | 17000/1801350 [00:03<06:50, 4345.66 examples/s]Grouping texts in chunks of 1024:   1%|          | 17000/1801350 [00:03<06:58, 4265.99 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 24000/1801350 [00:04<06:17, 4706.86 examples/s]Grouping texts in chunks of 1024:   1%|          | 17000/1801350 [00:03<06:58, 4262.05 examples/s]Grouping texts in chunks of 1024:   1%|          | 18000/1801350 [00:04<06:48, 4370.48 examples/s]Grouping texts in chunks of 1024:   1%|          | 18000/1801350 [00:04<06:51, 4336.54 examples/s]Grouping texts in chunks of 1024:   1%|          | 18000/1801350 [00:04<06:46, 4387.64 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 25000/1801350 [00:04<06:12, 4771.00 examples/s]Grouping texts in chunks of 1024:   1%|          | 19000/1801350 [00:04<06:38, 4471.59 examples/s]Grouping texts in chunks of 1024:   1%|          | 19000/1801350 [00:04<06:41, 4435.96 examples/s]Grouping texts in chunks of 1024:   1%|          | 19000/1801350 [00:04<06:39, 4459.97 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 26000/1801350 [00:04<06:37, 4461.89 examples/s]Grouping texts in chunks of 1024:   1%|          | 20000/1801350 [00:04<06:28, 4585.89 examples/s]Grouping texts in chunks of 1024:   1%|          | 20000/1801350 [00:04<06:34, 4516.76 examples/s]Grouping texts in chunks of 1024:   1%|          | 20000/1801350 [00:04<06:29, 4568.30 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 27000/1801350 [00:05<06:50, 4325.41 examples/s]Grouping texts in chunks of 1024:   1%|          | 21000/1801350 [00:04<06:43, 4411.76 examples/s]Grouping texts in chunks of 1024:   1%|          | 21000/1801350 [00:04<06:49, 4343.50 examples/s]Grouping texts in chunks of 1024:   1%|          | 21000/1801350 [00:04<06:46, 4378.60 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 28000/1801350 [00:05<07:01, 4211.95 examples/s]Grouping texts in chunks of 1024:   1%|          | 22000/1801350 [00:05<06:54, 4288.22 examples/s]Grouping texts in chunks of 1024:   1%|          | 22000/1801350 [00:05<06:59, 4244.60 examples/s]Grouping texts in chunks of 1024:   1%|          | 22000/1801350 [00:05<06:57, 4264.66 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 29000/1801350 [00:05<06:41, 4414.34 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 23000/1801350 [00:05<06:31, 4541.67 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 23000/1801350 [00:05<06:45, 4387.73 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 23000/1801350 [00:05<06:44, 4396.21 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 30000/1801350 [00:05<06:44, 4380.28 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 24000/1801350 [00:05<06:26, 4599.75 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 24000/1801350 [00:05<06:23, 4628.68 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 24000/1801350 [00:05<06:22, 4649.10 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 31000/1801350 [00:06<07:04, 4166.29 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 25000/1801350 [00:05<06:10, 4797.61 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 25000/1801350 [00:05<06:09, 4802.13 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 25000/1801350 [00:05<06:23, 4634.36 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 32000/1801350 [00:06<07:03, 4181.92 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 26000/1801350 [00:05<06:21, 4649.96 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 26000/1801350 [00:05<06:25, 4601.64 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 26000/1801350 [00:05<06:35, 4491.88 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 33000/1801350 [00:06<07:09, 4116.97 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 27000/1801350 [00:06<06:36, 4473.77 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 27000/1801350 [00:06<06:44, 4391.72 examples/s]Grouping texts in chunks of 1024:   1%|▏         | 27000/1801350 [00:06<06:50, 4325.43 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 34000/1801350 [00:06<07:09, 4112.52 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 28000/1801350 [00:06<06:54, 4273.35 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 28000/1801350 [00:06<06:54, 4277.41 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 28000/1801350 [00:06<06:51, 4305.33 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 35000/1801350 [00:07<06:59, 4209.92 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 29000/1801350 [00:06<06:33, 4505.37 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 29000/1801350 [00:06<06:39, 4434.46 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 29000/1801350 [00:06<06:46, 4359.61 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 36000/1801350 [00:07<06:56, 4238.38 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 30000/1801350 [00:06<06:33, 4505.55 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 30000/1801350 [00:06<06:39, 4432.96 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 30000/1801350 [00:06<06:32, 4512.87 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 37000/1801350 [00:07<07:01, 4184.60 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 31000/1801350 [00:07<07:01, 4204.69 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 31000/1801350 [00:07<07:14, 4071.30 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 31000/1801350 [00:07<07:06, 4154.45 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 38000/1801350 [00:07<07:09, 4105.31 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 32000/1801350 [00:07<07:00, 4208.42 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 32000/1801350 [00:07<06:57, 4235.79 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 32000/1801350 [00:07<07:07, 4141.90 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 39000/1801350 [00:08<07:05, 4137.09 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 33000/1801350 [00:07<07:00, 4203.99 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 33000/1801350 [00:07<07:09, 4113.33 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 33000/1801350 [00:07<07:07, 4132.70 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 40000/1801350 [00:08<06:54, 4250.32 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 34000/1801350 [00:07<07:02, 4181.14 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 34000/1801350 [00:07<07:08, 4122.18 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 34000/1801350 [00:07<07:01, 4194.51 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 41000/1801350 [00:08<06:47, 4319.00 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 35000/1801350 [00:07<06:49, 4316.49 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 35000/1801350 [00:08<06:48, 4321.36 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 35000/1801350 [00:08<06:57, 4228.40 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 36000/1801350 [00:08<06:52, 4279.58 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 42000/1801350 [00:08<07:08, 4109.29 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 36000/1801350 [00:08<07:00, 4194.34 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 36000/1801350 [00:08<06:59, 4206.32 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 37000/1801350 [00:08<06:54, 4256.68 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 43000/1801350 [00:09<07:11, 4074.96 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 37000/1801350 [00:08<07:06, 4133.31 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 37000/1801350 [00:08<07:00, 4199.36 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 44000/1801350 [00:09<06:57, 4212.31 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 38000/1801350 [00:08<07:06, 4134.54 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 38000/1801350 [00:08<07:05, 4146.69 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 38000/1801350 [00:08<07:10, 4093.34 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 45000/1801350 [00:09<06:53, 4249.79 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 39000/1801350 [00:08<06:59, 4202.61 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 39000/1801350 [00:08<06:52, 4269.81 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 39000/1801350 [00:08<06:59, 4200.03 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 46000/1801350 [00:09<06:37, 4412.67 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 40000/1801350 [00:09<06:47, 4319.37 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 40000/1801350 [00:09<06:58, 4210.33 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 40000/1801350 [00:09<06:55, 4242.74 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 47000/1801350 [00:09<06:42, 4356.69 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 41000/1801350 [00:09<06:41, 4385.77 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 41000/1801350 [00:09<06:46, 4333.15 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 41000/1801350 [00:09<06:39, 4405.84 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 48000/1801350 [00:10<05:54, 4943.16 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 42000/1801350 [00:09<07:00, 4185.41 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 49000/1801350 [00:10<05:57, 4907.80 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 42000/1801350 [00:09<07:05, 4136.96 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 42000/1801350 [00:09<07:04, 4146.98 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 43000/1801350 [00:09<07:00, 4183.36 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 50000/1801350 [00:10<06:01, 4840.50 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 43000/1801350 [00:09<06:56, 4224.71 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 43000/1801350 [00:09<07:08, 4101.06 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 44000/1801350 [00:10<06:46, 4318.61 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 51000/1801350 [00:10<06:19, 4610.02 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 44000/1801350 [00:10<06:52, 4264.48 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 44000/1801350 [00:10<06:52, 4255.25 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 45000/1801350 [00:10<06:50, 4277.20 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 52000/1801350 [00:10<06:20, 4592.51 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 45000/1801350 [00:10<06:48, 4297.76 examples/s]Grouping texts in chunks of 1024:   2%|▏         | 45000/1801350 [00:10<06:57, 4208.57 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 46000/1801350 [00:10<06:40, 4379.11 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 53000/1801350 [00:11<06:13, 4683.41 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 46000/1801350 [00:10<06:35, 4434.38 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 46000/1801350 [00:10<06:41, 4370.85 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 47000/1801350 [00:10<06:34, 4449.34 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 47000/1801350 [00:10<06:33, 4453.54 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 54000/1801350 [00:11<06:31, 4468.85 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 47000/1801350 [00:10<06:36, 4420.98 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 48000/1801350 [00:10<05:47, 5041.99 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 48000/1801350 [00:10<05:49, 5020.09 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 48000/1801350 [00:10<05:51, 4989.46 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 55000/1801350 [00:11<06:39, 4374.97 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 49000/1801350 [00:11<05:54, 4941.24 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 49000/1801350 [00:11<06:01, 4846.94 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 49000/1801350 [00:11<05:50, 4996.18 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 56000/1801350 [00:11<06:34, 4429.30 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 50000/1801350 [00:11<05:58, 4885.88 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 50000/1801350 [00:11<06:00, 4855.71 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 50000/1801350 [00:11<05:59, 4865.77 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 57000/1801350 [00:12<06:44, 4308.86 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 51000/1801350 [00:11<06:17, 4639.90 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 51000/1801350 [00:11<06:21, 4584.10 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 51000/1801350 [00:11<06:26, 4534.02 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 52000/1801350 [00:11<06:15, 4662.21 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 58000/1801350 [00:12<06:49, 4254.90 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 52000/1801350 [00:11<06:11, 4710.22 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 52000/1801350 [00:11<06:24, 4548.44 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 53000/1801350 [00:11<06:04, 4802.88 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 59000/1801350 [00:12<06:30, 4467.35 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 53000/1801350 [00:12<06:11, 4708.78 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 53000/1801350 [00:12<06:02, 4829.64 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 54000/1801350 [00:12<06:14, 4670.83 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 60000/1801350 [00:12<06:42, 4327.52 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 54000/1801350 [00:12<06:20, 4592.66 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 54000/1801350 [00:12<06:20, 4590.55 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 61000/1801350 [00:12<06:25, 4516.75 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 55000/1801350 [00:12<06:40, 4364.47 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 55000/1801350 [00:12<06:34, 4428.07 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 55000/1801350 [00:12<06:41, 4354.50 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 62000/1801350 [00:13<06:33, 4419.89 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 56000/1801350 [00:12<06:27, 4502.56 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 56000/1801350 [00:12<06:28, 4494.54 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 56000/1801350 [00:12<06:25, 4525.75 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 63000/1801350 [00:13<06:37, 4368.20 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 57000/1801350 [00:12<06:38, 4374.91 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 57000/1801350 [00:12<06:44, 4307.67 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 57000/1801350 [00:13<06:48, 4268.27 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 64000/1801350 [00:13<06:35, 4394.71 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 58000/1801350 [00:13<06:46, 4287.73 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 58000/1801350 [00:13<06:50, 4242.34 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 58000/1801350 [00:13<06:53, 4220.21 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 65000/1801350 [00:13<06:32, 4418.23 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 59000/1801350 [00:13<06:24, 4526.12 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 59000/1801350 [00:13<06:33, 4428.69 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 59000/1801350 [00:13<06:20, 4581.10 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 66000/1801350 [00:14<06:32, 4416.77 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 60000/1801350 [00:13<06:38, 4373.84 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 60000/1801350 [00:13<06:37, 4382.00 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 60000/1801350 [00:13<06:41, 4341.03 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 61000/1801350 [00:13<06:17, 4613.49 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 67000/1801350 [00:14<06:35, 4381.69 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 61000/1801350 [00:13<06:23, 4533.85 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 61000/1801350 [00:13<06:35, 4395.18 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 62000/1801350 [00:13<06:23, 4530.00 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 68000/1801350 [00:14<06:52, 4201.27 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 62000/1801350 [00:14<06:29, 4465.46 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 62000/1801350 [00:14<06:28, 4479.34 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 63000/1801350 [00:14<06:40, 4339.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 69000/1801350 [00:14<06:39, 4330.97 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 63000/1801350 [00:14<06:29, 4459.52 examples/s]Grouping texts in chunks of 1024:   3%|▎         | 63000/1801350 [00:14<06:37, 4375.82 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 64000/1801350 [00:14<06:30, 4445.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 70000/1801350 [00:15<06:27, 4472.05 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 64000/1801350 [00:14<06:28, 4476.46 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 64000/1801350 [00:14<06:35, 4391.65 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 65000/1801350 [00:14<06:30, 4445.89 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 71000/1801350 [00:15<06:35, 4380.43 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 65000/1801350 [00:14<06:30, 4440.92 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 65000/1801350 [00:14<06:37, 4371.53 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 72000/1801350 [00:15<06:24, 4493.46 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 66000/1801350 [00:14<06:34, 4404.18 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 66000/1801350 [00:15<06:29, 4452.11 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 66000/1801350 [00:15<07:08, 4053.91 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 73000/1801350 [00:15<06:07, 4702.22 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 67000/1801350 [00:15<06:15, 4614.02 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 67000/1801350 [00:15<06:36, 4378.91 examples/s]Grouping texts in chunks of 1024:   4%|▎         | 67000/1801350 [00:15<06:32, 4424.31 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 74000/1801350 [00:15<06:00, 4790.22 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 68000/1801350 [00:15<06:38, 4346.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 68000/1801350 [00:15<06:50, 4219.02 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 75000/1801350 [00:16<06:05, 4720.93 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 68000/1801350 [00:15<06:52, 4205.41 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 69000/1801350 [00:15<06:18, 4577.81 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 69000/1801350 [00:15<06:30, 4434.03 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 76000/1801350 [00:16<06:06, 4711.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 69000/1801350 [00:15<06:29, 4448.17 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 70000/1801350 [00:15<06:17, 4586.94 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 70000/1801350 [00:15<06:19, 4561.50 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 77000/1801350 [00:16<06:10, 4650.87 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 70000/1801350 [00:15<06:27, 4467.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 71000/1801350 [00:16<06:35, 4371.50 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 71000/1801350 [00:16<06:28, 4451.77 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 78000/1801350 [00:16<06:17, 4563.22 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 71000/1801350 [00:16<06:33, 4393.11 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 72000/1801350 [00:16<06:18, 4568.50 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 72000/1801350 [00:16<06:23, 4503.82 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 72000/1801350 [00:16<06:17, 4582.00 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 73000/1801350 [00:16<06:10, 4660.07 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 79000/1801350 [00:17<06:37, 4333.24 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 73000/1801350 [00:16<06:11, 4658.17 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 73000/1801350 [00:16<06:13, 4627.60 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 74000/1801350 [00:16<05:53, 4886.78 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 80000/1801350 [00:17<06:49, 4207.84 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 74000/1801350 [00:16<05:52, 4894.22 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 74000/1801350 [00:16<05:56, 4846.04 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 75000/1801350 [00:16<05:48, 4955.19 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 81000/1801350 [00:17<06:45, 4237.69 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 75000/1801350 [00:16<05:52, 4903.93 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 75000/1801350 [00:16<05:52, 4901.48 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 76000/1801350 [00:17<06:08, 4685.83 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 82000/1801350 [00:17<06:44, 4247.35 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 76000/1801350 [00:17<06:08, 4678.88 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 76000/1801350 [00:17<06:04, 4729.99 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 77000/1801350 [00:17<06:07, 4696.76 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 83000/1801350 [00:17<06:29, 4409.00 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 77000/1801350 [00:17<06:03, 4739.99 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 77000/1801350 [00:17<06:13, 4618.95 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 78000/1801350 [00:17<06:08, 4678.58 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 84000/1801350 [00:18<06:12, 4615.31 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 78000/1801350 [00:17<06:16, 4575.79 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 78000/1801350 [00:17<06:14, 4605.42 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 79000/1801350 [00:17<06:32, 4383.11 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 85000/1801350 [00:18<06:32, 4376.14 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 79000/1801350 [00:17<06:41, 4294.32 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 79000/1801350 [00:17<06:38, 4318.28 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 80000/1801350 [00:17<06:43, 4265.27 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 86000/1801350 [00:18<06:21, 4495.26 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 80000/1801350 [00:18<06:51, 4178.89 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 80000/1801350 [00:18<06:54, 4157.70 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 81000/1801350 [00:18<06:31, 4394.78 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 87000/1801350 [00:18<06:27, 4421.32 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 81000/1801350 [00:18<06:37, 4328.30 examples/s]Grouping texts in chunks of 1024:   4%|▍         | 81000/1801350 [00:18<06:42, 4272.53 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 82000/1801350 [00:18<06:34, 4362.72 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 88000/1801350 [00:19<06:24, 4459.45 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 82000/1801350 [00:18<06:34, 4354.43 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 82000/1801350 [00:18<06:41, 4282.89 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 83000/1801350 [00:18<06:27, 4430.45 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 89000/1801350 [00:19<06:43, 4239.38 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 83000/1801350 [00:18<06:32, 4379.61 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 83000/1801350 [00:18<06:24, 4469.68 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 84000/1801350 [00:18<06:16, 4564.24 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 90000/1801350 [00:19<06:44, 4235.65 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 84000/1801350 [00:18<06:10, 4634.23 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 84000/1801350 [00:19<06:22, 4486.26 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 85000/1801350 [00:19<06:28, 4423.26 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 91000/1801350 [00:19<06:49, 4174.65 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 85000/1801350 [00:19<06:30, 4392.64 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 85000/1801350 [00:19<06:33, 4358.66 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 86000/1801350 [00:19<06:22, 4482.25 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 92000/1801350 [00:19<06:33, 4338.83 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 86000/1801350 [00:19<06:19, 4522.19 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 86000/1801350 [00:19<06:18, 4528.89 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 87000/1801350 [00:19<06:15, 4569.29 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 93000/1801350 [00:20<06:29, 4384.20 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 87000/1801350 [00:19<06:18, 4534.94 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 88000/1801350 [00:19<06:05, 4684.74 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 87000/1801350 [00:19<06:19, 4517.09 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 88000/1801350 [00:19<06:06, 4668.58 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 94000/1801350 [00:20<06:38, 4282.47 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 88000/1801350 [00:19<06:15, 4564.36 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 89000/1801350 [00:19<06:30, 4383.30 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 95000/1801350 [00:20<06:23, 4450.64 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 89000/1801350 [00:20<06:31, 4373.80 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 89000/1801350 [00:20<06:31, 4368.36 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 90000/1801350 [00:20<06:38, 4292.58 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 96000/1801350 [00:20<06:33, 4338.73 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 90000/1801350 [00:20<06:37, 4307.73 examples/s]Grouping texts in chunks of 1024:   5%|▍         | 90000/1801350 [00:20<06:40, 4270.79 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 91000/1801350 [00:20<06:39, 4282.19 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 97000/1801350 [00:21<06:04, 4679.92 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 91000/1801350 [00:20<06:47, 4200.69 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 92000/1801350 [00:20<06:28, 4397.48 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 91000/1801350 [00:20<06:46, 4207.86 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 98000/1801350 [00:21<06:05, 4660.91 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 92000/1801350 [00:20<06:40, 4266.01 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 93000/1801350 [00:20<06:24, 4438.97 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 92000/1801350 [00:20<06:38, 4292.48 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 99000/1801350 [00:21<06:24, 4427.91 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 93000/1801350 [00:21<06:21, 4474.21 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 93000/1801350 [00:21<06:24, 4445.60 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 94000/1801350 [00:21<06:42, 4244.98 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 100000/1801350 [00:21<06:34, 4314.50 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 94000/1801350 [00:21<06:41, 4249.14 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 95000/1801350 [00:21<06:13, 4562.61 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 94000/1801350 [00:21<06:42, 4240.90 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 101000/1801350 [00:22<06:45, 4193.36 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 95000/1801350 [00:21<06:19, 4500.04 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 95000/1801350 [00:21<06:22, 4463.10 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 96000/1801350 [00:21<06:28, 4387.56 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 102000/1801350 [00:22<06:26, 4394.40 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 96000/1801350 [00:21<06:27, 4402.81 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 97000/1801350 [00:21<06:02, 4695.66 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 96000/1801350 [00:21<06:25, 4422.81 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 97000/1801350 [00:21<05:56, 4774.57 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 103000/1801350 [00:22<06:30, 4351.02 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 97000/1801350 [00:21<05:58, 4751.32 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 98000/1801350 [00:21<06:08, 4623.45 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 98000/1801350 [00:22<06:05, 4663.45 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 104000/1801350 [00:22<06:39, 4249.37 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 98000/1801350 [00:22<06:13, 4558.34 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 99000/1801350 [00:22<06:17, 4506.48 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 99000/1801350 [00:22<06:16, 4526.34 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 105000/1801350 [00:22<06:32, 4323.60 examples/s]Grouping texts in chunks of 1024:   5%|▌         | 99000/1801350 [00:22<06:16, 4522.53 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 100000/1801350 [00:22<06:32, 4340.16 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 106000/1801350 [00:23<06:26, 4381.23 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 100000/1801350 [00:22<06:36, 4287.98 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 100000/1801350 [00:22<06:32, 4329.71 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 101000/1801350 [00:22<06:29, 4361.71 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 101000/1801350 [00:22<06:30, 4351.11 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 107000/1801350 [00:23<06:35, 4284.36 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 102000/1801350 [00:22<06:26, 4392.45 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 101000/1801350 [00:22<06:41, 4230.82 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 102000/1801350 [00:23<06:28, 4368.59 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 108000/1801350 [00:23<06:37, 4259.20 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 102000/1801350 [00:23<06:23, 4430.13 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 103000/1801350 [00:23<06:28, 4369.03 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 103000/1801350 [00:23<06:24, 4419.07 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 109000/1801350 [00:23<06:49, 4136.50 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 104000/1801350 [00:23<06:34, 4306.48 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 103000/1801350 [00:23<06:37, 4271.75 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 104000/1801350 [00:23<06:36, 4282.62 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 110000/1801350 [00:24<06:45, 4168.33 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 105000/1801350 [00:23<06:27, 4373.28 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 104000/1801350 [00:23<06:34, 4306.62 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 105000/1801350 [00:23<06:29, 4352.67 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 111000/1801350 [00:24<06:26, 4377.78 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 106000/1801350 [00:23<06:27, 4376.39 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 105000/1801350 [00:23<06:32, 4323.09 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 106000/1801350 [00:24<06:34, 4299.56 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 112000/1801350 [00:24<06:22, 4412.93 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 107000/1801350 [00:24<06:33, 4304.80 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 106000/1801350 [00:24<06:32, 4320.17 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 107000/1801350 [00:24<06:37, 4264.36 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 113000/1801350 [00:24<06:26, 4369.88 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 108000/1801350 [00:24<06:28, 4363.84 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 107000/1801350 [00:24<06:36, 4271.84 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 108000/1801350 [00:24<06:28, 4360.08 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 114000/1801350 [00:25<06:36, 4253.43 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 108000/1801350 [00:24<06:33, 4307.78 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 109000/1801350 [00:24<06:41, 4215.41 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 115000/1801350 [00:25<06:27, 4349.54 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 109000/1801350 [00:24<06:47, 4154.45 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 110000/1801350 [00:24<06:41, 4212.31 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 109000/1801350 [00:24<06:47, 4152.50 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 110000/1801350 [00:24<06:38, 4243.62 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 111000/1801350 [00:24<06:21, 4428.34 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 110000/1801350 [00:25<06:42, 4197.70 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 111000/1801350 [00:25<06:16, 4490.47 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 112000/1801350 [00:25<06:17, 4471.78 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 111000/1801350 [00:25<06:24, 4398.70 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 116000/1801350 [00:25<10:08, 2767.75 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 112000/1801350 [00:25<06:31, 4312.58 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 113000/1801350 [00:25<06:17, 4474.58 examples/s]Grouping texts in chunks of 1024:   6%|▌         | 112000/1801350 [00:25<06:28, 4353.49 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 113000/1801350 [00:25<06:15, 4496.06 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 117000/1801350 [00:26<09:10, 3057.00 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 114000/1801350 [00:25<06:24, 4383.89 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 113000/1801350 [00:25<06:16, 4485.13 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 114000/1801350 [00:25<06:35, 4269.79 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 118000/1801350 [00:26<08:27, 3317.20 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 115000/1801350 [00:25<06:19, 4447.19 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 114000/1801350 [00:25<06:35, 4266.67 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 119000/1801350 [00:26<07:42, 3639.62 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 115000/1801350 [00:26<06:34, 4274.23 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 116000/1801350 [00:26<06:41, 4196.06 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 115000/1801350 [00:26<06:28, 4342.09 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 120000/1801350 [00:26<07:18, 3838.13 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 116000/1801350 [00:26<06:45, 4154.97 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 117000/1801350 [00:26<06:43, 4174.10 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 116000/1801350 [00:26<06:45, 4152.49 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 121000/1801350 [00:27<06:52, 4077.84 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 117000/1801350 [00:26<06:37, 4240.31 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 118000/1801350 [00:26<06:41, 4192.50 examples/s]Grouping texts in chunks of 1024:   6%|▋         | 117000/1801350 [00:26<06:35, 4262.46 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 122000/1801350 [00:27<07:04, 3959.83 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 118000/1801350 [00:26<06:44, 4165.31 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 119000/1801350 [00:26<06:23, 4389.89 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 118000/1801350 [00:26<06:48, 4123.77 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 123000/1801350 [00:27<06:51, 4081.80 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 119000/1801350 [00:27<06:33, 4271.97 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 120000/1801350 [00:27<06:23, 4383.55 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 119000/1801350 [00:27<06:27, 4341.88 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 124000/1801350 [00:27<06:47, 4112.02 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 120000/1801350 [00:27<06:35, 4253.68 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 121000/1801350 [00:27<06:19, 4427.83 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 120000/1801350 [00:27<06:33, 4272.12 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 121000/1801350 [00:27<06:08, 4563.30 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 125000/1801350 [00:28<06:38, 4201.80 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 122000/1801350 [00:27<06:27, 4330.96 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 121000/1801350 [00:27<06:21, 4403.50 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 126000/1801350 [00:28<06:28, 4314.78 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 122000/1801350 [00:27<06:32, 4282.52 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 123000/1801350 [00:27<06:18, 4432.56 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 122000/1801350 [00:27<06:34, 4259.11 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 127000/1801350 [00:28<06:19, 4412.46 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 123000/1801350 [00:27<06:28, 4320.14 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 124000/1801350 [00:28<06:35, 4243.56 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 123000/1801350 [00:28<06:28, 4322.12 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 128000/1801350 [00:28<06:22, 4376.90 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 124000/1801350 [00:28<06:26, 4340.37 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 125000/1801350 [00:28<06:25, 4352.75 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 124000/1801350 [00:28<06:32, 4275.53 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 129000/1801350 [00:28<06:30, 4284.25 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 125000/1801350 [00:28<06:23, 4370.41 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 126000/1801350 [00:28<06:22, 4376.89 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 125000/1801350 [00:28<06:27, 4325.64 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 127000/1801350 [00:28<05:59, 4651.62 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 130000/1801350 [00:29<06:31, 4269.83 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 126000/1801350 [00:28<06:25, 4342.67 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 126000/1801350 [00:28<06:22, 4380.37 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 127000/1801350 [00:28<06:10, 4522.99 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 131000/1801350 [00:29<06:27, 4310.26 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 128000/1801350 [00:28<06:11, 4499.66 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 127000/1801350 [00:28<06:10, 4513.25 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 128000/1801350 [00:29<06:19, 4409.40 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 129000/1801350 [00:29<06:17, 4430.86 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 132000/1801350 [00:29<06:56, 4006.95 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 128000/1801350 [00:29<06:18, 4422.34 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 129000/1801350 [00:29<06:20, 4390.77 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 130000/1801350 [00:29<06:26, 4324.20 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 133000/1801350 [00:29<06:35, 4219.92 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 129000/1801350 [00:29<06:29, 4288.37 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 134000/1801350 [00:30<06:18, 4401.65 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 130000/1801350 [00:29<06:32, 4262.02 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 131000/1801350 [00:29<06:27, 4307.79 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 130000/1801350 [00:29<06:29, 4292.06 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 135000/1801350 [00:30<06:05, 4556.15 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 131000/1801350 [00:29<06:27, 4309.52 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 132000/1801350 [00:29<06:55, 4019.80 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 131000/1801350 [00:29<06:25, 4331.20 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 136000/1801350 [00:30<06:05, 4557.11 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 133000/1801350 [00:30<06:28, 4291.64 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 132000/1801350 [00:30<06:55, 4013.01 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 137000/1801350 [00:30<05:43, 4839.05 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 132000/1801350 [00:30<06:52, 4044.34 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 133000/1801350 [00:30<06:24, 4338.21 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 134000/1801350 [00:30<06:18, 4402.32 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 133000/1801350 [00:30<06:29, 4282.26 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 138000/1801350 [00:30<06:00, 4608.46 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 134000/1801350 [00:30<06:14, 4449.22 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 135000/1801350 [00:30<06:07, 4538.68 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 134000/1801350 [00:30<06:24, 4338.61 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 139000/1801350 [00:31<05:57, 4648.65 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 135000/1801350 [00:30<05:59, 4631.07 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 136000/1801350 [00:30<06:01, 4609.23 examples/s]Grouping texts in chunks of 1024:   7%|▋         | 135000/1801350 [00:30<06:05, 4555.29 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 137000/1801350 [00:30<05:37, 4934.35 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 140000/1801350 [00:31<06:15, 4423.43 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 136000/1801350 [00:30<06:02, 4596.94 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 136000/1801350 [00:30<06:03, 4583.41 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 137000/1801350 [00:31<05:43, 4846.24 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 141000/1801350 [00:31<06:10, 4487.25 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 138000/1801350 [00:31<06:02, 4593.51 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 137000/1801350 [00:31<05:43, 4845.19 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 138000/1801350 [00:31<05:57, 4649.44 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 139000/1801350 [00:31<05:54, 4686.21 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 142000/1801350 [00:31<06:22, 4341.63 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 138000/1801350 [00:31<05:56, 4668.43 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 139000/1801350 [00:31<05:53, 4696.32 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 140000/1801350 [00:31<06:04, 4556.55 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 143000/1801350 [00:32<06:26, 4290.61 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 139000/1801350 [00:31<05:58, 4637.10 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 140000/1801350 [00:31<06:03, 4576.68 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 144000/1801350 [00:32<06:07, 4513.56 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 141000/1801350 [00:31<06:03, 4568.27 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 140000/1801350 [00:31<06:04, 4558.34 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 145000/1801350 [00:32<05:58, 4623.75 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 141000/1801350 [00:31<06:07, 4523.09 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 142000/1801350 [00:32<06:16, 4401.91 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 141000/1801350 [00:32<06:11, 4466.02 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 146000/1801350 [00:32<06:01, 4577.47 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 142000/1801350 [00:32<06:23, 4331.69 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 143000/1801350 [00:32<06:22, 4337.87 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 142000/1801350 [00:32<06:18, 4387.18 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 144000/1801350 [00:32<06:01, 4582.71 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 147000/1801350 [00:33<06:20, 4347.42 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 143000/1801350 [00:32<06:33, 4215.60 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 143000/1801350 [00:32<06:24, 4312.12 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 145000/1801350 [00:32<05:54, 4670.53 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 144000/1801350 [00:32<06:06, 4518.04 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 148000/1801350 [00:33<06:33, 4203.33 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 144000/1801350 [00:32<06:10, 4474.12 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 145000/1801350 [00:32<05:52, 4698.09 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 146000/1801350 [00:32<06:00, 4594.27 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 149000/1801350 [00:33<06:25, 4281.57 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 145000/1801350 [00:32<06:02, 4571.44 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 146000/1801350 [00:33<06:00, 4590.59 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 147000/1801350 [00:33<06:09, 4481.91 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 150000/1801350 [00:33<06:23, 4307.87 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 146000/1801350 [00:33<05:57, 4631.61 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 147000/1801350 [00:33<06:06, 4514.85 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 148000/1801350 [00:33<06:21, 4332.18 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 151000/1801350 [00:33<06:36, 4165.99 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 147000/1801350 [00:33<06:15, 4406.46 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 149000/1801350 [00:33<06:11, 4444.23 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 148000/1801350 [00:33<06:23, 4306.79 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 152000/1801350 [00:34<06:32, 4201.76 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 148000/1801350 [00:33<06:26, 4278.59 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 150000/1801350 [00:33<06:16, 4383.94 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 149000/1801350 [00:33<06:22, 4323.19 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 153000/1801350 [00:34<06:24, 4282.68 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 149000/1801350 [00:33<06:20, 4338.00 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 150000/1801350 [00:34<06:20, 4336.54 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 151000/1801350 [00:34<06:24, 4293.47 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 154000/1801350 [00:34<06:28, 4242.11 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 150000/1801350 [00:34<06:25, 4283.50 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 152000/1801350 [00:34<06:25, 4278.16 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 151000/1801350 [00:34<06:30, 4221.68 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 155000/1801350 [00:34<06:16, 4374.99 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 151000/1801350 [00:34<06:29, 4236.10 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 153000/1801350 [00:34<06:14, 4397.76 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 152000/1801350 [00:34<06:21, 4324.28 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 156000/1801350 [00:35<06:20, 4320.80 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 152000/1801350 [00:34<06:33, 4189.90 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 153000/1801350 [00:34<06:26, 4268.81 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 157000/1801350 [00:35<06:09, 4446.51 examples/s]Grouping texts in chunks of 1024:   8%|▊         | 153000/1801350 [00:34<06:21, 4319.66 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 158000/1801350 [00:35<06:01, 4551.69 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 154000/1801350 [00:35<09:49, 2794.36 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 159000/1801350 [00:35<06:03, 4513.54 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 154000/1801350 [00:35<09:55, 2767.32 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 155000/1801350 [00:35<08:54, 3080.30 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 160000/1801350 [00:35<06:04, 4507.39 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 154000/1801350 [00:35<09:27, 2901.64 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 156000/1801350 [00:35<07:56, 3452.90 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 155000/1801350 [00:35<08:55, 3072.94 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 161000/1801350 [00:36<06:07, 4458.63 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 155000/1801350 [00:35<08:25, 3254.43 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 157000/1801350 [00:35<07:22, 3715.90 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 156000/1801350 [00:35<08:05, 3389.19 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 162000/1801350 [00:36<06:08, 4443.32 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 156000/1801350 [00:35<07:42, 3559.93 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 158000/1801350 [00:36<06:51, 3994.54 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 157000/1801350 [00:36<07:13, 3793.54 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 163000/1801350 [00:36<06:10, 4424.59 examples/s]Grouping texts in chunks of 1024:   9%|▊         | 157000/1801350 [00:36<07:05, 3861.72 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 159000/1801350 [00:36<06:36, 4143.64 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 158000/1801350 [00:36<06:47, 4036.45 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 158000/1801350 [00:36<06:44, 4059.88 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 164000/1801350 [00:36<06:24, 4255.47 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 160000/1801350 [00:36<06:28, 4224.64 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 159000/1801350 [00:36<06:42, 4085.04 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 159000/1801350 [00:36<06:40, 4105.59 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 165000/1801350 [00:37<06:12, 4387.34 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 161000/1801350 [00:36<06:12, 4398.77 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 160000/1801350 [00:36<06:23, 4280.24 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 160000/1801350 [00:36<06:20, 4309.14 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 166000/1801350 [00:37<06:09, 4427.89 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 162000/1801350 [00:36<06:23, 4277.90 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 161000/1801350 [00:36<06:26, 4243.74 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 161000/1801350 [00:36<06:17, 4347.72 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 167000/1801350 [00:37<06:03, 4500.84 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 163000/1801350 [00:37<06:15, 4360.23 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 162000/1801350 [00:37<06:17, 4339.57 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 162000/1801350 [00:37<06:23, 4272.19 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 168000/1801350 [00:37<06:17, 4328.92 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 164000/1801350 [00:37<06:18, 4327.10 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 163000/1801350 [00:37<06:21, 4292.93 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 163000/1801350 [00:37<06:13, 4384.77 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 169000/1801350 [00:38<06:14, 4354.62 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 165000/1801350 [00:37<06:12, 4389.26 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 164000/1801350 [00:37<06:25, 4245.43 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 164000/1801350 [00:37<06:22, 4283.55 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 170000/1801350 [00:38<06:16, 4333.48 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 166000/1801350 [00:37<06:06, 4465.28 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 165000/1801350 [00:37<06:07, 4446.71 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 165000/1801350 [00:37<06:12, 4387.63 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 171000/1801350 [00:38<06:31, 4160.60 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 167000/1801350 [00:38<05:52, 4631.42 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 166000/1801350 [00:38<06:04, 4485.97 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 166000/1801350 [00:38<06:01, 4519.53 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 172000/1801350 [00:38<06:25, 4223.45 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 167000/1801350 [00:38<05:47, 4706.84 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 168000/1801350 [00:38<06:08, 4427.69 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 167000/1801350 [00:38<05:51, 4650.47 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 173000/1801350 [00:39<06:17, 4314.32 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 169000/1801350 [00:38<06:04, 4479.61 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 168000/1801350 [00:38<06:11, 4398.28 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 168000/1801350 [00:38<06:15, 4352.87 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 174000/1801350 [00:39<06:22, 4257.56 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 169000/1801350 [00:38<05:59, 4538.70 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 170000/1801350 [00:38<06:11, 4394.36 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 169000/1801350 [00:38<06:05, 4463.65 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 175000/1801350 [00:39<06:09, 4399.75 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 171000/1801350 [00:38<06:19, 4299.59 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 170000/1801350 [00:39<06:18, 4305.76 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 170000/1801350 [00:39<06:28, 4203.55 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 176000/1801350 [00:39<06:23, 4238.10 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 172000/1801350 [00:39<06:18, 4303.19 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 171000/1801350 [00:39<06:29, 4183.21 examples/s]Grouping texts in chunks of 1024:   9%|▉         | 171000/1801350 [00:39<06:31, 4169.57 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 177000/1801350 [00:39<06:22, 4248.93 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 173000/1801350 [00:39<06:19, 4292.38 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 172000/1801350 [00:39<06:17, 4316.38 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 172000/1801350 [00:39<06:16, 4332.84 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 174000/1801350 [00:39<06:11, 4378.70 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 178000/1801350 [00:40<06:47, 3983.92 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 173000/1801350 [00:39<06:14, 4352.49 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 173000/1801350 [00:39<06:16, 4330.42 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 179000/1801350 [00:40<06:26, 4195.99 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 175000/1801350 [00:39<06:08, 4407.47 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 174000/1801350 [00:39<06:10, 4388.52 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 174000/1801350 [00:39<06:19, 4290.16 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 176000/1801350 [00:40<06:10, 4385.37 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 180000/1801350 [00:40<06:33, 4117.69 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 175000/1801350 [00:40<06:08, 4411.21 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 175000/1801350 [00:40<06:10, 4389.98 examples/s]Grouping texts in chunks of 1024:  10%|█         | 181000/1801350 [00:40<06:32, 4127.52 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 176000/1801350 [00:40<06:17, 4310.25 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 177000/1801350 [00:40<06:17, 4305.78 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 176000/1801350 [00:40<06:22, 4245.81 examples/s]Grouping texts in chunks of 1024:  10%|█         | 182000/1801350 [00:41<06:29, 4152.20 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 177000/1801350 [00:40<06:25, 4211.55 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 178000/1801350 [00:40<06:42, 4035.95 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 177000/1801350 [00:40<06:22, 4244.68 examples/s]Grouping texts in chunks of 1024:  10%|█         | 183000/1801350 [00:41<06:20, 4253.50 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 179000/1801350 [00:40<06:26, 4199.87 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 178000/1801350 [00:40<06:37, 4079.74 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 178000/1801350 [00:40<06:42, 4036.03 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 180000/1801350 [00:41<06:30, 4149.08 examples/s]Grouping texts in chunks of 1024:  10%|█         | 184000/1801350 [00:41<06:44, 4002.56 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 179000/1801350 [00:41<06:32, 4128.19 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 179000/1801350 [00:41<06:20, 4260.47 examples/s]Grouping texts in chunks of 1024:  10%|█         | 181000/1801350 [00:41<06:27, 4177.46 examples/s]Grouping texts in chunks of 1024:  10%|█         | 185000/1801350 [00:41<06:36, 4078.52 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 180000/1801350 [00:41<06:30, 4154.22 examples/s]Grouping texts in chunks of 1024:  10%|▉         | 180000/1801350 [00:41<06:26, 4199.04 examples/s]Grouping texts in chunks of 1024:  10%|█         | 182000/1801350 [00:41<06:27, 4182.41 examples/s]Grouping texts in chunks of 1024:  10%|█         | 181000/1801350 [00:41<06:26, 4193.07 examples/s]Grouping texts in chunks of 1024:  10%|█         | 186000/1801350 [00:42<06:42, 4010.84 examples/s]Grouping texts in chunks of 1024:  10%|█         | 181000/1801350 [00:41<06:26, 4196.00 examples/s]Grouping texts in chunks of 1024:  10%|█         | 183000/1801350 [00:41<06:17, 4284.84 examples/s]Grouping texts in chunks of 1024:  10%|█         | 182000/1801350 [00:41<06:25, 4197.81 examples/s]Grouping texts in chunks of 1024:  10%|█         | 187000/1801350 [00:42<06:36, 4071.45 examples/s]Grouping texts in chunks of 1024:  10%|█         | 182000/1801350 [00:41<06:31, 4132.44 examples/s]Grouping texts in chunks of 1024:  10%|█         | 183000/1801350 [00:42<06:16, 4293.48 examples/s]Grouping texts in chunks of 1024:  10%|█         | 184000/1801350 [00:42<06:32, 4121.51 examples/s]Grouping texts in chunks of 1024:  10%|█         | 188000/1801350 [00:42<06:39, 4033.53 examples/s]Grouping texts in chunks of 1024:  10%|█         | 183000/1801350 [00:42<06:24, 4211.44 examples/s]Grouping texts in chunks of 1024:  10%|█         | 185000/1801350 [00:42<06:22, 4223.19 examples/s]Grouping texts in chunks of 1024:  10%|█         | 189000/1801350 [00:42<06:17, 4268.54 examples/s]Grouping texts in chunks of 1024:  10%|█         | 184000/1801350 [00:42<06:35, 4088.21 examples/s]Grouping texts in chunks of 1024:  10%|█         | 184000/1801350 [00:42<06:41, 4028.00 examples/s]Grouping texts in chunks of 1024:  11%|█         | 190000/1801350 [00:43<06:16, 4285.49 examples/s]Grouping texts in chunks of 1024:  10%|█         | 185000/1801350 [00:42<06:21, 4233.81 examples/s]Grouping texts in chunks of 1024:  10%|█         | 186000/1801350 [00:42<06:37, 4067.54 examples/s]Grouping texts in chunks of 1024:  10%|█         | 185000/1801350 [00:42<06:31, 4129.79 examples/s]Grouping texts in chunks of 1024:  11%|█         | 191000/1801350 [00:43<06:12, 4318.19 examples/s]Grouping texts in chunks of 1024:  10%|█         | 187000/1801350 [00:42<06:27, 4169.97 examples/s]Grouping texts in chunks of 1024:  10%|█         | 186000/1801350 [00:42<06:40, 4031.76 examples/s]Grouping texts in chunks of 1024:  10%|█         | 186000/1801350 [00:42<06:38, 4049.09 examples/s]Grouping texts in chunks of 1024:  11%|█         | 192000/1801350 [00:43<06:17, 4262.97 examples/s]Grouping texts in chunks of 1024:  10%|█         | 188000/1801350 [00:43<06:31, 4123.37 examples/s]Grouping texts in chunks of 1024:  10%|█         | 187000/1801350 [00:43<06:30, 4134.48 examples/s]Grouping texts in chunks of 1024:  10%|█         | 187000/1801350 [00:43<06:31, 4124.48 examples/s]Grouping texts in chunks of 1024:  11%|█         | 193000/1801350 [00:43<06:14, 4295.38 examples/s]Grouping texts in chunks of 1024:  10%|█         | 189000/1801350 [00:43<06:13, 4317.58 examples/s]Grouping texts in chunks of 1024:  10%|█         | 188000/1801350 [00:43<06:32, 4115.35 examples/s]Grouping texts in chunks of 1024:  10%|█         | 188000/1801350 [00:43<06:36, 4067.53 examples/s]Grouping texts in chunks of 1024:  11%|█         | 194000/1801350 [00:44<06:07, 4372.01 examples/s]Grouping texts in chunks of 1024:  11%|█         | 190000/1801350 [00:43<06:09, 4363.07 examples/s]Grouping texts in chunks of 1024:  10%|█         | 189000/1801350 [00:43<06:13, 4316.79 examples/s]Grouping texts in chunks of 1024:  10%|█         | 189000/1801350 [00:43<06:21, 4229.24 examples/s]Grouping texts in chunks of 1024:  11%|█         | 191000/1801350 [00:43<06:00, 4472.81 examples/s]Grouping texts in chunks of 1024:  11%|█         | 195000/1801350 [00:44<06:06, 4386.75 examples/s]Grouping texts in chunks of 1024:  11%|█         | 190000/1801350 [00:43<06:14, 4298.94 examples/s]Grouping texts in chunks of 1024:  11%|█         | 190000/1801350 [00:43<06:15, 4291.53 examples/s]Grouping texts in chunks of 1024:  11%|█         | 196000/1801350 [00:44<06:00, 4456.72 examples/s]Grouping texts in chunks of 1024:  11%|█         | 192000/1801350 [00:43<06:11, 4336.99 examples/s]Grouping texts in chunks of 1024:  11%|█         | 191000/1801350 [00:43<06:04, 4421.73 examples/s]Grouping texts in chunks of 1024:  11%|█         | 191000/1801350 [00:44<06:14, 4305.41 examples/s]Grouping texts in chunks of 1024:  11%|█         | 197000/1801350 [00:44<05:56, 4503.98 examples/s]Grouping texts in chunks of 1024:  11%|█         | 193000/1801350 [00:44<06:12, 4322.34 examples/s]Grouping texts in chunks of 1024:  11%|█         | 192000/1801350 [00:44<06:12, 4324.87 examples/s]Grouping texts in chunks of 1024:  11%|█         | 192000/1801350 [00:44<06:12, 4320.55 examples/s]Grouping texts in chunks of 1024:  11%|█         | 198000/1801350 [00:44<05:46, 4625.18 examples/s]Grouping texts in chunks of 1024:  11%|█         | 194000/1801350 [00:44<05:58, 4488.46 examples/s]Grouping texts in chunks of 1024:  11%|█         | 193000/1801350 [00:44<06:11, 4327.89 examples/s]Grouping texts in chunks of 1024:  11%|█         | 193000/1801350 [00:44<06:08, 4361.62 examples/s]Grouping texts in chunks of 1024:  11%|█         | 199000/1801350 [00:45<05:54, 4523.16 examples/s]Grouping texts in chunks of 1024:  11%|█         | 195000/1801350 [00:44<06:06, 4385.69 examples/s]Grouping texts in chunks of 1024:  11%|█         | 194000/1801350 [00:44<06:01, 4452.24 examples/s]Grouping texts in chunks of 1024:  11%|█         | 194000/1801350 [00:44<06:06, 4387.72 examples/s]Grouping texts in chunks of 1024:  11%|█         | 200000/1801350 [00:45<06:04, 4388.56 examples/s]Grouping texts in chunks of 1024:  11%|█         | 196000/1801350 [00:44<06:00, 4448.75 examples/s]Grouping texts in chunks of 1024:  11%|█         | 195000/1801350 [00:44<06:03, 4414.67 examples/s]Grouping texts in chunks of 1024:  11%|█         | 195000/1801350 [00:44<06:13, 4296.36 examples/s]Grouping texts in chunks of 1024:  11%|█         | 197000/1801350 [00:45<05:51, 4569.82 examples/s]Grouping texts in chunks of 1024:  11%|█         | 201000/1801350 [00:45<06:11, 4309.23 examples/s]Grouping texts in chunks of 1024:  11%|█         | 196000/1801350 [00:45<06:00, 4450.90 examples/s]Grouping texts in chunks of 1024:  11%|█         | 196000/1801350 [00:45<05:57, 4487.21 examples/s]Grouping texts in chunks of 1024:  11%|█         | 198000/1801350 [00:45<05:38, 4735.60 examples/s]Grouping texts in chunks of 1024:  11%|█         | 202000/1801350 [00:45<06:14, 4268.55 examples/s]Grouping texts in chunks of 1024:  11%|█         | 197000/1801350 [00:45<05:54, 4530.11 examples/s]Grouping texts in chunks of 1024:  11%|█         | 197000/1801350 [00:45<05:53, 4540.46 examples/s]Grouping texts in chunks of 1024:  11%|█         | 199000/1801350 [00:45<05:55, 4507.43 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 203000/1801350 [00:46<06:01, 4416.86 examples/s]Grouping texts in chunks of 1024:  11%|█         | 198000/1801350 [00:45<05:40, 4707.21 examples/s]Grouping texts in chunks of 1024:  11%|█         | 198000/1801350 [00:45<05:40, 4709.05 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 204000/1801350 [00:46<05:57, 4464.16 examples/s]Grouping texts in chunks of 1024:  11%|█         | 200000/1801350 [00:45<06:45, 3949.76 examples/s]Grouping texts in chunks of 1024:  11%|█         | 199000/1801350 [00:45<05:45, 4639.82 examples/s]Grouping texts in chunks of 1024:  11%|█         | 199000/1801350 [00:45<06:50, 3901.11 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 205000/1801350 [00:46<05:39, 4696.69 examples/s]Grouping texts in chunks of 1024:  11%|█         | 201000/1801350 [00:45<06:22, 4178.61 examples/s]Grouping texts in chunks of 1024:  11%|█         | 200000/1801350 [00:46<05:47, 4613.36 examples/s]Grouping texts in chunks of 1024:  11%|█         | 200000/1801350 [00:46<06:22, 4183.64 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 206000/1801350 [00:46<05:58, 4445.31 examples/s]Grouping texts in chunks of 1024:  11%|█         | 202000/1801350 [00:46<06:31, 4085.61 examples/s]Grouping texts in chunks of 1024:  11%|█         | 201000/1801350 [00:46<05:50, 4565.97 examples/s]Grouping texts in chunks of 1024:  11%|█         | 201000/1801350 [00:46<06:16, 4254.75 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 207000/1801350 [00:46<06:00, 4425.39 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 203000/1801350 [00:46<06:10, 4314.50 examples/s]Grouping texts in chunks of 1024:  11%|█         | 202000/1801350 [00:46<06:04, 4392.16 examples/s]Grouping texts in chunks of 1024:  11%|█         | 202000/1801350 [00:46<06:19, 4210.35 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 208000/1801350 [00:47<06:04, 4365.41 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 204000/1801350 [00:46<05:56, 4482.95 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 203000/1801350 [00:46<06:11, 4298.14 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 203000/1801350 [00:46<05:57, 4470.86 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 209000/1801350 [00:47<06:30, 4075.04 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 205000/1801350 [00:46<06:09, 4321.37 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 204000/1801350 [00:46<05:45, 4618.22 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 204000/1801350 [00:46<05:53, 4522.25 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 210000/1801350 [00:47<06:12, 4269.24 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 206000/1801350 [00:47<06:14, 4263.02 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 205000/1801350 [00:47<06:09, 4316.37 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 205000/1801350 [00:47<06:15, 4250.17 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 211000/1801350 [00:47<06:10, 4294.38 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 207000/1801350 [00:47<06:10, 4301.26 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 206000/1801350 [00:47<06:11, 4296.74 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 206000/1801350 [00:47<06:15, 4245.55 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 212000/1801350 [00:48<06:10, 4294.30 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 208000/1801350 [00:47<06:13, 4267.34 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 207000/1801350 [00:47<06:07, 4334.62 examples/s]Grouping texts in chunks of 1024:  11%|█▏        | 207000/1801350 [00:47<06:10, 4307.51 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 213000/1801350 [00:48<05:50, 4537.01 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 209000/1801350 [00:47<06:28, 4102.75 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 208000/1801350 [00:47<06:16, 4234.56 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 208000/1801350 [00:47<06:18, 4205.44 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 214000/1801350 [00:48<06:16, 4211.44 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 210000/1801350 [00:48<06:05, 4350.68 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 209000/1801350 [00:48<06:26, 4118.45 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 209000/1801350 [00:48<06:32, 4061.82 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 215000/1801350 [00:48<06:17, 4204.48 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 211000/1801350 [00:48<06:02, 4381.76 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 210000/1801350 [00:48<06:07, 4329.15 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 210000/1801350 [00:48<06:14, 4253.34 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 216000/1801350 [00:49<06:17, 4199.60 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 212000/1801350 [00:48<06:08, 4316.89 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 211000/1801350 [00:48<05:59, 4427.62 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 211000/1801350 [00:48<06:03, 4370.69 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 213000/1801350 [00:48<05:52, 4501.58 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 217000/1801350 [00:49<06:21, 4153.12 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 212000/1801350 [00:48<06:09, 4301.83 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 212000/1801350 [00:48<06:11, 4276.85 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 218000/1801350 [00:49<06:12, 4249.24 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 214000/1801350 [00:48<06:07, 4318.41 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 213000/1801350 [00:49<05:48, 4553.35 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 213000/1801350 [00:49<05:53, 4493.79 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 219000/1801350 [00:49<06:07, 4301.67 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 215000/1801350 [00:49<06:23, 4133.46 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 214000/1801350 [00:49<06:14, 4235.52 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 214000/1801350 [00:49<06:16, 4210.66 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 220000/1801350 [00:49<06:04, 4336.53 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 216000/1801350 [00:49<06:16, 4213.28 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 215000/1801350 [00:49<06:11, 4273.35 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 215000/1801350 [00:49<06:22, 4150.57 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 221000/1801350 [00:50<06:11, 4249.90 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 217000/1801350 [00:49<06:23, 4134.47 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 216000/1801350 [00:49<06:17, 4196.75 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 216000/1801350 [00:49<06:24, 4127.39 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 222000/1801350 [00:50<06:18, 4171.02 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 218000/1801350 [00:49<06:12, 4252.08 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 217000/1801350 [00:50<06:17, 4195.53 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 217000/1801350 [00:50<06:24, 4120.97 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 219000/1801350 [00:50<05:56, 4436.52 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 223000/1801350 [00:50<06:22, 4125.78 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 218000/1801350 [00:50<06:06, 4322.02 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 218000/1801350 [00:50<06:09, 4285.48 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 220000/1801350 [00:50<06:01, 4372.10 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 224000/1801350 [00:50<06:24, 4102.32 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 219000/1801350 [00:50<06:04, 4346.53 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 219000/1801350 [00:50<06:01, 4374.20 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 225000/1801350 [00:51<06:04, 4319.76 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 221000/1801350 [00:50<06:00, 4378.29 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 220000/1801350 [00:50<06:02, 4366.95 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 220000/1801350 [00:50<06:01, 4374.22 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 226000/1801350 [00:51<05:51, 4485.45 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 222000/1801350 [00:50<06:12, 4234.42 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 221000/1801350 [00:50<06:02, 4354.57 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 221000/1801350 [00:50<06:12, 4242.97 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 227000/1801350 [00:51<05:54, 4437.69 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 223000/1801350 [00:51<06:16, 4196.54 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 222000/1801350 [00:51<06:07, 4297.97 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 222000/1801350 [00:51<06:22, 4128.10 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 228000/1801350 [00:51<06:03, 4326.10 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 224000/1801350 [00:51<06:23, 4113.32 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 223000/1801350 [00:51<06:20, 4151.50 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 223000/1801350 [00:51<06:24, 4107.07 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 229000/1801350 [00:52<06:14, 4195.87 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 225000/1801350 [00:51<06:01, 4361.18 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 224000/1801350 [00:51<06:17, 4175.23 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 224000/1801350 [00:51<06:19, 4158.47 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 226000/1801350 [00:51<05:40, 4620.41 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 230000/1801350 [00:52<06:30, 4028.23 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 225000/1801350 [00:51<06:03, 4335.09 examples/s]Grouping texts in chunks of 1024:  12%|█▏        | 225000/1801350 [00:51<06:09, 4264.74 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 227000/1801350 [00:52<05:55, 4432.74 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 231000/1801350 [00:52<06:17, 4164.04 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 226000/1801350 [00:52<05:42, 4595.62 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 226000/1801350 [00:52<05:48, 4526.20 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 228000/1801350 [00:52<05:52, 4464.64 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 232000/1801350 [00:52<06:19, 4132.77 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 227000/1801350 [00:52<05:54, 4440.16 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 227000/1801350 [00:52<05:52, 4463.86 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 229000/1801350 [00:52<06:04, 4310.64 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 233000/1801350 [00:53<06:07, 4267.18 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 228000/1801350 [00:52<06:04, 4320.75 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 228000/1801350 [00:52<05:57, 4396.71 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 234000/1801350 [00:53<05:52, 4440.75 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 230000/1801350 [00:52<06:29, 4038.98 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 229000/1801350 [00:52<06:08, 4262.54 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 229000/1801350 [00:52<06:06, 4286.50 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 235000/1801350 [00:53<05:52, 4441.68 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 231000/1801350 [00:52<06:06, 4284.50 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 230000/1801350 [00:53<06:19, 4143.04 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 230000/1801350 [00:53<06:28, 4048.37 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 236000/1801350 [00:53<05:39, 4613.35 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 232000/1801350 [00:53<06:13, 4200.17 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 231000/1801350 [00:53<06:10, 4235.32 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 231000/1801350 [00:53<06:07, 4273.10 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 237000/1801350 [00:53<06:01, 4331.82 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 233000/1801350 [00:53<06:00, 4347.21 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 232000/1801350 [00:53<06:10, 4233.14 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 232000/1801350 [00:53<06:12, 4207.47 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 234000/1801350 [00:53<05:44, 4543.08 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 238000/1801350 [00:54<06:12, 4199.22 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 233000/1801350 [00:53<05:59, 4362.88 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 233000/1801350 [00:53<06:03, 4318.40 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 235000/1801350 [00:53<05:36, 4656.72 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 239000/1801350 [00:54<05:54, 4412.77 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 234000/1801350 [00:53<05:45, 4537.44 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 234000/1801350 [00:53<05:52, 4446.11 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 236000/1801350 [00:54<05:37, 4632.70 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 240000/1801350 [00:54<05:55, 4386.19 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 235000/1801350 [00:54<05:47, 4511.05 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 235000/1801350 [00:54<05:44, 4548.59 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 241000/1801350 [00:54<05:33, 4680.21 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 237000/1801350 [00:54<05:53, 4419.73 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 236000/1801350 [00:54<05:39, 4617.18 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 236000/1801350 [00:54<05:46, 4516.95 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 242000/1801350 [00:55<05:33, 4675.08 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 238000/1801350 [00:54<06:08, 4247.83 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 237000/1801350 [00:54<05:57, 4371.76 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 237000/1801350 [00:54<05:57, 4371.22 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 243000/1801350 [00:55<05:49, 4460.82 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 239000/1801350 [00:54<05:47, 4498.66 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 238000/1801350 [00:54<06:11, 4203.71 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 238000/1801350 [00:54<06:05, 4275.57 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 244000/1801350 [00:55<05:53, 4403.19 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 240000/1801350 [00:54<05:53, 4411.87 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 239000/1801350 [00:55<05:46, 4505.65 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 239000/1801350 [00:55<05:45, 4517.77 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 241000/1801350 [00:55<05:33, 4678.90 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 245000/1801350 [00:55<05:46, 4495.34 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 240000/1801350 [00:55<05:49, 4464.52 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 240000/1801350 [00:55<06:04, 4288.29 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 246000/1801350 [00:55<05:36, 4628.22 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 242000/1801350 [00:55<05:33, 4674.37 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 241000/1801350 [00:55<05:38, 4609.56 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 241000/1801350 [00:55<05:42, 4555.85 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 247000/1801350 [00:56<05:22, 4813.33 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 243000/1801350 [00:55<05:37, 4618.90 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 242000/1801350 [00:55<05:36, 4639.84 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 242000/1801350 [00:55<05:27, 4766.43 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 248000/1801350 [00:56<05:44, 4515.14 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 244000/1801350 [00:55<05:44, 4522.79 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 243000/1801350 [00:55<05:43, 4541.23 examples/s]Grouping texts in chunks of 1024:  13%|█▎        | 243000/1801350 [00:55<05:51, 4438.90 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 249000/1801350 [00:56<05:35, 4627.01 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 245000/1801350 [00:56<05:44, 4519.89 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 244000/1801350 [00:56<05:42, 4552.76 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 244000/1801350 [00:56<05:43, 4531.81 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 250000/1801350 [00:56<05:30, 4698.39 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 246000/1801350 [00:56<05:38, 4594.61 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 245000/1801350 [00:56<05:46, 4485.57 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 245000/1801350 [00:56<05:52, 4415.66 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 247000/1801350 [00:56<05:19, 4870.36 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 251000/1801350 [00:57<05:38, 4578.33 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 246000/1801350 [00:56<05:37, 4611.84 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 246000/1801350 [00:56<05:43, 4525.87 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 252000/1801350 [00:57<05:35, 4612.06 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 248000/1801350 [00:56<05:35, 4635.83 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 247000/1801350 [00:56<05:19, 4872.10 examples/s]Grouping texts in chunks of 1024:  14%|█▎        | 247000/1801350 [00:56<05:20, 4844.25 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 249000/1801350 [00:56<05:31, 4683.43 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 253000/1801350 [00:57<05:44, 4497.04 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 248000/1801350 [00:57<05:36, 4622.91 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 248000/1801350 [00:57<05:40, 4565.04 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 250000/1801350 [00:57<05:28, 4718.98 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 254000/1801350 [00:57<05:42, 4511.84 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 249000/1801350 [00:57<05:31, 4679.69 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 249000/1801350 [00:57<05:40, 4565.37 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 251000/1801350 [00:57<05:28, 4721.95 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 255000/1801350 [00:57<05:43, 4508.05 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 250000/1801350 [00:57<05:27, 4743.15 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 250000/1801350 [00:57<05:30, 4693.51 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 252000/1801350 [00:57<05:32, 4661.61 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 256000/1801350 [00:58<05:44, 4479.99 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 251000/1801350 [00:57<05:35, 4624.04 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 251000/1801350 [00:57<05:29, 4699.22 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 253000/1801350 [00:57<05:46, 4467.07 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 257000/1801350 [00:58<05:42, 4511.56 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 252000/1801350 [00:57<05:37, 4592.35 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 252000/1801350 [00:57<05:42, 4526.95 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 254000/1801350 [00:57<05:38, 4567.91 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 258000/1801350 [00:58<05:33, 4622.62 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 253000/1801350 [00:58<05:38, 4580.38 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 253000/1801350 [00:58<05:46, 4462.88 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 255000/1801350 [00:58<05:39, 4552.14 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 259000/1801350 [00:58<06:03, 4247.62 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 254000/1801350 [00:58<05:35, 4616.23 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 254000/1801350 [00:58<05:41, 4530.68 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 256000/1801350 [00:58<05:36, 4593.58 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 255000/1801350 [00:58<05:39, 4560.44 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 260000/1801350 [00:59<06:07, 4192.08 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 255000/1801350 [00:58<05:45, 4469.93 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 257000/1801350 [00:58<05:28, 4706.74 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 261000/1801350 [00:59<05:36, 4577.74 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 256000/1801350 [00:58<05:30, 4673.68 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 256000/1801350 [00:58<05:32, 4650.62 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 258000/1801350 [00:58<05:32, 4636.28 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 262000/1801350 [00:59<05:47, 4431.58 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 257000/1801350 [00:58<05:41, 4521.48 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 257000/1801350 [00:59<05:40, 4537.09 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 259000/1801350 [00:59<06:00, 4281.03 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 258000/1801350 [00:59<05:32, 4645.01 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 263000/1801350 [00:59<06:03, 4226.43 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 258000/1801350 [00:59<05:33, 4626.33 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 260000/1801350 [00:59<05:58, 4295.43 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 259000/1801350 [00:59<05:53, 4368.89 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 264000/1801350 [01:00<06:12, 4127.17 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 259000/1801350 [00:59<06:04, 4228.31 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 261000/1801350 [00:59<05:36, 4575.85 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 260000/1801350 [00:59<06:01, 4260.18 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 265000/1801350 [01:00<06:00, 4256.08 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 260000/1801350 [00:59<06:04, 4229.75 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 262000/1801350 [00:59<05:42, 4488.92 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 261000/1801350 [00:59<05:38, 4545.21 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 266000/1801350 [01:00<06:06, 4190.13 examples/s]Grouping texts in chunks of 1024:  14%|█▍        | 261000/1801350 [00:59<05:38, 4545.63 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 263000/1801350 [01:00<05:56, 4314.73 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 262000/1801350 [01:00<05:48, 4418.67 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 267000/1801350 [01:00<06:08, 4159.28 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 262000/1801350 [01:00<05:51, 4379.95 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 264000/1801350 [01:00<06:00, 4269.96 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 263000/1801350 [01:00<05:58, 4293.86 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 268000/1801350 [01:00<06:14, 4092.31 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 263000/1801350 [01:00<06:06, 4199.48 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 265000/1801350 [01:00<05:58, 4284.34 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 264000/1801350 [01:00<05:58, 4287.68 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 269000/1801350 [01:01<05:55, 4315.47 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 264000/1801350 [01:00<06:00, 4267.32 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 266000/1801350 [01:00<06:16, 4078.19 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 265000/1801350 [01:00<06:06, 4197.61 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 270000/1801350 [01:01<05:59, 4263.92 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 265000/1801350 [01:00<05:58, 4286.86 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 267000/1801350 [01:00<06:07, 4171.33 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 266000/1801350 [01:01<06:12, 4120.46 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 271000/1801350 [01:01<06:06, 4179.05 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 266000/1801350 [01:01<06:14, 4102.21 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 268000/1801350 [01:01<06:14, 4097.57 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 267000/1801350 [01:01<06:08, 4160.92 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 272000/1801350 [01:01<05:52, 4344.09 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 267000/1801350 [01:01<06:12, 4120.57 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 269000/1801350 [01:01<05:51, 4358.35 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 273000/1801350 [01:02<05:36, 4538.83 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 268000/1801350 [01:01<06:00, 4248.79 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 268000/1801350 [01:01<06:07, 4170.20 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 270000/1801350 [01:01<05:54, 4314.66 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 274000/1801350 [01:02<05:28, 4643.62 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 269000/1801350 [01:01<05:47, 4409.72 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 269000/1801350 [01:01<05:52, 4351.00 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 271000/1801350 [01:01<05:54, 4313.48 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 275000/1801350 [01:02<05:50, 4356.44 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 270000/1801350 [01:02<06:04, 4205.23 examples/s]Grouping texts in chunks of 1024:  15%|█▍        | 270000/1801350 [01:02<06:06, 4175.21 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 272000/1801350 [01:02<05:49, 4375.76 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 276000/1801350 [01:02<05:48, 4374.34 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 271000/1801350 [01:02<05:56, 4289.05 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 273000/1801350 [01:02<05:31, 4611.07 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 271000/1801350 [01:02<05:57, 4277.24 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 272000/1801350 [01:02<05:52, 4340.30 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 277000/1801350 [01:03<06:00, 4223.91 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 274000/1801350 [01:02<05:25, 4689.49 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 272000/1801350 [01:02<05:47, 4403.13 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 273000/1801350 [01:02<05:23, 4726.72 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 278000/1801350 [01:03<05:55, 4290.33 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 273000/1801350 [01:02<05:31, 4615.59 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 275000/1801350 [01:02<05:41, 4464.58 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 274000/1801350 [01:02<05:25, 4694.22 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 279000/1801350 [01:03<05:47, 4380.63 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 274000/1801350 [01:02<05:31, 4609.97 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 276000/1801350 [01:02<05:39, 4495.68 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 275000/1801350 [01:03<05:43, 4446.82 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 280000/1801350 [01:03<05:55, 4283.33 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 275000/1801350 [01:03<05:42, 4457.07 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 277000/1801350 [01:03<05:58, 4254.61 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 276000/1801350 [01:03<05:47, 4390.06 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 281000/1801350 [01:03<05:55, 4272.74 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 276000/1801350 [01:03<05:52, 4321.33 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 278000/1801350 [01:03<05:54, 4302.12 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 277000/1801350 [01:03<05:59, 4236.48 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 282000/1801350 [01:04<05:51, 4318.30 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 277000/1801350 [01:03<05:59, 4237.70 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 279000/1801350 [01:03<05:42, 4439.07 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 278000/1801350 [01:03<05:51, 4330.54 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 283000/1801350 [01:04<05:57, 4244.95 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 278000/1801350 [01:03<06:02, 4205.30 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 280000/1801350 [01:03<05:50, 4340.24 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 279000/1801350 [01:04<05:42, 4451.20 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 284000/1801350 [01:04<05:43, 4418.55 examples/s]Grouping texts in chunks of 1024:  15%|█▌        | 279000/1801350 [01:04<05:46, 4393.03 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 281000/1801350 [01:04<05:45, 4401.65 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 280000/1801350 [01:04<05:56, 4268.34 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 285000/1801350 [01:04<05:42, 4421.27 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 282000/1801350 [01:04<05:38, 4484.47 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 280000/1801350 [01:04<05:53, 4300.81 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 286000/1801350 [01:05<05:33, 4548.33 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 281000/1801350 [01:04<05:55, 4274.41 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 281000/1801350 [01:04<05:57, 4248.45 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 283000/1801350 [01:04<05:47, 4364.08 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 282000/1801350 [01:04<05:46, 4390.40 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 287000/1801350 [01:05<05:53, 4283.56 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 284000/1801350 [01:04<05:45, 4393.72 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 282000/1801350 [01:04<05:48, 4362.11 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 283000/1801350 [01:04<05:46, 4385.01 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 288000/1801350 [01:05<05:46, 4369.69 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 285000/1801350 [01:05<05:46, 4380.93 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 283000/1801350 [01:05<05:57, 4252.76 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 284000/1801350 [01:05<05:36, 4510.59 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 289000/1801350 [01:05<05:47, 4351.53 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 286000/1801350 [01:05<05:35, 4518.52 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 284000/1801350 [01:05<05:44, 4405.58 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 285000/1801350 [01:05<05:44, 4405.33 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 290000/1801350 [01:06<05:57, 4225.27 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 285000/1801350 [01:05<05:41, 4443.93 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 287000/1801350 [01:05<05:52, 4295.49 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 286000/1801350 [01:05<05:35, 4518.57 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 291000/1801350 [01:06<05:54, 4263.70 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 288000/1801350 [01:05<05:38, 4473.90 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 286000/1801350 [01:05<05:40, 4448.66 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 287000/1801350 [01:05<05:55, 4265.62 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 292000/1801350 [01:06<05:53, 4266.31 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 289000/1801350 [01:05<05:38, 4469.91 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 287000/1801350 [01:05<06:00, 4203.75 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 288000/1801350 [01:06<05:50, 4318.52 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 293000/1801350 [01:06<06:00, 4184.55 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 290000/1801350 [01:06<05:49, 4329.76 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 288000/1801350 [01:06<05:47, 4353.76 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 289000/1801350 [01:06<05:43, 4407.39 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 294000/1801350 [01:06<05:54, 4251.52 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 289000/1801350 [01:06<05:41, 4426.45 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 291000/1801350 [01:06<05:50, 4306.33 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 290000/1801350 [01:06<05:51, 4299.55 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 295000/1801350 [01:07<05:36, 4481.88 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 292000/1801350 [01:06<05:55, 4251.62 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 290000/1801350 [01:06<05:46, 4357.76 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 291000/1801350 [01:06<05:53, 4273.55 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 296000/1801350 [01:07<05:45, 4351.24 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 293000/1801350 [01:06<05:52, 4283.81 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 291000/1801350 [01:06<05:53, 4268.00 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 292000/1801350 [01:07<05:51, 4289.67 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 297000/1801350 [01:07<05:42, 4394.55 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 294000/1801350 [01:07<05:53, 4264.46 examples/s]Grouping texts in chunks of 1024:  16%|█▌        | 292000/1801350 [01:07<06:01, 4178.98 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 293000/1801350 [01:07<05:48, 4322.97 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 298000/1801350 [01:07<05:44, 4360.33 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 295000/1801350 [01:07<05:37, 4459.09 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 293000/1801350 [01:07<05:53, 4264.65 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 294000/1801350 [01:07<05:54, 4246.28 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 299000/1801350 [01:08<05:47, 4325.98 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 296000/1801350 [01:07<05:42, 4390.62 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 294000/1801350 [01:07<05:55, 4235.91 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 295000/1801350 [01:07<05:37, 4463.95 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 300000/1801350 [01:08<05:39, 4417.98 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 297000/1801350 [01:07<05:42, 4390.53 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 295000/1801350 [01:07<05:38, 4449.24 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 296000/1801350 [01:07<05:47, 4327.75 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 301000/1801350 [01:08<05:42, 4382.85 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 298000/1801350 [01:07<05:27, 4586.79 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 296000/1801350 [01:08<05:46, 4340.38 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 297000/1801350 [01:08<05:42, 4396.64 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 302000/1801350 [01:08<06:00, 4161.25 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 299000/1801350 [01:08<05:44, 4360.35 examples/s]Grouping texts in chunks of 1024:  16%|█▋        | 297000/1801350 [01:08<05:41, 4404.63 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 298000/1801350 [01:08<05:29, 4558.62 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 300000/1801350 [01:08<05:23, 4640.80 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 303000/1801350 [01:09<05:39, 4409.14 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 298000/1801350 [01:08<05:34, 4494.25 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 299000/1801350 [01:08<05:44, 4366.03 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 304000/1801350 [01:09<05:30, 4525.96 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 301000/1801350 [01:08<05:44, 4355.73 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 299000/1801350 [01:08<05:49, 4294.30 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 300000/1801350 [01:08<05:27, 4587.89 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 305000/1801350 [01:09<05:40, 4395.08 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 300000/1801350 [01:08<05:29, 4558.67 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 302000/1801350 [01:08<05:53, 4242.00 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 301000/1801350 [01:09<05:45, 4344.42 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 306000/1801350 [01:09<05:43, 4348.40 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 303000/1801350 [01:09<05:41, 4385.62 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 301000/1801350 [01:09<05:40, 4404.68 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 302000/1801350 [01:09<05:52, 4247.88 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 307000/1801350 [01:09<05:47, 4305.09 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 304000/1801350 [01:09<05:22, 4641.71 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 302000/1801350 [01:09<05:54, 4233.71 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 303000/1801350 [01:09<05:40, 4403.62 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 308000/1801350 [01:10<05:39, 4402.56 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 305000/1801350 [01:09<05:36, 4446.30 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 303000/1801350 [01:09<05:35, 4467.47 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 304000/1801350 [01:09<05:30, 4530.50 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 306000/1801350 [01:09<05:39, 4409.36 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 309000/1801350 [01:10<05:52, 4237.80 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 304000/1801350 [01:09<05:32, 4497.16 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 305000/1801350 [01:09<05:35, 4463.32 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 310000/1801350 [01:10<05:34, 4456.20 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 307000/1801350 [01:10<05:50, 4268.52 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 305000/1801350 [01:10<05:39, 4405.48 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 306000/1801350 [01:10<05:35, 4459.48 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 311000/1801350 [01:10<05:31, 4492.14 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 308000/1801350 [01:10<05:35, 4454.97 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 306000/1801350 [01:10<05:44, 4340.36 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 307000/1801350 [01:10<05:43, 4345.93 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 312000/1801350 [01:11<05:39, 4389.87 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 309000/1801350 [01:10<05:55, 4198.12 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 307000/1801350 [01:10<05:47, 4297.05 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 308000/1801350 [01:10<05:41, 4374.80 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 313000/1801350 [01:11<05:35, 4431.89 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 310000/1801350 [01:10<05:27, 4547.50 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 308000/1801350 [01:10<05:35, 4446.83 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 309000/1801350 [01:10<05:49, 4270.79 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 314000/1801350 [01:11<05:26, 4550.27 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 311000/1801350 [01:10<05:34, 4454.78 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 309000/1801350 [01:11<05:51, 4249.40 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 310000/1801350 [01:11<05:24, 4601.55 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 312000/1801350 [01:11<05:24, 4591.58 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 315000/1801350 [01:11<05:42, 4341.23 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 310000/1801350 [01:11<05:32, 4486.40 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 311000/1801350 [01:11<05:32, 4484.08 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 313000/1801350 [01:11<05:25, 4576.68 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 316000/1801350 [01:11<05:38, 4390.08 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 311000/1801350 [01:11<05:33, 4473.66 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 312000/1801350 [01:11<05:34, 4449.60 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 314000/1801350 [01:11<05:18, 4674.75 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 317000/1801350 [01:12<05:50, 4233.19 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 312000/1801350 [01:11<05:35, 4443.31 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 313000/1801350 [01:11<05:25, 4570.98 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 315000/1801350 [01:11<05:43, 4333.18 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 318000/1801350 [01:12<05:53, 4196.29 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 313000/1801350 [01:11<05:35, 4433.24 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 314000/1801350 [01:11<05:17, 4685.17 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 316000/1801350 [01:12<05:33, 4447.83 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 314000/1801350 [01:12<05:21, 4621.59 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 319000/1801350 [01:12<05:54, 4180.65 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 315000/1801350 [01:12<05:38, 4392.91 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 317000/1801350 [01:12<05:44, 4303.68 examples/s]Grouping texts in chunks of 1024:  17%|█▋        | 315000/1801350 [01:12<05:38, 4393.01 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 320000/1801350 [01:12<05:56, 4156.93 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 316000/1801350 [01:12<05:42, 4342.36 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 318000/1801350 [01:12<05:49, 4242.45 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 316000/1801350 [01:12<05:42, 4335.07 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 321000/1801350 [01:13<05:46, 4271.84 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 317000/1801350 [01:12<05:40, 4353.35 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 319000/1801350 [01:12<05:48, 4247.90 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 322000/1801350 [01:13<05:44, 4288.12 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 317000/1801350 [01:12<05:44, 4304.83 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 318000/1801350 [01:12<05:59, 4130.85 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 320000/1801350 [01:13<05:47, 4267.39 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 318000/1801350 [01:13<05:51, 4223.18 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 323000/1801350 [01:13<05:56, 4141.76 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 319000/1801350 [01:13<05:54, 4184.45 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 321000/1801350 [01:13<05:43, 4310.79 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 324000/1801350 [01:13<05:45, 4278.19 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 319000/1801350 [01:13<05:49, 4246.33 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 320000/1801350 [01:13<05:44, 4297.30 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 322000/1801350 [01:13<05:46, 4274.83 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 325000/1801350 [01:14<05:43, 4294.72 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 320000/1801350 [01:13<05:50, 4222.81 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 321000/1801350 [01:13<05:44, 4293.24 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 323000/1801350 [01:13<05:47, 4260.36 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 321000/1801350 [01:13<05:50, 4229.21 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 326000/1801350 [01:14<05:56, 4142.14 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 322000/1801350 [01:13<05:49, 4236.48 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 324000/1801350 [01:13<05:42, 4315.07 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 327000/1801350 [01:14<05:41, 4322.09 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 322000/1801350 [01:14<05:53, 4188.20 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 323000/1801350 [01:14<05:55, 4159.19 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 325000/1801350 [01:14<05:29, 4475.26 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 328000/1801350 [01:14<05:21, 4577.54 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 323000/1801350 [01:14<05:52, 4191.80 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 324000/1801350 [01:14<05:32, 4442.93 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 329000/1801350 [01:14<05:11, 4723.82 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 326000/1801350 [01:14<05:48, 4228.37 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 324000/1801350 [01:14<05:46, 4263.49 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 325000/1801350 [01:14<05:33, 4421.07 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 327000/1801350 [01:14<05:37, 4369.86 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 330000/1801350 [01:15<05:30, 4451.46 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 325000/1801350 [01:14<05:37, 4375.24 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 326000/1801350 [01:14<05:56, 4134.74 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 328000/1801350 [01:14<05:20, 4594.73 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 331000/1801350 [01:15<05:43, 4280.17 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 326000/1801350 [01:14<05:54, 4157.58 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 327000/1801350 [01:15<05:37, 4365.31 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 329000/1801350 [01:15<05:10, 4744.47 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 332000/1801350 [01:15<05:48, 4216.53 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 328000/1801350 [01:15<05:12, 4712.04 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 327000/1801350 [01:15<05:38, 4360.90 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 330000/1801350 [01:15<05:24, 4531.80 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 333000/1801350 [01:15<05:34, 4392.90 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 328000/1801350 [01:15<05:18, 4631.31 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 329000/1801350 [01:15<05:14, 4678.71 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 331000/1801350 [01:15<05:32, 4428.38 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 334000/1801350 [01:16<05:31, 4430.25 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 329000/1801350 [01:15<05:13, 4696.31 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 330000/1801350 [01:15<05:24, 4538.83 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 332000/1801350 [01:15<05:41, 4303.97 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 335000/1801350 [01:16<05:36, 4358.51 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 330000/1801350 [01:15<05:30, 4449.01 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 331000/1801350 [01:15<05:39, 4329.59 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 333000/1801350 [01:15<05:38, 4340.35 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 336000/1801350 [01:16<05:39, 4321.72 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 331000/1801350 [01:16<05:38, 4345.19 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 332000/1801350 [01:16<05:40, 4319.21 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 334000/1801350 [01:16<05:35, 4377.66 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 337000/1801350 [01:16<05:36, 4350.90 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 332000/1801350 [01:16<05:49, 4198.63 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 333000/1801350 [01:16<05:36, 4360.39 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 338000/1801350 [01:17<05:21, 4554.34 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 335000/1801350 [01:16<06:15, 3900.96 examples/s]Grouping texts in chunks of 1024:  18%|█▊        | 333000/1801350 [01:16<05:43, 4273.47 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 334000/1801350 [01:16<05:43, 4272.55 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 339000/1801350 [01:17<05:14, 4655.12 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 336000/1801350 [01:16<05:47, 4222.87 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 334000/1801350 [01:16<05:24, 4517.30 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 335000/1801350 [01:16<05:27, 4470.74 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 337000/1801350 [01:16<05:35, 4365.83 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 340000/1801350 [01:17<05:46, 4213.74 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 335000/1801350 [01:16<05:32, 4408.80 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 336000/1801350 [01:17<05:26, 4483.52 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 338000/1801350 [01:17<05:30, 4421.91 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 341000/1801350 [01:17<05:42, 4266.36 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 336000/1801350 [01:17<05:29, 4446.50 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 337000/1801350 [01:17<05:31, 4417.97 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 339000/1801350 [01:17<05:19, 4579.49 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 342000/1801350 [01:17<05:31, 4402.49 examples/s]Grouping texts in chunks of 1024:  19%|█▊        | 337000/1801350 [01:17<05:26, 4480.99 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 338000/1801350 [01:17<05:20, 4567.51 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 340000/1801350 [01:17<05:40, 4292.84 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 343000/1801350 [01:18<05:26, 4462.41 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 338000/1801350 [01:17<05:19, 4578.02 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 339000/1801350 [01:17<05:12, 4686.49 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 339000/1801350 [01:17<05:13, 4669.29 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 344000/1801350 [01:18<05:26, 4462.51 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 341000/1801350 [01:17<05:40, 4282.95 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 340000/1801350 [01:17<05:36, 4337.57 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 345000/1801350 [01:18<05:33, 4368.77 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 342000/1801350 [01:18<05:42, 4255.48 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 340000/1801350 [01:18<05:37, 4331.41 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 341000/1801350 [01:18<05:39, 4307.38 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 343000/1801350 [01:18<05:22, 4527.71 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 341000/1801350 [01:18<05:44, 4243.63 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 346000/1801350 [01:18<05:57, 4073.84 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 342000/1801350 [01:18<05:35, 4351.45 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 344000/1801350 [01:18<05:28, 4441.42 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 342000/1801350 [01:18<05:36, 4341.19 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 347000/1801350 [01:19<05:39, 4283.83 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 343000/1801350 [01:18<05:28, 4438.10 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 345000/1801350 [01:18<05:31, 4386.89 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 343000/1801350 [01:18<05:26, 4465.26 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 344000/1801350 [01:18<05:17, 4587.36 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 348000/1801350 [01:19<05:44, 4220.57 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 344000/1801350 [01:18<05:24, 4484.32 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 346000/1801350 [01:19<05:47, 4186.56 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 349000/1801350 [01:19<05:37, 4298.25 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 345000/1801350 [01:19<05:33, 4364.36 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 347000/1801350 [01:19<05:37, 4309.81 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 350000/1801350 [01:19<05:21, 4513.77 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 345000/1801350 [01:19<05:31, 4387.22 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 346000/1801350 [01:19<05:45, 4216.21 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 348000/1801350 [01:19<05:28, 4424.72 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 351000/1801350 [01:20<05:20, 4528.26 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 346000/1801350 [01:19<05:47, 4183.61 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 347000/1801350 [01:19<05:36, 4317.91 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 349000/1801350 [01:19<05:36, 4317.03 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 352000/1801350 [01:20<05:31, 4371.86 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 347000/1801350 [01:19<05:36, 4328.41 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 348000/1801350 [01:19<05:36, 4315.48 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 350000/1801350 [01:19<05:29, 4405.34 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 348000/1801350 [01:19<05:38, 4290.57 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 353000/1801350 [01:20<05:46, 4180.66 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 349000/1801350 [01:19<05:35, 4326.87 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 351000/1801350 [01:20<05:12, 4635.82 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 349000/1801350 [01:20<05:34, 4335.75 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 350000/1801350 [01:20<05:29, 4406.47 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 354000/1801350 [01:20<05:50, 4134.60 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 352000/1801350 [01:20<05:22, 4497.11 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 351000/1801350 [01:20<05:09, 4686.40 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 350000/1801350 [01:20<05:27, 4431.15 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 355000/1801350 [01:20<05:38, 4274.75 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 353000/1801350 [01:20<05:35, 4310.60 examples/s]Grouping texts in chunks of 1024:  19%|█▉        | 351000/1801350 [01:20<05:22, 4492.50 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 352000/1801350 [01:20<05:24, 4464.01 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 356000/1801350 [01:21<05:35, 4306.09 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 354000/1801350 [01:20<05:48, 4152.78 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 352000/1801350 [01:20<05:29, 4395.80 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 353000/1801350 [01:20<05:41, 4239.82 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 357000/1801350 [01:21<05:46, 4172.59 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 355000/1801350 [01:21<05:43, 4213.72 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 353000/1801350 [01:21<05:44, 4200.97 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 354000/1801350 [01:21<05:50, 4126.71 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 358000/1801350 [01:21<05:52, 4093.80 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 356000/1801350 [01:21<05:34, 4320.01 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 354000/1801350 [01:21<05:53, 4099.07 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 355000/1801350 [01:21<05:41, 4232.45 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 359000/1801350 [01:21<05:40, 4234.13 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 357000/1801350 [01:21<05:38, 4264.05 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 355000/1801350 [01:21<05:32, 4356.19 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 356000/1801350 [01:21<05:35, 4302.78 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 360000/1801350 [01:22<05:43, 4198.57 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 358000/1801350 [01:21<05:45, 4180.76 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 356000/1801350 [01:21<05:39, 4253.30 examples/s]Grouping texts in chunks of 1024:  20%|██        | 361000/1801350 [01:22<05:27, 4397.82 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 357000/1801350 [01:21<05:44, 4189.10 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 359000/1801350 [01:22<05:41, 4225.18 examples/s]Grouping texts in chunks of 1024:  20%|██        | 362000/1801350 [01:22<05:14, 4573.35 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 357000/1801350 [01:22<05:44, 4193.98 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 358000/1801350 [01:22<05:41, 4224.10 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 360000/1801350 [01:22<05:37, 4275.15 examples/s]Grouping texts in chunks of 1024:  20%|██        | 363000/1801350 [01:22<05:13, 4582.37 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 358000/1801350 [01:22<05:46, 4161.56 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 359000/1801350 [01:22<05:38, 4255.88 examples/s]Grouping texts in chunks of 1024:  20%|██        | 361000/1801350 [01:22<05:27, 4395.63 examples/s]Grouping texts in chunks of 1024:  20%|██        | 364000/1801350 [01:23<05:14, 4568.58 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 359000/1801350 [01:22<05:36, 4289.24 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 360000/1801350 [01:22<05:36, 4282.84 examples/s]Grouping texts in chunks of 1024:  20%|██        | 362000/1801350 [01:22<05:11, 4618.01 examples/s]Grouping texts in chunks of 1024:  20%|██        | 365000/1801350 [01:23<05:05, 4700.37 examples/s]Grouping texts in chunks of 1024:  20%|██        | 361000/1801350 [01:22<05:20, 4497.33 examples/s]Grouping texts in chunks of 1024:  20%|█▉        | 360000/1801350 [01:22<05:37, 4274.24 examples/s]Grouping texts in chunks of 1024:  20%|██        | 363000/1801350 [01:22<05:08, 4667.10 examples/s]Grouping texts in chunks of 1024:  20%|██        | 366000/1801350 [01:23<05:00, 4771.18 examples/s]Grouping texts in chunks of 1024:  20%|██        | 362000/1801350 [01:22<05:08, 4669.14 examples/s]Grouping texts in chunks of 1024:  20%|██        | 361000/1801350 [01:22<05:26, 4405.51 examples/s]Grouping texts in chunks of 1024:  20%|██        | 364000/1801350 [01:23<05:08, 4657.30 examples/s]Grouping texts in chunks of 1024:  20%|██        | 367000/1801350 [01:23<05:22, 4451.95 examples/s]Grouping texts in chunks of 1024:  20%|██        | 363000/1801350 [01:23<05:15, 4560.57 examples/s]Grouping texts in chunks of 1024:  20%|██        | 362000/1801350 [01:23<05:16, 4542.53 examples/s]Grouping texts in chunks of 1024:  20%|██        | 365000/1801350 [01:23<04:57, 4830.51 examples/s]Grouping texts in chunks of 1024:  20%|██        | 364000/1801350 [01:23<05:08, 4652.39 examples/s]Grouping texts in chunks of 1024:  20%|██        | 368000/1801350 [01:23<05:31, 4322.18 examples/s]Grouping texts in chunks of 1024:  20%|██        | 363000/1801350 [01:23<05:11, 4619.72 examples/s]Grouping texts in chunks of 1024:  20%|██        | 366000/1801350 [01:23<04:54, 4876.27 examples/s]Grouping texts in chunks of 1024:  20%|██        | 369000/1801350 [01:24<05:18, 4496.94 examples/s]Grouping texts in chunks of 1024:  20%|██        | 365000/1801350 [01:23<05:06, 4683.72 examples/s]Grouping texts in chunks of 1024:  20%|██        | 364000/1801350 [01:23<05:11, 4616.15 examples/s]Grouping texts in chunks of 1024:  20%|██        | 367000/1801350 [01:23<05:13, 4580.88 examples/s]Grouping texts in chunks of 1024:  20%|██        | 366000/1801350 [01:23<04:54, 4874.07 examples/s]Grouping texts in chunks of 1024:  20%|██        | 365000/1801350 [01:23<05:06, 4691.07 examples/s]Grouping texts in chunks of 1024:  21%|██        | 370000/1801350 [01:24<05:21, 4445.69 examples/s]Grouping texts in chunks of 1024:  20%|██        | 368000/1801350 [01:23<05:29, 4356.59 examples/s]Grouping texts in chunks of 1024:  20%|██        | 366000/1801350 [01:23<04:54, 4868.88 examples/s]Grouping texts in chunks of 1024:  20%|██        | 367000/1801350 [01:24<05:21, 4466.69 examples/s]Grouping texts in chunks of 1024:  21%|██        | 371000/1801350 [01:24<05:28, 4350.13 examples/s]Grouping texts in chunks of 1024:  20%|██        | 369000/1801350 [01:24<05:19, 4483.41 examples/s]Grouping texts in chunks of 1024:  20%|██        | 367000/1801350 [01:24<05:17, 4517.76 examples/s]Grouping texts in chunks of 1024:  20%|██        | 368000/1801350 [01:24<05:32, 4315.58 examples/s]Grouping texts in chunks of 1024:  21%|██        | 372000/1801350 [01:24<05:36, 4245.22 examples/s]Grouping texts in chunks of 1024:  21%|██        | 370000/1801350 [01:24<05:20, 4462.47 examples/s]Grouping texts in chunks of 1024:  20%|██        | 369000/1801350 [01:24<05:22, 4436.11 examples/s]Grouping texts in chunks of 1024:  20%|██        | 368000/1801350 [01:24<05:33, 4303.77 examples/s]Grouping texts in chunks of 1024:  21%|██        | 373000/1801350 [01:25<05:31, 4313.64 examples/s]Grouping texts in chunks of 1024:  21%|██        | 371000/1801350 [01:24<05:25, 4393.67 examples/s]Grouping texts in chunks of 1024:  21%|██        | 370000/1801350 [01:24<05:14, 4553.36 examples/s]Grouping texts in chunks of 1024:  20%|██        | 369000/1801350 [01:24<05:19, 4487.27 examples/s]Grouping texts in chunks of 1024:  21%|██        | 374000/1801350 [01:25<05:24, 4399.05 examples/s]Grouping texts in chunks of 1024:  21%|██        | 372000/1801350 [01:24<05:30, 4329.07 examples/s]Grouping texts in chunks of 1024:  21%|██        | 371000/1801350 [01:24<05:23, 4426.24 examples/s]Grouping texts in chunks of 1024:  21%|██        | 370000/1801350 [01:24<05:24, 4404.74 examples/s]Grouping texts in chunks of 1024:  21%|██        | 375000/1801350 [01:25<05:19, 4458.97 examples/s]Grouping texts in chunks of 1024:  21%|██        | 373000/1801350 [01:25<05:23, 4409.34 examples/s]Grouping texts in chunks of 1024:  21%|██        | 371000/1801350 [01:25<05:27, 4367.86 examples/s]Grouping texts in chunks of 1024:  21%|██        | 372000/1801350 [01:25<05:30, 4320.27 examples/s]Grouping texts in chunks of 1024:  21%|██        | 376000/1801350 [01:25<05:29, 4321.54 examples/s]Grouping texts in chunks of 1024:  21%|██        | 374000/1801350 [01:25<05:24, 4404.17 examples/s]Grouping texts in chunks of 1024:  21%|██        | 372000/1801350 [01:25<05:30, 4321.40 examples/s]Grouping texts in chunks of 1024:  21%|██        | 373000/1801350 [01:25<05:31, 4306.94 examples/s]Grouping texts in chunks of 1024:  21%|██        | 377000/1801350 [01:26<05:39, 4195.58 examples/s]Grouping texts in chunks of 1024:  21%|██        | 375000/1801350 [01:25<05:18, 4481.10 examples/s]Grouping texts in chunks of 1024:  21%|██        | 374000/1801350 [01:25<05:22, 4428.40 examples/s]Grouping texts in chunks of 1024:  21%|██        | 373000/1801350 [01:25<05:28, 4342.76 examples/s]Grouping texts in chunks of 1024:  21%|██        | 378000/1801350 [01:26<05:34, 4251.11 examples/s]Grouping texts in chunks of 1024:  21%|██        | 376000/1801350 [01:25<05:26, 4358.98 examples/s]Grouping texts in chunks of 1024:  21%|██        | 375000/1801350 [01:25<05:18, 4471.53 examples/s]Grouping texts in chunks of 1024:  21%|██        | 374000/1801350 [01:25<05:31, 4309.35 examples/s]Grouping texts in chunks of 1024:  21%|██        | 379000/1801350 [01:26<05:30, 4300.74 examples/s]Grouping texts in chunks of 1024:  21%|██        | 377000/1801350 [01:26<05:36, 4233.58 examples/s]Grouping texts in chunks of 1024:  21%|██        | 375000/1801350 [01:26<05:12, 4564.95 examples/s]Grouping texts in chunks of 1024:  21%|██        | 376000/1801350 [01:26<05:30, 4309.79 examples/s]Grouping texts in chunks of 1024:  21%|██        | 380000/1801350 [01:26<05:25, 4367.58 examples/s]Grouping texts in chunks of 1024:  21%|██        | 378000/1801350 [01:26<05:32, 4277.21 examples/s]Grouping texts in chunks of 1024:  21%|██        | 376000/1801350 [01:26<05:29, 4331.87 examples/s]Grouping texts in chunks of 1024:  21%|██        | 377000/1801350 [01:26<05:33, 4271.99 examples/s]Grouping texts in chunks of 1024:  21%|██        | 381000/1801350 [01:26<05:16, 4491.87 examples/s]Grouping texts in chunks of 1024:  21%|██        | 379000/1801350 [01:26<05:26, 4358.64 examples/s]Grouping texts in chunks of 1024:  21%|██        | 378000/1801350 [01:26<05:32, 4277.06 examples/s]Grouping texts in chunks of 1024:  21%|██        | 382000/1801350 [01:27<05:24, 4376.22 examples/s]Grouping texts in chunks of 1024:  21%|██        | 377000/1801350 [01:26<05:49, 4077.60 examples/s]Grouping texts in chunks of 1024:  21%|██        | 380000/1801350 [01:26<05:16, 4485.05 examples/s]Grouping texts in chunks of 1024:  21%|██        | 379000/1801350 [01:26<05:27, 4343.44 examples/s]Grouping texts in chunks of 1024:  21%|██        | 378000/1801350 [01:26<05:30, 4311.54 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 383000/1801350 [01:27<05:36, 4213.68 examples/s]Grouping texts in chunks of 1024:  21%|██        | 381000/1801350 [01:26<05:11, 4561.59 examples/s]Grouping texts in chunks of 1024:  21%|██        | 380000/1801350 [01:27<05:16, 4490.95 examples/s]Grouping texts in chunks of 1024:  21%|██        | 379000/1801350 [01:27<05:29, 4311.57 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 384000/1801350 [01:27<05:36, 4213.41 examples/s]Grouping texts in chunks of 1024:  21%|██        | 382000/1801350 [01:27<05:19, 4444.78 examples/s]Grouping texts in chunks of 1024:  21%|██        | 381000/1801350 [01:27<05:08, 4610.42 examples/s]Grouping texts in chunks of 1024:  21%|██        | 380000/1801350 [01:27<05:16, 4494.52 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 385000/1801350 [01:27<05:15, 4489.87 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 383000/1801350 [01:27<05:41, 4159.12 examples/s]Grouping texts in chunks of 1024:  21%|██        | 381000/1801350 [01:27<05:08, 4603.65 examples/s]Grouping texts in chunks of 1024:  21%|██        | 382000/1801350 [01:27<05:26, 4342.94 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 386000/1801350 [01:28<05:28, 4303.49 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 384000/1801350 [01:27<05:30, 4294.27 examples/s]Grouping texts in chunks of 1024:  21%|██        | 382000/1801350 [01:27<05:23, 4389.32 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 383000/1801350 [01:27<05:43, 4129.70 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 387000/1801350 [01:28<05:24, 4355.99 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 385000/1801350 [01:27<05:19, 4428.16 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 388000/1801350 [01:28<05:14, 4500.75 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 384000/1801350 [01:27<05:35, 4220.25 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 383000/1801350 [01:27<05:41, 4153.25 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 386000/1801350 [01:28<05:28, 4313.24 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 385000/1801350 [01:28<05:20, 4422.17 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 384000/1801350 [01:28<05:38, 4185.11 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 389000/1801350 [01:28<05:27, 4314.71 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 387000/1801350 [01:28<05:18, 4446.71 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 385000/1801350 [01:28<05:22, 4397.26 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 386000/1801350 [01:28<05:29, 4289.95 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 390000/1801350 [01:28<05:17, 4441.35 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 388000/1801350 [01:28<05:12, 4520.41 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 387000/1801350 [01:28<05:14, 4501.98 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 391000/1801350 [01:29<05:17, 4441.90 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 386000/1801350 [01:28<05:33, 4249.24 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 389000/1801350 [01:28<05:12, 4515.56 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 388000/1801350 [01:28<05:11, 4536.64 examples/s]Grouping texts in chunks of 1024:  21%|██▏       | 387000/1801350 [01:28<05:16, 4465.67 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 392000/1801350 [01:29<05:34, 4208.97 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 390000/1801350 [01:28<05:15, 4473.55 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 389000/1801350 [01:29<05:15, 4479.15 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 388000/1801350 [01:29<05:09, 4562.42 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 393000/1801350 [01:29<05:27, 4299.16 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 391000/1801350 [01:29<05:12, 4511.81 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 390000/1801350 [01:29<05:14, 4492.25 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 389000/1801350 [01:29<05:20, 4402.27 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 394000/1801350 [01:29<05:41, 4121.76 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 392000/1801350 [01:29<05:24, 4341.07 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 391000/1801350 [01:29<05:09, 4551.20 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 390000/1801350 [01:29<05:08, 4581.37 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 395000/1801350 [01:30<05:33, 4219.12 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 393000/1801350 [01:29<05:29, 4268.78 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 391000/1801350 [01:29<05:11, 4521.93 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 392000/1801350 [01:29<05:23, 4356.97 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 396000/1801350 [01:30<05:24, 4336.79 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 394000/1801350 [01:29<05:34, 4213.61 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 393000/1801350 [01:29<05:30, 4266.47 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 392000/1801350 [01:29<05:28, 4291.11 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 397000/1801350 [01:30<05:37, 4165.62 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 395000/1801350 [01:30<05:24, 4329.34 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 394000/1801350 [01:30<05:33, 4216.92 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 393000/1801350 [01:30<05:35, 4199.94 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 398000/1801350 [01:30<05:35, 4188.27 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 396000/1801350 [01:30<05:20, 4384.40 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 395000/1801350 [01:30<05:30, 4257.50 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 394000/1801350 [01:30<05:38, 4161.44 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 399000/1801350 [01:31<05:09, 4530.37 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 397000/1801350 [01:30<05:24, 4326.33 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 396000/1801350 [01:30<05:12, 4502.54 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 400000/1801350 [01:31<05:03, 4621.91 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 395000/1801350 [01:30<05:34, 4201.23 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 398000/1801350 [01:30<05:32, 4223.59 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 397000/1801350 [01:30<05:29, 4259.62 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 396000/1801350 [01:30<05:20, 4389.98 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 401000/1801350 [01:31<05:16, 4423.03 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 399000/1801350 [01:31<05:15, 4443.04 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 398000/1801350 [01:31<05:27, 4283.74 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 397000/1801350 [01:31<05:28, 4279.92 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 400000/1801350 [01:31<04:57, 4705.01 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 402000/1801350 [01:31<05:30, 4235.37 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 399000/1801350 [01:31<05:12, 4481.54 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 398000/1801350 [01:31<05:31, 4230.32 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 401000/1801350 [01:31<05:11, 4496.74 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 403000/1801350 [01:32<05:35, 4163.23 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 400000/1801350 [01:31<05:03, 4614.91 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 399000/1801350 [01:31<05:17, 4413.50 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 402000/1801350 [01:31<05:21, 4359.02 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 401000/1801350 [01:31<05:16, 4428.29 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 400000/1801350 [01:31<05:04, 4601.96 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 403000/1801350 [01:31<05:36, 4159.62 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 401000/1801350 [01:32<05:13, 4461.74 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 402000/1801350 [01:32<05:32, 4212.43 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 404000/1801350 [01:32<08:06, 2873.78 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 404000/1801350 [01:32<05:33, 4189.84 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 405000/1801350 [01:32<07:12, 3225.50 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 403000/1801350 [01:32<05:39, 4118.70 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 402000/1801350 [01:32<05:33, 4194.56 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 405000/1801350 [01:32<05:27, 4257.38 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 404000/1801350 [01:32<05:35, 4162.94 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 406000/1801350 [01:33<06:52, 3383.05 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 403000/1801350 [01:32<05:39, 4119.92 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 406000/1801350 [01:32<05:34, 4172.41 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 405000/1801350 [01:32<05:19, 4368.56 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 407000/1801350 [01:33<06:27, 3593.72 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 404000/1801350 [01:32<05:34, 4171.53 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 407000/1801350 [01:32<05:34, 4163.34 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 406000/1801350 [01:33<05:32, 4197.43 examples/s]Grouping texts in chunks of 1024:  22%|██▏       | 405000/1801350 [01:33<05:24, 4306.59 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 408000/1801350 [01:33<06:15, 3706.44 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 408000/1801350 [01:33<05:30, 4209.60 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 407000/1801350 [01:33<05:29, 4236.64 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 409000/1801350 [01:33<05:42, 4061.07 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 406000/1801350 [01:33<05:28, 4251.61 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 409000/1801350 [01:33<05:17, 4379.76 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 408000/1801350 [01:33<05:28, 4239.30 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 410000/1801350 [01:34<05:44, 4037.85 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 407000/1801350 [01:33<05:38, 4116.25 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 410000/1801350 [01:33<05:24, 4284.52 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 409000/1801350 [01:33<05:16, 4397.44 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 411000/1801350 [01:34<05:31, 4191.40 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 408000/1801350 [01:33<05:41, 4082.00 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 411000/1801350 [01:33<05:18, 4362.35 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 410000/1801350 [01:33<05:25, 4281.04 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 412000/1801350 [01:34<05:43, 4044.42 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 409000/1801350 [01:33<05:22, 4323.22 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 412000/1801350 [01:34<05:27, 4243.43 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 411000/1801350 [01:34<05:23, 4301.67 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 410000/1801350 [01:34<05:25, 4281.05 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 413000/1801350 [01:34<06:07, 3777.69 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 413000/1801350 [01:34<05:55, 3908.37 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 412000/1801350 [01:34<05:31, 4196.54 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 411000/1801350 [01:34<05:24, 4289.60 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 414000/1801350 [01:35<05:59, 3862.57 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 414000/1801350 [01:34<05:50, 3957.59 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 412000/1801350 [01:34<05:26, 4250.09 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 413000/1801350 [01:34<05:49, 3973.63 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 415000/1801350 [01:35<06:01, 3838.51 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 415000/1801350 [01:34<05:48, 3978.71 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 414000/1801350 [01:34<05:43, 4035.78 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 413000/1801350 [01:34<05:48, 3987.08 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 416000/1801350 [01:35<05:48, 3976.80 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 416000/1801350 [01:35<05:45, 4007.09 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 415000/1801350 [01:35<05:50, 3959.49 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 414000/1801350 [01:35<05:50, 3963.50 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 417000/1801350 [01:35<05:47, 3983.10 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 417000/1801350 [01:35<05:44, 4019.05 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 416000/1801350 [01:35<05:43, 4037.18 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 418000/1801350 [01:36<05:32, 4165.89 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 415000/1801350 [01:35<05:51, 3944.70 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 418000/1801350 [01:35<05:25, 4255.33 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 417000/1801350 [01:35<05:40, 4068.16 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 416000/1801350 [01:35<05:45, 4005.76 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 419000/1801350 [01:36<05:39, 4075.91 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 419000/1801350 [01:35<05:26, 4228.19 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 418000/1801350 [01:35<05:24, 4260.64 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 420000/1801350 [01:36<05:31, 4167.11 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 417000/1801350 [01:35<05:47, 3984.00 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 420000/1801350 [01:36<05:23, 4272.84 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 419000/1801350 [01:36<05:35, 4123.05 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 421000/1801350 [01:36<05:23, 4260.38 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 418000/1801350 [01:36<05:31, 4177.18 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 421000/1801350 [01:36<05:20, 4302.03 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 420000/1801350 [01:36<05:25, 4243.21 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 419000/1801350 [01:36<05:35, 4124.03 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 422000/1801350 [01:37<05:35, 4109.08 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 422000/1801350 [01:36<05:26, 4222.09 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 421000/1801350 [01:36<05:21, 4294.12 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 420000/1801350 [01:36<05:21, 4302.65 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 423000/1801350 [01:37<05:20, 4297.70 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 423000/1801350 [01:36<05:20, 4305.65 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 422000/1801350 [01:36<05:30, 4174.52 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 421000/1801350 [01:36<05:22, 4274.07 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 424000/1801350 [01:37<05:28, 4197.59 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 424000/1801350 [01:36<05:27, 4208.18 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 423000/1801350 [01:37<05:18, 4328.81 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 425000/1801350 [01:37<05:34, 4117.91 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 422000/1801350 [01:37<05:33, 4131.16 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 425000/1801350 [01:37<05:28, 4187.95 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 424000/1801350 [01:37<05:20, 4299.66 examples/s]Grouping texts in chunks of 1024:  23%|██▎       | 423000/1801350 [01:37<05:22, 4278.56 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 426000/1801350 [01:37<05:19, 4300.30 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 426000/1801350 [01:37<05:20, 4294.59 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 425000/1801350 [01:37<05:29, 4183.42 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 427000/1801350 [01:38<05:13, 4380.13 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 424000/1801350 [01:37<05:24, 4243.46 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 427000/1801350 [01:37<05:01, 4564.23 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 426000/1801350 [01:37<05:25, 4230.36 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 428000/1801350 [01:38<05:15, 4358.65 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 425000/1801350 [01:37<05:30, 4162.02 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 428000/1801350 [01:37<05:14, 4362.86 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 427000/1801350 [01:37<05:01, 4564.08 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 429000/1801350 [01:38<05:10, 4416.45 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 426000/1801350 [01:38<05:27, 4203.14 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 429000/1801350 [01:38<05:08, 4451.02 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 428000/1801350 [01:38<05:06, 4487.13 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 430000/1801350 [01:38<05:02, 4526.00 examples/s]Grouping texts in chunks of 1024:  24%|██▎       | 427000/1801350 [01:38<04:59, 4592.09 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 430000/1801350 [01:38<04:54, 4663.82 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 429000/1801350 [01:38<05:08, 4446.98 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 431000/1801350 [01:39<05:12, 4387.86 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 428000/1801350 [01:38<05:13, 4385.76 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 431000/1801350 [01:38<05:07, 4452.82 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 430000/1801350 [01:38<04:51, 4702.29 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 429000/1801350 [01:38<05:07, 4456.96 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 432000/1801350 [01:39<05:23, 4235.68 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 432000/1801350 [01:38<05:21, 4258.20 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 431000/1801350 [01:38<05:13, 4376.78 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 433000/1801350 [01:39<04:57, 4592.38 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 430000/1801350 [01:38<04:59, 4575.74 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 433000/1801350 [01:38<04:48, 4746.57 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 432000/1801350 [01:39<05:23, 4229.27 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 434000/1801350 [01:39<05:02, 4513.58 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 434000/1801350 [01:39<04:56, 4604.76 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 431000/1801350 [01:39<05:15, 4348.55 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 433000/1801350 [01:39<04:50, 4708.70 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 435000/1801350 [01:39<05:25, 4199.61 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 432000/1801350 [01:39<05:23, 4229.57 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 435000/1801350 [01:39<05:20, 4259.02 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 434000/1801350 [01:39<05:05, 4479.25 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 433000/1801350 [01:39<04:57, 4602.51 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 436000/1801350 [01:40<05:24, 4207.77 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 436000/1801350 [01:39<05:17, 4295.32 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 435000/1801350 [01:39<05:14, 4342.54 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 434000/1801350 [01:39<05:02, 4524.39 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 437000/1801350 [01:40<05:10, 4391.34 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 437000/1801350 [01:39<05:09, 4408.04 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 436000/1801350 [01:40<05:17, 4296.18 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 438000/1801350 [01:40<05:01, 4515.74 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 435000/1801350 [01:40<05:20, 4258.94 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 438000/1801350 [01:40<05:16, 4312.69 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 437000/1801350 [01:40<05:16, 4312.03 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 436000/1801350 [01:40<05:24, 4212.36 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 439000/1801350 [01:40<05:21, 4235.49 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 439000/1801350 [01:40<05:19, 4268.41 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 438000/1801350 [01:40<05:11, 4370.96 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 437000/1801350 [01:40<05:13, 4357.20 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 440000/1801350 [01:40<05:21, 4238.12 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 440000/1801350 [01:41<05:28, 4141.89 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 439000/1801350 [01:40<05:22, 4226.75 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 438000/1801350 [01:40<05:17, 4300.34 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 441000/1801350 [01:41<05:25, 4180.63 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 441000/1801350 [01:40<05:24, 4187.42 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 440000/1801350 [01:40<05:20, 4243.14 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 442000/1801350 [01:41<05:05, 4443.57 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 439000/1801350 [01:41<05:21, 4236.20 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 442000/1801350 [01:41<05:15, 4303.48 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 441000/1801350 [01:41<05:25, 4179.90 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 443000/1801350 [01:41<05:13, 4328.60 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 443000/1801350 [01:41<05:16, 4289.35 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 440000/1801350 [01:41<05:22, 4214.73 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 442000/1801350 [01:41<05:07, 4417.27 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 444000/1801350 [01:41<05:02, 4489.23 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 444000/1801350 [01:42<05:05, 4437.85 examples/s]Grouping texts in chunks of 1024:  24%|██▍       | 441000/1801350 [01:41<05:20, 4239.43 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 443000/1801350 [01:41<05:13, 4329.41 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 442000/1801350 [01:41<05:14, 4324.13 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 445000/1801350 [01:41<05:21, 4216.51 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 445000/1801350 [01:42<05:28, 4132.51 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 444000/1801350 [01:41<05:08, 4395.42 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 443000/1801350 [01:41<05:13, 4328.04 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 446000/1801350 [01:41<05:19, 4240.63 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 446000/1801350 [01:42<05:30, 4097.24 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 445000/1801350 [01:42<05:31, 4087.19 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 444000/1801350 [01:42<05:06, 4430.93 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 447000/1801350 [01:42<05:25, 4157.22 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 447000/1801350 [01:42<05:22, 4202.35 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 446000/1801350 [01:42<05:18, 4249.74 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 445000/1801350 [01:42<05:22, 4212.11 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 448000/1801350 [01:42<05:13, 4312.31 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 448000/1801350 [01:43<05:15, 4288.60 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 447000/1801350 [01:42<05:26, 4149.77 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 449000/1801350 [01:42<05:07, 4394.16 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 446000/1801350 [01:42<05:26, 4148.59 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 449000/1801350 [01:43<05:15, 4290.20 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 448000/1801350 [01:42<05:12, 4324.09 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 450000/1801350 [01:42<05:16, 4269.47 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 447000/1801350 [01:42<05:24, 4168.87 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 450000/1801350 [01:43<05:17, 4256.15 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 449000/1801350 [01:43<05:05, 4421.77 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 448000/1801350 [01:43<05:07, 4403.53 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 451000/1801350 [01:43<05:07, 4387.65 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 451000/1801350 [01:43<05:11, 4337.53 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 450000/1801350 [01:43<05:22, 4191.04 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 449000/1801350 [01:43<05:08, 4376.64 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 452000/1801350 [01:43<05:09, 4362.41 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 452000/1801350 [01:43<05:22, 4181.24 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 451000/1801350 [01:43<05:01, 4484.78 examples/s]Grouping texts in chunks of 1024:  25%|██▍       | 450000/1801350 [01:43<05:20, 4213.69 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 453000/1801350 [01:43<05:18, 4232.51 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 453000/1801350 [01:44<05:22, 4184.89 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 452000/1801350 [01:43<05:18, 4241.97 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 451000/1801350 [01:43<05:03, 4447.07 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 454000/1801350 [01:43<05:14, 4284.05 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 454000/1801350 [01:44<05:21, 4192.94 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 453000/1801350 [01:43<05:14, 4286.05 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 452000/1801350 [01:44<05:15, 4274.29 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 455000/1801350 [01:44<05:18, 4223.69 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 455000/1801350 [01:44<05:18, 4233.64 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 454000/1801350 [01:44<05:24, 4150.22 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 453000/1801350 [01:44<05:21, 4194.21 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 456000/1801350 [01:44<05:19, 4211.66 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 456000/1801350 [01:44<05:24, 4140.47 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 455000/1801350 [01:44<05:16, 4256.10 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 457000/1801350 [01:44<04:57, 4517.95 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 454000/1801350 [01:44<05:23, 4165.76 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 457000/1801350 [01:45<05:01, 4463.39 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 456000/1801350 [01:44<05:23, 4158.71 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 458000/1801350 [01:44<04:57, 4511.93 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 458000/1801350 [01:45<05:00, 4470.70 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 455000/1801350 [01:44<05:25, 4134.39 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 457000/1801350 [01:44<04:58, 4500.53 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 459000/1801350 [01:44<05:08, 4354.13 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 456000/1801350 [01:45<05:18, 4222.59 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 459000/1801350 [01:45<05:13, 4285.91 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 458000/1801350 [01:45<05:04, 4404.99 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 457000/1801350 [01:45<04:59, 4490.51 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 460000/1801350 [01:45<05:14, 4258.75 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 459000/1801350 [01:45<05:08, 4347.71 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 458000/1801350 [01:45<04:59, 4485.80 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 461000/1801350 [01:46<05:14, 4261.68 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 460000/1801350 [01:45<07:13, 3094.03 examples/s]Grouping texts in chunks of 1024:  25%|██▌       | 459000/1801350 [01:45<05:09, 4339.54 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 461000/1801350 [01:45<06:35, 3390.78 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 462000/1801350 [01:46<05:15, 4244.91 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 460000/1801350 [01:45<07:19, 3050.98 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 463000/1801350 [01:46<05:20, 4181.50 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 462000/1801350 [01:46<06:19, 3526.13 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 461000/1801350 [01:46<06:38, 3359.40 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 464000/1801350 [01:46<05:20, 4169.81 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 463000/1801350 [01:46<06:02, 3686.92 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 460000/1801350 [01:46<07:49, 2859.76 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 462000/1801350 [01:46<06:11, 3608.43 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 465000/1801350 [01:47<05:12, 4278.06 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 464000/1801350 [01:46<05:51, 3807.07 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 461000/1801350 [01:46<06:58, 3202.68 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 463000/1801350 [01:46<06:01, 3702.10 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 465000/1801350 [01:46<05:24, 4114.21 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 466000/1801350 [01:47<05:11, 4288.20 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 462000/1801350 [01:46<06:30, 3433.64 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 464000/1801350 [01:46<05:42, 3904.50 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 466000/1801350 [01:46<05:23, 4133.15 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 467000/1801350 [01:47<05:15, 4231.12 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 463000/1801350 [01:47<06:10, 3607.90 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 465000/1801350 [01:47<05:27, 4080.23 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 468000/1801350 [01:47<05:08, 4321.19 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 467000/1801350 [01:47<05:42, 3893.87 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 464000/1801350 [01:47<05:57, 3740.03 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 466000/1801350 [01:47<05:24, 4115.35 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 469000/1801350 [01:47<05:05, 4354.21 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 468000/1801350 [01:47<05:18, 4192.04 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 465000/1801350 [01:47<05:31, 4030.56 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 467000/1801350 [01:47<05:14, 4248.94 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 469000/1801350 [01:47<05:07, 4327.87 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 470000/1801350 [01:48<05:18, 4175.17 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 466000/1801350 [01:47<05:26, 4090.40 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 468000/1801350 [01:47<05:12, 4270.61 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 471000/1801350 [01:48<05:13, 4248.78 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 470000/1801350 [01:47<05:19, 4164.27 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 467000/1801350 [01:47<05:22, 4137.00 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 469000/1801350 [01:47<05:08, 4320.32 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 471000/1801350 [01:48<05:00, 4423.00 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 472000/1801350 [01:48<05:09, 4297.29 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 468000/1801350 [01:48<05:23, 4116.52 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 470000/1801350 [01:48<05:12, 4261.63 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 472000/1801350 [01:48<05:05, 4348.83 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 473000/1801350 [01:48<05:13, 4233.55 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 469000/1801350 [01:48<05:15, 4224.73 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 471000/1801350 [01:48<05:04, 4371.83 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 473000/1801350 [01:48<05:04, 4363.81 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 474000/1801350 [01:49<05:16, 4192.60 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 470000/1801350 [01:48<05:15, 4219.85 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 472000/1801350 [01:48<05:09, 4297.35 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 475000/1801350 [01:49<05:00, 4421.14 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 474000/1801350 [01:48<05:09, 4293.25 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 471000/1801350 [01:48<05:06, 4341.30 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 473000/1801350 [01:48<05:09, 4286.62 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 476000/1801350 [01:49<04:50, 4556.32 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 475000/1801350 [01:49<04:57, 4453.60 examples/s]Grouping texts in chunks of 1024:  26%|██▌       | 472000/1801350 [01:49<05:09, 4294.25 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 474000/1801350 [01:49<05:11, 4266.63 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 476000/1801350 [01:49<04:39, 4739.39 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 477000/1801350 [01:49<05:04, 4342.19 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 473000/1801350 [01:49<05:06, 4332.42 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 475000/1801350 [01:49<04:59, 4435.16 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 477000/1801350 [01:49<05:05, 4329.21 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 478000/1801350 [01:50<05:08, 4293.68 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 476000/1801350 [01:49<04:40, 4729.79 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 474000/1801350 [01:49<05:11, 4266.36 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 478000/1801350 [01:49<04:59, 4417.42 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 479000/1801350 [01:50<04:51, 4540.75 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 475000/1801350 [01:49<04:56, 4478.98 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 477000/1801350 [01:49<05:02, 4380.41 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 479000/1801350 [01:49<04:46, 4612.94 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 480000/1801350 [01:50<04:53, 4503.33 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 476000/1801350 [01:49<04:45, 4648.24 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 478000/1801350 [01:50<05:05, 4332.53 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 480000/1801350 [01:50<04:53, 4500.79 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 481000/1801350 [01:50<05:00, 4394.12 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 479000/1801350 [01:50<04:48, 4588.67 examples/s]Grouping texts in chunks of 1024:  26%|██▋       | 477000/1801350 [01:50<05:02, 4370.81 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 481000/1801350 [01:50<04:56, 4455.89 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 482000/1801350 [01:50<05:02, 4363.54 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 480000/1801350 [01:50<04:56, 4453.81 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 478000/1801350 [01:50<05:06, 4320.99 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 482000/1801350 [01:50<05:03, 4340.04 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 483000/1801350 [01:51<05:07, 4283.20 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 479000/1801350 [01:50<04:48, 4579.56 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 481000/1801350 [01:50<04:53, 4492.61 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 483000/1801350 [01:50<04:51, 4518.58 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 484000/1801350 [01:51<05:13, 4207.71 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 480000/1801350 [01:50<04:54, 4491.53 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 482000/1801350 [01:50<05:05, 4322.99 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 484000/1801350 [01:51<05:09, 4258.86 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 485000/1801350 [01:51<04:56, 4438.52 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 481000/1801350 [01:51<05:00, 4395.45 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 483000/1801350 [01:51<05:00, 4393.39 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 485000/1801350 [01:51<04:48, 4567.18 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 486000/1801350 [01:51<04:47, 4572.65 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 482000/1801350 [01:51<05:03, 4340.43 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 484000/1801350 [01:51<05:10, 4245.79 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 486000/1801350 [01:51<04:51, 4507.92 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 487000/1801350 [01:52<05:03, 4323.56 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 483000/1801350 [01:51<04:59, 4406.50 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 485000/1801350 [01:51<04:50, 4538.50 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 487000/1801350 [01:51<05:01, 4359.33 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 488000/1801350 [01:52<05:06, 4286.00 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 486000/1801350 [01:51<04:48, 4558.15 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 484000/1801350 [01:51<05:11, 4228.32 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 488000/1801350 [01:51<05:01, 4350.75 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 489000/1801350 [01:52<05:00, 4373.82 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 485000/1801350 [01:52<04:51, 4519.67 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 487000/1801350 [01:52<05:05, 4300.08 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 489000/1801350 [01:52<04:55, 4447.21 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 490000/1801350 [01:52<05:11, 4215.34 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 486000/1801350 [01:52<04:50, 4532.34 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 488000/1801350 [01:52<05:02, 4335.90 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 490000/1801350 [01:52<05:09, 4230.20 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 491000/1801350 [01:53<05:13, 4178.81 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 487000/1801350 [01:52<05:04, 4318.07 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 489000/1801350 [01:52<05:01, 4354.89 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 491000/1801350 [01:52<05:05, 4283.00 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 492000/1801350 [01:53<05:13, 4175.01 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 488000/1801350 [01:52<05:02, 4334.97 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 490000/1801350 [01:52<05:06, 4279.58 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 492000/1801350 [01:52<05:06, 4266.49 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 493000/1801350 [01:53<05:04, 4301.00 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 489000/1801350 [01:52<05:06, 4281.55 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 491000/1801350 [01:53<05:12, 4197.45 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 493000/1801350 [01:53<05:04, 4302.75 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 494000/1801350 [01:53<05:12, 4176.95 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 490000/1801350 [01:53<05:08, 4252.00 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 492000/1801350 [01:53<05:07, 4260.58 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 494000/1801350 [01:53<05:08, 4236.12 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 495000/1801350 [01:53<04:52, 4460.00 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 491000/1801350 [01:53<05:13, 4179.29 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 493000/1801350 [01:53<05:08, 4243.16 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 495000/1801350 [01:53<04:48, 4531.77 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 496000/1801350 [01:54<04:56, 4401.44 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 492000/1801350 [01:53<05:01, 4342.18 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 494000/1801350 [01:53<05:03, 4307.40 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 496000/1801350 [01:53<04:55, 4424.42 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 497000/1801350 [01:54<05:00, 4336.47 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 495000/1801350 [01:53<04:48, 4522.24 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 493000/1801350 [01:53<05:07, 4249.01 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 497000/1801350 [01:54<04:59, 4358.10 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 498000/1801350 [01:54<04:54, 4429.46 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 496000/1801350 [01:54<04:52, 4458.38 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 494000/1801350 [01:54<05:08, 4240.07 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 498000/1801350 [01:54<04:45, 4560.02 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 499000/1801350 [01:54<04:58, 4369.88 examples/s]Grouping texts in chunks of 1024:  27%|██▋       | 495000/1801350 [01:54<04:50, 4492.48 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 497000/1801350 [01:54<04:52, 4465.51 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 499000/1801350 [01:54<04:56, 4388.08 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 500000/1801350 [01:55<04:44, 4571.69 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 496000/1801350 [01:54<04:51, 4477.79 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 498000/1801350 [01:54<04:53, 4442.61 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 500000/1801350 [01:54<04:40, 4643.02 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 501000/1801350 [01:55<04:48, 4509.29 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 499000/1801350 [01:54<04:54, 4425.00 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 497000/1801350 [01:54<05:00, 4342.63 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 501000/1801350 [01:54<04:45, 4549.21 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 502000/1801350 [01:55<05:00, 4318.91 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 500000/1801350 [01:55<04:42, 4602.10 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 498000/1801350 [01:55<04:52, 4462.32 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 502000/1801350 [01:55<04:59, 4340.80 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 501000/1801350 [01:55<04:43, 4579.26 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 503000/1801350 [01:55<05:06, 4235.08 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 499000/1801350 [01:55<04:51, 4466.57 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 503000/1801350 [01:55<05:01, 4310.77 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 500000/1801350 [01:55<04:46, 4548.66 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 504000/1801350 [01:56<05:05, 4246.97 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 502000/1801350 [01:55<05:01, 4316.08 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 504000/1801350 [01:55<05:10, 4176.36 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 501000/1801350 [01:55<04:46, 4534.95 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 505000/1801350 [01:56<05:04, 4258.38 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 503000/1801350 [01:55<05:04, 4265.91 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 505000/1801350 [01:55<05:02, 4282.43 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 506000/1801350 [01:56<04:56, 4374.27 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 502000/1801350 [01:55<04:57, 4370.06 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 504000/1801350 [01:55<05:02, 4283.40 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 506000/1801350 [01:56<04:54, 4402.97 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 507000/1801350 [01:56<04:52, 4422.20 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 503000/1801350 [01:56<05:01, 4307.37 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 505000/1801350 [01:56<04:58, 4339.84 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 507000/1801350 [01:56<04:51, 4447.64 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 506000/1801350 [01:56<04:54, 4396.29 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 508000/1801350 [01:56<05:15, 4104.42 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 504000/1801350 [01:56<05:09, 4185.69 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 508000/1801350 [01:56<05:12, 4141.33 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 507000/1801350 [01:56<04:47, 4509.45 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 505000/1801350 [01:56<05:02, 4280.19 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 509000/1801350 [01:57<05:11, 4152.34 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 509000/1801350 [01:56<05:01, 4293.28 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 510000/1801350 [01:57<04:52, 4413.01 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 506000/1801350 [01:56<04:54, 4392.55 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 508000/1801350 [01:56<05:03, 4255.05 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 510000/1801350 [01:56<04:47, 4488.54 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 507000/1801350 [01:57<04:48, 4482.99 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 511000/1801350 [01:57<04:54, 4375.74 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 509000/1801350 [01:57<05:07, 4207.23 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 511000/1801350 [01:57<04:57, 4337.07 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 512000/1801350 [01:57<04:58, 4324.11 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 510000/1801350 [01:57<04:54, 4388.19 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 508000/1801350 [01:57<05:10, 4165.48 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 512000/1801350 [01:57<04:45, 4510.95 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 513000/1801350 [01:58<04:42, 4564.71 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 511000/1801350 [01:57<04:52, 4412.12 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 509000/1801350 [01:57<05:05, 4227.58 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 513000/1801350 [01:57<04:43, 4539.33 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 514000/1801350 [01:58<04:51, 4410.65 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 512000/1801350 [01:57<04:47, 4478.02 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 510000/1801350 [01:57<04:51, 4428.04 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 514000/1801350 [01:57<04:48, 4461.03 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 513000/1801350 [01:57<04:37, 4642.75 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 515000/1801350 [01:58<04:56, 4337.27 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 511000/1801350 [01:58<04:56, 4347.70 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 515000/1801350 [01:58<04:52, 4402.95 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 514000/1801350 [01:58<04:54, 4365.65 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 516000/1801350 [01:58<05:00, 4271.09 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 512000/1801350 [01:58<04:52, 4413.26 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 516000/1801350 [01:58<04:52, 4387.64 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 515000/1801350 [01:58<04:54, 4370.23 examples/s]Grouping texts in chunks of 1024:  28%|██▊       | 513000/1801350 [01:58<04:48, 4462.10 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 517000/1801350 [01:59<05:13, 4096.01 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 517000/1801350 [01:58<05:04, 4224.03 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 516000/1801350 [01:58<04:52, 4390.30 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 518000/1801350 [01:59<04:54, 4356.38 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 514000/1801350 [01:58<04:53, 4382.66 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 518000/1801350 [01:58<04:51, 4404.68 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 515000/1801350 [01:58<04:53, 4383.98 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 519000/1801350 [01:59<04:57, 4316.60 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 517000/1801350 [01:58<05:05, 4200.98 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 519000/1801350 [01:59<04:59, 4283.76 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 518000/1801350 [01:59<04:51, 4406.02 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 520000/1801350 [01:59<04:53, 4372.00 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 516000/1801350 [01:59<04:54, 4364.40 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 520000/1801350 [01:59<04:53, 4371.95 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 519000/1801350 [01:59<04:55, 4336.79 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 521000/1801350 [01:59<04:54, 4347.75 examples/s]Grouping texts in chunks of 1024:  29%|██▊       | 517000/1801350 [01:59<05:02, 4241.44 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 521000/1801350 [01:59<04:50, 4410.07 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 522000/1801350 [02:00<04:49, 4413.52 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 518000/1801350 [01:59<04:51, 4407.96 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 520000/1801350 [01:59<04:58, 4295.61 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 522000/1801350 [01:59<04:43, 4519.75 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 521000/1801350 [01:59<04:55, 4335.45 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 523000/1801350 [02:00<05:01, 4233.02 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 519000/1801350 [01:59<05:01, 4256.90 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 523000/1801350 [01:59<04:56, 4308.06 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 522000/1801350 [02:00<04:47, 4457.14 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 520000/1801350 [02:00<04:50, 4417.50 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 524000/1801350 [02:00<04:57, 4291.43 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 524000/1801350 [02:00<04:52, 4369.87 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 521000/1801350 [02:00<04:53, 4358.91 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 523000/1801350 [02:00<05:02, 4230.02 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 525000/1801350 [02:00<05:01, 4230.61 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 525000/1801350 [02:00<05:01, 4233.03 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 522000/1801350 [02:00<04:40, 4560.16 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 524000/1801350 [02:00<04:55, 4326.43 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 526000/1801350 [02:01<05:02, 4209.19 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 526000/1801350 [02:00<04:55, 4320.27 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 527000/1801350 [02:01<04:46, 4452.26 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 525000/1801350 [02:00<04:56, 4306.16 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 523000/1801350 [02:00<05:02, 4227.49 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 527000/1801350 [02:00<04:48, 4417.00 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 524000/1801350 [02:01<04:56, 4306.11 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 526000/1801350 [02:01<05:02, 4217.79 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 528000/1801350 [02:01<05:05, 4170.33 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 528000/1801350 [02:01<05:01, 4230.05 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 527000/1801350 [02:01<04:45, 4459.17 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 525000/1801350 [02:01<05:01, 4234.26 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 529000/1801350 [02:01<04:54, 4322.84 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 529000/1801350 [02:01<04:42, 4503.61 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 528000/1801350 [02:01<05:01, 4226.87 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 530000/1801350 [02:02<04:57, 4276.04 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 526000/1801350 [02:01<05:06, 4161.19 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 530000/1801350 [02:01<04:54, 4311.13 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 529000/1801350 [02:01<04:44, 4464.67 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 527000/1801350 [02:01<04:50, 4392.31 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 531000/1801350 [02:02<05:00, 4233.62 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 531000/1801350 [02:01<04:58, 4252.89 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 530000/1801350 [02:01<04:57, 4269.96 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 528000/1801350 [02:01<04:57, 4282.13 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 532000/1801350 [02:02<05:01, 4215.53 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 532000/1801350 [02:02<04:53, 4325.17 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 529000/1801350 [02:02<04:50, 4381.16 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 531000/1801350 [02:02<04:58, 4254.41 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 533000/1801350 [02:02<04:50, 4373.23 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 533000/1801350 [02:02<04:45, 4443.34 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 532000/1801350 [02:02<04:52, 4338.90 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 530000/1801350 [02:02<04:57, 4276.55 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 534000/1801350 [02:03<04:57, 4259.49 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 534000/1801350 [02:02<04:58, 4250.32 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 533000/1801350 [02:02<04:51, 4354.28 examples/s]Grouping texts in chunks of 1024:  29%|██▉       | 531000/1801350 [02:02<05:01, 4214.08 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 535000/1801350 [02:03<05:07, 4118.11 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 535000/1801350 [02:02<05:06, 4131.11 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 534000/1801350 [02:02<04:58, 4249.48 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 532000/1801350 [02:02<04:56, 4283.20 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 536000/1801350 [02:03<05:06, 4134.75 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 536000/1801350 [02:02<04:59, 4218.08 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 533000/1801350 [02:03<04:54, 4302.17 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 535000/1801350 [02:03<05:03, 4168.29 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 537000/1801350 [02:03<04:50, 4358.23 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 537000/1801350 [02:03<04:50, 4353.24 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 536000/1801350 [02:03<04:58, 4237.54 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 534000/1801350 [02:03<04:57, 4253.75 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 538000/1801350 [02:03<05:02, 4179.65 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 538000/1801350 [02:03<04:53, 4308.52 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 537000/1801350 [02:03<04:54, 4299.86 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 535000/1801350 [02:03<05:00, 4215.29 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 539000/1801350 [02:04<04:47, 4394.88 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 539000/1801350 [02:03<04:47, 4384.43 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 538000/1801350 [02:03<04:56, 4257.17 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 536000/1801350 [02:03<05:05, 4146.92 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 540000/1801350 [02:04<04:58, 4223.38 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 540000/1801350 [02:03<04:55, 4275.74 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 539000/1801350 [02:04<04:46, 4404.42 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 537000/1801350 [02:04<04:55, 4279.30 examples/s]Grouping texts in chunks of 1024:  30%|███       | 541000/1801350 [02:04<04:56, 4243.88 examples/s]Grouping texts in chunks of 1024:  30%|███       | 541000/1801350 [02:04<04:49, 4347.49 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 540000/1801350 [02:04<04:52, 4309.99 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 538000/1801350 [02:04<04:58, 4234.39 examples/s]Grouping texts in chunks of 1024:  30%|███       | 542000/1801350 [02:04<04:53, 4293.85 examples/s]Grouping texts in chunks of 1024:  30%|███       | 542000/1801350 [02:04<04:48, 4371.16 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 539000/1801350 [02:04<04:39, 4518.44 examples/s]Grouping texts in chunks of 1024:  30%|███       | 541000/1801350 [02:04<04:56, 4245.05 examples/s]Grouping texts in chunks of 1024:  30%|███       | 543000/1801350 [02:05<04:40, 4487.10 examples/s]Grouping texts in chunks of 1024:  30%|███       | 543000/1801350 [02:04<04:37, 4527.85 examples/s]Grouping texts in chunks of 1024:  30%|███       | 542000/1801350 [02:04<04:47, 4377.80 examples/s]Grouping texts in chunks of 1024:  30%|███       | 544000/1801350 [02:05<04:47, 4378.67 examples/s]Grouping texts in chunks of 1024:  30%|██▉       | 540000/1801350 [02:04<05:01, 4181.50 examples/s]Grouping texts in chunks of 1024:  30%|███       | 544000/1801350 [02:04<04:39, 4503.64 examples/s]Grouping texts in chunks of 1024:  30%|███       | 543000/1801350 [02:04<04:41, 4463.27 examples/s]Grouping texts in chunks of 1024:  30%|███       | 541000/1801350 [02:04<04:55, 4267.53 examples/s]Grouping texts in chunks of 1024:  30%|███       | 545000/1801350 [02:05<04:55, 4252.39 examples/s]Grouping texts in chunks of 1024:  30%|███       | 545000/1801350 [02:05<04:57, 4218.32 examples/s]Grouping texts in chunks of 1024:  30%|███       | 544000/1801350 [02:05<04:42, 4445.28 examples/s]Grouping texts in chunks of 1024:  30%|███       | 542000/1801350 [02:05<04:51, 4326.97 examples/s]Grouping texts in chunks of 1024:  30%|███       | 546000/1801350 [02:05<04:54, 4257.50 examples/s]Grouping texts in chunks of 1024:  30%|███       | 546000/1801350 [02:05<04:57, 4224.99 examples/s]Grouping texts in chunks of 1024:  30%|███       | 543000/1801350 [02:05<04:39, 4500.11 examples/s]Grouping texts in chunks of 1024:  30%|███       | 545000/1801350 [02:05<04:55, 4244.76 examples/s]Grouping texts in chunks of 1024:  30%|███       | 547000/1801350 [02:05<04:50, 4324.48 examples/s]Grouping texts in chunks of 1024:  30%|███       | 547000/1801350 [02:06<04:56, 4230.25 examples/s]Grouping texts in chunks of 1024:  30%|███       | 546000/1801350 [02:05<04:51, 4301.73 examples/s]Grouping texts in chunks of 1024:  30%|███       | 544000/1801350 [02:05<04:49, 4339.00 examples/s]Grouping texts in chunks of 1024:  30%|███       | 548000/1801350 [02:05<04:42, 4432.74 examples/s]Grouping texts in chunks of 1024:  30%|███       | 548000/1801350 [02:06<04:48, 4340.29 examples/s]Grouping texts in chunks of 1024:  30%|███       | 547000/1801350 [02:05<04:49, 4334.68 examples/s]Grouping texts in chunks of 1024:  30%|███       | 549000/1801350 [02:05<04:34, 4567.19 examples/s]Grouping texts in chunks of 1024:  30%|███       | 545000/1801350 [02:05<04:51, 4305.69 examples/s]Grouping texts in chunks of 1024:  30%|███       | 549000/1801350 [02:06<04:41, 4446.04 examples/s]Grouping texts in chunks of 1024:  30%|███       | 548000/1801350 [02:06<04:43, 4426.53 examples/s]Grouping texts in chunks of 1024:  31%|███       | 550000/1801350 [02:06<04:36, 4518.85 examples/s]Grouping texts in chunks of 1024:  31%|███       | 550000/1801350 [02:06<04:39, 4482.96 examples/s]Grouping texts in chunks of 1024:  30%|███       | 546000/1801350 [02:06<04:53, 4277.36 examples/s]Grouping texts in chunks of 1024:  30%|███       | 549000/1801350 [02:06<04:42, 4438.82 examples/s]Grouping texts in chunks of 1024:  31%|███       | 551000/1801350 [02:06<04:38, 4488.33 examples/s]Grouping texts in chunks of 1024:  31%|███       | 551000/1801350 [02:06<04:41, 4434.91 examples/s]Grouping texts in chunks of 1024:  30%|███       | 547000/1801350 [02:06<04:55, 4241.86 examples/s]Grouping texts in chunks of 1024:  31%|███       | 550000/1801350 [02:06<04:42, 4437.36 examples/s]Grouping texts in chunks of 1024:  31%|███       | 552000/1801350 [02:07<04:39, 4477.80 examples/s]Grouping texts in chunks of 1024:  31%|███       | 552000/1801350 [02:06<04:38, 4479.81 examples/s]Grouping texts in chunks of 1024:  30%|███       | 548000/1801350 [02:06<04:43, 4419.59 examples/s]Grouping texts in chunks of 1024:  31%|███       | 551000/1801350 [02:06<04:35, 4532.02 examples/s]Grouping texts in chunks of 1024:  30%|███       | 549000/1801350 [02:06<04:43, 4419.66 examples/s]Grouping texts in chunks of 1024:  31%|███       | 553000/1801350 [02:07<04:47, 4343.71 examples/s]Grouping texts in chunks of 1024:  31%|███       | 553000/1801350 [02:06<04:46, 4362.22 examples/s]Grouping texts in chunks of 1024:  31%|███       | 552000/1801350 [02:07<04:42, 4415.84 examples/s]Grouping texts in chunks of 1024:  31%|███       | 550000/1801350 [02:07<04:36, 4518.89 examples/s]Grouping texts in chunks of 1024:  31%|███       | 554000/1801350 [02:07<04:42, 4410.17 examples/s]Grouping texts in chunks of 1024:  31%|███       | 554000/1801350 [02:07<04:58, 4179.40 examples/s]Grouping texts in chunks of 1024:  31%|███       | 553000/1801350 [02:07<04:52, 4274.97 examples/s]Grouping texts in chunks of 1024:  31%|███       | 551000/1801350 [02:07<04:43, 4404.26 examples/s]Grouping texts in chunks of 1024:  31%|███       | 555000/1801350 [02:07<04:53, 4253.60 examples/s]Grouping texts in chunks of 1024:  31%|███       | 555000/1801350 [02:07<05:00, 4152.84 examples/s]Grouping texts in chunks of 1024:  31%|███       | 554000/1801350 [02:07<04:48, 4323.84 examples/s]Grouping texts in chunks of 1024:  31%|███       | 552000/1801350 [02:07<04:46, 4361.32 examples/s]Grouping texts in chunks of 1024:  31%|███       | 556000/1801350 [02:07<04:47, 4325.16 examples/s]Grouping texts in chunks of 1024:  31%|███       | 556000/1801350 [02:08<04:58, 4165.14 examples/s]Grouping texts in chunks of 1024:  31%|███       | 555000/1801350 [02:07<04:50, 4285.44 examples/s]Grouping texts in chunks of 1024:  31%|███       | 557000/1801350 [02:07<04:43, 4386.39 examples/s]Grouping texts in chunks of 1024:  31%|███       | 553000/1801350 [02:07<04:53, 4250.32 examples/s]Grouping texts in chunks of 1024:  31%|███       | 557000/1801350 [02:08<04:49, 4302.18 examples/s]Grouping texts in chunks of 1024:  31%|███       | 556000/1801350 [02:07<04:50, 4290.45 examples/s]Grouping texts in chunks of 1024:  31%|███       | 554000/1801350 [02:07<04:49, 4309.76 examples/s]Grouping texts in chunks of 1024:  31%|███       | 558000/1801350 [02:07<04:46, 4338.88 examples/s]Grouping texts in chunks of 1024:  31%|███       | 558000/1801350 [02:08<04:53, 4243.17 examples/s]Grouping texts in chunks of 1024:  31%|███       | 557000/1801350 [02:08<04:41, 4414.57 examples/s]Grouping texts in chunks of 1024:  31%|███       | 555000/1801350 [02:08<04:56, 4197.25 examples/s]Grouping texts in chunks of 1024:  31%|███       | 559000/1801350 [02:08<04:59, 4146.12 examples/s]Grouping texts in chunks of 1024:  31%|███       | 559000/1801350 [02:08<05:04, 4078.06 examples/s]Grouping texts in chunks of 1024:  31%|███       | 558000/1801350 [02:08<04:50, 4274.65 examples/s]Grouping texts in chunks of 1024:  31%|███       | 556000/1801350 [02:08<04:49, 4308.75 examples/s]Grouping texts in chunks of 1024:  31%|███       | 560000/1801350 [02:08<04:57, 4178.26 examples/s]Grouping texts in chunks of 1024:  31%|███       | 560000/1801350 [02:09<05:08, 4027.41 examples/s]Grouping texts in chunks of 1024:  31%|███       | 557000/1801350 [02:08<04:41, 4413.38 examples/s]Grouping texts in chunks of 1024:  31%|███       | 559000/1801350 [02:08<05:01, 4114.76 examples/s]Grouping texts in chunks of 1024:  31%|███       | 561000/1801350 [02:08<04:57, 4167.36 examples/s]Grouping texts in chunks of 1024:  31%|███       | 561000/1801350 [02:09<04:56, 4188.29 examples/s]Grouping texts in chunks of 1024:  31%|███       | 558000/1801350 [02:08<04:46, 4347.14 examples/s]Grouping texts in chunks of 1024:  31%|███       | 560000/1801350 [02:08<05:04, 4074.33 examples/s]Grouping texts in chunks of 1024:  31%|███       | 562000/1801350 [02:08<04:46, 4331.72 examples/s]Grouping texts in chunks of 1024:  31%|███       | 562000/1801350 [02:09<04:52, 4243.29 examples/s]Grouping texts in chunks of 1024:  31%|███       | 561000/1801350 [02:09<04:57, 4163.01 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 563000/1801350 [02:09<04:40, 4416.07 examples/s]Grouping texts in chunks of 1024:  31%|███       | 559000/1801350 [02:09<05:00, 4131.35 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 563000/1801350 [02:09<04:36, 4485.84 examples/s]Grouping texts in chunks of 1024:  31%|███       | 562000/1801350 [02:09<04:44, 4356.59 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 564000/1801350 [02:09<04:42, 4376.06 examples/s]Grouping texts in chunks of 1024:  31%|███       | 560000/1801350 [02:09<04:58, 4158.09 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 564000/1801350 [02:09<04:42, 4383.14 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 563000/1801350 [02:09<04:33, 4525.81 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 565000/1801350 [02:09<04:50, 4252.99 examples/s]Grouping texts in chunks of 1024:  31%|███       | 561000/1801350 [02:09<04:56, 4188.85 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 565000/1801350 [02:10<04:57, 4150.07 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 564000/1801350 [02:09<04:41, 4401.66 examples/s]Grouping texts in chunks of 1024:  31%|███       | 562000/1801350 [02:09<04:50, 4264.96 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 566000/1801350 [02:09<04:45, 4333.97 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 566000/1801350 [02:10<04:56, 4162.63 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 565000/1801350 [02:10<04:54, 4192.70 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 563000/1801350 [02:10<04:38, 4443.73 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 567000/1801350 [02:10<05:00, 4111.41 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 567000/1801350 [02:10<05:06, 4027.45 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 566000/1801350 [02:10<04:52, 4217.89 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 564000/1801350 [02:10<04:37, 4461.48 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 568000/1801350 [02:10<04:45, 4324.91 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 568000/1801350 [02:10<04:52, 4212.08 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 569000/1801350 [02:10<04:37, 4435.73 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 567000/1801350 [02:10<05:02, 4084.91 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 565000/1801350 [02:10<05:00, 4114.19 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 569000/1801350 [02:11<04:41, 4383.05 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 568000/1801350 [02:10<04:45, 4322.36 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 570000/1801350 [02:10<04:40, 4387.96 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 566000/1801350 [02:10<04:54, 4195.23 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 570000/1801350 [02:11<04:42, 4357.97 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 571000/1801350 [02:10<04:25, 4634.23 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 569000/1801350 [02:10<04:39, 4401.50 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 571000/1801350 [02:11<04:31, 4539.23 examples/s]Grouping texts in chunks of 1024:  31%|███▏      | 567000/1801350 [02:11<05:02, 4074.46 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 572000/1801350 [02:11<04:17, 4774.60 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 570000/1801350 [02:11<04:33, 4504.53 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 572000/1801350 [02:11<04:22, 4683.32 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 568000/1801350 [02:11<04:45, 4312.87 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 571000/1801350 [02:11<04:28, 4589.33 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 573000/1801350 [02:11<04:34, 4479.78 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 569000/1801350 [02:11<04:40, 4401.16 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 573000/1801350 [02:12<04:38, 4406.29 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 572000/1801350 [02:11<04:18, 4747.91 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 574000/1801350 [02:11<04:29, 4551.44 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 570000/1801350 [02:11<04:36, 4455.74 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 574000/1801350 [02:12<04:38, 4399.80 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 573000/1801350 [02:11<04:32, 4504.95 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 575000/1801350 [02:11<04:49, 4238.77 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 571000/1801350 [02:11<04:32, 4516.17 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 575000/1801350 [02:12<04:48, 4255.09 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 574000/1801350 [02:12<04:35, 4453.31 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 572000/1801350 [02:12<04:23, 4667.08 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 576000/1801350 [02:12<04:46, 4270.76 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 576000/1801350 [02:12<04:47, 4267.37 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 575000/1801350 [02:12<04:44, 4313.28 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 573000/1801350 [02:12<04:31, 4531.32 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 577000/1801350 [02:12<04:42, 4328.31 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 577000/1801350 [02:13<04:44, 4301.82 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 576000/1801350 [02:12<04:47, 4264.87 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 574000/1801350 [02:12<04:32, 4511.78 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 578000/1801350 [02:12<04:43, 4319.09 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 578000/1801350 [02:13<04:54, 4149.23 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 577000/1801350 [02:12<04:47, 4265.96 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 575000/1801350 [02:12<04:46, 4285.52 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 579000/1801350 [02:12<04:52, 4176.40 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 579000/1801350 [02:13<04:53, 4164.37 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 578000/1801350 [02:13<04:51, 4190.02 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 580000/1801350 [02:13<04:37, 4398.54 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 576000/1801350 [02:13<04:50, 4216.28 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 580000/1801350 [02:13<04:35, 4441.00 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 581000/1801350 [02:13<04:34, 4450.42 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 579000/1801350 [02:13<04:50, 4205.95 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 577000/1801350 [02:13<04:42, 4329.73 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 581000/1801350 [02:13<04:43, 4303.84 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 580000/1801350 [02:13<04:35, 4434.88 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 582000/1801350 [02:13<04:33, 4459.33 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 578000/1801350 [02:13<04:55, 4143.53 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 582000/1801350 [02:14<04:35, 4421.34 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 583000/1801350 [02:13<04:30, 4508.19 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 581000/1801350 [02:13<04:40, 4345.53 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 579000/1801350 [02:13<04:49, 4219.48 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 583000/1801350 [02:14<04:29, 4527.95 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 584000/1801350 [02:13<04:14, 4789.17 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 582000/1801350 [02:13<04:28, 4536.42 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 580000/1801350 [02:13<04:37, 4397.00 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 584000/1801350 [02:14<04:26, 4567.19 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 585000/1801350 [02:14<04:15, 4761.53 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 583000/1801350 [02:14<04:25, 4584.64 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 585000/1801350 [02:14<04:17, 4732.47 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 581000/1801350 [02:14<04:40, 4349.61 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 584000/1801350 [02:14<04:16, 4742.15 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 586000/1801350 [02:14<04:23, 4603.71 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 582000/1801350 [02:14<04:31, 4487.14 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 586000/1801350 [02:15<04:21, 4643.26 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 585000/1801350 [02:14<04:14, 4782.35 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 587000/1801350 [02:14<04:34, 4417.50 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 583000/1801350 [02:14<04:29, 4513.47 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 587000/1801350 [02:15<04:31, 4480.91 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 586000/1801350 [02:14<04:23, 4611.71 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 588000/1801350 [02:14<04:39, 4335.04 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 584000/1801350 [02:14<04:16, 4742.61 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 588000/1801350 [02:15<04:44, 4258.48 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 587000/1801350 [02:15<04:30, 4484.74 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 589000/1801350 [02:15<04:35, 4405.80 examples/s]Grouping texts in chunks of 1024:  32%|███▏      | 585000/1801350 [02:15<04:12, 4818.55 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 589000/1801350 [02:15<04:39, 4343.74 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 588000/1801350 [02:15<04:43, 4276.25 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 590000/1801350 [02:15<04:30, 4476.67 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 586000/1801350 [02:15<04:25, 4580.00 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 590000/1801350 [02:15<04:39, 4337.46 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 589000/1801350 [02:15<04:36, 4388.94 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 591000/1801350 [02:15<04:34, 4411.94 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 587000/1801350 [02:15<04:31, 4466.56 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 591000/1801350 [02:16<04:34, 4404.04 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 590000/1801350 [02:15<04:27, 4528.16 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 592000/1801350 [02:15<04:32, 4434.16 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 588000/1801350 [02:15<04:42, 4291.41 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 592000/1801350 [02:16<04:40, 4309.26 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 591000/1801350 [02:15<04:35, 4396.53 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 593000/1801350 [02:15<04:50, 4161.71 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 589000/1801350 [02:15<04:36, 4388.96 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 593000/1801350 [02:16<04:47, 4201.52 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 592000/1801350 [02:16<04:33, 4429.69 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 594000/1801350 [02:16<04:35, 4386.44 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 590000/1801350 [02:16<04:39, 4332.73 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 594000/1801350 [02:16<04:44, 4245.54 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 593000/1801350 [02:16<04:44, 4254.17 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 595000/1801350 [02:16<04:32, 4432.70 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 591000/1801350 [02:16<04:35, 4394.31 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 595000/1801350 [02:17<04:37, 4345.06 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 594000/1801350 [02:16<04:40, 4300.73 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 596000/1801350 [02:16<04:37, 4339.40 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 592000/1801350 [02:16<04:36, 4367.40 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 596000/1801350 [02:17<04:45, 4222.96 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 595000/1801350 [02:16<04:33, 4408.68 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 597000/1801350 [02:16<04:35, 4363.62 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 593000/1801350 [02:16<04:44, 4241.38 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 597000/1801350 [02:17<04:39, 4312.49 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 596000/1801350 [02:17<04:43, 4254.93 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 598000/1801350 [02:17<04:41, 4280.26 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 594000/1801350 [02:17<04:38, 4328.52 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 598000/1801350 [02:17<04:45, 4210.73 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 597000/1801350 [02:17<04:34, 4385.53 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 599000/1801350 [02:17<04:42, 4260.91 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 595000/1801350 [02:17<04:32, 4426.62 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 599000/1801350 [02:18<04:44, 4226.44 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 598000/1801350 [02:17<04:39, 4301.07 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 600000/1801350 [02:17<04:30, 4439.95 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 596000/1801350 [02:17<04:48, 4174.31 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 600000/1801350 [02:18<04:32, 4401.84 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 599000/1801350 [02:17<04:39, 4295.53 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 601000/1801350 [02:17<04:35, 4354.57 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 601000/1801350 [02:18<04:29, 4460.98 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 602000/1801350 [02:17<04:26, 4505.23 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 597000/1801350 [02:18<05:39, 3545.06 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 600000/1801350 [02:18<04:57, 4039.37 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 602000/1801350 [02:18<04:27, 4488.77 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 603000/1801350 [02:18<04:24, 4522.25 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 598000/1801350 [02:18<05:11, 3861.99 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 601000/1801350 [02:18<04:35, 4351.56 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 604000/1801350 [02:18<04:18, 4635.54 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 603000/1801350 [02:18<04:40, 4278.38 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 599000/1801350 [02:18<05:01, 3982.57 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 602000/1801350 [02:18<04:58, 4013.29 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 604000/1801350 [02:19<04:31, 4415.73 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 605000/1801350 [02:18<04:20, 4584.32 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 600000/1801350 [02:18<04:40, 4276.16 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 603000/1801350 [02:18<04:52, 4091.76 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 605000/1801350 [02:19<04:31, 4405.97 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 601000/1801350 [02:18<04:45, 4208.35 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 606000/1801350 [02:18<04:37, 4306.04 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 604000/1801350 [02:18<04:37, 4313.33 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 606000/1801350 [02:19<04:37, 4315.10 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 607000/1801350 [02:19<04:26, 4479.63 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 602000/1801350 [02:19<04:58, 4013.64 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 605000/1801350 [02:19<04:39, 4287.33 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 607000/1801350 [02:19<04:33, 4371.41 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 608000/1801350 [02:19<04:29, 4425.76 examples/s]Grouping texts in chunks of 1024:  33%|███▎      | 603000/1801350 [02:19<04:50, 4132.23 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 606000/1801350 [02:19<04:38, 4292.74 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 608000/1801350 [02:20<04:36, 4323.46 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 609000/1801350 [02:19<04:40, 4250.17 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 604000/1801350 [02:19<04:44, 4209.99 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 607000/1801350 [02:19<04:27, 4466.51 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 610000/1801350 [02:19<04:27, 4451.52 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 609000/1801350 [02:20<04:50, 4107.95 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 605000/1801350 [02:19<04:40, 4267.39 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 608000/1801350 [02:19<04:40, 4261.50 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 611000/1801350 [02:20<04:25, 4484.55 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 610000/1801350 [02:20<04:35, 4328.36 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 606000/1801350 [02:20<04:41, 4250.70 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 609000/1801350 [02:20<04:43, 4207.51 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 612000/1801350 [02:20<04:27, 4450.25 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 611000/1801350 [02:20<04:30, 4404.12 examples/s]Grouping texts in chunks of 1024:  34%|███▎      | 607000/1801350 [02:20<04:30, 4413.16 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 610000/1801350 [02:20<04:36, 4312.66 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 612000/1801350 [02:21<04:27, 4448.37 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 613000/1801350 [02:20<04:29, 4412.90 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 608000/1801350 [02:20<04:38, 4278.53 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 611000/1801350 [02:20<04:29, 4420.65 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 613000/1801350 [02:21<04:34, 4334.26 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 614000/1801350 [02:20<04:36, 4298.30 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 612000/1801350 [02:20<04:23, 4507.57 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 609000/1801350 [02:20<04:51, 4086.83 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 614000/1801350 [02:21<04:39, 4247.63 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 615000/1801350 [02:20<04:44, 4174.17 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 610000/1801350 [02:20<04:31, 4391.43 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 613000/1801350 [02:21<04:28, 4431.57 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 615000/1801350 [02:21<04:41, 4209.74 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 616000/1801350 [02:21<04:43, 4182.66 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 611000/1801350 [02:21<04:32, 4371.42 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 614000/1801350 [02:21<04:38, 4269.16 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 617000/1801350 [02:21<04:17, 4591.90 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 612000/1801350 [02:21<04:26, 4463.94 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 616000/1801350 [02:22<04:54, 4027.66 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 615000/1801350 [02:21<04:41, 4210.03 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 618000/1801350 [02:21<04:17, 4599.52 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 617000/1801350 [02:22<04:23, 4502.85 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 613000/1801350 [02:21<04:28, 4427.50 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 616000/1801350 [02:21<04:45, 4154.67 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 619000/1801350 [02:21<04:06, 4788.38 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 618000/1801350 [02:22<04:14, 4643.96 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 614000/1801350 [02:21<04:37, 4286.30 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 617000/1801350 [02:21<04:25, 4458.50 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 620000/1801350 [02:21<04:00, 4909.71 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 619000/1801350 [02:22<04:14, 4653.85 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 618000/1801350 [02:22<04:12, 4678.73 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 621000/1801350 [02:22<03:58, 4942.96 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 615000/1801350 [02:22<04:46, 4144.72 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 620000/1801350 [02:22<03:59, 4926.33 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 619000/1801350 [02:22<04:08, 4752.57 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 622000/1801350 [02:22<04:12, 4676.41 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 616000/1801350 [02:22<04:45, 4152.65 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 621000/1801350 [02:23<04:03, 4851.71 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 620000/1801350 [02:22<03:53, 5068.28 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 617000/1801350 [02:22<04:17, 4599.75 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 623000/1801350 [02:22<04:09, 4726.66 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 622000/1801350 [02:23<04:14, 4640.25 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 621000/1801350 [02:22<03:55, 5018.48 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 618000/1801350 [02:22<04:17, 4592.64 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 624000/1801350 [02:22<04:16, 4584.11 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 623000/1801350 [02:23<04:15, 4611.72 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 622000/1801350 [02:22<04:15, 4607.34 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 619000/1801350 [02:22<04:08, 4751.25 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 625000/1801350 [02:23<04:12, 4651.81 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 624000/1801350 [02:23<04:20, 4518.93 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 623000/1801350 [02:23<04:10, 4711.84 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 620000/1801350 [02:23<04:04, 4841.46 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 626000/1801350 [02:23<04:08, 4722.69 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 625000/1801350 [02:23<04:22, 4475.61 examples/s]Grouping texts in chunks of 1024:  34%|███▍      | 621000/1801350 [02:23<03:57, 4970.35 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 624000/1801350 [02:23<04:12, 4657.44 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 627000/1801350 [02:23<04:24, 4435.38 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 626000/1801350 [02:24<04:08, 4726.42 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 625000/1801350 [02:23<04:17, 4572.67 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 622000/1801350 [02:23<04:15, 4609.03 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 628000/1801350 [02:23<04:27, 4380.96 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 627000/1801350 [02:24<04:27, 4384.49 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 626000/1801350 [02:23<04:06, 4768.32 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 623000/1801350 [02:23<04:16, 4593.39 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 629000/1801350 [02:23<04:17, 4560.21 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 628000/1801350 [02:24<04:25, 4415.55 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 627000/1801350 [02:24<04:23, 4457.36 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 624000/1801350 [02:24<04:16, 4583.00 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 630000/1801350 [02:24<04:21, 4475.88 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 629000/1801350 [02:24<04:21, 4487.94 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 628000/1801350 [02:24<04:23, 4448.54 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 625000/1801350 [02:24<04:19, 4541.75 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 631000/1801350 [02:24<04:16, 4563.45 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 630000/1801350 [02:25<04:22, 4458.27 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 626000/1801350 [02:24<04:10, 4695.06 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 629000/1801350 [02:24<04:18, 4542.97 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 632000/1801350 [02:24<04:03, 4798.23 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 631000/1801350 [02:25<04:17, 4538.61 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 630000/1801350 [02:24<04:22, 4470.71 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 627000/1801350 [02:24<04:20, 4499.81 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 633000/1801350 [02:24<04:06, 4749.21 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 632000/1801350 [02:25<04:14, 4596.84 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 631000/1801350 [02:24<04:22, 4462.65 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 628000/1801350 [02:24<04:24, 4441.51 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 634000/1801350 [02:25<04:07, 4719.84 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 633000/1801350 [02:25<04:08, 4700.64 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 632000/1801350 [02:25<04:05, 4765.75 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 629000/1801350 [02:25<04:21, 4489.34 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 635000/1801350 [02:25<04:12, 4625.33 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 634000/1801350 [02:25<04:10, 4667.39 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 633000/1801350 [02:25<04:09, 4686.21 examples/s]Grouping texts in chunks of 1024:  35%|███▍      | 630000/1801350 [02:25<04:27, 4373.20 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 636000/1801350 [02:25<04:10, 4650.05 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 634000/1801350 [02:25<04:01, 4828.62 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 635000/1801350 [02:26<04:21, 4458.26 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 631000/1801350 [02:25<04:24, 4423.04 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 637000/1801350 [02:25<04:22, 4428.12 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 636000/1801350 [02:26<04:15, 4569.33 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 635000/1801350 [02:25<04:14, 4583.72 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 632000/1801350 [02:25<04:10, 4660.96 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 638000/1801350 [02:25<04:16, 4537.95 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 636000/1801350 [02:26<04:14, 4576.47 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 637000/1801350 [02:26<04:28, 4332.29 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 633000/1801350 [02:26<04:10, 4658.77 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 639000/1801350 [02:26<04:12, 4605.75 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 638000/1801350 [02:26<04:24, 4402.30 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 637000/1801350 [02:26<04:19, 4489.66 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 634000/1801350 [02:26<04:04, 4767.94 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 640000/1801350 [02:26<04:31, 4277.66 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 639000/1801350 [02:27<04:17, 4518.14 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 638000/1801350 [02:26<04:22, 4432.74 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 635000/1801350 [02:26<04:15, 4567.52 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 641000/1801350 [02:26<04:10, 4638.76 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 639000/1801350 [02:26<04:18, 4502.30 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 636000/1801350 [02:26<04:14, 4582.01 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 640000/1801350 [02:27<04:33, 4252.84 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 642000/1801350 [02:26<04:13, 4580.40 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 641000/1801350 [02:27<04:10, 4631.93 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 640000/1801350 [02:26<04:27, 4335.16 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 637000/1801350 [02:26<04:27, 4359.55 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 643000/1801350 [02:27<04:16, 4521.84 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 642000/1801350 [02:27<04:16, 4519.89 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 641000/1801350 [02:27<04:10, 4626.85 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 638000/1801350 [02:27<04:17, 4516.69 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 644000/1801350 [02:27<04:26, 4350.62 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 642000/1801350 [02:27<04:13, 4580.96 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 643000/1801350 [02:27<04:23, 4393.14 examples/s]Grouping texts in chunks of 1024:  35%|███▌      | 639000/1801350 [02:27<04:15, 4547.29 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 645000/1801350 [02:27<04:33, 4220.84 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 643000/1801350 [02:27<04:20, 4443.37 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 644000/1801350 [02:28<04:27, 4324.06 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 640000/1801350 [02:27<04:29, 4308.60 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 646000/1801350 [02:27<04:11, 4587.39 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 644000/1801350 [02:27<04:24, 4373.44 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 641000/1801350 [02:27<04:18, 4491.03 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 645000/1801350 [02:28<04:37, 4167.49 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 647000/1801350 [02:27<04:21, 4412.21 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 642000/1801350 [02:28<04:11, 4605.95 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 646000/1801350 [02:28<04:21, 4412.78 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 645000/1801350 [02:28<04:36, 4174.65 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 648000/1801350 [02:28<04:41, 4097.63 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 646000/1801350 [02:28<04:14, 4537.56 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 643000/1801350 [02:28<04:19, 4459.78 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 647000/1801350 [02:28<04:29, 4275.92 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 649000/1801350 [02:28<04:40, 4103.70 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 647000/1801350 [02:28<04:24, 4360.18 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 644000/1801350 [02:28<04:25, 4362.38 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 648000/1801350 [02:29<04:47, 4010.48 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 650000/1801350 [02:28<04:45, 4035.16 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 645000/1801350 [02:28<04:28, 4299.35 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 648000/1801350 [02:28<04:42, 4076.65 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 649000/1801350 [02:29<04:41, 4091.93 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 651000/1801350 [02:28<04:36, 4161.81 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 646000/1801350 [02:28<04:15, 4523.35 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 649000/1801350 [02:29<04:35, 4181.97 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 650000/1801350 [02:29<04:51, 3949.33 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 652000/1801350 [02:29<04:30, 4249.60 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 647000/1801350 [02:29<04:24, 4363.24 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 650000/1801350 [02:29<04:45, 4034.20 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 651000/1801350 [02:29<04:43, 4063.67 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 653000/1801350 [02:29<04:29, 4266.66 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 648000/1801350 [02:29<04:43, 4074.88 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 651000/1801350 [02:29<04:45, 4029.20 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 652000/1801350 [02:30<04:28, 4272.75 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 654000/1801350 [02:29<04:19, 4418.20 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 649000/1801350 [02:29<04:37, 4147.62 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 652000/1801350 [02:29<04:28, 4281.58 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 653000/1801350 [02:30<04:30, 4247.99 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 655000/1801350 [02:29<04:18, 4439.41 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 653000/1801350 [02:29<04:28, 4281.66 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 654000/1801350 [02:30<04:23, 4351.24 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 650000/1801350 [02:30<04:50, 3961.93 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 656000/1801350 [02:30<04:18, 4434.89 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 654000/1801350 [02:30<04:18, 4446.04 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 651000/1801350 [02:30<04:36, 4166.87 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 655000/1801350 [02:30<04:25, 4320.39 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 657000/1801350 [02:30<04:20, 4400.05 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 655000/1801350 [02:30<04:19, 4414.35 examples/s]Grouping texts in chunks of 1024:  36%|███▌      | 652000/1801350 [02:30<04:29, 4263.59 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 656000/1801350 [02:31<04:28, 4262.48 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 658000/1801350 [02:30<04:17, 4444.50 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 656000/1801350 [02:30<04:20, 4393.40 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 657000/1801350 [02:31<04:20, 4397.53 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 653000/1801350 [02:30<04:33, 4202.20 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 659000/1801350 [02:30<04:16, 4454.84 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 657000/1801350 [02:30<04:15, 4477.98 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 654000/1801350 [02:30<04:23, 4352.37 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 658000/1801350 [02:31<04:19, 4404.84 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 660000/1801350 [02:30<04:11, 4534.74 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 658000/1801350 [02:31<04:13, 4515.72 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 659000/1801350 [02:31<04:14, 4491.81 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 655000/1801350 [02:31<04:23, 4349.23 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 661000/1801350 [02:31<04:19, 4401.28 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 659000/1801350 [02:31<04:17, 4436.90 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 660000/1801350 [02:31<04:15, 4468.99 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 656000/1801350 [02:31<04:23, 4345.45 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 662000/1801350 [02:31<04:07, 4612.32 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 660000/1801350 [02:31<04:07, 4619.34 examples/s]Grouping texts in chunks of 1024:  36%|███▋      | 657000/1801350 [02:31<04:17, 4435.69 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 661000/1801350 [02:32<04:22, 4346.84 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 663000/1801350 [02:31<04:17, 4422.80 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 661000/1801350 [02:31<04:17, 4429.43 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 658000/1801350 [02:31<04:15, 4474.87 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 662000/1801350 [02:32<04:14, 4471.48 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 664000/1801350 [02:31<04:20, 4372.60 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 662000/1801350 [02:31<04:14, 4477.67 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 659000/1801350 [02:32<04:17, 4428.86 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 663000/1801350 [02:32<04:19, 4392.01 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 665000/1801350 [02:32<04:15, 4444.82 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 663000/1801350 [02:32<04:19, 4389.90 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 660000/1801350 [02:32<04:10, 4555.29 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 664000/1801350 [02:32<04:18, 4394.74 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 666000/1801350 [02:32<04:12, 4500.67 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 664000/1801350 [02:32<04:20, 4366.95 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 661000/1801350 [02:32<04:19, 4397.41 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 665000/1801350 [02:33<04:17, 4416.52 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 667000/1801350 [02:32<04:07, 4578.82 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 665000/1801350 [02:32<04:15, 4444.72 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 662000/1801350 [02:32<04:11, 4537.23 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 666000/1801350 [02:33<04:11, 4515.52 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 668000/1801350 [02:32<04:13, 4472.33 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 666000/1801350 [02:32<04:11, 4514.90 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 663000/1801350 [02:32<04:18, 4407.62 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 667000/1801350 [02:33<04:16, 4423.24 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 669000/1801350 [02:32<04:04, 4633.39 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 667000/1801350 [02:33<04:12, 4493.23 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 664000/1801350 [02:33<04:20, 4362.25 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 670000/1801350 [02:33<04:05, 4604.17 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 668000/1801350 [02:33<04:37, 4077.28 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 668000/1801350 [02:33<04:12, 4495.58 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 671000/1801350 [02:33<04:02, 4661.58 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 665000/1801350 [02:33<04:16, 4424.37 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 669000/1801350 [02:33<04:07, 4574.69 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 669000/1801350 [02:33<04:05, 4613.68 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 672000/1801350 [02:33<03:56, 4775.20 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 666000/1801350 [02:33<04:11, 4506.21 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 670000/1801350 [02:34<04:08, 4546.03 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 670000/1801350 [02:33<04:01, 4688.52 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 673000/1801350 [02:33<04:04, 4616.20 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 667000/1801350 [02:33<04:14, 4456.32 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 671000/1801350 [02:34<04:08, 4556.48 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 671000/1801350 [02:33<04:03, 4640.54 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 672000/1801350 [02:34<04:05, 4606.45 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 674000/1801350 [02:34<04:10, 4500.75 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 668000/1801350 [02:34<04:15, 4440.80 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 672000/1801350 [02:34<03:58, 4730.30 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 675000/1801350 [02:34<04:02, 4637.80 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 669000/1801350 [02:34<04:06, 4594.60 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 673000/1801350 [02:34<04:13, 4454.98 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 673000/1801350 [02:34<04:02, 4645.40 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 676000/1801350 [02:34<04:05, 4590.28 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 670000/1801350 [02:34<04:09, 4537.16 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 674000/1801350 [02:35<04:17, 4373.85 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 674000/1801350 [02:34<04:13, 4450.39 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 671000/1801350 [02:34<04:10, 4504.75 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 675000/1801350 [02:35<04:05, 4583.11 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 677000/1801350 [02:34<04:15, 4406.84 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 675000/1801350 [02:34<04:07, 4543.62 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 672000/1801350 [02:34<03:57, 4759.66 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 676000/1801350 [02:35<04:07, 4552.76 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 678000/1801350 [02:34<04:15, 4404.87 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 676000/1801350 [02:35<03:59, 4690.86 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 673000/1801350 [02:35<04:05, 4588.77 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 677000/1801350 [02:35<04:15, 4392.21 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 679000/1801350 [02:35<04:20, 4309.27 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 677000/1801350 [02:35<04:18, 4346.65 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 674000/1801350 [02:35<04:09, 4510.83 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 678000/1801350 [02:35<04:16, 4378.23 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 680000/1801350 [02:35<04:19, 4325.66 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 678000/1801350 [02:35<04:15, 4392.15 examples/s]Grouping texts in chunks of 1024:  37%|███▋      | 675000/1801350 [02:35<04:09, 4521.98 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 681000/1801350 [02:35<04:04, 4581.43 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 679000/1801350 [02:36<04:28, 4185.23 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 679000/1801350 [02:35<04:19, 4318.25 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 676000/1801350 [02:35<04:05, 4588.46 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 682000/1801350 [02:35<04:15, 4376.97 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 680000/1801350 [02:36<04:22, 4274.38 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 680000/1801350 [02:35<04:16, 4368.25 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 677000/1801350 [02:36<04:14, 4409.36 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 683000/1801350 [02:36<04:20, 4285.55 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 681000/1801350 [02:36<04:13, 4423.81 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 681000/1801350 [02:36<04:09, 4491.33 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 678000/1801350 [02:36<04:17, 4368.57 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 684000/1801350 [02:36<04:08, 4488.57 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 682000/1801350 [02:36<04:20, 4294.93 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 682000/1801350 [02:36<04:20, 4289.51 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 685000/1801350 [02:36<03:58, 4688.24 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 679000/1801350 [02:36<04:23, 4254.98 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 683000/1801350 [02:37<04:22, 4255.00 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 683000/1801350 [02:36<04:20, 4298.46 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 680000/1801350 [02:36<04:15, 4384.29 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 686000/1801350 [02:36<04:05, 4538.10 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 684000/1801350 [02:37<04:13, 4404.09 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 684000/1801350 [02:36<04:08, 4491.30 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 681000/1801350 [02:36<04:05, 4557.10 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 687000/1801350 [02:36<04:14, 4386.99 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 685000/1801350 [02:37<04:01, 4619.34 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 685000/1801350 [02:37<04:05, 4552.17 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 682000/1801350 [02:37<04:22, 4267.20 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 688000/1801350 [02:37<04:14, 4381.00 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 686000/1801350 [02:37<04:10, 4456.36 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 686000/1801350 [02:37<04:10, 4459.78 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 683000/1801350 [02:37<04:23, 4249.58 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 689000/1801350 [02:37<04:17, 4313.39 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 687000/1801350 [02:38<04:21, 4256.36 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 687000/1801350 [02:37<04:16, 4338.20 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 684000/1801350 [02:37<04:08, 4496.88 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 690000/1801350 [02:37<04:12, 4399.78 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 688000/1801350 [02:38<04:19, 4290.59 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 688000/1801350 [02:37<04:07, 4499.99 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 685000/1801350 [02:37<04:03, 4585.00 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 691000/1801350 [02:37<04:21, 4244.39 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 689000/1801350 [02:38<04:20, 4264.09 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 689000/1801350 [02:38<04:19, 4287.19 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 686000/1801350 [02:38<04:10, 4455.77 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 692000/1801350 [02:38<04:24, 4194.54 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 690000/1801350 [02:38<04:15, 4344.14 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 690000/1801350 [02:38<04:14, 4369.93 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 687000/1801350 [02:38<04:19, 4291.52 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 693000/1801350 [02:38<04:30, 4101.87 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 691000/1801350 [02:39<04:24, 4204.79 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 691000/1801350 [02:38<04:21, 4240.56 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 688000/1801350 [02:38<04:14, 4368.91 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 694000/1801350 [02:38<04:23, 4197.80 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 692000/1801350 [02:38<04:29, 4122.34 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 689000/1801350 [02:38<04:20, 4275.44 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 695000/1801350 [02:38<04:17, 4291.68 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 690000/1801350 [02:39<04:17, 4313.87 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 693000/1801350 [02:39<04:33, 4051.28 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 696000/1801350 [02:39<04:22, 4203.22 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 692000/1801350 [02:39<06:49, 2709.03 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 694000/1801350 [02:39<04:28, 4130.71 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 691000/1801350 [02:39<04:24, 4199.01 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 697000/1801350 [02:39<04:22, 4204.13 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 693000/1801350 [02:39<06:11, 2982.00 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 695000/1801350 [02:39<04:23, 4197.77 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 692000/1801350 [02:39<04:28, 4129.50 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 698000/1801350 [02:39<04:11, 4382.58 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 694000/1801350 [02:40<05:41, 3244.61 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 696000/1801350 [02:39<04:15, 4320.01 examples/s]Grouping texts in chunks of 1024:  38%|███▊      | 693000/1801350 [02:39<04:32, 4070.81 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 699000/1801350 [02:39<04:21, 4215.75 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 695000/1801350 [02:40<05:13, 3533.76 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 697000/1801350 [02:39<04:22, 4214.60 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 694000/1801350 [02:40<04:30, 4095.88 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 700000/1801350 [02:40<04:16, 4289.31 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 696000/1801350 [02:40<04:57, 3718.15 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 698000/1801350 [02:40<04:17, 4287.84 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 695000/1801350 [02:40<04:17, 4299.78 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 701000/1801350 [02:40<04:10, 4396.50 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 697000/1801350 [02:40<04:47, 3840.61 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 699000/1801350 [02:40<04:19, 4248.59 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 696000/1801350 [02:40<04:22, 4206.38 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 702000/1801350 [02:40<04:08, 4420.12 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 698000/1801350 [02:41<04:32, 4045.09 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 700000/1801350 [02:40<04:14, 4321.61 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 703000/1801350 [02:40<03:56, 4637.72 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 697000/1801350 [02:40<04:24, 4176.43 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 699000/1801350 [02:41<04:35, 4003.77 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 701000/1801350 [02:40<04:12, 4352.41 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 704000/1801350 [02:40<04:05, 4476.31 examples/s]Grouping texts in chunks of 1024:  39%|███▊      | 698000/1801350 [02:40<04:17, 4282.81 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 700000/1801350 [02:41<04:26, 4125.49 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 702000/1801350 [02:41<04:05, 4470.07 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 705000/1801350 [02:41<04:12, 4348.20 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 699000/1801350 [02:41<04:24, 4161.69 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 701000/1801350 [02:41<04:23, 4171.46 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 703000/1801350 [02:41<04:02, 4536.25 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 700000/1801350 [02:41<04:15, 4315.38 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 706000/1801350 [02:41<04:29, 4059.53 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 702000/1801350 [02:42<04:12, 4349.30 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 704000/1801350 [02:41<04:02, 4516.49 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 701000/1801350 [02:41<04:13, 4344.93 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 707000/1801350 [02:41<04:18, 4235.23 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 703000/1801350 [02:42<04:07, 4433.00 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 705000/1801350 [02:41<04:12, 4346.52 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 702000/1801350 [02:41<04:07, 4440.05 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 708000/1801350 [02:41<04:14, 4294.81 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 704000/1801350 [02:42<04:06, 4445.90 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 703000/1801350 [02:42<03:58, 4602.46 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 706000/1801350 [02:42<04:30, 4049.88 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 709000/1801350 [02:42<04:10, 4366.56 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 705000/1801350 [02:42<04:13, 4331.13 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 707000/1801350 [02:42<04:17, 4250.00 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 704000/1801350 [02:42<04:05, 4465.47 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 710000/1801350 [02:42<04:05, 4440.57 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 706000/1801350 [02:43<04:34, 3994.16 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 708000/1801350 [02:42<04:14, 4298.34 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 711000/1801350 [02:42<04:01, 4511.31 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 705000/1801350 [02:42<04:15, 4291.53 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 707000/1801350 [02:43<04:23, 4159.93 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 709000/1801350 [02:42<04:08, 4389.24 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 712000/1801350 [02:42<03:57, 4589.03 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 706000/1801350 [02:42<04:31, 4040.84 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 708000/1801350 [02:43<04:20, 4189.17 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 710000/1801350 [02:42<04:09, 4368.12 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 713000/1801350 [02:42<03:55, 4617.00 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 707000/1801350 [02:43<04:20, 4194.86 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 709000/1801350 [02:43<04:20, 4193.93 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 711000/1801350 [02:43<04:07, 4407.93 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 714000/1801350 [02:43<03:57, 4574.57 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 708000/1801350 [02:43<04:15, 4272.55 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 710000/1801350 [02:43<04:14, 4280.34 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 712000/1801350 [02:43<04:01, 4517.02 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 715000/1801350 [02:43<04:00, 4516.61 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 709000/1801350 [02:43<04:15, 4279.45 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 713000/1801350 [02:43<03:55, 4621.76 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 711000/1801350 [02:44<04:09, 4377.02 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 716000/1801350 [02:43<04:03, 4452.23 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 710000/1801350 [02:43<04:10, 4354.79 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 712000/1801350 [02:44<04:01, 4504.64 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 714000/1801350 [02:43<03:59, 4549.27 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 717000/1801350 [02:43<03:59, 4522.26 examples/s]Grouping texts in chunks of 1024:  39%|███▉      | 711000/1801350 [02:43<04:05, 4433.68 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 713000/1801350 [02:44<03:53, 4651.82 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 715000/1801350 [02:44<03:59, 4535.74 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 718000/1801350 [02:44<04:07, 4381.37 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 712000/1801350 [02:44<03:58, 4568.27 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 714000/1801350 [02:44<03:59, 4530.95 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 716000/1801350 [02:44<04:00, 4516.58 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 719000/1801350 [02:44<04:10, 4319.80 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 713000/1801350 [02:44<03:59, 4541.05 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 715000/1801350 [02:44<04:02, 4488.71 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 717000/1801350 [02:44<03:54, 4617.86 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 720000/1801350 [02:44<04:15, 4234.96 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 714000/1801350 [02:44<04:04, 4451.52 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 716000/1801350 [02:45<03:59, 4524.79 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 718000/1801350 [02:44<04:05, 4408.36 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 715000/1801350 [02:44<04:01, 4506.06 examples/s]Grouping texts in chunks of 1024:  40%|████      | 721000/1801350 [02:44<04:11, 4290.94 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 717000/1801350 [02:45<04:02, 4464.34 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 719000/1801350 [02:44<04:11, 4299.00 examples/s]Grouping texts in chunks of 1024:  40%|████      | 722000/1801350 [02:45<04:02, 4444.68 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 716000/1801350 [02:45<03:59, 4529.55 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 718000/1801350 [02:45<04:10, 4329.48 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 720000/1801350 [02:45<04:18, 4176.24 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 717000/1801350 [02:45<03:58, 4551.63 examples/s]Grouping texts in chunks of 1024:  40%|████      | 723000/1801350 [02:45<04:07, 4355.93 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 719000/1801350 [02:45<04:07, 4377.11 examples/s]Grouping texts in chunks of 1024:  40%|████      | 721000/1801350 [02:45<04:15, 4229.33 examples/s]Grouping texts in chunks of 1024:  40%|████      | 724000/1801350 [02:45<04:04, 4407.53 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 718000/1801350 [02:45<04:10, 4324.88 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 720000/1801350 [02:46<04:20, 4158.06 examples/s]Grouping texts in chunks of 1024:  40%|████      | 722000/1801350 [02:45<04:07, 4353.95 examples/s]Grouping texts in chunks of 1024:  40%|████      | 725000/1801350 [02:45<04:07, 4351.10 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 719000/1801350 [02:45<04:11, 4310.80 examples/s]Grouping texts in chunks of 1024:  40%|████      | 721000/1801350 [02:46<04:14, 4247.90 examples/s]Grouping texts in chunks of 1024:  40%|████      | 723000/1801350 [02:45<04:04, 4409.01 examples/s]Grouping texts in chunks of 1024:  40%|████      | 726000/1801350 [02:45<04:15, 4200.74 examples/s]Grouping texts in chunks of 1024:  40%|███▉      | 720000/1801350 [02:45<04:18, 4187.89 examples/s]Grouping texts in chunks of 1024:  40%|████      | 722000/1801350 [02:46<04:10, 4315.17 examples/s]Grouping texts in chunks of 1024:  40%|████      | 724000/1801350 [02:46<04:08, 4333.93 examples/s]Grouping texts in chunks of 1024:  40%|████      | 727000/1801350 [02:46<04:09, 4312.93 examples/s]Grouping texts in chunks of 1024:  40%|████      | 721000/1801350 [02:46<04:14, 4239.13 examples/s]Grouping texts in chunks of 1024:  40%|████      | 723000/1801350 [02:46<04:08, 4346.65 examples/s]Grouping texts in chunks of 1024:  40%|████      | 725000/1801350 [02:46<04:11, 4286.09 examples/s]Grouping texts in chunks of 1024:  40%|████      | 728000/1801350 [02:46<03:58, 4497.95 examples/s]Grouping texts in chunks of 1024:  40%|████      | 722000/1801350 [02:46<04:07, 4352.37 examples/s]Grouping texts in chunks of 1024:  40%|████      | 724000/1801350 [02:47<04:04, 4412.74 examples/s]Grouping texts in chunks of 1024:  40%|████      | 726000/1801350 [02:46<04:15, 4213.04 examples/s]Grouping texts in chunks of 1024:  40%|████      | 729000/1801350 [02:46<04:13, 4222.68 examples/s]Grouping texts in chunks of 1024:  40%|████      | 723000/1801350 [02:46<04:09, 4330.51 examples/s]Grouping texts in chunks of 1024:  40%|████      | 725000/1801350 [02:47<04:10, 4290.55 examples/s]Grouping texts in chunks of 1024:  40%|████      | 727000/1801350 [02:46<04:13, 4234.38 examples/s]Grouping texts in chunks of 1024:  40%|████      | 724000/1801350 [02:46<04:07, 4358.53 examples/s]Grouping texts in chunks of 1024:  41%|████      | 730000/1801350 [02:46<04:15, 4196.30 examples/s]Grouping texts in chunks of 1024:  40%|████      | 728000/1801350 [02:47<04:02, 4432.36 examples/s]Grouping texts in chunks of 1024:  40%|████      | 726000/1801350 [02:47<04:22, 4089.30 examples/s]Grouping texts in chunks of 1024:  40%|████      | 725000/1801350 [02:47<04:03, 4415.35 examples/s]Grouping texts in chunks of 1024:  41%|████      | 731000/1801350 [02:47<04:12, 4236.50 examples/s]Grouping texts in chunks of 1024:  40%|████      | 727000/1801350 [02:47<04:14, 4222.09 examples/s]Grouping texts in chunks of 1024:  40%|████      | 729000/1801350 [02:47<04:13, 4225.13 examples/s]Grouping texts in chunks of 1024:  41%|████      | 732000/1801350 [02:47<04:10, 4272.02 examples/s]Grouping texts in chunks of 1024:  40%|████      | 726000/1801350 [02:47<04:16, 4194.06 examples/s]Grouping texts in chunks of 1024:  40%|████      | 728000/1801350 [02:48<04:06, 4357.27 examples/s]Grouping texts in chunks of 1024:  41%|████      | 730000/1801350 [02:47<04:16, 4171.16 examples/s]Grouping texts in chunks of 1024:  40%|████      | 727000/1801350 [02:47<04:07, 4339.73 examples/s]Grouping texts in chunks of 1024:  41%|████      | 733000/1801350 [02:47<04:10, 4263.58 examples/s]Grouping texts in chunks of 1024:  40%|████      | 729000/1801350 [02:48<04:16, 4185.57 examples/s]Grouping texts in chunks of 1024:  41%|████      | 731000/1801350 [02:47<04:06, 4335.63 examples/s]Grouping texts in chunks of 1024:  41%|████      | 734000/1801350 [02:47<03:47, 4683.26 examples/s]Grouping texts in chunks of 1024:  40%|████      | 728000/1801350 [02:47<04:02, 4431.37 examples/s]Grouping texts in chunks of 1024:  41%|████      | 730000/1801350 [02:48<04:15, 4187.33 examples/s]Grouping texts in chunks of 1024:  41%|████      | 732000/1801350 [02:47<04:13, 4222.18 examples/s]Grouping texts in chunks of 1024:  41%|████      | 735000/1801350 [02:48<03:58, 4466.83 examples/s]Grouping texts in chunks of 1024:  40%|████      | 729000/1801350 [02:48<04:20, 4121.00 examples/s]Grouping texts in chunks of 1024:  41%|████      | 733000/1801350 [02:48<04:08, 4292.21 examples/s]Grouping texts in chunks of 1024:  41%|████      | 731000/1801350 [02:48<04:21, 4094.40 examples/s]Grouping texts in chunks of 1024:  41%|████      | 736000/1801350 [02:48<04:06, 4314.29 examples/s]Grouping texts in chunks of 1024:  41%|████      | 730000/1801350 [02:48<04:16, 4173.90 examples/s]Grouping texts in chunks of 1024:  41%|████      | 734000/1801350 [02:48<03:50, 4636.31 examples/s]Grouping texts in chunks of 1024:  41%|████      | 737000/1801350 [02:48<03:47, 4673.60 examples/s]Grouping texts in chunks of 1024:  41%|████      | 732000/1801350 [02:49<04:12, 4232.40 examples/s]Grouping texts in chunks of 1024:  41%|████      | 731000/1801350 [02:48<04:15, 4196.89 examples/s]Grouping texts in chunks of 1024:  41%|████      | 733000/1801350 [02:49<04:07, 4309.65 examples/s]Grouping texts in chunks of 1024:  41%|████      | 738000/1801350 [02:48<03:59, 4444.99 examples/s]Grouping texts in chunks of 1024:  41%|████      | 735000/1801350 [02:48<04:34, 3887.37 examples/s]Grouping texts in chunks of 1024:  41%|████      | 732000/1801350 [02:48<04:04, 4374.06 examples/s]Grouping texts in chunks of 1024:  41%|████      | 734000/1801350 [02:49<03:51, 4620.04 examples/s]Grouping texts in chunks of 1024:  41%|████      | 739000/1801350 [02:48<03:44, 4721.69 examples/s]Grouping texts in chunks of 1024:  41%|████      | 736000/1801350 [02:48<04:19, 4100.93 examples/s]Grouping texts in chunks of 1024:  41%|████      | 733000/1801350 [02:48<04:09, 4273.99 examples/s]Grouping texts in chunks of 1024:  41%|████      | 735000/1801350 [02:49<03:58, 4474.69 examples/s]Grouping texts in chunks of 1024:  41%|████      | 740000/1801350 [02:49<04:00, 4415.48 examples/s]Grouping texts in chunks of 1024:  41%|████      | 737000/1801350 [02:49<03:57, 4475.59 examples/s]Grouping texts in chunks of 1024:  41%|████      | 734000/1801350 [02:49<03:49, 4651.16 examples/s]Grouping texts in chunks of 1024:  41%|████      | 736000/1801350 [02:49<04:01, 4409.49 examples/s]Grouping texts in chunks of 1024:  41%|████      | 741000/1801350 [02:49<03:57, 4468.09 examples/s]Grouping texts in chunks of 1024:  41%|████      | 738000/1801350 [02:49<04:02, 4384.45 examples/s]Grouping texts in chunks of 1024:  41%|████      | 735000/1801350 [02:49<03:59, 4443.91 examples/s]Grouping texts in chunks of 1024:  41%|████      | 737000/1801350 [02:50<03:48, 4649.94 examples/s]Grouping texts in chunks of 1024:  41%|████      | 739000/1801350 [02:49<03:56, 4489.65 examples/s]Grouping texts in chunks of 1024:  41%|████      | 742000/1801350 [02:49<04:07, 4287.68 examples/s]Grouping texts in chunks of 1024:  41%|████      | 736000/1801350 [02:49<04:06, 4314.04 examples/s]Grouping texts in chunks of 1024:  41%|████      | 738000/1801350 [02:50<03:51, 4584.41 examples/s]Grouping texts in chunks of 1024:  41%|████      | 740000/1801350 [02:49<04:05, 4328.37 examples/s]Grouping texts in chunks of 1024:  41%|████      | 737000/1801350 [02:49<03:49, 4646.68 examples/s]Grouping texts in chunks of 1024:  41%|████      | 739000/1801350 [02:50<03:52, 4566.64 examples/s]Grouping texts in chunks of 1024:  41%|████      | 741000/1801350 [02:50<04:02, 4369.96 examples/s]Grouping texts in chunks of 1024:  41%|████      | 738000/1801350 [02:50<03:53, 4545.17 examples/s]Grouping texts in chunks of 1024:  41%|████      | 740000/1801350 [02:50<04:08, 4268.45 examples/s]Grouping texts in chunks of 1024:  41%|████      | 743000/1801350 [02:50<06:17, 2801.72 examples/s]Grouping texts in chunks of 1024:  41%|████      | 739000/1801350 [02:50<03:56, 4499.07 examples/s]Grouping texts in chunks of 1024:  41%|████      | 742000/1801350 [02:50<04:11, 4215.71 examples/s]Grouping texts in chunks of 1024:  41%|████      | 741000/1801350 [02:50<04:01, 4388.94 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 744000/1801350 [02:50<05:38, 3125.09 examples/s]Grouping texts in chunks of 1024:  41%|████      | 740000/1801350 [02:50<04:06, 4298.33 examples/s]Grouping texts in chunks of 1024:  41%|████      | 742000/1801350 [02:51<04:11, 4213.05 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 745000/1801350 [02:50<05:15, 3352.71 examples/s]Grouping texts in chunks of 1024:  41%|████      | 741000/1801350 [02:50<03:56, 4489.53 examples/s]Grouping texts in chunks of 1024:  41%|████      | 743000/1801350 [02:51<04:14, 4163.17 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 746000/1801350 [02:50<04:53, 3597.14 examples/s]Grouping texts in chunks of 1024:  41%|████      | 743000/1801350 [02:50<06:25, 2743.60 examples/s]Grouping texts in chunks of 1024:  41%|████      | 742000/1801350 [02:51<04:13, 4182.93 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 744000/1801350 [02:51<04:10, 4214.35 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 744000/1801350 [02:51<05:36, 3139.69 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 747000/1801350 [02:51<04:38, 3786.50 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 745000/1801350 [02:51<04:08, 4252.98 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 748000/1801350 [02:51<04:27, 3933.82 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 745000/1801350 [02:51<05:13, 3367.12 examples/s]Grouping texts in chunks of 1024:  41%|████      | 743000/1801350 [02:51<06:05, 2898.89 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 746000/1801350 [02:52<04:12, 4180.81 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 749000/1801350 [02:51<04:21, 4018.30 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 746000/1801350 [02:51<04:55, 3572.79 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 744000/1801350 [02:51<05:29, 3207.47 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 747000/1801350 [02:52<04:09, 4231.51 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 750000/1801350 [02:51<04:16, 4095.41 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 747000/1801350 [02:51<04:36, 3816.65 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 745000/1801350 [02:52<05:01, 3504.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 751000/1801350 [02:52<04:12, 4159.54 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 748000/1801350 [02:52<04:12, 4171.28 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 748000/1801350 [02:52<04:29, 3904.05 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 746000/1801350 [02:52<04:48, 3659.66 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 749000/1801350 [02:52<04:07, 4243.94 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 752000/1801350 [02:52<04:11, 4170.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 749000/1801350 [02:52<04:21, 4020.05 examples/s]Grouping texts in chunks of 1024:  41%|████▏     | 747000/1801350 [02:52<04:34, 3839.19 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 753000/1801350 [02:52<04:05, 4271.86 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 750000/1801350 [02:53<04:14, 4130.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 750000/1801350 [02:52<04:21, 4025.82 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 754000/1801350 [02:52<03:56, 4421.17 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 748000/1801350 [02:52<04:32, 3869.01 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 751000/1801350 [02:53<04:07, 4244.08 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 751000/1801350 [02:52<04:16, 4097.56 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 749000/1801350 [02:53<04:20, 4037.24 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 755000/1801350 [02:53<04:10, 4181.06 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 752000/1801350 [02:53<04:12, 4153.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 752000/1801350 [02:53<04:15, 4113.63 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 750000/1801350 [02:53<04:19, 4059.15 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 753000/1801350 [02:53<04:05, 4276.22 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 753000/1801350 [02:53<04:09, 4206.79 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 756000/1801350 [02:53<04:17, 4061.23 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 751000/1801350 [02:53<04:08, 4227.65 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 754000/1801350 [02:53<03:59, 4379.63 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 754000/1801350 [02:54<03:55, 4438.72 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 757000/1801350 [02:53<04:09, 4180.59 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 752000/1801350 [02:53<04:13, 4146.50 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 758000/1801350 [02:53<04:03, 4291.65 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 755000/1801350 [02:53<04:05, 4260.17 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 755000/1801350 [02:54<04:08, 4218.09 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 759000/1801350 [02:53<04:01, 4320.71 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 753000/1801350 [02:53<04:13, 4136.28 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 756000/1801350 [02:54<04:16, 4081.89 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 756000/1801350 [02:54<04:22, 3987.71 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 754000/1801350 [02:54<04:01, 4336.09 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 760000/1801350 [02:54<03:57, 4384.43 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 757000/1801350 [02:54<04:12, 4137.10 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 757000/1801350 [02:54<04:14, 4099.03 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 761000/1801350 [02:54<03:49, 4532.13 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 755000/1801350 [02:54<04:06, 4252.47 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 758000/1801350 [02:54<04:02, 4293.87 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 758000/1801350 [02:55<04:08, 4190.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 762000/1801350 [02:54<03:50, 4513.00 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 756000/1801350 [02:54<04:13, 4125.00 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 759000/1801350 [02:54<04:02, 4293.42 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 759000/1801350 [02:55<04:02, 4297.06 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 763000/1801350 [02:54<04:10, 4149.07 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 760000/1801350 [02:54<03:57, 4380.97 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 757000/1801350 [02:54<04:10, 4176.84 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 760000/1801350 [02:55<04:04, 4251.44 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 764000/1801350 [02:55<04:03, 4254.36 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 761000/1801350 [02:55<03:54, 4434.75 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 761000/1801350 [02:55<03:51, 4495.41 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 758000/1801350 [02:55<04:08, 4190.19 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 765000/1801350 [02:55<03:59, 4334.66 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 762000/1801350 [02:55<03:52, 4476.62 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 762000/1801350 [02:55<03:51, 4493.91 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 759000/1801350 [02:55<04:05, 4241.09 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 760000/1801350 [02:55<03:56, 4410.38 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 766000/1801350 [02:55<04:05, 4215.44 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 763000/1801350 [02:55<04:09, 4159.80 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 763000/1801350 [02:56<04:11, 4129.70 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 767000/1801350 [02:55<03:54, 4419.61 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 761000/1801350 [02:55<03:53, 4455.53 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 764000/1801350 [02:55<04:04, 4237.74 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 764000/1801350 [02:56<04:05, 4224.65 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 762000/1801350 [02:56<03:51, 4481.77 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 768000/1801350 [02:56<03:56, 4368.83 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 765000/1801350 [02:56<04:04, 4230.54 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 765000/1801350 [02:56<04:09, 4155.19 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 769000/1801350 [02:56<04:04, 4222.89 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 763000/1801350 [02:56<04:07, 4199.35 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 766000/1801350 [02:56<04:03, 4247.55 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 766000/1801350 [02:56<04:09, 4150.12 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 767000/1801350 [02:56<03:51, 4473.37 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 770000/1801350 [02:56<04:05, 4193.81 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 764000/1801350 [02:56<04:05, 4232.80 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 767000/1801350 [02:57<03:54, 4413.39 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 768000/1801350 [02:56<03:54, 4407.74 examples/s]Grouping texts in chunks of 1024:  42%|████▏     | 765000/1801350 [02:56<04:06, 4209.16 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 771000/1801350 [02:56<04:09, 4131.67 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 768000/1801350 [02:57<03:56, 4370.99 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 772000/1801350 [02:56<03:57, 4326.08 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 769000/1801350 [02:57<04:04, 4227.60 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 766000/1801350 [02:57<04:10, 4128.79 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 769000/1801350 [02:57<04:07, 4170.05 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 767000/1801350 [02:57<03:52, 4447.95 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 773000/1801350 [02:57<03:57, 4332.59 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 770000/1801350 [02:57<04:05, 4194.78 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 770000/1801350 [02:57<04:14, 4048.41 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 774000/1801350 [02:57<03:51, 4434.25 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 768000/1801350 [02:57<03:52, 4439.37 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 771000/1801350 [02:57<04:04, 4208.19 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 771000/1801350 [02:58<04:09, 4127.46 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 775000/1801350 [02:57<04:03, 4219.25 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 772000/1801350 [02:57<03:57, 4329.06 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 769000/1801350 [02:57<04:08, 4155.33 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 772000/1801350 [02:58<04:04, 4218.26 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 776000/1801350 [02:57<03:52, 4403.46 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 773000/1801350 [02:57<03:57, 4326.60 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 770000/1801350 [02:57<04:10, 4115.15 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 773000/1801350 [02:58<04:01, 4253.97 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 777000/1801350 [02:58<04:01, 4240.18 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 774000/1801350 [02:58<03:52, 4423.56 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 771000/1801350 [02:58<04:13, 4064.71 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 774000/1801350 [02:58<03:54, 4379.92 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 778000/1801350 [02:58<03:56, 4330.81 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 775000/1801350 [02:58<03:59, 4278.27 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 772000/1801350 [02:58<03:59, 4299.75 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 775000/1801350 [02:59<04:03, 4206.64 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 779000/1801350 [02:58<03:55, 4338.44 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 776000/1801350 [02:58<03:57, 4310.76 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 773000/1801350 [02:58<03:59, 4298.93 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 776000/1801350 [02:59<03:58, 4290.40 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 780000/1801350 [02:58<04:00, 4240.16 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 774000/1801350 [02:58<03:53, 4403.37 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 777000/1801350 [02:58<03:59, 4269.08 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 777000/1801350 [02:59<04:06, 4157.65 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 781000/1801350 [02:59<03:59, 4252.97 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 778000/1801350 [02:59<03:55, 4353.12 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 775000/1801350 [02:59<03:57, 4327.32 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 778000/1801350 [02:59<04:01, 4231.80 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 782000/1801350 [02:59<03:47, 4471.93 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 779000/1801350 [02:59<03:51, 4415.36 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 776000/1801350 [02:59<04:00, 4259.74 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 779000/1801350 [03:00<03:59, 4269.98 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 783000/1801350 [02:59<04:08, 4093.57 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 780000/1801350 [02:59<04:04, 4181.91 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 777000/1801350 [02:59<04:06, 4157.90 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 780000/1801350 [03:00<03:57, 4303.81 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 781000/1801350 [02:59<03:58, 4270.72 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 778000/1801350 [02:59<03:56, 4334.46 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 784000/1801350 [02:59<04:09, 4080.71 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 781000/1801350 [03:00<04:04, 4171.77 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 782000/1801350 [03:00<03:47, 4483.74 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 779000/1801350 [03:00<03:57, 4303.92 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 785000/1801350 [03:00<04:10, 4065.36 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 782000/1801350 [03:00<03:48, 4457.71 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 786000/1801350 [03:00<04:00, 4223.59 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 780000/1801350 [03:00<03:59, 4256.35 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 783000/1801350 [03:00<04:08, 4093.08 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 783000/1801350 [03:00<04:16, 3973.38 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 787000/1801350 [03:00<03:56, 4295.48 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 781000/1801350 [03:00<04:04, 4173.14 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 784000/1801350 [03:00<04:10, 4060.21 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 784000/1801350 [03:01<04:15, 3979.68 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 788000/1801350 [03:00<03:51, 4368.44 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 782000/1801350 [03:00<03:50, 4413.17 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 785000/1801350 [03:00<04:08, 4097.93 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 785000/1801350 [03:01<04:10, 4056.27 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 789000/1801350 [03:00<03:56, 4289.05 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 786000/1801350 [03:01<04:05, 4134.66 examples/s]Grouping texts in chunks of 1024:  43%|████▎     | 783000/1801350 [03:01<04:11, 4041.45 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 786000/1801350 [03:01<04:05, 4132.12 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 790000/1801350 [03:01<03:56, 4277.98 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 787000/1801350 [03:01<03:52, 4369.14 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 784000/1801350 [03:01<04:11, 4038.39 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 787000/1801350 [03:01<03:59, 4241.67 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 791000/1801350 [03:01<03:51, 4360.43 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 788000/1801350 [03:01<03:52, 4364.05 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 785000/1801350 [03:01<04:09, 4079.02 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 788000/1801350 [03:02<03:56, 4290.32 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 792000/1801350 [03:01<04:02, 4154.12 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 789000/1801350 [03:01<03:57, 4264.50 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 786000/1801350 [03:01<03:59, 4237.35 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 789000/1801350 [03:02<04:00, 4208.96 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 793000/1801350 [03:01<03:48, 4410.53 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 790000/1801350 [03:01<03:55, 4301.26 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 787000/1801350 [03:01<03:58, 4247.92 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 790000/1801350 [03:02<04:03, 4159.55 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 794000/1801350 [03:02<03:57, 4234.44 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 791000/1801350 [03:02<03:52, 4336.68 examples/s]Grouping texts in chunks of 1024:  44%|████▎     | 788000/1801350 [03:02<03:56, 4292.86 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 791000/1801350 [03:02<03:57, 4262.12 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 795000/1801350 [03:02<03:51, 4356.33 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 792000/1801350 [03:02<04:04, 4129.17 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 789000/1801350 [03:02<03:58, 4240.74 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 792000/1801350 [03:03<04:08, 4065.32 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 796000/1801350 [03:02<03:54, 4284.44 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 793000/1801350 [03:02<03:47, 4424.96 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 790000/1801350 [03:02<03:57, 4261.86 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 793000/1801350 [03:03<03:53, 4325.03 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 797000/1801350 [03:02<03:51, 4344.89 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 794000/1801350 [03:02<03:57, 4246.88 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 791000/1801350 [03:02<03:49, 4397.31 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 794000/1801350 [03:03<04:02, 4156.54 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 798000/1801350 [03:03<03:48, 4394.50 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 795000/1801350 [03:03<03:55, 4264.48 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 792000/1801350 [03:03<04:01, 4182.55 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 795000/1801350 [03:03<03:53, 4311.62 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 799000/1801350 [03:03<03:49, 4375.91 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 796000/1801350 [03:03<03:48, 4405.69 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 793000/1801350 [03:03<03:55, 4276.64 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 796000/1801350 [03:04<03:52, 4322.07 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 800000/1801350 [03:03<03:47, 4400.05 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 797000/1801350 [03:03<03:48, 4393.81 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 794000/1801350 [03:03<04:02, 4160.20 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 797000/1801350 [03:04<03:54, 4283.08 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 801000/1801350 [03:03<03:54, 4272.49 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 798000/1801350 [03:03<03:53, 4293.03 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 795000/1801350 [03:03<03:52, 4319.83 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 802000/1801350 [03:03<03:40, 4540.77 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 798000/1801350 [03:04<03:58, 4202.93 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 799000/1801350 [03:04<03:48, 4394.98 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 796000/1801350 [03:04<03:54, 4281.25 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 799000/1801350 [03:04<03:52, 4303.26 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 803000/1801350 [03:04<03:59, 4164.77 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 800000/1801350 [03:04<03:51, 4320.00 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 797000/1801350 [03:04<03:51, 4347.03 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 800000/1801350 [03:04<03:51, 4332.67 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 804000/1801350 [03:04<03:57, 4203.53 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 801000/1801350 [03:04<03:52, 4298.40 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 798000/1801350 [03:04<03:49, 4363.67 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 801000/1801350 [03:05<03:55, 4251.66 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 805000/1801350 [03:04<03:46, 4393.84 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 802000/1801350 [03:04<03:48, 4377.19 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 799000/1801350 [03:04<03:50, 4350.91 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 802000/1801350 [03:05<03:47, 4396.55 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 806000/1801350 [03:04<03:52, 4286.42 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 803000/1801350 [03:04<03:59, 4163.78 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 800000/1801350 [03:04<03:47, 4402.34 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 807000/1801350 [03:05<03:45, 4406.92 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 803000/1801350 [03:05<04:03, 4107.49 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 804000/1801350 [03:05<03:54, 4258.24 examples/s]Grouping texts in chunks of 1024:  44%|████▍     | 801000/1801350 [03:05<03:53, 4285.26 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 804000/1801350 [03:05<03:53, 4270.85 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 808000/1801350 [03:05<04:00, 4125.79 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 805000/1801350 [03:05<03:51, 4312.25 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 802000/1801350 [03:05<03:52, 4305.72 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 805000/1801350 [03:06<03:55, 4232.03 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 809000/1801350 [03:05<03:55, 4207.08 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 806000/1801350 [03:05<03:53, 4262.50 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 803000/1801350 [03:05<04:01, 4133.28 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 806000/1801350 [03:06<03:57, 4198.35 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 810000/1801350 [03:05<03:51, 4286.61 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 807000/1801350 [03:05<03:51, 4292.17 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 804000/1801350 [03:05<03:59, 4171.99 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 807000/1801350 [03:06<03:46, 4389.76 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 808000/1801350 [03:06<03:59, 4156.18 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 811000/1801350 [03:06<04:09, 3974.17 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 805000/1801350 [03:06<03:46, 4393.91 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 808000/1801350 [03:06<04:06, 4031.89 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 809000/1801350 [03:06<03:55, 4210.83 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 812000/1801350 [03:06<04:02, 4077.54 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 806000/1801350 [03:06<03:53, 4254.83 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 809000/1801350 [03:07<03:58, 4157.14 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 810000/1801350 [03:06<03:48, 4346.87 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 813000/1801350 [03:06<04:02, 4080.58 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 807000/1801350 [03:06<03:53, 4253.12 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 810000/1801350 [03:07<03:57, 4170.33 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 814000/1801350 [03:06<03:52, 4247.37 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 811000/1801350 [03:06<04:09, 3976.22 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 808000/1801350 [03:06<04:01, 4113.99 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 815000/1801350 [03:07<03:38, 4509.48 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 811000/1801350 [03:07<04:12, 3925.46 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 812000/1801350 [03:07<04:02, 4073.88 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 809000/1801350 [03:07<03:55, 4213.51 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 816000/1801350 [03:07<03:33, 4609.36 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 812000/1801350 [03:07<04:06, 4021.67 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 813000/1801350 [03:07<04:01, 4099.84 examples/s]Grouping texts in chunks of 1024:  45%|████▍     | 810000/1801350 [03:07<03:57, 4166.84 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 817000/1801350 [03:07<03:29, 4702.51 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 813000/1801350 [03:08<04:02, 4067.82 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 814000/1801350 [03:07<03:54, 4201.80 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 818000/1801350 [03:07<03:22, 4852.01 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 811000/1801350 [03:07<04:11, 3935.98 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 815000/1801350 [03:07<03:39, 4489.78 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 814000/1801350 [03:08<03:54, 4203.76 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 819000/1801350 [03:07<03:35, 4555.83 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 812000/1801350 [03:07<04:04, 4049.13 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 816000/1801350 [03:07<03:33, 4625.25 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 815000/1801350 [03:08<03:45, 4366.79 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 820000/1801350 [03:08<03:34, 4584.96 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 813000/1801350 [03:08<04:01, 4097.98 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 817000/1801350 [03:08<03:23, 4832.17 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 816000/1801350 [03:08<03:37, 4525.17 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 821000/1801350 [03:08<03:28, 4699.82 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 814000/1801350 [03:08<03:50, 4278.98 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 818000/1801350 [03:08<03:21, 4869.81 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 817000/1801350 [03:08<03:25, 4778.83 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 822000/1801350 [03:08<03:38, 4480.40 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 815000/1801350 [03:08<03:45, 4378.31 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 818000/1801350 [03:09<03:29, 4691.90 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 819000/1801350 [03:08<03:37, 4518.53 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 816000/1801350 [03:08<03:40, 4472.05 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 823000/1801350 [03:08<03:43, 4368.23 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 820000/1801350 [03:08<03:31, 4633.06 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 819000/1801350 [03:09<03:37, 4526.44 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 817000/1801350 [03:08<03:28, 4719.15 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 824000/1801350 [03:08<03:35, 4545.31 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 821000/1801350 [03:09<03:32, 4620.25 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 820000/1801350 [03:09<03:38, 4490.72 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 818000/1801350 [03:09<03:23, 4837.19 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 825000/1801350 [03:09<03:48, 4271.94 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 821000/1801350 [03:09<03:34, 4573.25 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 822000/1801350 [03:09<03:40, 4446.89 examples/s]Grouping texts in chunks of 1024:  45%|████▌     | 819000/1801350 [03:09<03:37, 4506.35 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 823000/1801350 [03:09<03:39, 4462.59 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 822000/1801350 [03:10<03:41, 4423.13 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 826000/1801350 [03:09<04:00, 4063.52 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 820000/1801350 [03:09<03:36, 4526.42 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 827000/1801350 [03:09<03:45, 4316.58 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 824000/1801350 [03:09<03:40, 4423.32 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 823000/1801350 [03:10<03:46, 4324.21 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 821000/1801350 [03:09<03:29, 4689.16 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 828000/1801350 [03:09<03:44, 4340.11 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 824000/1801350 [03:10<03:39, 4461.06 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 825000/1801350 [03:10<03:47, 4283.83 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 822000/1801350 [03:10<03:41, 4416.26 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 829000/1801350 [03:10<03:59, 4057.86 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 825000/1801350 [03:10<03:55, 4154.45 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 826000/1801350 [03:10<03:56, 4115.68 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 823000/1801350 [03:10<03:46, 4314.97 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 827000/1801350 [03:10<03:48, 4264.05 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 830000/1801350 [03:10<03:59, 4061.01 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 826000/1801350 [03:11<04:03, 4012.69 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 824000/1801350 [03:10<03:41, 4421.95 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 828000/1801350 [03:10<03:44, 4344.82 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 827000/1801350 [03:11<03:51, 4216.28 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 831000/1801350 [03:10<04:01, 4012.58 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 825000/1801350 [03:10<03:49, 4247.45 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 828000/1801350 [03:11<03:46, 4299.79 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 832000/1801350 [03:10<03:51, 4194.07 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 829000/1801350 [03:11<04:05, 3967.06 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 826000/1801350 [03:11<03:58, 4091.25 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 833000/1801350 [03:11<03:46, 4272.97 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 830000/1801350 [03:11<03:57, 4092.56 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 829000/1801350 [03:11<04:03, 3995.14 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 827000/1801350 [03:11<03:46, 4299.58 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 834000/1801350 [03:11<03:43, 4322.87 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 830000/1801350 [03:12<03:56, 4114.18 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 831000/1801350 [03:11<04:00, 4035.42 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 828000/1801350 [03:11<03:46, 4305.70 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 835000/1801350 [03:11<03:41, 4360.22 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 832000/1801350 [03:11<03:50, 4202.59 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 831000/1801350 [03:12<04:04, 3970.30 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 829000/1801350 [03:11<04:02, 4011.80 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 836000/1801350 [03:11<03:41, 4352.23 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 833000/1801350 [03:11<03:48, 4242.24 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 832000/1801350 [03:12<03:48, 4241.37 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 830000/1801350 [03:12<04:00, 4037.69 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 837000/1801350 [03:12<03:41, 4353.35 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 834000/1801350 [03:12<03:41, 4360.26 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 833000/1801350 [03:12<03:57, 4077.78 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 831000/1801350 [03:12<03:59, 4057.56 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 838000/1801350 [03:12<03:40, 4376.08 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 835000/1801350 [03:12<03:44, 4305.70 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 834000/1801350 [03:12<03:43, 4336.53 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 832000/1801350 [03:12<03:51, 4190.10 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 839000/1801350 [03:12<03:35, 4461.03 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 836000/1801350 [03:12<03:37, 4435.54 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 835000/1801350 [03:13<03:42, 4350.16 examples/s]Grouping texts in chunks of 1024:  46%|████▌     | 833000/1801350 [03:12<03:52, 4167.72 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 840000/1801350 [03:12<03:45, 4264.46 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 837000/1801350 [03:12<03:43, 4307.81 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 836000/1801350 [03:13<03:40, 4383.51 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 834000/1801350 [03:12<03:42, 4342.45 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 841000/1801350 [03:12<03:35, 4457.46 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 838000/1801350 [03:13<03:33, 4503.47 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 837000/1801350 [03:13<03:45, 4276.57 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 842000/1801350 [03:13<03:29, 4568.98 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 835000/1801350 [03:13<03:47, 4254.29 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 839000/1801350 [03:13<03:38, 4409.80 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 838000/1801350 [03:13<03:42, 4324.55 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 836000/1801350 [03:13<03:44, 4291.29 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 843000/1801350 [03:13<03:37, 4399.11 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 840000/1801350 [03:13<03:45, 4265.06 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 839000/1801350 [03:14<03:42, 4332.82 examples/s]Grouping texts in chunks of 1024:  46%|████▋     | 837000/1801350 [03:13<03:43, 4322.26 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 841000/1801350 [03:13<03:33, 4489.08 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 844000/1801350 [03:13<03:57, 4028.89 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 840000/1801350 [03:14<03:50, 4165.55 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 838000/1801350 [03:13<03:41, 4353.21 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 842000/1801350 [03:13<03:34, 4475.20 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 845000/1801350 [03:13<03:59, 3985.78 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 841000/1801350 [03:14<03:35, 4462.42 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 839000/1801350 [03:14<03:40, 4356.55 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 843000/1801350 [03:14<03:44, 4274.68 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 846000/1801350 [03:14<03:51, 4119.27 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 842000/1801350 [03:14<03:34, 4482.51 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 840000/1801350 [03:14<03:50, 4172.24 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 847000/1801350 [03:14<03:56, 4043.08 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 844000/1801350 [03:14<03:59, 4003.75 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 843000/1801350 [03:15<03:44, 4269.92 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 841000/1801350 [03:14<03:32, 4523.51 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 848000/1801350 [03:14<03:49, 4147.08 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 845000/1801350 [03:14<04:04, 3907.80 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 844000/1801350 [03:15<04:01, 3971.29 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 842000/1801350 [03:14<03:38, 4382.54 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 849000/1801350 [03:14<03:42, 4285.33 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 846000/1801350 [03:14<03:55, 4063.39 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 843000/1801350 [03:15<03:39, 4361.08 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 845000/1801350 [03:15<04:09, 3839.04 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 850000/1801350 [03:15<03:40, 4323.57 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 847000/1801350 [03:15<03:54, 4072.27 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 846000/1801350 [03:15<03:55, 4060.21 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 844000/1801350 [03:15<03:58, 4011.35 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 851000/1801350 [03:15<03:52, 4093.71 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 848000/1801350 [03:15<03:48, 4175.65 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 847000/1801350 [03:16<04:03, 3923.24 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 845000/1801350 [03:15<04:04, 3909.48 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 852000/1801350 [03:15<03:43, 4240.63 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 849000/1801350 [03:15<03:44, 4243.91 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 848000/1801350 [03:16<03:52, 4101.28 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 846000/1801350 [03:15<03:58, 4010.09 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 853000/1801350 [03:15<03:50, 4108.04 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 850000/1801350 [03:15<03:43, 4253.81 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 849000/1801350 [03:16<03:50, 4129.92 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 847000/1801350 [03:16<03:59, 3983.74 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 854000/1801350 [03:16<03:46, 4185.04 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 851000/1801350 [03:16<03:52, 4086.71 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 850000/1801350 [03:16<03:48, 4155.37 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 848000/1801350 [03:16<03:51, 4124.13 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 855000/1801350 [03:16<03:42, 4247.03 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 852000/1801350 [03:16<03:43, 4256.62 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 851000/1801350 [03:17<03:52, 4092.45 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 849000/1801350 [03:16<03:41, 4296.88 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 856000/1801350 [03:16<03:39, 4308.04 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 853000/1801350 [03:16<03:46, 4188.80 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 852000/1801350 [03:17<03:48, 4154.92 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 850000/1801350 [03:16<03:46, 4198.99 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 857000/1801350 [03:16<03:40, 4289.12 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 854000/1801350 [03:16<03:49, 4124.05 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 853000/1801350 [03:17<03:52, 4071.00 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 851000/1801350 [03:17<03:52, 4087.25 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 858000/1801350 [03:17<03:37, 4341.76 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 855000/1801350 [03:17<03:45, 4193.15 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 854000/1801350 [03:17<03:51, 4095.45 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 852000/1801350 [03:17<03:46, 4186.73 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 859000/1801350 [03:17<03:48, 4120.32 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 856000/1801350 [03:17<03:41, 4274.73 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 855000/1801350 [03:18<03:48, 4139.19 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 853000/1801350 [03:17<03:50, 4115.92 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 860000/1801350 [03:17<03:38, 4318.07 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 857000/1801350 [03:17<03:40, 4279.03 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 856000/1801350 [03:18<03:44, 4214.11 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 861000/1801350 [03:17<03:26, 4544.22 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 854000/1801350 [03:17<03:46, 4173.57 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 858000/1801350 [03:17<03:39, 4306.13 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 857000/1801350 [03:18<03:40, 4286.22 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 862000/1801350 [03:17<03:29, 4477.82 examples/s]Grouping texts in chunks of 1024:  47%|████▋     | 855000/1801350 [03:17<03:43, 4238.73 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 859000/1801350 [03:18<03:44, 4199.29 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 863000/1801350 [03:18<03:18, 4726.59 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 858000/1801350 [03:18<03:43, 4220.80 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 856000/1801350 [03:18<03:47, 4163.65 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 860000/1801350 [03:18<03:39, 4280.44 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 864000/1801350 [03:18<03:32, 4414.16 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 859000/1801350 [03:18<03:47, 4135.65 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 857000/1801350 [03:18<03:40, 4285.60 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 861000/1801350 [03:18<03:22, 4652.75 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 865000/1801350 [03:18<03:33, 4393.83 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 860000/1801350 [03:19<03:45, 4183.23 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 858000/1801350 [03:18<03:40, 4281.18 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 862000/1801350 [03:18<03:26, 4547.32 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 861000/1801350 [03:19<03:19, 4704.22 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 866000/1801350 [03:18<03:42, 4211.86 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 863000/1801350 [03:18<03:20, 4674.90 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 859000/1801350 [03:18<03:45, 4170.99 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 862000/1801350 [03:19<03:33, 4393.34 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 867000/1801350 [03:19<03:30, 4444.62 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 864000/1801350 [03:19<03:32, 4418.62 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 860000/1801350 [03:19<03:46, 4151.54 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 863000/1801350 [03:19<03:26, 4542.04 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 864000/1801350 [03:19<02:59, 5235.38 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 868000/1801350 [03:19<04:09, 3748.06 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 861000/1801350 [03:19<04:07, 3802.86 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 865000/1801350 [03:19<04:13, 3700.64 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 869000/1801350 [03:19<03:46, 4115.21 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 862000/1801350 [03:19<03:53, 4015.61 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 866000/1801350 [03:20<02:47, 5584.19 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 866000/1801350 [03:19<03:58, 3921.86 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 870000/1801350 [03:19<03:36, 4299.53 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 863000/1801350 [03:19<03:38, 4301.01 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 867000/1801350 [03:19<03:46, 4125.12 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 867000/1801350 [03:20<03:00, 5180.67 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 871000/1801350 [03:20<03:32, 4379.75 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 864000/1801350 [03:20<03:46, 4144.22 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 868000/1801350 [03:20<03:09, 4928.34 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 868000/1801350 [03:20<03:48, 4085.50 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 872000/1801350 [03:20<03:30, 4415.05 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 865000/1801350 [03:20<03:39, 4261.79 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 869000/1801350 [03:20<03:41, 4216.90 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 869000/1801350 [03:20<03:15, 4773.93 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 873000/1801350 [03:20<03:31, 4386.61 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 870000/1801350 [03:21<03:15, 4770.92 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 866000/1801350 [03:20<03:47, 4109.32 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 870000/1801350 [03:20<03:36, 4298.20 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 874000/1801350 [03:20<03:30, 4402.94 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 871000/1801350 [03:21<03:18, 4676.45 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 867000/1801350 [03:20<03:41, 4215.64 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 871000/1801350 [03:20<03:33, 4362.30 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 875000/1801350 [03:20<03:30, 4391.60 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 872000/1801350 [03:21<03:22, 4579.05 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 868000/1801350 [03:21<03:38, 4262.13 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 872000/1801350 [03:21<03:31, 4392.74 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 876000/1801350 [03:21<03:24, 4519.65 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 873000/1801350 [03:21<03:24, 4539.23 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 873000/1801350 [03:21<03:29, 4434.49 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 869000/1801350 [03:21<03:38, 4272.81 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 877000/1801350 [03:21<03:30, 4393.21 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 874000/1801350 [03:22<03:23, 4560.94 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 870000/1801350 [03:21<03:30, 4430.64 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 874000/1801350 [03:21<03:27, 4468.13 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 878000/1801350 [03:21<03:34, 4299.79 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 871000/1801350 [03:21<03:27, 4476.13 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 875000/1801350 [03:21<03:25, 4504.45 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 875000/1801350 [03:22<03:27, 4464.65 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 879000/1801350 [03:21<03:32, 4347.22 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 872000/1801350 [03:21<03:24, 4536.76 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 876000/1801350 [03:21<03:23, 4545.96 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 876000/1801350 [03:22<03:26, 4478.69 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 880000/1801350 [03:22<03:34, 4299.74 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 877000/1801350 [03:22<03:29, 4410.41 examples/s]Grouping texts in chunks of 1024:  48%|████▊     | 873000/1801350 [03:22<03:33, 4343.93 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 877000/1801350 [03:22<03:33, 4332.19 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 881000/1801350 [03:22<03:36, 4254.37 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 874000/1801350 [03:22<03:31, 4393.10 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 878000/1801350 [03:22<03:31, 4357.69 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 878000/1801350 [03:23<03:31, 4362.80 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 882000/1801350 [03:22<03:46, 4066.59 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 875000/1801350 [03:22<03:25, 4515.24 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 879000/1801350 [03:22<03:26, 4467.67 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 879000/1801350 [03:23<03:34, 4296.64 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 883000/1801350 [03:22<03:41, 4143.04 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 876000/1801350 [03:22<03:26, 4470.32 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 880000/1801350 [03:22<03:35, 4278.04 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 880000/1801350 [03:23<03:35, 4276.36 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 884000/1801350 [03:23<03:32, 4319.27 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 877000/1801350 [03:23<03:31, 4366.61 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 881000/1801350 [03:23<03:38, 4214.99 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 881000/1801350 [03:23<03:39, 4188.73 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 885000/1801350 [03:23<03:41, 4133.79 examples/s]Grouping texts in chunks of 1024:  49%|████▊     | 878000/1801350 [03:23<03:34, 4298.55 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 882000/1801350 [03:23<03:50, 3987.36 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 882000/1801350 [03:24<03:50, 3994.51 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 886000/1801350 [03:23<03:28, 4381.47 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 879000/1801350 [03:23<03:30, 4381.82 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 883000/1801350 [03:23<03:44, 4085.25 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 883000/1801350 [03:24<03:47, 4030.86 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 887000/1801350 [03:23<03:23, 4494.29 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 880000/1801350 [03:23<03:39, 4190.67 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 884000/1801350 [03:23<03:35, 4257.94 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 884000/1801350 [03:24<03:40, 4166.79 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 888000/1801350 [03:23<03:31, 4316.32 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 881000/1801350 [03:24<03:36, 4246.01 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 885000/1801350 [03:24<03:38, 4198.13 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 885000/1801350 [03:24<03:40, 4164.40 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 889000/1801350 [03:24<03:32, 4295.90 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 886000/1801350 [03:24<03:29, 4359.70 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 882000/1801350 [03:24<03:50, 3985.53 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 886000/1801350 [03:24<03:27, 4406.90 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 890000/1801350 [03:24<03:31, 4299.33 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 887000/1801350 [03:24<03:24, 4473.95 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 883000/1801350 [03:24<03:42, 4133.47 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 887000/1801350 [03:25<03:26, 4431.94 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 891000/1801350 [03:24<03:20, 4548.74 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 888000/1801350 [03:24<03:31, 4314.54 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 884000/1801350 [03:24<03:39, 4171.14 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 888000/1801350 [03:25<03:29, 4352.52 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 892000/1801350 [03:24<03:31, 4292.13 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 889000/1801350 [03:25<03:32, 4285.80 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 885000/1801350 [03:25<03:38, 4185.88 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 889000/1801350 [03:25<03:36, 4212.13 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 893000/1801350 [03:25<03:31, 4293.14 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 886000/1801350 [03:25<03:30, 4346.87 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 890000/1801350 [03:25<03:29, 4345.91 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 890000/1801350 [03:25<03:31, 4307.32 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 894000/1801350 [03:25<03:42, 4078.21 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 887000/1801350 [03:25<03:21, 4529.24 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 891000/1801350 [03:25<03:22, 4501.20 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 891000/1801350 [03:26<03:26, 4397.98 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 895000/1801350 [03:25<03:44, 4038.72 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 888000/1801350 [03:25<03:33, 4273.53 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 892000/1801350 [03:25<03:32, 4287.65 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 892000/1801350 [03:26<03:33, 4251.32 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 896000/1801350 [03:25<03:32, 4254.53 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 889000/1801350 [03:25<03:30, 4344.41 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 893000/1801350 [03:25<03:35, 4216.83 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 893000/1801350 [03:26<03:34, 4238.31 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 897000/1801350 [03:26<03:28, 4347.77 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 890000/1801350 [03:26<03:28, 4363.59 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 894000/1801350 [03:26<03:38, 4149.25 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 894000/1801350 [03:26<03:45, 4023.56 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 898000/1801350 [03:26<03:25, 4398.78 examples/s]Grouping texts in chunks of 1024:  49%|████▉     | 891000/1801350 [03:26<03:25, 4426.15 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 895000/1801350 [03:26<03:45, 4025.67 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 895000/1801350 [03:27<03:43, 4055.67 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 899000/1801350 [03:26<03:19, 4529.14 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 892000/1801350 [03:26<03:36, 4198.45 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 896000/1801350 [03:26<03:32, 4251.17 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 896000/1801350 [03:27<03:34, 4211.30 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 900000/1801350 [03:26<03:18, 4548.13 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 893000/1801350 [03:26<03:38, 4153.34 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 897000/1801350 [03:26<03:30, 4300.47 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 897000/1801350 [03:27<03:36, 4180.84 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 901000/1801350 [03:26<03:26, 4362.89 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 898000/1801350 [03:27<03:25, 4399.94 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 894000/1801350 [03:27<03:40, 4113.69 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 898000/1801350 [03:27<03:29, 4319.08 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 902000/1801350 [03:27<03:29, 4302.14 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 899000/1801350 [03:27<03:19, 4534.37 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 895000/1801350 [03:27<03:40, 4116.06 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 899000/1801350 [03:27<03:25, 4399.36 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 903000/1801350 [03:27<03:39, 4098.80 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 900000/1801350 [03:27<03:18, 4532.75 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 896000/1801350 [03:27<03:35, 4206.17 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 900000/1801350 [03:28<03:27, 4345.55 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 904000/1801350 [03:27<03:35, 4154.82 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 901000/1801350 [03:27<03:23, 4413.60 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 897000/1801350 [03:27<03:29, 4326.75 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 901000/1801350 [03:28<03:30, 4282.50 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 905000/1801350 [03:28<03:47, 3946.46 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 902000/1801350 [03:28<03:34, 4191.07 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 898000/1801350 [03:28<03:32, 4249.76 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 902000/1801350 [03:28<03:34, 4195.09 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 906000/1801350 [03:28<03:32, 4204.73 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 899000/1801350 [03:28<03:25, 4392.16 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 903000/1801350 [03:28<03:42, 4039.35 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 903000/1801350 [03:28<03:42, 4039.14 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 907000/1801350 [03:28<03:26, 4327.69 examples/s]Grouping texts in chunks of 1024:  50%|████▉     | 900000/1801350 [03:28<03:23, 4430.26 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 904000/1801350 [03:28<03:39, 4088.87 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 904000/1801350 [03:29<03:39, 4096.04 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 908000/1801350 [03:28<03:39, 4062.00 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 901000/1801350 [03:28<03:31, 4262.37 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 905000/1801350 [03:28<03:45, 3980.17 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 909000/1801350 [03:28<03:32, 4197.14 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 905000/1801350 [03:29<03:55, 3798.12 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 902000/1801350 [03:28<03:33, 4213.14 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 906000/1801350 [03:29<03:35, 4154.13 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 906000/1801350 [03:29<03:38, 4106.19 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 910000/1801350 [03:29<03:31, 4214.97 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 907000/1801350 [03:29<03:24, 4363.55 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 903000/1801350 [03:29<03:40, 4065.56 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 907000/1801350 [03:29<03:25, 4353.68 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 911000/1801350 [03:29<03:28, 4265.93 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 904000/1801350 [03:29<03:33, 4203.00 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 908000/1801350 [03:29<03:38, 4090.80 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 912000/1801350 [03:29<03:18, 4471.13 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 908000/1801350 [03:30<03:43, 3992.90 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 909000/1801350 [03:29<03:30, 4245.41 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 905000/1801350 [03:29<03:48, 3927.95 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 909000/1801350 [03:30<03:29, 4264.01 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 913000/1801350 [03:29<03:26, 4311.21 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 906000/1801350 [03:29<03:31, 4238.76 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 910000/1801350 [03:29<03:30, 4243.51 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 914000/1801350 [03:30<03:27, 4271.54 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 910000/1801350 [03:30<03:35, 4141.02 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 907000/1801350 [03:30<03:27, 4320.03 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 911000/1801350 [03:30<03:28, 4277.95 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 911000/1801350 [03:30<03:27, 4299.70 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 915000/1801350 [03:30<03:35, 4119.47 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 912000/1801350 [03:30<03:21, 4418.06 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 908000/1801350 [03:30<03:36, 4117.20 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 912000/1801350 [03:31<03:21, 4409.44 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 916000/1801350 [03:30<03:25, 4299.23 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 913000/1801350 [03:30<03:19, 4448.40 examples/s]Grouping texts in chunks of 1024:  50%|█████     | 909000/1801350 [03:30<03:28, 4279.49 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 917000/1801350 [03:30<03:16, 4510.41 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 913000/1801350 [03:31<03:25, 4321.10 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 914000/1801350 [03:30<03:30, 4217.26 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 910000/1801350 [03:30<03:36, 4111.27 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 918000/1801350 [03:30<03:17, 4481.62 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 914000/1801350 [03:31<03:30, 4222.65 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 915000/1801350 [03:31<03:34, 4130.96 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 911000/1801350 [03:31<03:30, 4223.64 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 919000/1801350 [03:31<03:15, 4505.59 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 915000/1801350 [03:31<03:39, 4034.42 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 912000/1801350 [03:31<03:16, 4515.41 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 916000/1801350 [03:31<03:27, 4260.79 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 920000/1801350 [03:31<03:22, 4345.43 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 916000/1801350 [03:32<03:29, 4235.22 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 917000/1801350 [03:31<03:19, 4443.04 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 913000/1801350 [03:31<03:22, 4390.31 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 921000/1801350 [03:31<03:04, 4766.49 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 917000/1801350 [03:32<03:19, 4440.30 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 918000/1801350 [03:31<03:18, 4441.56 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 914000/1801350 [03:31<03:30, 4208.12 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 922000/1801350 [03:31<03:16, 4478.10 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 918000/1801350 [03:32<03:18, 4439.32 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 919000/1801350 [03:32<03:14, 4531.92 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 923000/1801350 [03:32<03:10, 4612.28 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 915000/1801350 [03:32<03:31, 4185.92 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 919000/1801350 [03:32<03:20, 4389.81 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 920000/1801350 [03:32<03:20, 4386.56 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 924000/1801350 [03:32<03:17, 4442.68 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 916000/1801350 [03:32<03:30, 4212.30 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 920000/1801350 [03:32<03:21, 4381.05 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 921000/1801350 [03:32<03:05, 4734.16 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 917000/1801350 [03:32<03:14, 4542.14 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 925000/1801350 [03:32<03:12, 4552.58 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 921000/1801350 [03:33<03:09, 4655.13 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 922000/1801350 [03:32<03:16, 4469.12 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 918000/1801350 [03:32<03:18, 4458.04 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 926000/1801350 [03:32<03:12, 4542.38 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 922000/1801350 [03:33<03:14, 4525.37 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 923000/1801350 [03:32<03:10, 4618.72 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 919000/1801350 [03:32<03:17, 4473.03 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 927000/1801350 [03:33<03:24, 4279.72 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 923000/1801350 [03:33<03:14, 4517.97 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 924000/1801350 [03:33<03:18, 4421.35 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 920000/1801350 [03:33<03:22, 4359.88 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 928000/1801350 [03:33<03:22, 4320.03 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 924000/1801350 [03:33<03:21, 4344.71 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 925000/1801350 [03:33<03:16, 4461.97 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 921000/1801350 [03:33<03:03, 4796.71 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 929000/1801350 [03:33<03:18, 4394.30 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 925000/1801350 [03:34<03:16, 4451.28 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 926000/1801350 [03:33<03:14, 4506.55 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 922000/1801350 [03:33<03:17, 4446.25 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 930000/1801350 [03:33<03:19, 4365.08 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 926000/1801350 [03:34<03:18, 4401.65 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 927000/1801350 [03:33<03:20, 4356.89 examples/s]Grouping texts in chunks of 1024:  51%|█████     | 923000/1801350 [03:33<03:11, 4585.84 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 931000/1801350 [03:33<03:20, 4333.29 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 927000/1801350 [03:34<03:24, 4269.75 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 928000/1801350 [03:34<03:24, 4265.29 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 924000/1801350 [03:34<03:20, 4373.07 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 932000/1801350 [03:34<03:20, 4332.94 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 928000/1801350 [03:34<03:29, 4162.83 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 925000/1801350 [03:34<03:12, 4562.44 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 929000/1801350 [03:34<03:23, 4295.05 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 933000/1801350 [03:34<03:20, 4340.13 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 929000/1801350 [03:34<03:21, 4335.70 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 926000/1801350 [03:34<03:15, 4485.09 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 930000/1801350 [03:34<03:23, 4288.05 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 934000/1801350 [03:34<03:30, 4126.97 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 930000/1801350 [03:35<03:26, 4215.07 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 931000/1801350 [03:34<03:22, 4300.17 examples/s]Grouping texts in chunks of 1024:  51%|█████▏    | 927000/1801350 [03:34<03:22, 4308.95 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 935000/1801350 [03:34<03:22, 4272.97 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 931000/1801350 [03:35<03:23, 4271.99 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 932000/1801350 [03:34<03:19, 4358.16 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 928000/1801350 [03:34<03:23, 4293.81 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 936000/1801350 [03:35<03:19, 4343.44 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 932000/1801350 [03:35<03:18, 4384.29 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 933000/1801350 [03:35<03:24, 4252.00 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 929000/1801350 [03:35<03:25, 4241.26 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 937000/1801350 [03:35<03:23, 4239.16 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 933000/1801350 [03:35<03:23, 4259.32 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 930000/1801350 [03:35<03:19, 4358.43 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 934000/1801350 [03:35<03:25, 4223.31 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 938000/1801350 [03:35<03:31, 4075.12 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 934000/1801350 [03:36<03:30, 4127.20 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 935000/1801350 [03:35<03:24, 4242.10 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 931000/1801350 [03:35<03:23, 4267.97 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 939000/1801350 [03:35<03:20, 4296.06 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 935000/1801350 [03:36<03:29, 4135.12 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 936000/1801350 [03:35<03:18, 4353.25 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 932000/1801350 [03:35<03:20, 4335.20 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 940000/1801350 [03:36<03:28, 4141.06 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 936000/1801350 [03:36<03:19, 4338.79 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 937000/1801350 [03:36<03:22, 4266.05 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 933000/1801350 [03:36<03:25, 4231.86 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 941000/1801350 [03:36<03:15, 4392.91 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 937000/1801350 [03:36<03:24, 4222.55 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 938000/1801350 [03:36<03:29, 4114.35 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 934000/1801350 [03:36<03:30, 4125.44 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 942000/1801350 [03:36<03:16, 4367.73 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 938000/1801350 [03:37<03:34, 4024.77 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 939000/1801350 [03:36<03:21, 4281.49 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 935000/1801350 [03:36<03:26, 4200.96 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 943000/1801350 [03:36<03:23, 4228.07 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 939000/1801350 [03:37<03:24, 4213.70 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 936000/1801350 [03:36<03:19, 4334.25 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 940000/1801350 [03:36<03:26, 4174.22 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 944000/1801350 [03:36<03:26, 4144.10 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 941000/1801350 [03:37<03:16, 4371.76 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 940000/1801350 [03:37<03:37, 3955.19 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 937000/1801350 [03:37<03:24, 4219.15 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 945000/1801350 [03:37<03:32, 4025.95 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 941000/1801350 [03:37<03:24, 4211.00 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 942000/1801350 [03:37<03:17, 4344.79 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 938000/1801350 [03:37<03:33, 4045.75 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 946000/1801350 [03:37<03:25, 4167.13 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 942000/1801350 [03:38<03:25, 4176.86 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 943000/1801350 [03:37<03:23, 4226.81 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 939000/1801350 [03:37<03:28, 4145.59 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 947000/1801350 [03:37<03:19, 4290.72 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 943000/1801350 [03:38<03:29, 4096.33 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 944000/1801350 [03:37<03:29, 4093.55 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 940000/1801350 [03:37<03:32, 4062.19 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 948000/1801350 [03:37<03:17, 4314.47 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 944000/1801350 [03:38<03:27, 4126.47 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 941000/1801350 [03:38<03:16, 4386.15 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 945000/1801350 [03:38<03:31, 4040.24 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 949000/1801350 [03:38<03:01, 4695.25 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 946000/1801350 [03:38<03:21, 4241.52 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 942000/1801350 [03:38<03:15, 4396.50 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 945000/1801350 [03:38<03:33, 4016.07 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 950000/1801350 [03:38<03:05, 4598.76 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 947000/1801350 [03:38<03:19, 4286.72 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 946000/1801350 [03:39<03:25, 4157.63 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 943000/1801350 [03:38<03:22, 4235.92 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 951000/1801350 [03:38<03:12, 4422.33 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 948000/1801350 [03:38<03:16, 4350.12 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 947000/1801350 [03:39<03:22, 4219.55 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 952000/1801350 [03:38<03:08, 4516.07 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 944000/1801350 [03:38<03:27, 4138.40 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 949000/1801350 [03:38<03:01, 4688.34 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 948000/1801350 [03:39<03:18, 4301.61 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 953000/1801350 [03:39<03:13, 4382.33 examples/s]Grouping texts in chunks of 1024:  52%|█████▏    | 945000/1801350 [03:39<03:28, 4113.54 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 949000/1801350 [03:39<02:58, 4780.39 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 950000/1801350 [03:39<03:03, 4642.71 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 954000/1801350 [03:39<03:12, 4390.67 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 946000/1801350 [03:39<03:23, 4197.60 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 950000/1801350 [03:39<03:06, 4568.47 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 951000/1801350 [03:39<03:12, 4415.79 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 955000/1801350 [03:39<03:05, 4563.25 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 947000/1801350 [03:39<03:16, 4342.00 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 952000/1801350 [03:39<03:13, 4382.52 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 951000/1801350 [03:40<03:16, 4329.22 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 956000/1801350 [03:39<03:05, 4557.22 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 948000/1801350 [03:39<03:20, 4256.82 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 953000/1801350 [03:39<03:16, 4328.11 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 952000/1801350 [03:40<03:15, 4343.75 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 949000/1801350 [03:39<03:02, 4668.30 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 957000/1801350 [03:39<03:07, 4491.69 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 954000/1801350 [03:40<03:10, 4458.79 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 958000/1801350 [03:40<02:57, 4744.75 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 953000/1801350 [03:40<03:15, 4333.61 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 950000/1801350 [03:40<03:04, 4612.77 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 955000/1801350 [03:40<03:10, 4437.72 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 954000/1801350 [03:40<03:13, 4367.99 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 959000/1801350 [03:40<03:08, 4462.41 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 951000/1801350 [03:40<03:10, 4456.91 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 956000/1801350 [03:40<03:07, 4515.23 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 955000/1801350 [03:41<03:07, 4502.16 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 960000/1801350 [03:40<03:07, 4493.45 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 952000/1801350 [03:40<03:11, 4436.49 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 957000/1801350 [03:40<03:03, 4597.08 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 956000/1801350 [03:41<03:11, 4414.62 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 961000/1801350 [03:40<03:06, 4509.44 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 953000/1801350 [03:40<03:17, 4300.69 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 958000/1801350 [03:40<03:01, 4637.25 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 962000/1801350 [03:40<02:59, 4674.47 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 957000/1801350 [03:41<03:08, 4477.44 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 954000/1801350 [03:41<03:14, 4365.59 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 958000/1801350 [03:41<02:59, 4698.52 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 959000/1801350 [03:41<03:10, 4417.26 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 963000/1801350 [03:41<03:01, 4610.16 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 955000/1801350 [03:41<03:06, 4533.35 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 960000/1801350 [03:41<03:08, 4460.47 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 959000/1801350 [03:41<03:10, 4419.75 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 964000/1801350 [03:41<03:05, 4506.63 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 956000/1801350 [03:41<03:06, 4531.36 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 961000/1801350 [03:41<03:01, 4629.12 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 960000/1801350 [03:42<03:12, 4380.09 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 965000/1801350 [03:41<03:09, 4415.86 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 957000/1801350 [03:41<03:08, 4474.24 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 962000/1801350 [03:41<03:02, 4610.18 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 961000/1801350 [03:42<03:10, 4406.41 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 966000/1801350 [03:41<03:07, 4445.69 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 958000/1801350 [03:41<03:00, 4668.24 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 963000/1801350 [03:42<03:01, 4627.86 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 962000/1801350 [03:42<03:04, 4537.69 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 967000/1801350 [03:42<03:11, 4363.76 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 959000/1801350 [03:42<03:08, 4465.52 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 964000/1801350 [03:42<03:08, 4438.91 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 963000/1801350 [03:42<03:04, 4550.38 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 968000/1801350 [03:42<03:14, 4289.18 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 960000/1801350 [03:42<03:10, 4404.99 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 965000/1801350 [03:42<03:06, 4480.94 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 964000/1801350 [03:43<03:09, 4412.90 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 969000/1801350 [03:42<03:06, 4455.03 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 961000/1801350 [03:42<03:08, 4464.64 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 966000/1801350 [03:42<03:08, 4434.61 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 965000/1801350 [03:43<03:08, 4429.69 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 962000/1801350 [03:42<03:00, 4639.37 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 970000/1801350 [03:42<03:09, 4389.47 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 967000/1801350 [03:42<03:11, 4357.34 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 966000/1801350 [03:43<03:09, 4398.58 examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 963000/1801350 [03:43<03:05, 4514.27 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 971000/1801350 [03:43<03:10, 4366.16 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 968000/1801350 [03:43<03:14, 4295.50 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 967000/1801350 [03:43<03:14, 4285.19 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 964000/1801350 [03:43<03:07, 4463.22 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 972000/1801350 [03:43<03:10, 4362.47 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 969000/1801350 [03:43<03:09, 4398.34 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 973000/1801350 [03:43<02:51, 4824.23 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 968000/1801350 [03:44<03:15, 4260.96 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 965000/1801350 [03:43<03:12, 4355.41 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 974000/1801350 [03:43<02:45, 5000.17 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 970000/1801350 [03:43<03:10, 4374.83 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 966000/1801350 [03:43<03:03, 4559.14 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 969000/1801350 [03:44<03:11, 4345.51 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 975000/1801350 [03:43<02:56, 4669.45 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 971000/1801350 [03:43<03:06, 4449.27 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 967000/1801350 [03:43<03:09, 4392.08 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 970000/1801350 [03:44<03:14, 4268.11 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 976000/1801350 [03:44<02:50, 4847.77 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 972000/1801350 [03:44<03:13, 4294.80 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 971000/1801350 [03:44<03:10, 4350.96 examples/s]Grouping texts in chunks of 1024:  54%|█████▎    | 968000/1801350 [03:44<03:15, 4273.34 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 973000/1801350 [03:44<02:50, 4860.54 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 977000/1801350 [03:44<02:59, 4594.96 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 972000/1801350 [03:44<03:12, 4313.19 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 969000/1801350 [03:44<03:11, 4355.73 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 974000/1801350 [03:44<02:47, 4933.71 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 978000/1801350 [03:44<02:59, 4585.69 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 973000/1801350 [03:45<02:54, 4740.59 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 970000/1801350 [03:44<03:13, 4292.31 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 975000/1801350 [03:44<02:59, 4612.63 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 979000/1801350 [03:44<03:00, 4552.66 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 974000/1801350 [03:45<02:47, 4926.44 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 971000/1801350 [03:44<03:11, 4345.86 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 976000/1801350 [03:44<02:53, 4743.70 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 980000/1801350 [03:44<02:58, 4605.52 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 975000/1801350 [03:45<02:59, 4594.98 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 972000/1801350 [03:45<03:10, 4344.71 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 977000/1801350 [03:45<02:57, 4650.77 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 981000/1801350 [03:45<03:04, 4453.66 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 976000/1801350 [03:45<02:54, 4740.12 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 973000/1801350 [03:45<02:52, 4811.56 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 978000/1801350 [03:45<02:57, 4640.13 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 982000/1801350 [03:45<02:51, 4771.05 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 977000/1801350 [03:45<02:55, 4688.93 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 974000/1801350 [03:45<02:48, 4896.40 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 979000/1801350 [03:45<03:01, 4532.53 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 983000/1801350 [03:45<03:05, 4418.51 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 978000/1801350 [03:46<03:01, 4529.64 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 975000/1801350 [03:45<02:58, 4628.81 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 980000/1801350 [03:45<02:56, 4664.18 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 984000/1801350 [03:45<03:11, 4271.32 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 979000/1801350 [03:46<03:03, 4475.84 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 976000/1801350 [03:45<02:52, 4775.69 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 981000/1801350 [03:46<02:58, 4585.63 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 985000/1801350 [03:46<03:01, 4501.26 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 980000/1801350 [03:46<02:57, 4625.53 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 977000/1801350 [03:46<02:57, 4643.74 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 982000/1801350 [03:46<02:53, 4717.26 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 986000/1801350 [03:46<03:00, 4505.69 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 981000/1801350 [03:46<02:59, 4560.27 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 978000/1801350 [03:46<02:56, 4673.83 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 983000/1801350 [03:46<03:06, 4382.76 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 982000/1801350 [03:47<02:56, 4642.42 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 987000/1801350 [03:46<03:02, 4454.29 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 979000/1801350 [03:46<03:00, 4547.46 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 984000/1801350 [03:46<03:07, 4370.50 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 980000/1801350 [03:46<02:56, 4654.98 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 983000/1801350 [03:47<03:06, 4381.10 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 988000/1801350 [03:46<03:11, 4241.31 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 985000/1801350 [03:46<03:02, 4466.05 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 989000/1801350 [03:47<03:06, 4353.16 examples/s]Grouping texts in chunks of 1024:  54%|█████▍    | 981000/1801350 [03:47<03:02, 4484.56 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 984000/1801350 [03:47<03:12, 4255.27 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 986000/1801350 [03:47<03:02, 4471.17 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 982000/1801350 [03:47<02:58, 4597.12 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 990000/1801350 [03:47<03:05, 4385.17 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 985000/1801350 [03:47<03:06, 4388.93 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 987000/1801350 [03:47<03:06, 4363.07 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 991000/1801350 [03:47<03:05, 4376.49 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 986000/1801350 [03:48<03:05, 4397.32 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 983000/1801350 [03:47<03:06, 4385.32 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 988000/1801350 [03:47<03:12, 4225.60 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 992000/1801350 [03:47<03:03, 4401.83 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 987000/1801350 [03:48<03:06, 4358.57 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 984000/1801350 [03:47<03:12, 4237.23 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 989000/1801350 [03:47<03:13, 4204.41 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 993000/1801350 [03:47<02:58, 4537.33 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 985000/1801350 [03:47<03:04, 4420.44 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 988000/1801350 [03:48<03:11, 4252.61 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 990000/1801350 [03:48<03:03, 4417.31 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 994000/1801350 [03:48<02:48, 4803.15 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 986000/1801350 [03:48<03:02, 4461.01 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 989000/1801350 [03:48<03:13, 4207.26 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 995000/1801350 [03:48<02:51, 4704.70 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 991000/1801350 [03:48<03:06, 4350.61 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 987000/1801350 [03:48<03:00, 4517.79 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 990000/1801350 [03:48<03:11, 4228.78 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 996000/1801350 [03:48<02:46, 4846.76 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 992000/1801350 [03:48<03:06, 4348.80 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 988000/1801350 [03:48<03:07, 4334.27 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 991000/1801350 [03:49<03:05, 4370.28 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 993000/1801350 [03:48<02:58, 4533.64 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 997000/1801350 [03:48<03:01, 4434.84 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 992000/1801350 [03:49<03:04, 4396.40 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 989000/1801350 [03:48<03:12, 4215.23 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 994000/1801350 [03:48<02:56, 4586.94 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 998000/1801350 [03:48<02:59, 4467.41 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 993000/1801350 [03:49<02:59, 4491.29 examples/s]Grouping texts in chunks of 1024:  55%|█████▍    | 990000/1801350 [03:49<03:07, 4338.37 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 995000/1801350 [03:49<02:50, 4740.47 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 999000/1801350 [03:49<03:00, 4447.93 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 994000/1801350 [03:49<02:55, 4592.94 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 991000/1801350 [03:49<03:08, 4298.97 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 996000/1801350 [03:49<02:50, 4719.42 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1000000/1801350 [03:49<03:02, 4380.20 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 995000/1801350 [03:50<02:55, 4590.83 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 992000/1801350 [03:49<03:06, 4329.45 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 997000/1801350 [03:49<03:01, 4431.01 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1001000/1801350 [03:49<03:03, 4361.52 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 996000/1801350 [03:50<02:53, 4647.37 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 993000/1801350 [03:49<02:57, 4558.46 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 998000/1801350 [03:49<02:58, 4497.48 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1002000/1801350 [03:49<03:01, 4399.57 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 994000/1801350 [03:49<02:53, 4647.64 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 997000/1801350 [03:50<03:03, 4376.31 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 998000/1801350 [03:50<02:46, 4821.81 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1003000/1801350 [03:50<03:09, 4223.58 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 995000/1801350 [03:50<02:57, 4539.93 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 999000/1801350 [03:50<03:35, 3720.65 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 999000/1801350 [03:50<02:48, 4774.36 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 996000/1801350 [03:50<02:44, 4892.10 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1004000/1801350 [03:50<03:00, 4408.07 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1000000/1801350 [03:50<03:20, 4000.26 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1005000/1801350 [03:50<03:01, 4383.54 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1000000/1801350 [03:51<02:58, 4494.45 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 997000/1801350 [03:50<02:56, 4552.78 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1001000/1801350 [03:50<03:09, 4233.74 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1001000/1801350 [03:51<02:52, 4629.24 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1006000/1801350 [03:50<03:01, 4386.08 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 998000/1801350 [03:50<02:57, 4517.65 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1002000/1801350 [03:50<03:09, 4211.83 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1002000/1801350 [03:51<02:56, 4524.66 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1007000/1801350 [03:51<03:05, 4284.72 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1003000/1801350 [03:51<03:02, 4371.93 examples/s]Grouping texts in chunks of 1024:  55%|█████▌    | 999000/1801350 [03:51<03:03, 4379.78 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1003000/1801350 [03:51<02:58, 4466.74 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1008000/1801350 [03:51<03:01, 4364.20 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1004000/1801350 [03:51<03:00, 4414.91 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1000000/1801350 [03:51<03:05, 4319.28 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1004000/1801350 [03:52<02:54, 4556.72 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1001000/1801350 [03:51<02:57, 4510.27 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1009000/1801350 [03:51<03:03, 4312.19 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1005000/1801350 [03:51<03:07, 4246.19 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1005000/1801350 [03:52<03:05, 4296.48 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1002000/1801350 [03:51<02:58, 4470.10 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1010000/1801350 [03:51<03:04, 4298.99 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1006000/1801350 [03:51<03:01, 4385.96 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1006000/1801350 [03:52<02:58, 4451.36 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1003000/1801350 [03:51<02:56, 4519.91 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1011000/1801350 [03:51<03:04, 4274.98 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1007000/1801350 [03:52<03:04, 4312.24 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1004000/1801350 [03:52<02:58, 4479.13 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1007000/1801350 [03:52<03:06, 4267.24 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1012000/1801350 [03:52<03:03, 4308.13 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1008000/1801350 [03:52<03:02, 4352.65 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1008000/1801350 [03:52<03:06, 4264.52 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1013000/1801350 [03:52<03:00, 4377.26 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1005000/1801350 [03:52<03:06, 4261.82 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1009000/1801350 [03:52<03:06, 4239.63 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1006000/1801350 [03:52<02:58, 4446.57 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1014000/1801350 [03:52<02:56, 4471.45 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1009000/1801350 [03:53<03:06, 4250.97 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1010000/1801350 [03:52<03:01, 4367.89 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1015000/1801350 [03:52<02:50, 4603.80 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1007000/1801350 [03:52<03:02, 4359.22 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1010000/1801350 [03:53<03:05, 4264.96 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1011000/1801350 [03:52<03:05, 4270.32 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1016000/1801350 [03:53<02:59, 4364.71 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1008000/1801350 [03:53<03:08, 4215.58 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1011000/1801350 [03:53<03:08, 4184.12 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1012000/1801350 [03:53<03:03, 4310.33 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1017000/1801350 [03:53<03:00, 4351.20 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1009000/1801350 [03:53<03:06, 4249.48 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1012000/1801350 [03:53<03:06, 4243.34 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1013000/1801350 [03:53<03:00, 4357.68 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1018000/1801350 [03:53<03:01, 4309.43 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1013000/1801350 [03:54<02:59, 4381.90 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1010000/1801350 [03:53<03:03, 4323.65 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1014000/1801350 [03:53<02:57, 4432.95 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1019000/1801350 [03:53<02:56, 4420.42 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1014000/1801350 [03:54<02:54, 4500.71 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1015000/1801350 [03:53<02:53, 4538.49 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1011000/1801350 [03:53<03:04, 4289.14 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1020000/1801350 [03:54<02:57, 4408.17 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1015000/1801350 [03:54<02:57, 4431.89 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1016000/1801350 [03:54<03:01, 4319.56 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1012000/1801350 [03:54<03:07, 4213.68 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1021000/1801350 [03:54<02:57, 4393.71 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1016000/1801350 [03:54<03:03, 4273.20 examples/s]Grouping texts in chunks of 1024:  56%|█████▌    | 1013000/1801350 [03:54<03:00, 4376.53 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1017000/1801350 [03:54<03:00, 4351.43 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1014000/1801350 [03:54<02:55, 4485.84 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1017000/1801350 [03:55<03:03, 4285.89 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1018000/1801350 [03:54<03:01, 4321.40 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1022000/1801350 [03:54<03:11, 4079.07 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1015000/1801350 [03:54<02:52, 4571.66 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1019000/1801350 [03:54<02:56, 4431.01 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1023000/1801350 [03:54<03:06, 4162.75 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1018000/1801350 [03:55<03:08, 4163.66 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1020000/1801350 [03:54<02:54, 4475.57 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1016000/1801350 [03:54<03:01, 4332.79 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1019000/1801350 [03:55<02:59, 4368.33 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1024000/1801350 [03:54<03:05, 4180.48 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1021000/1801350 [03:55<02:54, 4465.03 examples/s]Grouping texts in chunks of 1024:  56%|█████▋    | 1017000/1801350 [03:55<03:02, 4307.48 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1020000/1801350 [03:55<03:02, 4284.98 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1025000/1801350 [03:55<03:17, 3932.37 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1021000/1801350 [03:56<02:59, 4352.54 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1018000/1801350 [03:55<03:05, 4222.01 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1022000/1801350 [03:55<03:12, 4046.30 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1026000/1801350 [03:55<03:18, 3902.59 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1019000/1801350 [03:55<02:56, 4422.25 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1023000/1801350 [03:55<03:12, 4052.95 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1022000/1801350 [03:56<03:15, 3987.94 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1027000/1801350 [03:55<03:11, 4041.97 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1020000/1801350 [03:55<03:00, 4328.70 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1024000/1801350 [03:55<03:06, 4167.04 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1023000/1801350 [03:56<03:10, 4081.71 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1028000/1801350 [03:56<03:16, 3930.96 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1021000/1801350 [03:56<03:00, 4327.28 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1024000/1801350 [03:56<03:11, 4065.52 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1025000/1801350 [03:56<03:17, 3924.93 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1029000/1801350 [03:56<03:12, 4021.98 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1022000/1801350 [03:56<03:13, 4022.57 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1030000/1801350 [03:56<03:01, 4256.24 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1025000/1801350 [03:57<03:20, 3868.18 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1026000/1801350 [03:56<03:20, 3858.68 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1023000/1801350 [03:56<03:07, 4143.46 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1031000/1801350 [03:56<02:56, 4371.02 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1027000/1801350 [03:56<03:12, 4023.17 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1026000/1801350 [03:57<03:19, 3892.62 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1024000/1801350 [03:56<03:06, 4171.60 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1032000/1801350 [03:56<02:59, 4283.00 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1027000/1801350 [03:57<03:12, 4031.97 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1028000/1801350 [03:57<03:17, 3922.25 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1033000/1801350 [03:57<02:50, 4495.79 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1025000/1801350 [03:57<03:23, 3819.95 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1029000/1801350 [03:57<03:10, 4045.94 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1028000/1801350 [03:57<03:17, 3925.58 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1034000/1801350 [03:57<02:49, 4528.21 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1026000/1801350 [03:57<03:18, 3898.29 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1030000/1801350 [03:57<03:03, 4202.21 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1029000/1801350 [03:58<03:15, 3956.53 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1035000/1801350 [03:57<02:49, 4509.90 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1031000/1801350 [03:57<02:56, 4375.33 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1027000/1801350 [03:57<03:13, 3998.31 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1030000/1801350 [03:58<03:02, 4217.93 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1036000/1801350 [03:57<02:42, 4720.03 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1032000/1801350 [03:57<03:01, 4250.12 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1031000/1801350 [03:58<02:59, 4282.31 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1028000/1801350 [03:57<03:18, 3897.67 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1037000/1801350 [03:57<02:47, 4570.23 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1033000/1801350 [03:58<02:50, 4500.76 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1032000/1801350 [03:58<03:00, 4259.75 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1029000/1801350 [03:58<03:14, 3963.31 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1038000/1801350 [03:58<02:38, 4811.06 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1034000/1801350 [03:58<02:56, 4348.11 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1030000/1801350 [03:58<03:01, 4251.65 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1039000/1801350 [03:58<02:36, 4874.51 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1033000/1801350 [03:58<03:00, 4254.40 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1035000/1801350 [03:58<02:47, 4572.49 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1031000/1801350 [03:58<03:02, 4231.56 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1034000/1801350 [03:59<02:56, 4344.40 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1040000/1801350 [03:58<02:47, 4546.87 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1036000/1801350 [03:58<02:45, 4620.64 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1035000/1801350 [03:59<02:50, 4506.33 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1032000/1801350 [03:58<03:00, 4272.62 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1041000/1801350 [03:58<02:51, 4429.77 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1037000/1801350 [03:58<02:47, 4575.65 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1036000/1801350 [03:59<02:44, 4663.34 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1033000/1801350 [03:59<02:54, 4414.70 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1042000/1801350 [03:59<02:54, 4341.89 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1038000/1801350 [03:59<02:43, 4682.01 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1037000/1801350 [03:59<02:47, 4569.53 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1034000/1801350 [03:59<02:52, 4441.09 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1043000/1801350 [03:59<02:54, 4333.96 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1039000/1801350 [03:59<02:37, 4826.79 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1038000/1801350 [04:00<02:42, 4702.72 examples/s]Grouping texts in chunks of 1024:  57%|█████▋    | 1035000/1801350 [03:59<02:46, 4615.56 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1044000/1801350 [03:59<02:46, 4537.13 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1040000/1801350 [03:59<02:44, 4641.15 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1039000/1801350 [04:00<02:41, 4713.92 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1036000/1801350 [03:59<02:42, 4717.48 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1045000/1801350 [03:59<02:43, 4613.33 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1041000/1801350 [03:59<02:53, 4392.69 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1040000/1801350 [04:00<02:47, 4547.00 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1037000/1801350 [03:59<02:46, 4577.29 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1046000/1801350 [03:59<02:45, 4553.31 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1042000/1801350 [04:00<02:53, 4372.25 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1038000/1801350 [04:00<02:41, 4722.35 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1041000/1801350 [04:00<02:51, 4421.05 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1047000/1801350 [04:00<02:46, 4517.59 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1039000/1801350 [04:00<02:39, 4766.43 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1043000/1801350 [04:00<02:53, 4369.31 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1042000/1801350 [04:00<02:56, 4309.15 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1048000/1801350 [04:00<02:42, 4632.72 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1044000/1801350 [04:00<02:44, 4596.39 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1040000/1801350 [04:00<02:45, 4613.83 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1049000/1801350 [04:00<02:38, 4735.24 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1043000/1801350 [04:01<02:56, 4305.80 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1045000/1801350 [04:00<02:42, 4647.37 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1041000/1801350 [04:00<02:51, 4429.64 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1044000/1801350 [04:01<02:50, 4450.20 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1050000/1801350 [04:00<02:44, 4569.36 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1046000/1801350 [04:00<02:47, 4518.89 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1045000/1801350 [04:01<02:45, 4570.93 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1042000/1801350 [04:01<02:57, 4284.14 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1051000/1801350 [04:01<02:46, 4500.72 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1047000/1801350 [04:01<02:45, 4556.03 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1046000/1801350 [04:01<02:47, 4500.52 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1043000/1801350 [04:01<02:58, 4237.47 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1052000/1801350 [04:01<02:51, 4362.89 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1048000/1801350 [04:01<02:46, 4525.36 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1044000/1801350 [04:01<02:45, 4563.58 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1047000/1801350 [04:02<02:46, 4531.82 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1053000/1801350 [04:01<02:50, 4382.72 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1049000/1801350 [04:01<02:39, 4710.38 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1045000/1801350 [04:01<02:42, 4668.54 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1048000/1801350 [04:02<02:48, 4461.30 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1054000/1801350 [04:01<02:44, 4529.47 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1050000/1801350 [04:01<02:42, 4636.93 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1046000/1801350 [04:01<02:46, 4546.74 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1055000/1801350 [04:01<02:48, 4425.58 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1051000/1801350 [04:02<02:46, 4494.98 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1047000/1801350 [04:02<02:46, 4525.74 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1056000/1801350 [04:02<02:51, 4355.33 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1052000/1801350 [04:02<02:52, 4351.47 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1049000/1801350 [04:02<04:18, 2907.00 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1048000/1801350 [04:02<02:46, 4516.96 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1057000/1801350 [04:02<02:53, 4296.85 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1053000/1801350 [04:02<02:52, 4349.03 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1049000/1801350 [04:02<02:43, 4596.87 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1050000/1801350 [04:03<03:50, 3257.32 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1058000/1801350 [04:02<02:44, 4513.92 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1054000/1801350 [04:02<02:46, 4495.06 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1050000/1801350 [04:02<02:43, 4585.37 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1051000/1801350 [04:03<03:32, 3523.09 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1059000/1801350 [04:02<02:51, 4337.00 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1055000/1801350 [04:02<02:52, 4326.64 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1051000/1801350 [04:02<02:44, 4553.89 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1052000/1801350 [04:03<03:26, 3621.11 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1060000/1801350 [04:03<02:48, 4390.06 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1056000/1801350 [04:03<02:52, 4326.85 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1052000/1801350 [04:03<02:51, 4363.35 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1053000/1801350 [04:03<03:14, 3851.23 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1061000/1801350 [04:03<02:47, 4415.23 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1054000/1801350 [04:04<03:01, 4125.88 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1057000/1801350 [04:03<02:56, 4221.68 examples/s]Grouping texts in chunks of 1024:  58%|█████▊    | 1053000/1801350 [04:03<02:52, 4334.20 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1062000/1801350 [04:03<02:37, 4702.76 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1058000/1801350 [04:03<02:46, 4471.62 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1054000/1801350 [04:03<02:51, 4370.12 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1055000/1801350 [04:04<03:05, 4023.96 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1063000/1801350 [04:03<02:40, 4607.69 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1059000/1801350 [04:03<02:50, 4364.94 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1055000/1801350 [04:03<02:56, 4238.10 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1064000/1801350 [04:03<02:35, 4738.16 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1056000/1801350 [04:04<03:03, 4069.13 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1060000/1801350 [04:04<02:44, 4503.04 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1056000/1801350 [04:04<02:46, 4472.74 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1065000/1801350 [04:04<02:45, 4444.10 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1057000/1801350 [04:04<03:06, 3980.98 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1061000/1801350 [04:04<02:47, 4433.19 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1058000/1801350 [04:04<02:50, 4369.13 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1057000/1801350 [04:04<02:55, 4236.28 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1066000/1801350 [04:04<02:39, 4607.08 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1062000/1801350 [04:04<02:35, 4748.25 examples/s]Grouping texts in chunks of 1024:  59%|█████▊    | 1058000/1801350 [04:04<02:48, 4423.29 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1067000/1801350 [04:04<02:44, 4463.81 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1059000/1801350 [04:05<02:57, 4193.51 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1063000/1801350 [04:04<02:37, 4686.14 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1068000/1801350 [04:04<02:34, 4733.34 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1059000/1801350 [04:04<02:50, 4359.52 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1060000/1801350 [04:05<02:51, 4323.46 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1064000/1801350 [04:04<02:39, 4625.52 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1069000/1801350 [04:05<02:34, 4754.45 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1060000/1801350 [04:05<02:51, 4329.06 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1061000/1801350 [04:05<02:48, 4405.67 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1065000/1801350 [04:05<02:41, 4549.46 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1062000/1801350 [04:05<02:38, 4656.08 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1070000/1801350 [04:05<02:40, 4563.15 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1061000/1801350 [04:05<02:46, 4454.03 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1066000/1801350 [04:05<02:42, 4524.15 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1062000/1801350 [04:05<02:34, 4800.01 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1063000/1801350 [04:06<02:41, 4578.01 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1071000/1801350 [04:05<02:45, 4417.02 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1067000/1801350 [04:05<02:43, 4496.08 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1063000/1801350 [04:05<02:40, 4590.51 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1064000/1801350 [04:06<02:41, 4559.06 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1072000/1801350 [04:05<02:44, 4441.40 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1068000/1801350 [04:05<02:37, 4651.93 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1064000/1801350 [04:05<02:39, 4626.62 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1065000/1801350 [04:06<02:45, 4450.91 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1073000/1801350 [04:06<02:47, 4353.29 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1069000/1801350 [04:06<02:36, 4686.03 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1065000/1801350 [04:06<02:48, 4373.17 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1066000/1801350 [04:06<02:43, 4498.36 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1074000/1801350 [04:06<02:52, 4226.32 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1070000/1801350 [04:06<02:42, 4514.32 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1066000/1801350 [04:06<02:43, 4496.37 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1067000/1801350 [04:06<02:45, 4450.16 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1075000/1801350 [04:06<02:50, 4263.46 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1071000/1801350 [04:06<02:41, 4514.65 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1068000/1801350 [04:07<02:37, 4667.49 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1067000/1801350 [04:06<02:45, 4438.56 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1072000/1801350 [04:06<02:43, 4450.60 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1068000/1801350 [04:06<02:36, 4692.02 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1069000/1801350 [04:07<02:39, 4598.13 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1073000/1801350 [04:07<02:56, 4138.22 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1069000/1801350 [04:07<02:39, 4603.75 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1070000/1801350 [04:07<02:42, 4509.64 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1076000/1801350 [04:07<04:20, 2781.32 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1074000/1801350 [04:07<02:53, 4180.62 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1070000/1801350 [04:07<02:41, 4516.93 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1071000/1801350 [04:07<02:48, 4340.17 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1077000/1801350 [04:07<03:56, 3057.08 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1075000/1801350 [04:07<02:55, 4136.59 examples/s]Grouping texts in chunks of 1024:  59%|█████▉    | 1071000/1801350 [04:07<02:47, 4363.93 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1072000/1801350 [04:08<02:47, 4354.94 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1078000/1801350 [04:07<03:28, 3462.35 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1072000/1801350 [04:07<02:45, 4412.59 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1073000/1801350 [04:08<02:50, 4269.58 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1079000/1801350 [04:07<03:17, 3652.88 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1073000/1801350 [04:07<02:51, 4234.83 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1074000/1801350 [04:08<02:53, 4194.42 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1080000/1801350 [04:08<03:21, 3576.84 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1076000/1801350 [04:08<04:22, 2760.40 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1074000/1801350 [04:08<02:54, 4163.11 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1075000/1801350 [04:08<02:53, 4195.63 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1081000/1801350 [04:08<03:04, 3908.79 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1077000/1801350 [04:08<03:53, 3096.00 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1075000/1801350 [04:08<02:53, 4191.70 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1076000/1801350 [04:09<02:49, 4285.02 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1082000/1801350 [04:08<02:58, 4040.84 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1078000/1801350 [04:08<03:27, 3489.02 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1077000/1801350 [04:09<02:50, 4241.33 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1083000/1801350 [04:08<02:56, 4062.75 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1079000/1801350 [04:08<03:19, 3613.33 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1078000/1801350 [04:09<02:46, 4356.80 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1084000/1801350 [04:09<02:51, 4194.87 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1076000/1801350 [04:09<04:19, 2799.71 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1080000/1801350 [04:09<03:20, 3589.37 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1079000/1801350 [04:09<02:50, 4225.70 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1085000/1801350 [04:09<02:50, 4203.16 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1081000/1801350 [04:09<03:04, 3897.78 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1077000/1801350 [04:09<03:56, 3067.63 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1080000/1801350 [04:10<02:58, 4031.77 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1086000/1801350 [04:09<02:54, 4105.76 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1078000/1801350 [04:09<03:29, 3455.04 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1082000/1801350 [04:09<03:02, 3947.38 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1081000/1801350 [04:10<02:52, 4173.16 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1087000/1801350 [04:09<02:49, 4214.86 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1083000/1801350 [04:09<02:57, 4057.78 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1079000/1801350 [04:09<03:18, 3642.81 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1082000/1801350 [04:10<02:51, 4196.44 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1088000/1801350 [04:09<02:50, 4182.93 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1084000/1801350 [04:10<02:47, 4291.15 examples/s]Grouping texts in chunks of 1024:  60%|█████▉    | 1080000/1801350 [04:10<03:18, 3636.34 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1083000/1801350 [04:10<02:49, 4236.84 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1089000/1801350 [04:10<02:51, 4154.92 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1085000/1801350 [04:10<02:51, 4174.35 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1081000/1801350 [04:10<03:05, 3887.29 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1084000/1801350 [04:10<02:43, 4378.34 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1090000/1801350 [04:10<02:42, 4367.43 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1086000/1801350 [04:10<02:58, 3999.73 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1082000/1801350 [04:10<03:02, 3948.85 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1085000/1801350 [04:11<02:50, 4194.04 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1091000/1801350 [04:10<02:47, 4247.11 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1087000/1801350 [04:10<02:50, 4187.91 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1083000/1801350 [04:10<02:54, 4105.12 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1092000/1801350 [04:10<02:39, 4442.54 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1086000/1801350 [04:11<02:51, 4167.75 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1088000/1801350 [04:10<02:48, 4221.25 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1084000/1801350 [04:10<02:50, 4196.59 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1087000/1801350 [04:11<02:47, 4266.06 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1093000/1801350 [04:11<02:45, 4286.24 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1089000/1801350 [04:11<02:51, 4149.17 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1085000/1801350 [04:11<02:52, 4150.69 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1094000/1801350 [04:11<02:44, 4303.42 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1088000/1801350 [04:11<02:49, 4196.19 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1090000/1801350 [04:11<02:42, 4375.26 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1086000/1801350 [04:11<02:58, 4005.98 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1095000/1801350 [04:11<02:48, 4183.29 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1089000/1801350 [04:12<02:55, 4055.67 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1091000/1801350 [04:11<02:44, 4314.29 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1087000/1801350 [04:11<02:48, 4247.78 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1090000/1801350 [04:12<02:44, 4322.64 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1096000/1801350 [04:11<02:46, 4246.85 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1092000/1801350 [04:11<02:43, 4340.13 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1088000/1801350 [04:11<02:50, 4177.80 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1097000/1801350 [04:12<02:37, 4463.08 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1091000/1801350 [04:12<02:49, 4196.28 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1093000/1801350 [04:12<02:42, 4350.10 examples/s]Grouping texts in chunks of 1024:  60%|██████    | 1089000/1801350 [04:12<02:52, 4122.76 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1098000/1801350 [04:12<02:44, 4265.36 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1092000/1801350 [04:12<02:46, 4259.19 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1094000/1801350 [04:12<02:49, 4180.53 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1090000/1801350 [04:12<02:47, 4235.53 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1099000/1801350 [04:12<02:42, 4332.59 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1093000/1801350 [04:13<02:46, 4265.79 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1095000/1801350 [04:12<02:50, 4151.17 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1091000/1801350 [04:12<02:48, 4210.01 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1100000/1801350 [04:12<02:38, 4438.61 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1094000/1801350 [04:13<02:46, 4243.88 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1096000/1801350 [04:12<02:46, 4232.16 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1092000/1801350 [04:12<02:45, 4295.20 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1101000/1801350 [04:12<02:38, 4420.36 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1095000/1801350 [04:13<02:49, 4171.95 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1097000/1801350 [04:13<02:39, 4426.60 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1093000/1801350 [04:13<02:45, 4289.97 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1102000/1801350 [04:13<02:46, 4196.87 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1096000/1801350 [04:13<02:47, 4202.43 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1098000/1801350 [04:13<02:41, 4342.23 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1094000/1801350 [04:13<02:46, 4250.32 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1103000/1801350 [04:13<02:41, 4311.66 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1097000/1801350 [04:14<02:40, 4401.31 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1099000/1801350 [04:13<02:43, 4289.88 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1095000/1801350 [04:13<02:48, 4193.30 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1104000/1801350 [04:13<02:40, 4353.73 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1098000/1801350 [04:14<02:44, 4283.16 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1100000/1801350 [04:13<02:40, 4360.54 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1096000/1801350 [04:13<02:44, 4284.58 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1105000/1801350 [04:13<02:44, 4240.13 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1099000/1801350 [04:14<02:47, 4198.63 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1101000/1801350 [04:13<02:38, 4406.38 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1097000/1801350 [04:14<02:40, 4380.30 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1106000/1801350 [04:14<02:43, 4253.71 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1100000/1801350 [04:14<02:38, 4428.07 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1102000/1801350 [04:14<02:41, 4341.47 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1098000/1801350 [04:14<02:46, 4218.86 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1107000/1801350 [04:14<02:40, 4321.41 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1101000/1801350 [04:14<02:38, 4405.40 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1103000/1801350 [04:14<02:40, 4354.97 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1099000/1801350 [04:14<02:44, 4270.83 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1108000/1801350 [04:14<02:41, 4290.80 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1102000/1801350 [04:15<02:44, 4239.73 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1104000/1801350 [04:14<02:41, 4320.17 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1100000/1801350 [04:14<02:38, 4413.99 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1109000/1801350 [04:14<02:37, 4398.49 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1103000/1801350 [04:15<02:44, 4239.53 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1105000/1801350 [04:14<02:46, 4181.08 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1101000/1801350 [04:14<02:40, 4370.55 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1110000/1801350 [04:15<02:39, 4347.11 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1104000/1801350 [04:15<02:46, 4195.76 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1106000/1801350 [04:15<02:43, 4262.63 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1102000/1801350 [04:15<02:44, 4259.64 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1111000/1801350 [04:15<02:36, 4423.88 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1105000/1801350 [04:15<02:48, 4137.99 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1107000/1801350 [04:15<02:41, 4301.18 examples/s]Grouping texts in chunks of 1024:  61%|██████    | 1103000/1801350 [04:15<02:39, 4378.80 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1112000/1801350 [04:15<02:38, 4350.32 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1106000/1801350 [04:16<02:43, 4241.40 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1108000/1801350 [04:15<02:39, 4354.28 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1104000/1801350 [04:15<02:42, 4281.25 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1113000/1801350 [04:15<02:34, 4463.15 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1107000/1801350 [04:16<02:41, 4290.89 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1109000/1801350 [04:15<02:39, 4351.06 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1114000/1801350 [04:15<02:29, 4612.39 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1105000/1801350 [04:15<02:44, 4223.17 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1108000/1801350 [04:16<02:42, 4263.78 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1110000/1801350 [04:16<02:42, 4242.53 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1115000/1801350 [04:16<02:32, 4497.87 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1106000/1801350 [04:16<02:44, 4216.44 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1109000/1801350 [04:16<02:41, 4274.95 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1111000/1801350 [04:16<02:36, 4398.50 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1116000/1801350 [04:16<02:32, 4487.52 examples/s]Grouping texts in chunks of 1024:  61%|██████▏   | 1107000/1801350 [04:16<02:40, 4337.71 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1110000/1801350 [04:17<02:40, 4313.51 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1112000/1801350 [04:16<02:35, 4429.73 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1117000/1801350 [04:16<02:24, 4725.39 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1108000/1801350 [04:16<02:39, 4341.47 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1113000/1801350 [04:16<02:33, 4474.23 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1111000/1801350 [04:17<02:39, 4317.52 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1118000/1801350 [04:16<02:31, 4496.58 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1109000/1801350 [04:16<02:40, 4311.89 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1114000/1801350 [04:16<02:30, 4576.33 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1112000/1801350 [04:17<02:37, 4368.72 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1119000/1801350 [04:17<02:34, 4417.64 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1110000/1801350 [04:17<02:40, 4311.46 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1115000/1801350 [04:17<02:33, 4464.62 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1113000/1801350 [04:17<02:36, 4404.86 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1120000/1801350 [04:17<02:35, 4368.73 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1111000/1801350 [04:17<02:36, 4423.26 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1114000/1801350 [04:17<02:32, 4515.38 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1116000/1801350 [04:17<02:36, 4375.23 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1121000/1801350 [04:17<02:31, 4484.55 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1112000/1801350 [04:17<02:36, 4406.03 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1117000/1801350 [04:17<02:25, 4691.39 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1115000/1801350 [04:18<02:35, 4410.87 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1122000/1801350 [04:17<02:26, 4623.82 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1113000/1801350 [04:17<02:37, 4378.10 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1118000/1801350 [04:17<02:33, 4438.05 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1116000/1801350 [04:18<02:36, 4388.31 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1123000/1801350 [04:17<02:26, 4624.10 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1114000/1801350 [04:17<02:30, 4559.06 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1117000/1801350 [04:18<02:28, 4595.49 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1119000/1801350 [04:18<02:33, 4433.16 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1124000/1801350 [04:18<02:26, 4620.92 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1115000/1801350 [04:18<02:34, 4434.84 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1120000/1801350 [04:18<02:33, 4428.98 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1118000/1801350 [04:18<02:35, 4383.64 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1125000/1801350 [04:18<02:25, 4632.84 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1116000/1801350 [04:18<02:34, 4443.79 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1121000/1801350 [04:18<02:32, 4471.62 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1119000/1801350 [04:19<02:34, 4418.02 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1126000/1801350 [04:18<02:32, 4425.16 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1117000/1801350 [04:18<02:30, 4561.30 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1122000/1801350 [04:18<02:30, 4527.14 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1120000/1801350 [04:19<02:33, 4440.47 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1127000/1801350 [04:18<02:33, 4407.24 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1118000/1801350 [04:18<02:32, 4477.93 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1123000/1801350 [04:18<02:27, 4589.67 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1121000/1801350 [04:19<02:33, 4431.83 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1128000/1801350 [04:19<02:32, 4411.58 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1119000/1801350 [04:19<02:35, 4397.79 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1124000/1801350 [04:19<02:26, 4613.19 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1122000/1801350 [04:19<02:30, 4504.33 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1129000/1801350 [04:19<02:32, 4395.89 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1120000/1801350 [04:19<02:33, 4433.71 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1125000/1801350 [04:19<02:27, 4599.11 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1123000/1801350 [04:19<02:31, 4473.89 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1130000/1801350 [04:19<02:36, 4303.50 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1121000/1801350 [04:19<02:31, 4479.40 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1124000/1801350 [04:20<02:26, 4638.62 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1126000/1801350 [04:19<02:34, 4383.49 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1131000/1801350 [04:19<02:32, 4404.37 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1122000/1801350 [04:19<02:28, 4576.69 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1125000/1801350 [04:20<02:27, 4585.79 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1127000/1801350 [04:19<02:35, 4350.34 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1123000/1801350 [04:19<02:25, 4650.35 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1132000/1801350 [04:19<02:29, 4478.45 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1128000/1801350 [04:20<02:28, 4537.66 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1126000/1801350 [04:20<02:34, 4375.83 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1133000/1801350 [04:20<02:27, 4530.84 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1124000/1801350 [04:20<02:28, 4570.11 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1127000/1801350 [04:20<02:34, 4365.59 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1129000/1801350 [04:20<02:37, 4257.52 examples/s]Grouping texts in chunks of 1024:  62%|██████▏   | 1125000/1801350 [04:20<02:28, 4541.16 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1134000/1801350 [04:20<02:37, 4240.90 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1128000/1801350 [04:21<02:31, 4450.60 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1130000/1801350 [04:20<02:36, 4287.67 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1126000/1801350 [04:20<02:33, 4395.36 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1135000/1801350 [04:20<02:41, 4123.71 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1129000/1801350 [04:21<02:38, 4252.07 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1136000/1801350 [04:20<02:29, 4453.79 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1127000/1801350 [04:20<02:37, 4290.70 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1131000/1801350 [04:20<03:00, 3708.58 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1130000/1801350 [04:21<02:31, 4439.98 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1132000/1801350 [04:21<02:36, 4268.25 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1128000/1801350 [04:21<02:29, 4502.92 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1137000/1801350 [04:21<02:36, 4245.24 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1131000/1801350 [04:21<02:32, 4398.83 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1133000/1801350 [04:21<02:38, 4215.92 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1129000/1801350 [04:21<02:34, 4343.58 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1138000/1801350 [04:21<02:35, 4252.32 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1132000/1801350 [04:21<02:25, 4591.65 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1134000/1801350 [04:21<02:39, 4171.71 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1130000/1801350 [04:21<02:35, 4312.26 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1139000/1801350 [04:21<02:35, 4256.07 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1133000/1801350 [04:22<02:28, 4487.87 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1131000/1801350 [04:21<02:33, 4375.27 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1140000/1801350 [04:21<02:33, 4300.47 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1135000/1801350 [04:21<02:48, 3951.11 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1134000/1801350 [04:22<02:38, 4200.90 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1132000/1801350 [04:21<02:26, 4576.79 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1136000/1801350 [04:22<02:43, 4075.40 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1141000/1801350 [04:22<02:37, 4203.78 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1133000/1801350 [04:22<02:29, 4481.20 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1135000/1801350 [04:22<02:49, 3937.49 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1142000/1801350 [04:22<02:30, 4387.96 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1137000/1801350 [04:22<02:37, 4227.24 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1136000/1801350 [04:23<02:40, 4133.79 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1134000/1801350 [04:22<02:38, 4220.15 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1143000/1801350 [04:22<02:29, 4404.56 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1138000/1801350 [04:22<02:39, 4148.97 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1137000/1801350 [04:23<02:39, 4153.02 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1144000/1801350 [04:22<02:33, 4281.59 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1135000/1801350 [04:22<02:46, 4006.13 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1139000/1801350 [04:22<02:38, 4179.97 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1138000/1801350 [04:23<02:38, 4188.33 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1136000/1801350 [04:22<02:39, 4159.68 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1145000/1801350 [04:22<02:32, 4292.79 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1140000/1801350 [04:23<02:34, 4274.86 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1139000/1801350 [04:23<02:41, 4109.04 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1137000/1801350 [04:23<02:37, 4224.46 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1146000/1801350 [04:23<02:33, 4274.41 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1141000/1801350 [04:23<02:36, 4211.48 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1140000/1801350 [04:23<02:39, 4151.71 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1138000/1801350 [04:23<02:39, 4155.82 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1142000/1801350 [04:23<02:30, 4370.91 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1147000/1801350 [04:23<02:40, 4087.35 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1141000/1801350 [04:24<02:37, 4186.30 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1143000/1801350 [04:23<02:30, 4360.22 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1139000/1801350 [04:23<02:37, 4210.96 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1148000/1801350 [04:23<02:32, 4285.04 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1142000/1801350 [04:24<02:33, 4295.90 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1149000/1801350 [04:23<02:30, 4329.32 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1144000/1801350 [04:23<02:34, 4257.66 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1140000/1801350 [04:23<02:38, 4167.31 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1143000/1801350 [04:24<02:31, 4342.40 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1150000/1801350 [04:24<02:31, 4306.60 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1141000/1801350 [04:24<02:36, 4207.05 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1145000/1801350 [04:24<02:37, 4173.31 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1144000/1801350 [04:24<02:32, 4320.52 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1151000/1801350 [04:24<02:26, 4438.03 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1142000/1801350 [04:24<02:33, 4301.87 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1146000/1801350 [04:24<02:35, 4213.77 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1145000/1801350 [04:25<02:37, 4162.34 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1152000/1801350 [04:24<02:24, 4492.02 examples/s]Grouping texts in chunks of 1024:  63%|██████▎   | 1143000/1801350 [04:24<02:29, 4395.31 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1147000/1801350 [04:24<02:36, 4171.65 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1153000/1801350 [04:24<02:27, 4392.45 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1146000/1801350 [04:25<02:38, 4125.12 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1144000/1801350 [04:24<02:32, 4310.77 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1148000/1801350 [04:24<02:30, 4348.61 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1147000/1801350 [04:25<02:38, 4122.11 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1145000/1801350 [04:25<02:36, 4183.54 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1154000/1801350 [04:25<02:38, 4079.52 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1149000/1801350 [04:25<02:34, 4221.33 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1148000/1801350 [04:25<02:33, 4265.26 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1146000/1801350 [04:25<02:35, 4205.26 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1155000/1801350 [04:25<02:36, 4123.15 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1150000/1801350 [04:25<02:34, 4211.83 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1149000/1801350 [04:26<02:37, 4149.29 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1151000/1801350 [04:25<02:29, 4345.37 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1156000/1801350 [04:25<02:33, 4210.97 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1147000/1801350 [04:25<02:41, 4041.37 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1152000/1801350 [04:25<02:19, 4640.98 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1150000/1801350 [04:26<02:32, 4259.29 examples/s]Grouping texts in chunks of 1024:  64%|██████▎   | 1148000/1801350 [04:25<02:33, 4265.95 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1157000/1801350 [04:25<02:35, 4143.69 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1151000/1801350 [04:26<02:28, 4391.01 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1153000/1801350 [04:26<02:30, 4309.70 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1158000/1801350 [04:26<02:29, 4302.67 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1149000/1801350 [04:26<02:32, 4271.94 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1152000/1801350 [04:26<02:23, 4521.66 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1150000/1801350 [04:26<02:31, 4291.14 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1159000/1801350 [04:26<02:32, 4223.99 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1154000/1801350 [04:26<02:39, 4062.57 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1153000/1801350 [04:26<02:31, 4287.08 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1151000/1801350 [04:26<02:29, 4338.01 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1160000/1801350 [04:26<02:29, 4278.82 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1155000/1801350 [04:26<02:35, 4162.66 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1152000/1801350 [04:26<02:24, 4500.74 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1161000/1801350 [04:26<02:25, 4414.91 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1154000/1801350 [04:27<02:41, 4020.35 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1156000/1801350 [04:26<02:30, 4284.10 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1155000/1801350 [04:27<02:35, 4155.73 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1153000/1801350 [04:26<02:32, 4260.64 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1162000/1801350 [04:26<02:31, 4223.69 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1157000/1801350 [04:27<02:33, 4187.34 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1156000/1801350 [04:27<02:32, 4233.85 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1154000/1801350 [04:27<02:35, 4153.12 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1158000/1801350 [04:27<02:33, 4189.87 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1163000/1801350 [04:27<02:35, 4105.45 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1157000/1801350 [04:27<02:35, 4145.68 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1164000/1801350 [04:27<02:27, 4321.95 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1155000/1801350 [04:27<02:34, 4191.07 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1159000/1801350 [04:27<02:33, 4193.76 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1158000/1801350 [04:28<02:31, 4235.53 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1160000/1801350 [04:27<02:28, 4309.68 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1156000/1801350 [04:27<02:33, 4209.62 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1165000/1801350 [04:27<02:31, 4192.91 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1161000/1801350 [04:27<02:24, 4445.51 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1159000/1801350 [04:28<02:34, 4152.76 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1166000/1801350 [04:27<02:26, 4333.53 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1157000/1801350 [04:27<02:35, 4145.56 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1160000/1801350 [04:28<02:31, 4219.85 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1167000/1801350 [04:28<02:25, 4347.85 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1158000/1801350 [04:28<02:31, 4243.12 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1162000/1801350 [04:28<02:36, 4096.84 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1161000/1801350 [04:28<02:27, 4343.30 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1168000/1801350 [04:28<02:23, 4401.98 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1159000/1801350 [04:28<02:36, 4110.28 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1163000/1801350 [04:28<02:36, 4082.39 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1169000/1801350 [04:28<02:22, 4445.12 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1162000/1801350 [04:29<02:35, 4103.75 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1164000/1801350 [04:28<02:27, 4328.08 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1160000/1801350 [04:28<02:31, 4245.76 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1170000/1801350 [04:28<02:14, 4679.13 examples/s]Grouping texts in chunks of 1024:  64%|██████▍   | 1161000/1801350 [04:28<02:27, 4347.54 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1163000/1801350 [04:29<02:37, 4065.01 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1165000/1801350 [04:28<02:30, 4216.95 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1171000/1801350 [04:28<02:17, 4589.53 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1164000/1801350 [04:29<02:30, 4244.13 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1166000/1801350 [04:29<02:27, 4302.94 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1162000/1801350 [04:29<02:32, 4181.53 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1172000/1801350 [04:29<02:14, 4684.49 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1167000/1801350 [04:29<02:24, 4402.63 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1165000/1801350 [04:29<02:31, 4211.81 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1163000/1801350 [04:29<02:37, 4055.66 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1173000/1801350 [04:29<02:21, 4455.51 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1166000/1801350 [04:30<02:29, 4263.18 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1168000/1801350 [04:29<02:28, 4252.87 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1164000/1801350 [04:29<02:31, 4205.91 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1174000/1801350 [04:29<02:19, 4481.43 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1169000/1801350 [04:29<02:21, 4482.55 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1167000/1801350 [04:30<02:28, 4267.13 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1165000/1801350 [04:29<02:32, 4180.39 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1175000/1801350 [04:29<02:24, 4335.83 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1170000/1801350 [04:29<02:15, 4669.10 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1168000/1801350 [04:30<02:27, 4293.98 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1166000/1801350 [04:30<02:30, 4232.87 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1176000/1801350 [04:30<02:17, 4537.96 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1171000/1801350 [04:30<02:19, 4514.27 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1169000/1801350 [04:30<02:25, 4356.12 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1167000/1801350 [04:30<02:26, 4324.39 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1177000/1801350 [04:30<02:19, 4473.23 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1172000/1801350 [04:30<02:14, 4677.97 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1170000/1801350 [04:30<02:15, 4644.69 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1168000/1801350 [04:30<02:25, 4339.56 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1178000/1801350 [04:30<02:13, 4665.40 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1173000/1801350 [04:30<02:21, 4449.59 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1171000/1801350 [04:31<02:21, 4463.03 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1169000/1801350 [04:30<02:24, 4383.24 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1179000/1801350 [04:30<02:21, 4384.86 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1172000/1801350 [04:31<02:15, 4648.69 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1174000/1801350 [04:30<02:20, 4460.42 examples/s]Grouping texts in chunks of 1024:  65%|██████▍   | 1170000/1801350 [04:30<02:16, 4640.11 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1180000/1801350 [04:30<02:13, 4671.03 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1173000/1801350 [04:31<02:22, 4409.79 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1175000/1801350 [04:31<02:24, 4334.93 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1171000/1801350 [04:31<02:17, 4587.97 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1181000/1801350 [04:31<02:14, 4627.53 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1176000/1801350 [04:31<02:20, 4463.35 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1174000/1801350 [04:31<02:20, 4449.39 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1172000/1801350 [04:31<02:16, 4615.04 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1182000/1801350 [04:31<02:23, 4313.26 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1177000/1801350 [04:31<02:18, 4494.73 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1175000/1801350 [04:32<02:24, 4325.71 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1173000/1801350 [04:31<02:23, 4381.73 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1183000/1801350 [04:31<02:24, 4269.29 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1178000/1801350 [04:31<02:13, 4654.94 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1176000/1801350 [04:32<02:24, 4331.67 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1174000/1801350 [04:31<02:19, 4483.57 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1184000/1801350 [04:31<02:24, 4265.35 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1179000/1801350 [04:31<02:18, 4490.34 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1177000/1801350 [04:32<02:19, 4489.01 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1175000/1801350 [04:32<02:26, 4286.00 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1180000/1801350 [04:32<02:12, 4684.35 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1178000/1801350 [04:32<02:14, 4623.03 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1185000/1801350 [04:32<02:31, 4055.61 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1176000/1801350 [04:32<02:22, 4391.54 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1181000/1801350 [04:32<02:15, 4594.53 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1186000/1801350 [04:32<02:26, 4205.78 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1179000/1801350 [04:33<02:24, 4299.21 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1177000/1801350 [04:32<02:19, 4470.65 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1182000/1801350 [04:32<02:21, 4362.85 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1180000/1801350 [04:33<02:14, 4602.97 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1187000/1801350 [04:32<02:26, 4199.94 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1178000/1801350 [04:32<02:12, 4692.59 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1188000/1801350 [04:32<02:24, 4249.05 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1181000/1801350 [04:33<02:18, 4473.34 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1183000/1801350 [04:32<02:26, 4217.04 examples/s]Grouping texts in chunks of 1024:  65%|██████▌   | 1179000/1801350 [04:32<02:23, 4349.46 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1184000/1801350 [04:33<02:26, 4222.64 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1182000/1801350 [04:33<02:23, 4316.37 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1180000/1801350 [04:33<02:14, 4609.25 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1189000/1801350 [04:33<02:32, 4027.75 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1181000/1801350 [04:33<02:15, 4571.79 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1185000/1801350 [04:33<02:28, 4140.18 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1183000/1801350 [04:33<02:29, 4141.11 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1190000/1801350 [04:33<02:32, 3999.21 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1186000/1801350 [04:33<02:26, 4203.94 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1191000/1801350 [04:33<02:25, 4202.40 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1184000/1801350 [04:34<02:26, 4206.46 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1182000/1801350 [04:33<02:25, 4258.93 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1187000/1801350 [04:33<02:27, 4173.16 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1185000/1801350 [04:34<02:30, 4096.84 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1192000/1801350 [04:33<02:30, 4046.19 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1183000/1801350 [04:33<02:25, 4249.64 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1188000/1801350 [04:34<02:25, 4222.89 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1193000/1801350 [04:34<02:21, 4310.03 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1186000/1801350 [04:34<02:28, 4142.23 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1184000/1801350 [04:34<02:28, 4166.52 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1194000/1801350 [04:34<02:18, 4393.88 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1187000/1801350 [04:34<02:28, 4149.73 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1185000/1801350 [04:34<02:28, 4141.28 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1189000/1801350 [04:34<02:35, 3945.29 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1195000/1801350 [04:34<02:27, 4100.43 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1186000/1801350 [04:34<02:27, 4175.52 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1188000/1801350 [04:35<02:29, 4105.91 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1190000/1801350 [04:34<02:34, 3967.51 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1196000/1801350 [04:34<02:26, 4139.76 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1191000/1801350 [04:34<02:25, 4182.83 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1187000/1801350 [04:34<02:31, 4052.74 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1189000/1801350 [04:35<02:33, 3981.21 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1197000/1801350 [04:35<02:27, 4091.94 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1192000/1801350 [04:35<02:28, 4114.62 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1188000/1801350 [04:35<02:26, 4192.77 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1190000/1801350 [04:35<02:35, 3926.19 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1198000/1801350 [04:35<02:20, 4282.43 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1193000/1801350 [04:35<02:23, 4235.06 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1189000/1801350 [04:35<02:31, 4049.33 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1191000/1801350 [04:35<02:28, 4113.47 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1194000/1801350 [04:35<02:19, 4346.45 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1199000/1801350 [04:35<02:22, 4231.51 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1192000/1801350 [04:36<02:31, 4016.76 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1190000/1801350 [04:35<02:35, 3933.26 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1200000/1801350 [04:35<02:23, 4176.85 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1195000/1801350 [04:35<02:26, 4131.33 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1191000/1801350 [04:35<02:24, 4211.20 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1193000/1801350 [04:36<02:24, 4205.68 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1201000/1801350 [04:35<02:15, 4423.34 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1196000/1801350 [04:36<02:26, 4139.42 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1192000/1801350 [04:36<02:27, 4119.19 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1194000/1801350 [04:36<02:30, 4027.70 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1202000/1801350 [04:36<02:11, 4557.27 examples/s]Grouping texts in chunks of 1024:  66%|██████▌   | 1193000/1801350 [04:36<02:21, 4285.03 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1197000/1801350 [04:36<02:30, 4024.66 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1195000/1801350 [04:36<02:26, 4126.32 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1203000/1801350 [04:36<02:07, 4684.67 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1198000/1801350 [04:36<02:20, 4292.07 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1194000/1801350 [04:36<02:18, 4379.95 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1196000/1801350 [04:37<02:29, 4039.63 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1204000/1801350 [04:36<02:11, 4555.05 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1199000/1801350 [04:36<02:20, 4301.79 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1195000/1801350 [04:36<02:26, 4148.82 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1205000/1801350 [04:36<02:09, 4599.64 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1197000/1801350 [04:37<02:29, 4029.35 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1200000/1801350 [04:36<02:22, 4220.96 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1196000/1801350 [04:37<02:28, 4084.07 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1198000/1801350 [04:37<02:21, 4274.92 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1206000/1801350 [04:37<02:12, 4494.76 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1201000/1801350 [04:37<02:18, 4322.31 examples/s]Grouping texts in chunks of 1024:  66%|██████▋   | 1197000/1801350 [04:37<02:29, 4050.41 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1207000/1801350 [04:37<02:16, 4364.48 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1199000/1801350 [04:37<02:24, 4161.10 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1202000/1801350 [04:37<02:15, 4413.06 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1198000/1801350 [04:37<02:23, 4210.95 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1200000/1801350 [04:38<02:24, 4150.11 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1208000/1801350 [04:37<02:22, 4151.68 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1203000/1801350 [04:37<02:09, 4617.20 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1199000/1801350 [04:37<02:21, 4267.36 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1201000/1801350 [04:38<02:17, 4352.42 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1209000/1801350 [04:37<02:19, 4248.99 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1204000/1801350 [04:37<02:11, 4554.17 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1202000/1801350 [04:38<02:16, 4381.40 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1200000/1801350 [04:37<02:24, 4170.73 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1210000/1801350 [04:38<02:16, 4323.07 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1205000/1801350 [04:38<02:10, 4558.49 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1203000/1801350 [04:38<02:12, 4515.98 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1201000/1801350 [04:38<02:19, 4302.89 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1211000/1801350 [04:38<02:16, 4335.52 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1206000/1801350 [04:38<02:12, 4486.54 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1204000/1801350 [04:38<02:13, 4481.03 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1202000/1801350 [04:38<02:17, 4361.58 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1212000/1801350 [04:38<02:21, 4168.66 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1207000/1801350 [04:38<02:15, 4393.69 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1203000/1801350 [04:38<02:08, 4641.49 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1205000/1801350 [04:39<02:13, 4461.94 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1213000/1801350 [04:38<02:12, 4426.82 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1208000/1801350 [04:38<02:22, 4150.72 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1204000/1801350 [04:38<02:09, 4606.63 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1206000/1801350 [04:39<02:13, 4450.68 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1214000/1801350 [04:38<02:07, 4595.24 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1209000/1801350 [04:39<02:24, 4100.93 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1205000/1801350 [04:39<02:12, 4516.37 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1215000/1801350 [04:39<02:00, 4872.48 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1207000/1801350 [04:39<02:17, 4323.58 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1210000/1801350 [04:39<02:14, 4407.04 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1206000/1801350 [04:39<02:13, 4475.17 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1216000/1801350 [04:39<02:09, 4517.74 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1208000/1801350 [04:39<02:24, 4113.76 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1211000/1801350 [04:39<02:13, 4413.35 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1207000/1801350 [04:39<02:16, 4362.65 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1217000/1801350 [04:39<02:06, 4607.09 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1209000/1801350 [04:40<02:23, 4114.99 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1212000/1801350 [04:39<02:19, 4230.77 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1218000/1801350 [04:39<02:09, 4508.87 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1208000/1801350 [04:39<02:26, 4057.90 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1210000/1801350 [04:40<02:18, 4271.47 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1213000/1801350 [04:39<02:15, 4326.68 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1219000/1801350 [04:40<02:11, 4412.64 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1211000/1801350 [04:40<02:13, 4411.46 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1209000/1801350 [04:40<02:23, 4120.07 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1214000/1801350 [04:40<02:09, 4552.51 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1220000/1801350 [04:40<02:06, 4601.38 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1210000/1801350 [04:40<02:16, 4327.13 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1215000/1801350 [04:40<02:01, 4828.51 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1212000/1801350 [04:40<02:22, 4135.81 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1221000/1801350 [04:40<02:11, 4406.92 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1211000/1801350 [04:40<02:13, 4407.03 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1213000/1801350 [04:41<02:16, 4315.44 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1216000/1801350 [04:40<02:07, 4588.44 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1222000/1801350 [04:40<02:08, 4502.64 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1214000/1801350 [04:41<02:08, 4580.99 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1212000/1801350 [04:40<02:20, 4197.44 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1217000/1801350 [04:40<02:10, 4464.59 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1215000/1801350 [04:41<02:04, 4716.22 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1223000/1801350 [04:40<02:16, 4222.54 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1213000/1801350 [04:40<02:15, 4342.30 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1218000/1801350 [04:41<02:07, 4585.96 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1224000/1801350 [04:41<02:11, 4380.56 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1214000/1801350 [04:41<02:10, 4488.94 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1216000/1801350 [04:41<02:12, 4431.40 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1219000/1801350 [04:41<02:11, 4422.58 examples/s]Grouping texts in chunks of 1024:  67%|██████▋   | 1215000/1801350 [04:41<02:01, 4834.10 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1217000/1801350 [04:41<02:10, 4465.38 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1225000/1801350 [04:41<02:16, 4233.45 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1220000/1801350 [04:41<02:07, 4563.25 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1216000/1801350 [04:41<02:10, 4488.33 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1218000/1801350 [04:42<02:07, 4565.24 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1226000/1801350 [04:41<02:10, 4405.87 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1221000/1801350 [04:41<02:11, 4417.64 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1217000/1801350 [04:41<02:06, 4628.11 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1227000/1801350 [04:41<02:07, 4493.94 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1219000/1801350 [04:42<02:13, 4374.25 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1222000/1801350 [04:41<02:08, 4525.75 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1218000/1801350 [04:42<02:08, 4532.90 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1220000/1801350 [04:42<02:07, 4563.84 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1228000/1801350 [04:42<02:10, 4383.01 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1223000/1801350 [04:42<02:17, 4197.67 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1219000/1801350 [04:42<02:11, 4437.49 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1229000/1801350 [04:42<02:11, 4359.94 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1221000/1801350 [04:42<02:13, 4353.82 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1224000/1801350 [04:42<02:11, 4395.12 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1220000/1801350 [04:42<02:08, 4506.60 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1222000/1801350 [04:43<02:09, 4472.37 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1230000/1801350 [04:42<02:12, 4305.34 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1225000/1801350 [04:42<02:15, 4252.68 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1221000/1801350 [04:42<02:11, 4410.16 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1231000/1801350 [04:42<02:10, 4378.74 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1223000/1801350 [04:43<02:20, 4108.23 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1226000/1801350 [04:42<02:12, 4340.18 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1222000/1801350 [04:42<02:08, 4509.77 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1232000/1801350 [04:42<02:04, 4572.51 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1224000/1801350 [04:43<02:16, 4241.09 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1227000/1801350 [04:43<02:07, 4494.88 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1233000/1801350 [04:43<02:03, 4590.13 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1223000/1801350 [04:43<02:19, 4157.95 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1225000/1801350 [04:43<02:14, 4300.61 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1228000/1801350 [04:43<02:10, 4377.05 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1234000/1801350 [04:43<02:08, 4422.74 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1224000/1801350 [04:43<02:16, 4242.57 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1226000/1801350 [04:44<02:12, 4342.71 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1229000/1801350 [04:43<02:15, 4220.67 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1235000/1801350 [04:43<02:06, 4472.43 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1225000/1801350 [04:43<02:14, 4289.40 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1227000/1801350 [04:44<02:11, 4361.44 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1230000/1801350 [04:43<02:13, 4266.72 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1236000/1801350 [04:43<02:06, 4485.39 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1226000/1801350 [04:43<02:13, 4323.88 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1228000/1801350 [04:44<02:12, 4318.47 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1231000/1801350 [04:44<02:11, 4339.89 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1237000/1801350 [04:44<02:06, 4457.74 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1227000/1801350 [04:44<02:10, 4386.56 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1229000/1801350 [04:44<02:15, 4213.65 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1232000/1801350 [04:44<02:07, 4471.18 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1238000/1801350 [04:44<02:06, 4442.56 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1228000/1801350 [04:44<02:09, 4414.69 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1230000/1801350 [04:44<02:12, 4306.28 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1233000/1801350 [04:44<02:04, 4548.04 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1239000/1801350 [04:44<02:02, 4596.91 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1229000/1801350 [04:44<02:14, 4270.91 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1231000/1801350 [04:45<02:14, 4253.69 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1234000/1801350 [04:44<02:09, 4395.70 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1240000/1801350 [04:44<02:07, 4390.43 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1230000/1801350 [04:44<02:13, 4266.89 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1232000/1801350 [04:45<02:07, 4467.20 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1235000/1801350 [04:44<02:04, 4539.35 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1241000/1801350 [04:44<02:08, 4372.10 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1231000/1801350 [04:45<02:10, 4383.54 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1233000/1801350 [04:45<02:04, 4556.34 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1236000/1801350 [04:45<02:10, 4341.95 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1232000/1801350 [04:45<02:07, 4461.56 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1242000/1801350 [04:45<02:12, 4226.26 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1234000/1801350 [04:45<02:08, 4416.02 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1237000/1801350 [04:45<02:06, 4447.57 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1243000/1801350 [04:45<02:09, 4324.20 examples/s]Grouping texts in chunks of 1024:  68%|██████▊   | 1233000/1801350 [04:45<02:06, 4507.06 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1235000/1801350 [04:46<02:06, 4482.03 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1238000/1801350 [04:45<02:07, 4426.08 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1234000/1801350 [04:45<02:08, 4430.70 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1244000/1801350 [04:45<02:09, 4298.36 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1236000/1801350 [04:46<02:10, 4342.31 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1239000/1801350 [04:45<02:06, 4428.96 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1235000/1801350 [04:45<02:08, 4419.39 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1245000/1801350 [04:45<02:08, 4334.12 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1237000/1801350 [04:46<02:10, 4337.28 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1240000/1801350 [04:46<02:06, 4439.15 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1246000/1801350 [04:46<02:05, 4424.19 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1236000/1801350 [04:46<02:08, 4410.66 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1238000/1801350 [04:46<02:08, 4395.87 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1241000/1801350 [04:46<02:07, 4408.06 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1237000/1801350 [04:46<02:07, 4422.90 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1247000/1801350 [04:46<02:12, 4175.29 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1239000/1801350 [04:46<02:05, 4476.16 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1242000/1801350 [04:46<02:13, 4184.71 examples/s]Grouping texts in chunks of 1024:  69%|██████▊   | 1238000/1801350 [04:46<02:06, 4448.30 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1248000/1801350 [04:46<02:06, 4371.43 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1240000/1801350 [04:47<02:09, 4337.92 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1243000/1801350 [04:46<02:13, 4175.07 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1239000/1801350 [04:46<02:07, 4395.51 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1249000/1801350 [04:46<02:08, 4311.51 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1241000/1801350 [04:47<02:10, 4309.08 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1244000/1801350 [04:46<02:10, 4254.67 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1250000/1801350 [04:47<02:02, 4497.48 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1240000/1801350 [04:47<02:06, 4435.41 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1242000/1801350 [04:47<02:12, 4235.03 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1245000/1801350 [04:47<02:06, 4390.46 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1241000/1801350 [04:47<02:11, 4255.66 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1251000/1801350 [04:47<02:09, 4250.07 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1243000/1801350 [04:47<02:12, 4203.50 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1246000/1801350 [04:47<02:07, 4364.34 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1252000/1801350 [04:47<02:05, 4384.07 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1242000/1801350 [04:47<02:13, 4186.89 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1244000/1801350 [04:48<02:11, 4253.27 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1247000/1801350 [04:47<02:13, 4162.41 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1253000/1801350 [04:47<02:02, 4468.22 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1243000/1801350 [04:47<02:11, 4239.77 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1245000/1801350 [04:48<02:07, 4350.21 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1248000/1801350 [04:47<02:09, 4273.62 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1254000/1801350 [04:47<02:05, 4364.05 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1244000/1801350 [04:48<02:11, 4239.19 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1246000/1801350 [04:48<02:06, 4387.31 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1249000/1801350 [04:48<02:09, 4257.30 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1255000/1801350 [04:48<02:05, 4363.45 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1245000/1801350 [04:48<02:07, 4359.30 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1247000/1801350 [04:48<02:13, 4159.19 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1250000/1801350 [04:48<02:03, 4448.45 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1256000/1801350 [04:48<02:04, 4395.35 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1246000/1801350 [04:48<02:08, 4309.75 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1248000/1801350 [04:49<02:11, 4195.34 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1251000/1801350 [04:48<02:07, 4301.74 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1257000/1801350 [04:48<02:03, 4400.58 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1247000/1801350 [04:48<02:14, 4115.81 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1249000/1801350 [04:49<02:10, 4233.78 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1252000/1801350 [04:48<02:04, 4410.63 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1258000/1801350 [04:48<02:01, 4469.98 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1248000/1801350 [04:48<02:09, 4289.51 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1253000/1801350 [04:49<02:00, 4552.84 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1250000/1801350 [04:49<02:04, 4430.04 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1259000/1801350 [04:49<02:02, 4420.82 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1249000/1801350 [04:49<02:07, 4332.44 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1254000/1801350 [04:49<02:04, 4399.44 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1251000/1801350 [04:49<02:11, 4198.04 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1260000/1801350 [04:49<01:59, 4518.52 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1250000/1801350 [04:49<02:06, 4357.82 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1255000/1801350 [04:49<02:03, 4441.10 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1252000/1801350 [04:50<02:08, 4291.68 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1261000/1801350 [04:49<01:57, 4601.40 examples/s]Grouping texts in chunks of 1024:  69%|██████▉   | 1251000/1801350 [04:49<02:07, 4328.73 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1253000/1801350 [04:50<02:03, 4427.38 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1256000/1801350 [04:49<02:04, 4369.04 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1262000/1801350 [04:49<01:56, 4616.81 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1252000/1801350 [04:49<02:06, 4329.82 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1257000/1801350 [04:49<02:05, 4329.67 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1254000/1801350 [04:50<02:08, 4265.64 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1263000/1801350 [04:49<01:58, 4545.77 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1253000/1801350 [04:50<02:04, 4393.60 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1255000/1801350 [04:50<02:02, 4478.17 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1264000/1801350 [04:50<01:52, 4760.92 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1258000/1801350 [04:50<02:02, 4425.66 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1254000/1801350 [04:50<02:04, 4412.92 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1259000/1801350 [04:50<02:00, 4512.86 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1256000/1801350 [04:50<02:06, 4303.20 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1265000/1801350 [04:50<02:04, 4313.75 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1255000/1801350 [04:50<02:02, 4448.33 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1260000/1801350 [04:50<02:02, 4433.36 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1266000/1801350 [04:50<01:56, 4603.53 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1257000/1801350 [04:51<02:04, 4357.84 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1256000/1801350 [04:50<02:07, 4260.76 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1261000/1801350 [04:50<01:55, 4669.95 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1258000/1801350 [04:51<02:04, 4378.57 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1267000/1801350 [04:50<01:59, 4476.97 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1257000/1801350 [04:51<02:05, 4342.77 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1262000/1801350 [04:51<01:56, 4647.53 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1259000/1801350 [04:51<02:03, 4396.42 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1268000/1801350 [04:51<02:00, 4438.29 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1258000/1801350 [04:51<02:03, 4411.00 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1263000/1801350 [04:51<01:58, 4557.13 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1260000/1801350 [04:51<02:00, 4482.94 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1269000/1801350 [04:51<01:58, 4502.86 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1261000/1801350 [04:52<01:53, 4755.72 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1270000/1801350 [04:51<02:06, 4187.05 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1263000/1801350 [04:52<01:17, 6958.87 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1259000/1801350 [04:51<02:31, 3586.96 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1264000/1801350 [04:51<02:30, 3571.95 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1271000/1801350 [04:51<01:57, 4525.67 examples/s]Grouping texts in chunks of 1024:  70%|██████▉   | 1260000/1801350 [04:51<02:14, 4010.58 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1264000/1801350 [04:52<01:28, 6071.33 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1265000/1801350 [04:51<02:23, 3728.62 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1272000/1801350 [04:51<01:58, 4454.59 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1261000/1801350 [04:52<02:08, 4210.65 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1265000/1801350 [04:52<01:41, 5294.24 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1266000/1801350 [04:52<02:11, 4069.65 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1262000/1801350 [04:52<02:03, 4362.85 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1273000/1801350 [04:52<02:02, 4327.51 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1266000/1801350 [04:52<01:42, 5242.19 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1267000/1801350 [04:52<02:07, 4177.57 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1263000/1801350 [04:52<02:05, 4294.52 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1274000/1801350 [04:52<02:02, 4315.61 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1267000/1801350 [04:53<01:48, 4923.91 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1268000/1801350 [04:52<02:08, 4141.21 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1264000/1801350 [04:52<02:00, 4450.01 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1275000/1801350 [04:52<02:08, 4094.07 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1268000/1801350 [04:53<01:54, 4664.11 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1269000/1801350 [04:52<02:03, 4327.39 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1265000/1801350 [04:52<02:08, 4185.97 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1276000/1801350 [04:52<02:02, 4297.33 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1269000/1801350 [04:53<01:54, 4638.40 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1270000/1801350 [04:53<02:02, 4320.87 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1266000/1801350 [04:53<02:00, 4460.46 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1277000/1801350 [04:53<01:59, 4376.47 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1270000/1801350 [04:53<01:56, 4556.39 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1271000/1801350 [04:53<02:00, 4390.37 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1278000/1801350 [04:53<01:54, 4559.62 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1267000/1801350 [04:53<02:03, 4338.78 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1271000/1801350 [04:53<01:56, 4550.70 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1272000/1801350 [04:53<02:00, 4389.57 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1279000/1801350 [04:53<01:54, 4548.48 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1268000/1801350 [04:53<02:02, 4366.43 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1272000/1801350 [04:54<01:58, 4449.72 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1273000/1801350 [04:53<02:04, 4245.71 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1280000/1801350 [04:53<01:54, 4560.23 examples/s]Grouping texts in chunks of 1024:  70%|███████   | 1269000/1801350 [04:53<02:00, 4411.30 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1273000/1801350 [04:54<02:00, 4367.54 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1274000/1801350 [04:53<02:04, 4226.39 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1281000/1801350 [04:54<01:53, 4584.23 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1270000/1801350 [04:54<01:59, 4455.75 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1274000/1801350 [04:54<02:05, 4214.89 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1275000/1801350 [04:54<02:08, 4089.29 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1282000/1801350 [04:54<01:54, 4530.23 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1271000/1801350 [04:54<01:59, 4429.12 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1275000/1801350 [04:54<02:09, 4078.53 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1276000/1801350 [04:54<02:03, 4271.03 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1283000/1801350 [04:54<02:00, 4319.54 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1272000/1801350 [04:54<02:02, 4322.52 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1277000/1801350 [04:54<01:59, 4380.68 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1276000/1801350 [04:55<02:03, 4254.27 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1284000/1801350 [04:54<01:51, 4632.54 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1273000/1801350 [04:54<02:02, 4301.25 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1278000/1801350 [04:54<01:58, 4411.14 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1277000/1801350 [04:55<02:01, 4308.58 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1285000/1801350 [04:54<01:55, 4460.99 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1274000/1801350 [04:54<02:03, 4257.64 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1279000/1801350 [04:55<01:55, 4512.98 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1278000/1801350 [04:55<01:57, 4444.63 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1286000/1801350 [04:55<01:55, 4474.29 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1275000/1801350 [04:55<02:07, 4121.51 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1280000/1801350 [04:55<01:55, 4526.56 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1279000/1801350 [04:55<01:58, 4406.45 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1287000/1801350 [04:55<01:56, 4397.23 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1276000/1801350 [04:55<02:05, 4185.95 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1281000/1801350 [04:55<01:53, 4582.93 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1280000/1801350 [04:56<01:55, 4525.00 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1288000/1801350 [04:55<01:56, 4406.49 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1277000/1801350 [04:55<02:02, 4265.81 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1281000/1801350 [04:56<01:52, 4608.73 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1282000/1801350 [04:55<01:55, 4492.34 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1289000/1801350 [04:55<02:01, 4229.75 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1278000/1801350 [04:55<01:59, 4397.20 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1282000/1801350 [04:56<01:56, 4463.93 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1283000/1801350 [04:55<01:58, 4382.60 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1290000/1801350 [04:56<01:58, 4302.50 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1279000/1801350 [04:56<01:56, 4483.19 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1284000/1801350 [04:56<01:50, 4684.28 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1283000/1801350 [04:56<02:00, 4309.52 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1280000/1801350 [04:56<01:57, 4444.80 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1291000/1801350 [04:56<02:05, 4082.71 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1284000/1801350 [04:56<01:52, 4593.09 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1285000/1801350 [04:56<01:56, 4422.96 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1281000/1801350 [04:56<01:54, 4545.31 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1292000/1801350 [04:56<02:00, 4229.65 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1286000/1801350 [04:56<01:56, 4416.33 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1285000/1801350 [04:57<01:58, 4353.09 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1282000/1801350 [04:56<01:56, 4454.13 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1293000/1801350 [04:56<02:01, 4191.21 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1287000/1801350 [04:56<01:56, 4424.74 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1286000/1801350 [04:57<01:57, 4375.27 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1294000/1801350 [04:57<01:52, 4498.46 examples/s]Grouping texts in chunks of 1024:  71%|███████   | 1283000/1801350 [04:57<01:59, 4348.10 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1287000/1801350 [04:57<01:58, 4334.18 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1288000/1801350 [04:57<02:01, 4222.80 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1295000/1801350 [04:57<01:49, 4632.19 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1284000/1801350 [04:57<01:50, 4668.37 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1288000/1801350 [04:57<01:58, 4317.23 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1289000/1801350 [04:57<02:01, 4206.61 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1296000/1801350 [04:57<01:50, 4557.59 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1285000/1801350 [04:57<01:56, 4425.22 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1290000/1801350 [04:57<01:57, 4364.72 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1289000/1801350 [04:58<02:03, 4159.97 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1297000/1801350 [04:57<01:51, 4515.39 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1286000/1801350 [04:57<01:55, 4469.63 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1290000/1801350 [04:58<01:59, 4280.21 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1291000/1801350 [04:57<02:04, 4090.15 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1298000/1801350 [04:57<01:50, 4553.52 examples/s]Grouping texts in chunks of 1024:  71%|███████▏  | 1287000/1801350 [04:57<01:56, 4401.64 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1292000/1801350 [04:58<02:01, 4186.81 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1291000/1801350 [04:58<02:06, 4030.58 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1299000/1801350 [04:58<01:53, 4439.91 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1288000/1801350 [04:58<01:58, 4316.23 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1293000/1801350 [04:58<01:59, 4255.26 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1300000/1801350 [04:58<01:49, 4593.28 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1292000/1801350 [04:58<02:03, 4124.42 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1289000/1801350 [04:58<02:02, 4194.14 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1294000/1801350 [04:58<01:54, 4426.06 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1293000/1801350 [04:59<01:59, 4249.84 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1301000/1801350 [04:58<01:53, 4411.93 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1290000/1801350 [04:58<01:58, 4305.38 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1295000/1801350 [04:58<01:50, 4570.04 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1294000/1801350 [04:59<01:54, 4436.16 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1302000/1801350 [04:58<01:49, 4570.25 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1291000/1801350 [04:58<02:04, 4105.00 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1296000/1801350 [04:58<01:54, 4407.47 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1295000/1801350 [04:59<01:51, 4556.59 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1303000/1801350 [04:58<01:49, 4542.46 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1297000/1801350 [04:59<01:49, 4585.84 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1292000/1801350 [04:59<02:04, 4096.38 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1296000/1801350 [04:59<01:51, 4513.10 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1304000/1801350 [04:59<01:54, 4345.26 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1298000/1801350 [04:59<01:49, 4585.33 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1293000/1801350 [04:59<01:59, 4254.36 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1297000/1801350 [04:59<01:51, 4523.75 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1305000/1801350 [04:59<01:53, 4370.19 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1294000/1801350 [04:59<01:55, 4385.80 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1299000/1801350 [04:59<01:55, 4362.86 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1298000/1801350 [05:00<01:51, 4527.43 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1306000/1801350 [04:59<01:51, 4438.55 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1295000/1801350 [04:59<01:53, 4475.39 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1300000/1801350 [04:59<01:48, 4602.90 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1299000/1801350 [05:00<01:54, 4385.20 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1307000/1801350 [04:59<01:59, 4138.59 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1296000/1801350 [05:00<01:52, 4508.88 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1301000/1801350 [05:00<01:52, 4449.35 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1300000/1801350 [05:00<01:51, 4482.66 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1308000/1801350 [05:00<01:50, 4483.25 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1297000/1801350 [05:00<01:50, 4545.08 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1302000/1801350 [05:00<01:52, 4454.21 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1301000/1801350 [05:00<01:52, 4458.41 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1309000/1801350 [05:00<01:49, 4489.29 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1298000/1801350 [05:00<01:50, 4556.20 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1303000/1801350 [05:00<01:48, 4576.37 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1302000/1801350 [05:01<01:51, 4476.62 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1310000/1801350 [05:00<01:55, 4260.18 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1299000/1801350 [05:00<01:53, 4425.22 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1304000/1801350 [05:00<01:54, 4352.74 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1303000/1801350 [05:01<01:51, 4451.16 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1311000/1801350 [05:00<01:51, 4387.38 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1300000/1801350 [05:00<01:51, 4488.34 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1305000/1801350 [05:00<01:55, 4294.28 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1304000/1801350 [05:01<01:53, 4369.34 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1312000/1801350 [05:01<01:54, 4255.60 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1301000/1801350 [05:01<01:52, 4461.38 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1306000/1801350 [05:01<01:55, 4289.00 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1305000/1801350 [05:01<01:53, 4386.86 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1313000/1801350 [05:01<01:57, 4159.45 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1302000/1801350 [05:01<01:52, 4430.22 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1307000/1801350 [05:01<01:56, 4252.94 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1306000/1801350 [05:02<01:55, 4293.67 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1314000/1801350 [05:01<01:54, 4255.39 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1303000/1801350 [05:01<01:52, 4443.26 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1308000/1801350 [05:01<01:50, 4468.17 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1307000/1801350 [05:02<01:59, 4139.53 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1315000/1801350 [05:01<01:54, 4257.80 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1304000/1801350 [05:01<01:53, 4377.04 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1309000/1801350 [05:01<01:48, 4540.57 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1308000/1801350 [05:02<01:51, 4413.52 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1316000/1801350 [05:02<01:48, 4459.11 examples/s]Grouping texts in chunks of 1024:  72%|███████▏  | 1305000/1801350 [05:02<01:54, 4350.28 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1310000/1801350 [05:02<01:55, 4246.91 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1309000/1801350 [05:02<01:50, 4445.57 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1317000/1801350 [05:02<01:45, 4583.36 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1306000/1801350 [05:02<01:52, 4399.64 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1311000/1801350 [05:02<01:52, 4355.74 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1310000/1801350 [05:02<01:56, 4234.99 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1318000/1801350 [05:02<01:42, 4695.56 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1307000/1801350 [05:02<01:58, 4160.69 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1312000/1801350 [05:02<01:57, 4177.42 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1311000/1801350 [05:03<01:53, 4324.60 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1319000/1801350 [05:02<01:45, 4553.54 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1308000/1801350 [05:02<01:51, 4422.87 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1320000/1801350 [05:02<01:41, 4721.15 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1313000/1801350 [05:02<01:58, 4126.16 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1312000/1801350 [05:03<01:55, 4233.81 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1309000/1801350 [05:02<01:51, 4420.77 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1321000/1801350 [05:03<01:43, 4628.93 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1314000/1801350 [05:03<01:53, 4278.25 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1313000/1801350 [05:03<01:57, 4165.50 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1310000/1801350 [05:03<01:57, 4175.15 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1315000/1801350 [05:03<01:52, 4314.92 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1322000/1801350 [05:03<01:47, 4441.07 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1314000/1801350 [05:03<01:56, 4169.97 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1311000/1801350 [05:03<01:54, 4293.19 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1316000/1801350 [05:03<01:48, 4474.46 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1323000/1801350 [05:03<01:45, 4536.09 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1315000/1801350 [05:04<01:54, 4260.84 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1312000/1801350 [05:03<01:56, 4215.06 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1317000/1801350 [05:03<01:45, 4572.88 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1324000/1801350 [05:03<01:45, 4521.54 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1316000/1801350 [05:04<01:47, 4526.40 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1318000/1801350 [05:03<01:44, 4609.35 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1325000/1801350 [05:03<01:42, 4645.52 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1313000/1801350 [05:03<01:58, 4115.10 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1317000/1801350 [05:04<01:47, 4524.36 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1319000/1801350 [05:04<01:45, 4570.01 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1314000/1801350 [05:04<01:55, 4228.42 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1326000/1801350 [05:04<01:46, 4447.81 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1318000/1801350 [05:04<01:44, 4604.64 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1320000/1801350 [05:04<01:42, 4675.68 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1315000/1801350 [05:04<01:54, 4257.75 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1327000/1801350 [05:04<01:47, 4424.52 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1319000/1801350 [05:05<01:46, 4538.40 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1321000/1801350 [05:04<01:43, 4662.57 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1316000/1801350 [05:04<01:47, 4505.68 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1320000/1801350 [05:05<01:44, 4584.76 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1328000/1801350 [05:04<01:47, 4414.11 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1317000/1801350 [05:04<01:47, 4524.14 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1322000/1801350 [05:04<01:51, 4311.14 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1321000/1801350 [05:05<01:43, 4660.25 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1329000/1801350 [05:04<01:49, 4322.23 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1318000/1801350 [05:05<01:44, 4613.62 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1323000/1801350 [05:05<01:46, 4500.15 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1322000/1801350 [05:05<01:52, 4269.33 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1330000/1801350 [05:05<01:50, 4282.59 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1324000/1801350 [05:05<01:43, 4611.64 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1319000/1801350 [05:05<01:46, 4509.74 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1323000/1801350 [05:05<01:46, 4496.22 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1331000/1801350 [05:05<01:49, 4296.54 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1320000/1801350 [05:05<01:44, 4591.59 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1325000/1801350 [05:05<01:45, 4497.35 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1324000/1801350 [05:06<01:45, 4505.66 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1332000/1801350 [05:05<01:47, 4377.52 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1321000/1801350 [05:05<01:42, 4675.11 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1326000/1801350 [05:05<01:48, 4390.03 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1325000/1801350 [05:06<01:46, 4466.30 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1333000/1801350 [05:05<01:49, 4293.77 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1322000/1801350 [05:05<01:50, 4337.06 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1327000/1801350 [05:05<01:49, 4320.43 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1326000/1801350 [05:06<01:50, 4314.64 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1334000/1801350 [05:06<01:50, 4222.05 examples/s]Grouping texts in chunks of 1024:  73%|███████▎  | 1323000/1801350 [05:06<01:46, 4491.48 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1328000/1801350 [05:06<01:48, 4360.29 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1327000/1801350 [05:06<01:50, 4304.69 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1335000/1801350 [05:06<01:49, 4265.98 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1324000/1801350 [05:06<01:43, 4622.82 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1329000/1801350 [05:06<01:50, 4277.65 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1328000/1801350 [05:07<01:48, 4355.38 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1336000/1801350 [05:06<01:49, 4261.36 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1325000/1801350 [05:06<01:44, 4574.01 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1330000/1801350 [05:06<01:50, 4268.11 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1329000/1801350 [05:07<01:51, 4243.00 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1337000/1801350 [05:06<01:44, 4459.40 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1326000/1801350 [05:06<01:51, 4251.43 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1331000/1801350 [05:06<01:49, 4288.18 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1338000/1801350 [05:06<01:42, 4518.45 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1330000/1801350 [05:07<01:54, 4110.24 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1327000/1801350 [05:07<01:50, 4309.25 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1332000/1801350 [05:07<01:46, 4405.64 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1339000/1801350 [05:07<01:42, 4513.68 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1331000/1801350 [05:07<01:53, 4136.57 examples/s]Grouping texts in chunks of 1024:  74%|███████▎  | 1328000/1801350 [05:07<01:51, 4232.22 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1333000/1801350 [05:07<01:51, 4211.63 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1340000/1801350 [05:07<01:46, 4346.08 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1332000/1801350 [05:08<01:50, 4257.02 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1329000/1801350 [05:07<01:53, 4153.49 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1334000/1801350 [05:07<01:51, 4201.74 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1341000/1801350 [05:07<01:41, 4543.64 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1333000/1801350 [05:08<01:52, 4147.41 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1330000/1801350 [05:07<01:49, 4300.84 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1335000/1801350 [05:07<01:51, 4201.23 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1342000/1801350 [05:07<01:44, 4408.78 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1334000/1801350 [05:08<01:53, 4128.66 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1331000/1801350 [05:08<01:52, 4184.27 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1343000/1801350 [05:08<01:41, 4508.41 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1336000/1801350 [05:08<01:51, 4191.06 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1335000/1801350 [05:08<01:52, 4161.87 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1332000/1801350 [05:08<01:49, 4284.06 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1337000/1801350 [05:08<01:44, 4439.57 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1344000/1801350 [05:08<01:41, 4512.32 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1336000/1801350 [05:08<01:51, 4191.98 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1338000/1801350 [05:08<01:42, 4510.34 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1333000/1801350 [05:08<01:51, 4194.94 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1345000/1801350 [05:08<01:44, 4376.51 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1337000/1801350 [05:09<01:46, 4380.23 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1339000/1801350 [05:08<01:40, 4601.07 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1346000/1801350 [05:08<01:41, 4507.67 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1334000/1801350 [05:08<01:51, 4189.64 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1338000/1801350 [05:09<01:45, 4374.26 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1340000/1801350 [05:08<01:46, 4316.48 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1335000/1801350 [05:08<01:49, 4263.10 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1347000/1801350 [05:08<01:42, 4436.60 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1339000/1801350 [05:09<01:42, 4506.24 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1341000/1801350 [05:09<01:41, 4529.10 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1348000/1801350 [05:09<01:39, 4561.47 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1336000/1801350 [05:09<01:50, 4208.28 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1340000/1801350 [05:09<01:47, 4301.33 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1342000/1801350 [05:09<01:41, 4510.56 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1349000/1801350 [05:09<01:38, 4578.30 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1337000/1801350 [05:09<01:45, 4413.07 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1341000/1801350 [05:10<01:42, 4483.70 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1343000/1801350 [05:09<01:42, 4464.25 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1350000/1801350 [05:09<01:39, 4522.63 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1338000/1801350 [05:09<01:45, 4408.27 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1342000/1801350 [05:10<01:42, 4463.07 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1351000/1801350 [05:09<01:38, 4576.75 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1339000/1801350 [05:09<01:41, 4569.43 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1344000/1801350 [05:09<01:41, 4520.23 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1343000/1801350 [05:10<01:40, 4553.11 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1345000/1801350 [05:10<01:44, 4372.03 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1352000/1801350 [05:10<01:41, 4415.39 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1340000/1801350 [05:10<01:44, 4407.72 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1344000/1801350 [05:10<01:44, 4369.98 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1341000/1801350 [05:10<01:39, 4616.17 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1346000/1801350 [05:10<01:43, 4416.98 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1353000/1801350 [05:10<01:43, 4327.17 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1345000/1801350 [05:11<01:44, 4373.96 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1347000/1801350 [05:10<01:43, 4387.52 examples/s]Grouping texts in chunks of 1024:  74%|███████▍  | 1342000/1801350 [05:10<01:44, 4385.07 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1354000/1801350 [05:10<01:45, 4257.99 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1346000/1801350 [05:11<01:40, 4510.87 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1348000/1801350 [05:10<01:37, 4661.19 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1343000/1801350 [05:10<01:41, 4514.86 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1355000/1801350 [05:10<01:41, 4401.25 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1347000/1801350 [05:11<01:42, 4412.98 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1349000/1801350 [05:10<01:40, 4515.83 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1356000/1801350 [05:10<01:39, 4475.14 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1344000/1801350 [05:10<01:45, 4349.44 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1348000/1801350 [05:11<01:38, 4582.71 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1350000/1801350 [05:11<01:40, 4506.73 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1345000/1801350 [05:11<01:41, 4480.47 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1357000/1801350 [05:11<01:40, 4435.08 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1349000/1801350 [05:11<01:38, 4577.09 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1351000/1801350 [05:11<01:39, 4527.15 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1346000/1801350 [05:11<01:41, 4466.64 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1358000/1801350 [05:11<01:39, 4457.38 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1350000/1801350 [05:12<01:41, 4432.92 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1352000/1801350 [05:11<01:41, 4413.34 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1347000/1801350 [05:11<01:42, 4436.58 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1359000/1801350 [05:11<01:42, 4318.99 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1351000/1801350 [05:12<01:38, 4571.63 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1353000/1801350 [05:11<01:41, 4415.72 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1348000/1801350 [05:11<01:39, 4567.68 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1360000/1801350 [05:11<01:45, 4185.28 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1352000/1801350 [05:12<01:45, 4278.73 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1349000/1801350 [05:12<01:41, 4464.39 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1354000/1801350 [05:12<01:46, 4189.96 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1361000/1801350 [05:12<01:42, 4277.81 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1353000/1801350 [05:12<01:44, 4287.71 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1350000/1801350 [05:12<01:40, 4500.48 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1355000/1801350 [05:12<01:44, 4259.51 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1362000/1801350 [05:12<01:39, 4396.90 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1354000/1801350 [05:13<01:49, 4103.02 examples/s]Grouping texts in chunks of 1024:  75%|███████▍  | 1351000/1801350 [05:12<01:38, 4554.38 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1356000/1801350 [05:12<01:39, 4469.87 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1363000/1801350 [05:12<01:37, 4484.48 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1355000/1801350 [05:13<01:45, 4230.54 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1357000/1801350 [05:12<01:39, 4460.17 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1352000/1801350 [05:12<01:43, 4355.60 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1364000/1801350 [05:12<01:47, 4074.07 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1356000/1801350 [05:13<01:40, 4416.36 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1358000/1801350 [05:13<01:39, 4446.40 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1353000/1801350 [05:13<01:43, 4329.07 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1365000/1801350 [05:13<01:43, 4212.45 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1357000/1801350 [05:13<01:42, 4328.44 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1359000/1801350 [05:13<01:41, 4354.76 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1354000/1801350 [05:13<01:47, 4154.80 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1366000/1801350 [05:13<01:45, 4109.18 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1358000/1801350 [05:13<01:40, 4410.55 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1355000/1801350 [05:13<01:42, 4368.16 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1360000/1801350 [05:13<01:47, 4094.25 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1367000/1801350 [05:13<01:42, 4236.71 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1359000/1801350 [05:14<01:42, 4295.27 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1356000/1801350 [05:13<01:41, 4382.70 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1361000/1801350 [05:13<01:43, 4256.09 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1368000/1801350 [05:13<01:43, 4178.75 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1360000/1801350 [05:14<01:46, 4138.51 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1362000/1801350 [05:13<01:39, 4431.30 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1357000/1801350 [05:13<01:41, 4374.20 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1369000/1801350 [05:14<01:37, 4426.27 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1361000/1801350 [05:14<01:43, 4270.19 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1358000/1801350 [05:14<01:39, 4434.81 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1363000/1801350 [05:14<01:42, 4291.81 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1370000/1801350 [05:14<01:47, 4005.36 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1362000/1801350 [05:14<01:41, 4328.12 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1359000/1801350 [05:14<01:43, 4283.24 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1364000/1801350 [05:14<01:47, 4078.29 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1371000/1801350 [05:14<01:44, 4124.60 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1363000/1801350 [05:15<01:41, 4298.30 examples/s]Grouping texts in chunks of 1024:  75%|███████▌  | 1360000/1801350 [05:14<01:45, 4178.89 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1365000/1801350 [05:14<01:46, 4088.19 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1372000/1801350 [05:14<01:43, 4163.88 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1364000/1801350 [05:15<01:49, 4001.37 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1361000/1801350 [05:14<01:44, 4232.74 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1366000/1801350 [05:14<01:45, 4141.50 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1373000/1801350 [05:15<01:45, 4060.84 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1362000/1801350 [05:15<01:39, 4396.59 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1365000/1801350 [05:15<01:47, 4057.48 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1367000/1801350 [05:15<01:44, 4175.41 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1374000/1801350 [05:15<01:49, 3906.92 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1363000/1801350 [05:15<01:42, 4296.46 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1366000/1801350 [05:15<01:47, 4053.59 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1368000/1801350 [05:15<01:43, 4200.89 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1375000/1801350 [05:15<01:40, 4223.28 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1367000/1801350 [05:16<01:44, 4164.99 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1364000/1801350 [05:15<01:44, 4174.34 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1369000/1801350 [05:15<01:41, 4267.99 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1376000/1801350 [05:15<01:38, 4302.81 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1368000/1801350 [05:16<01:44, 4140.08 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1365000/1801350 [05:15<01:46, 4090.28 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1370000/1801350 [05:15<01:48, 3974.14 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1377000/1801350 [05:15<01:38, 4297.59 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1369000/1801350 [05:16<01:41, 4248.33 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1366000/1801350 [05:16<01:46, 4071.66 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1371000/1801350 [05:16<01:43, 4163.04 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1378000/1801350 [05:16<01:36, 4389.53 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1367000/1801350 [05:16<01:43, 4196.15 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1370000/1801350 [05:16<01:51, 3854.89 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1372000/1801350 [05:16<01:42, 4193.79 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1379000/1801350 [05:16<01:38, 4302.14 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1368000/1801350 [05:16<01:44, 4160.25 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1371000/1801350 [05:17<01:46, 4033.35 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1373000/1801350 [05:16<01:47, 3991.06 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1380000/1801350 [05:16<01:36, 4358.94 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1369000/1801350 [05:16<01:39, 4352.33 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1372000/1801350 [05:17<01:44, 4089.62 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1381000/1801350 [05:16<01:39, 4237.55 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1374000/1801350 [05:16<01:50, 3869.16 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1373000/1801350 [05:17<01:47, 3989.45 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1375000/1801350 [05:17<01:39, 4291.52 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1370000/1801350 [05:17<01:50, 3888.23 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1382000/1801350 [05:17<01:38, 4242.37 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1371000/1801350 [05:17<01:46, 4057.43 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1376000/1801350 [05:17<01:40, 4213.34 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1374000/1801350 [05:17<01:50, 3859.38 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1383000/1801350 [05:17<01:35, 4368.63 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1375000/1801350 [05:18<01:41, 4194.27 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1377000/1801350 [05:17<01:37, 4353.90 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1372000/1801350 [05:17<01:45, 4063.06 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1384000/1801350 [05:17<01:36, 4319.36 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1378000/1801350 [05:17<01:35, 4413.96 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1376000/1801350 [05:18<01:41, 4200.16 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1385000/1801350 [05:17<01:34, 4405.45 examples/s]Grouping texts in chunks of 1024:  76%|███████▌  | 1373000/1801350 [05:17<01:48, 3956.03 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1377000/1801350 [05:18<01:38, 4313.26 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1379000/1801350 [05:18<01:39, 4264.77 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1386000/1801350 [05:18<01:37, 4257.67 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1374000/1801350 [05:18<01:49, 3919.16 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1378000/1801350 [05:18<01:37, 4358.90 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1380000/1801350 [05:18<01:38, 4278.19 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1375000/1801350 [05:18<01:40, 4257.77 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1387000/1801350 [05:18<01:37, 4267.47 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1379000/1801350 [05:19<01:40, 4218.21 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1388000/1801350 [05:18<01:30, 4561.09 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1376000/1801350 [05:18<01:38, 4310.73 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1381000/1801350 [05:18<01:40, 4175.80 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1380000/1801350 [05:19<01:39, 4255.96 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1389000/1801350 [05:18<01:32, 4470.81 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1377000/1801350 [05:18<01:38, 4327.12 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1382000/1801350 [05:18<01:38, 4239.23 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1390000/1801350 [05:18<01:32, 4469.80 examples/s]Grouping texts in chunks of 1024:  76%|███████▋  | 1378000/1801350 [05:18<01:36, 4393.17 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1383000/1801350 [05:18<01:36, 4321.36 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1381000/1801350 [05:19<01:43, 4065.23 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1391000/1801350 [05:19<01:34, 4322.72 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1384000/1801350 [05:19<01:37, 4261.45 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1382000/1801350 [05:19<01:41, 4140.90 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1379000/1801350 [05:19<01:41, 4164.59 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1385000/1801350 [05:19<01:34, 4403.04 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1380000/1801350 [05:19<01:36, 4358.33 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1383000/1801350 [05:20<01:37, 4278.98 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1392000/1801350 [05:19<01:35, 4280.33 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1384000/1801350 [05:20<01:37, 4272.07 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1386000/1801350 [05:19<01:38, 4217.47 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1393000/1801350 [05:19<01:37, 4187.09 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1381000/1801350 [05:19<01:39, 4238.82 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1385000/1801350 [05:20<01:34, 4382.97 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1387000/1801350 [05:19<01:35, 4347.29 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1382000/1801350 [05:19<01:39, 4196.95 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1394000/1801350 [05:19<01:37, 4186.76 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1388000/1801350 [05:20<01:32, 4460.56 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1386000/1801350 [05:20<01:37, 4280.70 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1395000/1801350 [05:20<01:34, 4320.65 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1383000/1801350 [05:20<01:38, 4249.39 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1389000/1801350 [05:20<01:32, 4464.67 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1387000/1801350 [05:20<01:37, 4257.96 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1384000/1801350 [05:20<01:37, 4269.94 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1396000/1801350 [05:20<01:37, 4139.68 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1388000/1801350 [05:21<01:30, 4544.21 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1390000/1801350 [05:20<01:32, 4427.32 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1385000/1801350 [05:20<01:34, 4392.36 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1397000/1801350 [05:20<01:35, 4228.92 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1389000/1801350 [05:21<01:31, 4483.84 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1391000/1801350 [05:20<01:34, 4338.84 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1386000/1801350 [05:20<01:37, 4252.03 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1398000/1801350 [05:20<01:34, 4278.08 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1392000/1801350 [05:21<01:34, 4313.80 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1390000/1801350 [05:21<01:36, 4243.18 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1399000/1801350 [05:21<01:29, 4484.01 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1387000/1801350 [05:21<01:35, 4353.52 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1388000/1801350 [05:21<01:32, 4450.74 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1391000/1801350 [05:21<01:36, 4244.56 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1393000/1801350 [05:21<01:38, 4166.36 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1400000/1801350 [05:21<01:31, 4375.23 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1389000/1801350 [05:21<01:32, 4467.16 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1392000/1801350 [05:22<01:32, 4408.60 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1401000/1801350 [05:21<01:30, 4445.84 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1394000/1801350 [05:21<01:38, 4151.28 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1402000/1801350 [05:21<01:27, 4549.10 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1390000/1801350 [05:21<01:32, 4426.56 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1393000/1801350 [05:22<01:38, 4139.15 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1395000/1801350 [05:21<01:37, 4188.74 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1403000/1801350 [05:21<01:27, 4531.21 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1391000/1801350 [05:21<01:36, 4267.01 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1394000/1801350 [05:22<01:37, 4191.95 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1396000/1801350 [05:22<01:37, 4171.48 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1395000/1801350 [05:22<01:34, 4292.21 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1404000/1801350 [05:22<01:45, 3749.78 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1392000/1801350 [05:22<01:52, 3625.41 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1397000/1801350 [05:22<01:06, 6115.59 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1397000/1801350 [05:22<01:54, 3523.53 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1405000/1801350 [05:22<01:32, 4283.48 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1393000/1801350 [05:22<01:46, 3841.59 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1398000/1801350 [05:22<01:44, 3858.20 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1398000/1801350 [05:23<01:15, 5340.85 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1406000/1801350 [05:22<01:37, 4036.04 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1399000/1801350 [05:22<01:38, 4075.20 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1394000/1801350 [05:22<01:44, 3879.61 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1399000/1801350 [05:23<01:16, 5250.87 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1407000/1801350 [05:23<01:37, 4039.64 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1400000/1801350 [05:23<01:18, 5128.04 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1400000/1801350 [05:23<01:37, 4124.59 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1395000/1801350 [05:23<01:41, 3997.83 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1408000/1801350 [05:23<01:32, 4265.26 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1401000/1801350 [05:23<01:34, 4230.27 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1401000/1801350 [05:23<01:22, 4851.94 examples/s]Grouping texts in chunks of 1024:  77%|███████▋  | 1396000/1801350 [05:23<01:40, 4013.90 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1409000/1801350 [05:23<01:31, 4306.68 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1402000/1801350 [05:23<01:30, 4392.04 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1402000/1801350 [05:24<01:23, 4765.31 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1397000/1801350 [05:23<01:38, 4108.43 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1410000/1801350 [05:23<01:30, 4329.37 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1403000/1801350 [05:23<01:31, 4373.58 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1403000/1801350 [05:24<01:26, 4591.13 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1398000/1801350 [05:23<01:39, 4045.87 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1411000/1801350 [05:23<01:33, 4193.86 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1404000/1801350 [05:23<01:30, 4393.52 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1404000/1801350 [05:24<01:28, 4511.94 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1399000/1801350 [05:23<01:32, 4368.87 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1405000/1801350 [05:24<01:26, 4606.33 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1412000/1801350 [05:24<01:30, 4279.13 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1405000/1801350 [05:24<01:24, 4686.20 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1400000/1801350 [05:24<01:34, 4243.71 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1413000/1801350 [05:24<01:29, 4321.18 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1406000/1801350 [05:24<01:33, 4209.24 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1406000/1801350 [05:25<01:31, 4314.33 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1401000/1801350 [05:24<01:32, 4325.73 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1414000/1801350 [05:24<01:29, 4335.76 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1407000/1801350 [05:24<01:33, 4224.24 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1402000/1801350 [05:24<01:28, 4493.55 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1407000/1801350 [05:25<01:34, 4188.04 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1415000/1801350 [05:24<01:26, 4457.84 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1408000/1801350 [05:24<01:29, 4395.10 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1403000/1801350 [05:24<01:29, 4474.62 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1408000/1801350 [05:25<01:30, 4349.70 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1416000/1801350 [05:25<01:30, 4249.72 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1409000/1801350 [05:25<01:28, 4424.99 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1409000/1801350 [05:25<01:27, 4476.45 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1404000/1801350 [05:25<01:29, 4442.94 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1417000/1801350 [05:25<01:26, 4437.71 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1405000/1801350 [05:25<01:27, 4505.10 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1410000/1801350 [05:25<01:32, 4231.14 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1410000/1801350 [05:25<01:32, 4242.43 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1418000/1801350 [05:25<01:27, 4358.04 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1411000/1801350 [05:25<01:30, 4293.57 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1406000/1801350 [05:25<01:30, 4354.82 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1411000/1801350 [05:26<01:31, 4257.41 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1419000/1801350 [05:25<01:28, 4339.93 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1412000/1801350 [05:25<01:29, 4341.70 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1412000/1801350 [05:26<01:29, 4365.24 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1407000/1801350 [05:25<01:34, 4194.35 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1420000/1801350 [05:25<01:28, 4313.69 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1413000/1801350 [05:26<01:27, 4443.02 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1413000/1801350 [05:26<01:27, 4419.33 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1408000/1801350 [05:26<01:31, 4291.84 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1421000/1801350 [05:26<01:28, 4288.01 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1414000/1801350 [05:26<01:29, 4342.25 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1409000/1801350 [05:26<01:29, 4396.34 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1414000/1801350 [05:26<01:30, 4286.77 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1415000/1801350 [05:26<01:27, 4438.29 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1422000/1801350 [05:26<01:31, 4133.00 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1415000/1801350 [05:27<01:28, 4361.17 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1410000/1801350 [05:26<01:31, 4277.20 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1423000/1801350 [05:26<01:29, 4232.33 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1416000/1801350 [05:26<01:30, 4246.13 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1411000/1801350 [05:26<01:31, 4266.03 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1416000/1801350 [05:27<01:31, 4207.14 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1424000/1801350 [05:26<01:27, 4330.61 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1417000/1801350 [05:26<01:26, 4422.34 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1417000/1801350 [05:27<01:26, 4451.37 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1412000/1801350 [05:26<01:29, 4357.35 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1425000/1801350 [05:27<01:23, 4529.45 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1418000/1801350 [05:27<01:28, 4328.17 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1413000/1801350 [05:27<01:29, 4362.04 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1418000/1801350 [05:27<01:29, 4302.73 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1426000/1801350 [05:27<01:24, 4447.55 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1419000/1801350 [05:27<01:27, 4361.01 examples/s]Grouping texts in chunks of 1024:  78%|███████▊  | 1414000/1801350 [05:27<01:27, 4407.05 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1419000/1801350 [05:28<01:27, 4351.94 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1427000/1801350 [05:27<01:22, 4534.63 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1420000/1801350 [05:27<01:26, 4414.78 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1415000/1801350 [05:27<01:27, 4412.42 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1420000/1801350 [05:28<01:27, 4360.97 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1428000/1801350 [05:27<01:26, 4334.58 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1421000/1801350 [05:27<01:26, 4422.02 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1416000/1801350 [05:27<01:30, 4251.35 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1421000/1801350 [05:28<01:29, 4242.67 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1429000/1801350 [05:28<01:28, 4222.23 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1417000/1801350 [05:28<01:25, 4469.62 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1422000/1801350 [05:28<01:31, 4146.93 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1422000/1801350 [05:28<01:34, 4013.96 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1430000/1801350 [05:28<01:30, 4125.73 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1423000/1801350 [05:28<01:31, 4119.80 examples/s]Grouping texts in chunks of 1024:  79%|███████▊  | 1418000/1801350 [05:28<01:31, 4209.07 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1423000/1801350 [05:28<01:31, 4130.68 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1431000/1801350 [05:28<01:25, 4323.56 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1424000/1801350 [05:28<01:30, 4186.23 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1419000/1801350 [05:28<01:29, 4270.40 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1424000/1801350 [05:29<01:27, 4309.34 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1432000/1801350 [05:28<01:27, 4238.61 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1425000/1801350 [05:28<01:26, 4352.05 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1420000/1801350 [05:28<01:27, 4347.03 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1425000/1801350 [05:29<01:26, 4351.69 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1433000/1801350 [05:28<01:25, 4332.16 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1426000/1801350 [05:29<01:26, 4356.52 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1421000/1801350 [05:29<01:27, 4361.38 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1426000/1801350 [05:29<01:25, 4409.27 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1427000/1801350 [05:29<01:23, 4496.98 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1434000/1801350 [05:29<01:27, 4217.11 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1427000/1801350 [05:29<01:23, 4494.50 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1422000/1801350 [05:29<01:33, 4066.21 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1435000/1801350 [05:29<01:16, 4817.73 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1428000/1801350 [05:29<01:26, 4308.06 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1428000/1801350 [05:30<01:27, 4283.98 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1423000/1801350 [05:29<01:31, 4156.92 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1436000/1801350 [05:29<01:15, 4859.43 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1429000/1801350 [05:29<01:27, 4234.35 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1424000/1801350 [05:29<01:26, 4354.79 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1429000/1801350 [05:30<01:29, 4165.70 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1437000/1801350 [05:29<01:19, 4606.20 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1430000/1801350 [05:29<01:29, 4147.49 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1425000/1801350 [05:29<01:26, 4368.92 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1430000/1801350 [05:30<01:30, 4110.74 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1438000/1801350 [05:30<01:20, 4518.91 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1431000/1801350 [05:30<01:25, 4349.65 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1426000/1801350 [05:30<01:25, 4410.12 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1431000/1801350 [05:30<01:26, 4306.02 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1439000/1801350 [05:30<01:19, 4565.21 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1432000/1801350 [05:30<01:27, 4238.75 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1427000/1801350 [05:30<01:24, 4416.28 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1440000/1801350 [05:30<01:20, 4493.20 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1432000/1801350 [05:31<01:27, 4217.25 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1433000/1801350 [05:30<01:25, 4314.79 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1428000/1801350 [05:30<01:27, 4271.03 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1433000/1801350 [05:31<01:25, 4312.86 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1441000/1801350 [05:30<01:22, 4363.02 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1434000/1801350 [05:30<01:24, 4327.19 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1429000/1801350 [05:30<01:26, 4289.93 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1434000/1801350 [05:31<01:28, 4167.95 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1442000/1801350 [05:31<01:26, 4176.89 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1435000/1801350 [05:31<01:18, 4691.85 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1435000/1801350 [05:31<01:18, 4689.49 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1430000/1801350 [05:31<01:27, 4260.43 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1443000/1801350 [05:31<01:21, 4417.01 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1436000/1801350 [05:31<01:16, 4747.41 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1436000/1801350 [05:31<01:17, 4729.76 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1431000/1801350 [05:31<01:25, 4324.35 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1444000/1801350 [05:31<01:21, 4380.74 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1437000/1801350 [05:31<01:20, 4543.83 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1437000/1801350 [05:32<01:19, 4611.92 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1445000/1801350 [05:31<01:17, 4601.86 examples/s]Grouping texts in chunks of 1024:  79%|███████▉  | 1432000/1801350 [05:31<01:28, 4179.46 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1438000/1801350 [05:31<01:21, 4484.98 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1433000/1801350 [05:31<01:25, 4304.77 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1446000/1801350 [05:31<01:22, 4305.56 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1439000/1801350 [05:31<01:20, 4488.73 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1434000/1801350 [05:32<01:26, 4226.46 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1447000/1801350 [05:32<01:22, 4301.74 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1440000/1801350 [05:32<01:19, 4530.47 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1438000/1801350 [05:32<02:03, 2943.98 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1435000/1801350 [05:32<01:17, 4751.84 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1448000/1801350 [05:32<01:18, 4484.62 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1441000/1801350 [05:32<01:21, 4438.32 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1439000/1801350 [05:32<01:50, 3270.01 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1436000/1801350 [05:32<01:18, 4670.67 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1449000/1801350 [05:32<01:20, 4362.53 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1440000/1801350 [05:33<01:41, 3555.85 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1442000/1801350 [05:32<01:25, 4213.08 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1437000/1801350 [05:32<01:20, 4521.10 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1450000/1801350 [05:32<01:19, 4409.41 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1443000/1801350 [05:32<01:21, 4399.07 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1441000/1801350 [05:33<01:37, 3697.92 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1438000/1801350 [05:32<01:21, 4482.38 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1451000/1801350 [05:33<01:22, 4228.67 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1444000/1801350 [05:33<01:22, 4330.30 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1439000/1801350 [05:33<01:20, 4526.09 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1442000/1801350 [05:33<01:37, 3690.34 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1452000/1801350 [05:33<01:22, 4218.23 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1445000/1801350 [05:33<01:19, 4505.36 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1443000/1801350 [05:33<01:28, 4035.99 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1440000/1801350 [05:33<01:20, 4481.31 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1453000/1801350 [05:33<01:23, 4173.89 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1446000/1801350 [05:33<01:22, 4291.28 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1444000/1801350 [05:34<01:27, 4096.60 examples/s]Grouping texts in chunks of 1024:  80%|███████▉  | 1441000/1801350 [05:33<01:21, 4440.27 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1454000/1801350 [05:33<01:24, 4112.31 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1447000/1801350 [05:33<01:23, 4261.56 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1445000/1801350 [05:34<01:26, 4135.19 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1442000/1801350 [05:33<01:26, 4142.26 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1448000/1801350 [05:34<01:19, 4435.04 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1455000/1801350 [05:34<01:23, 4139.81 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1446000/1801350 [05:34<01:25, 4170.00 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1443000/1801350 [05:34<01:21, 4392.12 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1456000/1801350 [05:34<01:20, 4290.49 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1449000/1801350 [05:34<01:22, 4272.84 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1444000/1801350 [05:34<01:21, 4399.98 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1447000/1801350 [05:34<01:27, 4043.60 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1450000/1801350 [05:34<01:18, 4469.52 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1457000/1801350 [05:34<01:22, 4152.01 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1448000/1801350 [05:35<01:21, 4321.64 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1445000/1801350 [05:34<01:20, 4427.45 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1458000/1801350 [05:34<01:20, 4280.28 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1451000/1801350 [05:34<01:22, 4270.46 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1449000/1801350 [05:35<01:23, 4229.20 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1446000/1801350 [05:34<01:22, 4293.07 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1459000/1801350 [05:34<01:20, 4266.46 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1452000/1801350 [05:34<01:21, 4261.59 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1450000/1801350 [05:35<01:18, 4451.88 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1447000/1801350 [05:35<01:25, 4133.76 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1460000/1801350 [05:35<01:19, 4320.46 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1453000/1801350 [05:35<01:23, 4179.14 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1448000/1801350 [05:35<01:19, 4446.60 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1451000/1801350 [05:35<01:23, 4194.68 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1461000/1801350 [05:35<01:14, 4549.76 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1454000/1801350 [05:35<01:24, 4097.48 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1452000/1801350 [05:36<01:23, 4183.36 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1449000/1801350 [05:35<01:22, 4265.54 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1462000/1801350 [05:35<01:13, 4605.27 examples/s]Grouping texts in chunks of 1024:  80%|████████  | 1450000/1801350 [05:35<01:19, 4407.97 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1455000/1801350 [05:35<01:23, 4152.51 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1453000/1801350 [05:36<01:25, 4085.87 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1463000/1801350 [05:35<01:14, 4531.81 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1456000/1801350 [05:35<01:20, 4285.73 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1451000/1801350 [05:35<01:21, 4277.95 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1454000/1801350 [05:36<01:24, 4088.24 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1464000/1801350 [05:36<01:15, 4445.20 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1457000/1801350 [05:36<01:22, 4156.87 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1452000/1801350 [05:36<01:23, 4204.37 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1455000/1801350 [05:36<01:23, 4155.19 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1458000/1801350 [05:36<01:21, 4218.39 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1456000/1801350 [05:37<01:21, 4263.10 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1453000/1801350 [05:36<01:24, 4145.33 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1459000/1801350 [05:36<01:20, 4238.71 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1454000/1801350 [05:36<01:23, 4150.09 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1465000/1801350 [05:36<01:59, 2808.59 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1457000/1801350 [05:37<01:25, 4041.48 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1460000/1801350 [05:36<01:18, 4333.22 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1455000/1801350 [05:36<01:23, 4125.52 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1458000/1801350 [05:37<01:23, 4116.15 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1466000/1801350 [05:36<01:50, 3045.67 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1461000/1801350 [05:37<01:16, 4477.35 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1456000/1801350 [05:37<01:22, 4179.30 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1459000/1801350 [05:37<01:21, 4197.74 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1467000/1801350 [05:37<01:38, 3385.40 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1462000/1801350 [05:37<01:16, 4461.35 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1460000/1801350 [05:37<01:21, 4199.41 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1468000/1801350 [05:37<01:32, 3603.04 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1457000/1801350 [05:37<01:25, 4038.50 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1463000/1801350 [05:37<01:17, 4390.20 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1461000/1801350 [05:38<01:16, 4464.45 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1458000/1801350 [05:37<01:22, 4141.78 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1469000/1801350 [05:37<01:29, 3709.30 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1464000/1801350 [05:37<01:17, 4325.67 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1462000/1801350 [05:38<01:14, 4553.71 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1459000/1801350 [05:37<01:21, 4194.96 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1470000/1801350 [05:37<01:25, 3880.38 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1463000/1801350 [05:38<01:15, 4499.03 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1460000/1801350 [05:38<01:19, 4296.55 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1471000/1801350 [05:38<01:25, 3866.15 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1464000/1801350 [05:38<01:18, 4311.93 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1461000/1801350 [05:38<01:16, 4446.02 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1472000/1801350 [05:38<01:22, 4005.48 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1465000/1801350 [05:38<02:01, 2764.85 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1462000/1801350 [05:38<01:15, 4493.33 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1465000/1801350 [05:39<01:23, 4026.00 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1473000/1801350 [05:38<01:16, 4273.82 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1466000/1801350 [05:38<01:51, 2998.06 examples/s]Grouping texts in chunks of 1024:  81%|████████  | 1463000/1801350 [05:38<01:14, 4535.70 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1474000/1801350 [05:38<01:15, 4312.01 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1466000/1801350 [05:39<01:24, 3954.61 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1467000/1801350 [05:38<01:40, 3322.54 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1464000/1801350 [05:39<01:18, 4304.23 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1467000/1801350 [05:39<01:20, 4170.51 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1475000/1801350 [05:39<01:17, 4210.00 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1468000/1801350 [05:39<01:31, 3642.94 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1476000/1801350 [05:39<01:14, 4395.17 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1468000/1801350 [05:39<01:19, 4186.83 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1469000/1801350 [05:39<01:28, 3759.16 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1477000/1801350 [05:39<01:14, 4367.88 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1469000/1801350 [05:40<01:20, 4120.58 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1470000/1801350 [05:39<01:26, 3831.82 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1465000/1801350 [05:39<02:04, 2710.24 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1478000/1801350 [05:39<01:17, 4189.48 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1470000/1801350 [05:40<01:20, 4132.33 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1471000/1801350 [05:39<01:24, 3905.11 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1466000/1801350 [05:39<01:54, 2925.03 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1479000/1801350 [05:40<01:16, 4216.55 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1471000/1801350 [05:40<01:21, 4070.46 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1472000/1801350 [05:40<01:20, 4069.09 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1467000/1801350 [05:40<01:39, 3350.97 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1480000/1801350 [05:40<01:17, 4137.51 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1472000/1801350 [05:40<01:18, 4210.20 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1473000/1801350 [05:40<01:16, 4300.41 examples/s]Grouping texts in chunks of 1024:  81%|████████▏ | 1468000/1801350 [05:40<01:33, 3572.71 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1473000/1801350 [05:41<01:14, 4418.05 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1481000/1801350 [05:40<01:15, 4229.77 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1474000/1801350 [05:40<01:17, 4227.25 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1469000/1801350 [05:40<01:28, 3745.12 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1474000/1801350 [05:41<01:16, 4294.95 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1482000/1801350 [05:40<01:15, 4202.79 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1475000/1801350 [05:40<01:15, 4319.48 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1470000/1801350 [05:40<01:27, 3804.12 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1483000/1801350 [05:40<01:12, 4388.75 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1475000/1801350 [05:41<01:16, 4281.22 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1476000/1801350 [05:41<01:14, 4376.55 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1471000/1801350 [05:41<01:24, 3898.62 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1476000/1801350 [05:41<01:13, 4440.18 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1484000/1801350 [05:41<01:15, 4229.75 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1477000/1801350 [05:41<01:15, 4273.32 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1472000/1801350 [05:41<01:21, 4029.17 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1477000/1801350 [05:41<01:15, 4278.54 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1485000/1801350 [05:41<01:13, 4279.32 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1478000/1801350 [05:41<01:15, 4258.25 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1473000/1801350 [05:41<01:17, 4236.06 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1486000/1801350 [05:41<01:11, 4401.11 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1478000/1801350 [05:42<01:17, 4161.12 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1479000/1801350 [05:41<01:19, 4072.78 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1474000/1801350 [05:41<01:17, 4242.83 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1487000/1801350 [05:41<01:12, 4335.64 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1479000/1801350 [05:42<01:17, 4174.84 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1480000/1801350 [05:41<01:17, 4149.84 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1475000/1801350 [05:42<01:16, 4258.73 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1488000/1801350 [05:42<01:10, 4456.33 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1480000/1801350 [05:42<01:18, 4090.52 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1481000/1801350 [05:42<01:15, 4248.84 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1476000/1801350 [05:42<01:14, 4374.44 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1489000/1801350 [05:42<01:10, 4437.38 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1481000/1801350 [05:42<01:17, 4143.28 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1482000/1801350 [05:42<01:14, 4281.15 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1477000/1801350 [05:42<01:14, 4354.65 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1490000/1801350 [05:42<01:10, 4434.51 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1482000/1801350 [05:43<01:16, 4180.90 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1483000/1801350 [05:42<01:13, 4334.30 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1491000/1801350 [05:42<01:09, 4474.72 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1478000/1801350 [05:42<01:16, 4213.29 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1483000/1801350 [05:43<01:15, 4190.03 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1484000/1801350 [05:42<01:15, 4186.53 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1492000/1801350 [05:42<01:11, 4352.47 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1479000/1801350 [05:43<01:18, 4093.30 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1484000/1801350 [05:43<01:15, 4189.19 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1485000/1801350 [05:43<01:12, 4349.30 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1493000/1801350 [05:43<01:10, 4380.67 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1480000/1801350 [05:43<01:18, 4088.01 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1485000/1801350 [05:43<01:13, 4295.78 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1486000/1801350 [05:43<01:13, 4266.65 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1494000/1801350 [05:43<01:06, 4603.03 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1481000/1801350 [05:43<01:16, 4165.60 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1486000/1801350 [05:44<01:14, 4231.59 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1487000/1801350 [05:43<01:11, 4381.62 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1495000/1801350 [05:43<01:07, 4523.15 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1482000/1801350 [05:43<01:15, 4253.28 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1487000/1801350 [05:44<01:14, 4244.09 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1488000/1801350 [05:43<01:11, 4390.07 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1496000/1801350 [05:43<01:06, 4617.15 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1483000/1801350 [05:43<01:15, 4199.24 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1488000/1801350 [05:44<01:10, 4459.48 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1489000/1801350 [05:44<01:12, 4309.33 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1497000/1801350 [05:44<01:06, 4585.38 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1484000/1801350 [05:44<01:15, 4202.18 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1489000/1801350 [05:44<01:12, 4314.09 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1490000/1801350 [05:44<01:10, 4411.18 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1498000/1801350 [05:44<01:08, 4422.58 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1485000/1801350 [05:44<01:13, 4313.85 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1490000/1801350 [05:45<01:09, 4476.04 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1491000/1801350 [05:44<01:10, 4398.88 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1499000/1801350 [05:44<01:06, 4578.22 examples/s]Grouping texts in chunks of 1024:  82%|████████▏ | 1486000/1801350 [05:44<01:13, 4291.36 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1491000/1801350 [05:45<01:11, 4355.78 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1492000/1801350 [05:44<01:09, 4444.69 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1500000/1801350 [05:44<01:04, 4663.51 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1487000/1801350 [05:44<01:12, 4312.59 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1501000/1801350 [05:44<01:03, 4731.61 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1492000/1801350 [05:45<01:12, 4287.70 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1493000/1801350 [05:44<01:10, 4356.53 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1488000/1801350 [05:45<01:10, 4435.71 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1494000/1801350 [05:45<01:06, 4640.64 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1493000/1801350 [05:45<01:11, 4336.33 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1502000/1801350 [05:45<01:07, 4427.20 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1494000/1801350 [05:45<01:05, 4672.18 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1489000/1801350 [05:45<01:13, 4254.58 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1495000/1801350 [05:45<01:06, 4638.77 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1503000/1801350 [05:45<01:06, 4490.98 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1490000/1801350 [05:45<01:10, 4398.69 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1496000/1801350 [05:45<01:06, 4609.05 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1495000/1801350 [05:46<01:07, 4521.79 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1504000/1801350 [05:45<01:04, 4590.69 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1491000/1801350 [05:45<01:10, 4407.56 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1496000/1801350 [05:46<01:07, 4522.23 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1497000/1801350 [05:45<01:07, 4496.50 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1505000/1801350 [05:45<01:06, 4485.31 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1492000/1801350 [05:45<01:10, 4385.65 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1497000/1801350 [05:46<01:07, 4510.79 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1498000/1801350 [05:46<01:07, 4502.93 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1506000/1801350 [05:46<01:08, 4334.19 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1499000/1801350 [05:46<01:05, 4588.17 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1493000/1801350 [05:46<01:10, 4362.88 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1498000/1801350 [05:46<01:08, 4442.02 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1507000/1801350 [05:46<01:07, 4333.63 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1500000/1801350 [05:46<01:04, 4701.06 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1494000/1801350 [05:46<01:07, 4559.90 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1499000/1801350 [05:47<01:07, 4451.18 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1508000/1801350 [05:46<01:09, 4193.37 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1501000/1801350 [05:46<01:05, 4604.45 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1495000/1801350 [05:46<01:08, 4503.61 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1500000/1801350 [05:47<01:06, 4560.50 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1509000/1801350 [05:46<01:05, 4430.55 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1501000/1801350 [05:47<01:03, 4694.75 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1496000/1801350 [05:46<01:07, 4553.67 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1502000/1801350 [05:46<01:06, 4480.36 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1510000/1801350 [05:47<01:07, 4341.81 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1497000/1801350 [05:47<01:07, 4540.38 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1502000/1801350 [05:47<01:06, 4533.03 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1503000/1801350 [05:47<01:07, 4420.71 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1511000/1801350 [05:47<01:06, 4387.46 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1504000/1801350 [05:47<01:05, 4574.35 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1498000/1801350 [05:47<01:08, 4439.64 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1503000/1801350 [05:47<01:07, 4445.56 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1512000/1801350 [05:47<01:06, 4358.43 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1499000/1801350 [05:47<01:06, 4532.31 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1504000/1801350 [05:48<01:05, 4511.62 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1505000/1801350 [05:47<01:07, 4412.06 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1513000/1801350 [05:47<01:05, 4393.90 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1500000/1801350 [05:47<01:05, 4570.80 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1505000/1801350 [05:48<01:07, 4374.02 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1506000/1801350 [05:47<01:07, 4366.54 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1514000/1801350 [05:47<01:03, 4524.19 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1501000/1801350 [05:47<01:05, 4565.37 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1506000/1801350 [05:48<01:08, 4319.43 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1507000/1801350 [05:48<01:08, 4281.35 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1515000/1801350 [05:48<01:06, 4303.39 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1502000/1801350 [05:48<01:06, 4495.31 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1508000/1801350 [05:48<01:09, 4246.24 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1507000/1801350 [05:48<01:10, 4190.49 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1516000/1801350 [05:48<01:03, 4490.36 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1503000/1801350 [05:48<01:07, 4418.18 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1509000/1801350 [05:48<01:06, 4367.86 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1517000/1801350 [05:48<01:01, 4654.93 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1508000/1801350 [05:49<01:11, 4128.98 examples/s]Grouping texts in chunks of 1024:  83%|████████▎ | 1504000/1801350 [05:48<01:05, 4532.18 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1510000/1801350 [05:48<01:07, 4315.89 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1509000/1801350 [05:49<01:07, 4337.26 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1518000/1801350 [05:48<01:03, 4469.65 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1505000/1801350 [05:48<01:07, 4366.59 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1511000/1801350 [05:48<01:05, 4437.82 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1510000/1801350 [05:49<01:08, 4279.44 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1519000/1801350 [05:49<01:05, 4290.57 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1506000/1801350 [05:49<01:06, 4457.03 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1512000/1801350 [05:49<01:07, 4305.89 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1511000/1801350 [05:49<01:06, 4377.21 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1520000/1801350 [05:49<01:07, 4164.43 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1507000/1801350 [05:49<01:10, 4152.73 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1513000/1801350 [05:49<01:07, 4263.87 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1512000/1801350 [05:50<01:08, 4223.38 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1521000/1801350 [05:49<01:03, 4437.97 examples/s]Grouping texts in chunks of 1024:  84%|████████▎ | 1508000/1801350 [05:49<01:10, 4179.33 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1514000/1801350 [05:49<01:03, 4518.11 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1513000/1801350 [05:50<01:07, 4263.86 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1522000/1801350 [05:49<01:04, 4351.32 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1509000/1801350 [05:49<01:06, 4417.04 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1514000/1801350 [05:50<01:02, 4565.43 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1515000/1801350 [05:49<01:07, 4265.38 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1523000/1801350 [05:49<01:03, 4386.92 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1510000/1801350 [05:50<01:07, 4291.93 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1516000/1801350 [05:50<01:05, 4365.69 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1515000/1801350 [05:50<01:07, 4237.52 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1524000/1801350 [05:50<01:02, 4462.85 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1517000/1801350 [05:50<01:00, 4696.31 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1511000/1801350 [05:50<01:07, 4329.73 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1516000/1801350 [05:50<01:05, 4356.83 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1525000/1801350 [05:50<01:04, 4306.60 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1512000/1801350 [05:50<01:07, 4265.44 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1518000/1801350 [05:50<01:03, 4438.52 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1517000/1801350 [05:51<01:02, 4551.80 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1526000/1801350 [05:50<01:05, 4208.77 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1513000/1801350 [05:50<01:06, 4329.42 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1519000/1801350 [05:50<01:06, 4277.08 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1518000/1801350 [05:51<01:04, 4414.53 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1527000/1801350 [05:50<01:05, 4219.62 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1514000/1801350 [05:50<01:03, 4512.99 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1520000/1801350 [05:51<01:06, 4255.78 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1519000/1801350 [05:51<01:05, 4324.91 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1528000/1801350 [05:51<01:06, 4137.30 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1515000/1801350 [05:51<01:07, 4239.84 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1521000/1801350 [05:51<01:04, 4352.91 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1520000/1801350 [05:51<01:09, 4074.67 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1529000/1801350 [05:51<01:06, 4073.81 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1516000/1801350 [05:51<01:04, 4432.01 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1522000/1801350 [05:51<01:04, 4350.41 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1521000/1801350 [05:52<01:05, 4284.97 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1517000/1801350 [05:51<01:01, 4622.53 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1530000/1801350 [05:51<01:07, 4024.74 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1523000/1801350 [05:51<01:03, 4410.44 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1522000/1801350 [05:52<01:04, 4335.12 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1518000/1801350 [05:51<01:04, 4396.90 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1531000/1801350 [05:51<01:07, 4028.73 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1524000/1801350 [05:51<01:02, 4413.33 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1523000/1801350 [05:52<01:03, 4383.84 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1532000/1801350 [05:52<01:02, 4320.22 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1519000/1801350 [05:52<01:05, 4335.97 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1525000/1801350 [05:52<01:04, 4257.94 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1524000/1801350 [05:52<01:03, 4395.23 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1533000/1801350 [05:52<01:01, 4354.75 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1520000/1801350 [05:52<01:08, 4087.82 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1526000/1801350 [05:52<01:05, 4178.19 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1525000/1801350 [05:53<01:06, 4179.69 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1534000/1801350 [05:52<00:59, 4499.20 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1521000/1801350 [05:52<01:03, 4404.01 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1527000/1801350 [05:52<01:06, 4153.08 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1526000/1801350 [05:53<01:06, 4139.13 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1535000/1801350 [05:52<00:59, 4458.12 examples/s]Grouping texts in chunks of 1024:  84%|████████▍ | 1522000/1801350 [05:52<01:05, 4251.80 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1527000/1801350 [05:53<01:06, 4153.07 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1536000/1801350 [05:52<00:59, 4423.49 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1523000/1801350 [05:53<01:02, 4440.51 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1528000/1801350 [05:53<01:17, 3512.16 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1528000/1801350 [05:53<01:04, 4252.36 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1537000/1801350 [05:53<00:57, 4559.83 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1524000/1801350 [05:53<01:01, 4480.54 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1529000/1801350 [05:53<01:10, 3853.06 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1538000/1801350 [05:53<00:57, 4579.66 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1529000/1801350 [05:54<01:05, 4140.65 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1525000/1801350 [05:53<01:03, 4324.09 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1530000/1801350 [05:53<01:09, 3891.93 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1539000/1801350 [05:53<00:57, 4546.49 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1530000/1801350 [05:54<01:06, 4078.18 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1526000/1801350 [05:53<01:05, 4193.70 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1531000/1801350 [05:53<01:09, 3912.89 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1540000/1801350 [05:53<00:59, 4398.86 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1531000/1801350 [05:54<01:04, 4166.14 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1532000/1801350 [05:53<01:04, 4152.26 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1527000/1801350 [05:54<01:06, 4138.35 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1541000/1801350 [05:54<00:57, 4551.57 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1532000/1801350 [05:54<01:02, 4284.36 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1533000/1801350 [05:54<01:01, 4330.14 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1528000/1801350 [05:54<01:05, 4148.13 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1542000/1801350 [05:54<00:54, 4757.99 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1533000/1801350 [05:54<01:00, 4419.53 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1534000/1801350 [05:54<01:01, 4379.25 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1529000/1801350 [05:54<01:06, 4099.47 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1543000/1801350 [05:54<00:55, 4623.09 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1534000/1801350 [05:55<01:00, 4416.22 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1535000/1801350 [05:54<00:59, 4477.33 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1544000/1801350 [05:54<00:54, 4705.40 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1530000/1801350 [05:54<01:07, 4045.77 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1535000/1801350 [05:55<01:00, 4420.07 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1536000/1801350 [05:54<00:59, 4486.82 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1545000/1801350 [05:54<00:51, 5025.70 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1536000/1801350 [05:55<00:57, 4593.51 examples/s]Grouping texts in chunks of 1024:  85%|████████▍ | 1531000/1801350 [05:54<01:06, 4067.44 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1537000/1801350 [05:55<00:59, 4423.40 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1546000/1801350 [05:55<00:51, 4952.14 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1532000/1801350 [05:55<01:03, 4263.92 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1537000/1801350 [05:55<00:59, 4419.97 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1547000/1801350 [05:55<00:51, 4942.33 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1538000/1801350 [05:55<00:58, 4473.26 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1533000/1801350 [05:55<01:01, 4397.01 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1538000/1801350 [05:56<00:59, 4440.23 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1539000/1801350 [05:55<00:59, 4379.45 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1548000/1801350 [05:55<00:56, 4462.42 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1534000/1801350 [05:55<01:00, 4383.89 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1539000/1801350 [05:56<01:00, 4366.13 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1540000/1801350 [05:55<01:00, 4328.41 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1549000/1801350 [05:55<00:56, 4446.91 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1535000/1801350 [05:55<00:58, 4565.98 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1540000/1801350 [05:56<01:00, 4309.27 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1541000/1801350 [05:55<00:56, 4587.33 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1550000/1801350 [05:55<00:54, 4593.62 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1536000/1801350 [05:56<00:59, 4433.82 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1541000/1801350 [05:56<00:58, 4457.51 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1542000/1801350 [05:56<00:56, 4614.66 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1551000/1801350 [05:56<00:52, 4769.23 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1537000/1801350 [05:56<00:58, 4501.11 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1542000/1801350 [05:56<00:56, 4592.51 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1543000/1801350 [05:56<00:56, 4557.14 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1552000/1801350 [05:56<00:53, 4693.53 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1538000/1801350 [05:56<00:59, 4462.40 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1543000/1801350 [05:57<00:56, 4534.44 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1553000/1801350 [05:56<00:51, 4795.47 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1544000/1801350 [05:56<00:55, 4608.73 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1539000/1801350 [05:56<00:59, 4427.37 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1545000/1801350 [05:56<00:51, 5001.06 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1544000/1801350 [05:57<00:55, 4642.06 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1554000/1801350 [05:56<00:53, 4616.00 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1545000/1801350 [05:57<00:51, 4988.39 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1546000/1801350 [05:56<00:52, 4889.44 examples/s]Grouping texts in chunks of 1024:  85%|████████▌ | 1540000/1801350 [05:57<01:01, 4266.88 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1555000/1801350 [05:57<00:51, 4806.50 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1546000/1801350 [05:57<00:53, 4796.76 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1547000/1801350 [05:57<00:51, 4901.38 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1541000/1801350 [05:57<00:57, 4525.51 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1556000/1801350 [05:57<00:50, 4854.87 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1547000/1801350 [05:57<00:53, 4756.78 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1542000/1801350 [05:57<00:56, 4605.53 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1557000/1801350 [05:57<00:50, 4865.80 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1548000/1801350 [05:57<00:55, 4564.65 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1548000/1801350 [05:58<00:55, 4526.26 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1543000/1801350 [05:57<00:57, 4508.86 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1549000/1801350 [05:57<00:56, 4455.90 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1558000/1801350 [05:57<00:57, 4244.46 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1544000/1801350 [05:57<00:55, 4627.15 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1549000/1801350 [05:58<00:57, 4412.54 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1550000/1801350 [05:57<00:55, 4515.26 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1559000/1801350 [05:57<00:54, 4423.89 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1545000/1801350 [05:57<00:50, 5104.20 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1551000/1801350 [05:58<00:52, 4726.82 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1550000/1801350 [05:58<00:56, 4444.97 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1560000/1801350 [05:58<00:57, 4227.21 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1546000/1801350 [05:58<00:52, 4872.07 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1551000/1801350 [05:58<00:53, 4714.56 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1552000/1801350 [05:58<00:53, 4659.82 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1547000/1801350 [05:58<00:52, 4887.26 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1561000/1801350 [05:58<00:56, 4265.07 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1552000/1801350 [05:59<00:52, 4744.00 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1553000/1801350 [05:58<00:52, 4716.75 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1562000/1801350 [05:58<00:55, 4312.99 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1548000/1801350 [05:58<00:57, 4425.19 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1553000/1801350 [05:59<00:53, 4615.15 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1554000/1801350 [05:58<00:53, 4646.19 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1563000/1801350 [05:58<00:54, 4359.18 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1555000/1801350 [05:58<00:51, 4801.53 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1549000/1801350 [05:58<00:56, 4441.07 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1554000/1801350 [05:59<00:54, 4572.85 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1556000/1801350 [05:59<00:50, 4881.75 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1555000/1801350 [05:59<00:51, 4810.86 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1564000/1801350 [05:59<00:55, 4256.68 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1550000/1801350 [05:59<00:56, 4427.53 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1551000/1801350 [05:59<00:52, 4783.43 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1565000/1801350 [05:59<00:53, 4456.45 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1556000/1801350 [05:59<00:51, 4776.11 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1557000/1801350 [05:59<00:51, 4753.64 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1557000/1801350 [06:00<00:51, 4747.93 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1566000/1801350 [05:59<00:53, 4408.24 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1552000/1801350 [05:59<00:54, 4592.32 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1558000/1801350 [05:59<00:57, 4267.04 examples/s]Grouping texts in chunks of 1024:  86%|████████▌ | 1553000/1801350 [05:59<00:52, 4745.36 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1567000/1801350 [05:59<00:51, 4536.08 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1558000/1801350 [06:00<00:57, 4222.45 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1559000/1801350 [05:59<00:55, 4338.13 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1554000/1801350 [05:59<00:53, 4585.21 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1568000/1801350 [06:00<00:52, 4429.96 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1559000/1801350 [06:00<00:55, 4391.96 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1560000/1801350 [06:00<00:57, 4207.90 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1555000/1801350 [06:00<00:51, 4793.45 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1569000/1801350 [06:00<00:49, 4662.73 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1560000/1801350 [06:00<00:58, 4148.14 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1561000/1801350 [06:00<00:56, 4260.36 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1556000/1801350 [06:00<00:50, 4880.84 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1570000/1801350 [06:00<00:49, 4647.44 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1562000/1801350 [06:00<00:55, 4316.04 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1561000/1801350 [06:01<00:58, 4132.16 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1557000/1801350 [06:00<00:52, 4686.42 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1571000/1801350 [06:00<00:51, 4478.22 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1563000/1801350 [06:00<00:55, 4299.56 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1562000/1801350 [06:01<00:57, 4171.84 examples/s]Grouping texts in chunks of 1024:  86%|████████▋ | 1558000/1801350 [06:00<00:55, 4349.32 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1572000/1801350 [06:00<00:52, 4396.15 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1563000/1801350 [06:01<00:55, 4260.26 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1564000/1801350 [06:01<00:56, 4233.87 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1559000/1801350 [06:01<00:55, 4345.94 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1573000/1801350 [06:01<00:52, 4349.45 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1565000/1801350 [06:01<00:52, 4501.78 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1564000/1801350 [06:01<00:56, 4209.93 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1574000/1801350 [06:01<00:51, 4374.05 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1560000/1801350 [06:01<00:57, 4186.47 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1565000/1801350 [06:02<00:53, 4400.85 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1566000/1801350 [06:01<00:54, 4300.23 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1575000/1801350 [06:01<00:50, 4526.30 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1561000/1801350 [06:01<00:56, 4251.81 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1567000/1801350 [06:01<00:52, 4488.14 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1566000/1801350 [06:02<00:55, 4248.36 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1576000/1801350 [06:01<00:50, 4469.75 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1562000/1801350 [06:01<00:57, 4183.90 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1568000/1801350 [06:01<00:51, 4527.84 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1567000/1801350 [06:02<00:52, 4422.42 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1577000/1801350 [06:02<00:51, 4393.63 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1563000/1801350 [06:02<00:55, 4277.84 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1569000/1801350 [06:02<00:49, 4731.89 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1568000/1801350 [06:02<00:51, 4570.57 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1578000/1801350 [06:02<00:51, 4334.13 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1564000/1801350 [06:02<00:54, 4322.38 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1570000/1801350 [06:02<00:50, 4577.70 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1569000/1801350 [06:02<00:49, 4673.51 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1579000/1801350 [06:02<00:50, 4434.04 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1565000/1801350 [06:02<00:52, 4477.59 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1571000/1801350 [06:02<00:51, 4473.62 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1570000/1801350 [06:03<00:50, 4555.21 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1580000/1801350 [06:02<00:51, 4327.77 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1566000/1801350 [06:02<00:55, 4277.73 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1572000/1801350 [06:02<00:51, 4447.98 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1571000/1801350 [06:03<00:52, 4389.20 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1581000/1801350 [06:02<00:49, 4432.21 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1567000/1801350 [06:02<00:52, 4502.19 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1573000/1801350 [06:03<00:52, 4322.59 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1572000/1801350 [06:03<00:53, 4279.26 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1568000/1801350 [06:03<00:51, 4528.88 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1582000/1801350 [06:03<00:50, 4347.92 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1574000/1801350 [06:03<00:52, 4359.66 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1573000/1801350 [06:03<00:53, 4273.80 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1569000/1801350 [06:03<00:49, 4664.51 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1583000/1801350 [06:03<00:50, 4310.97 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1575000/1801350 [06:03<00:49, 4536.32 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1574000/1801350 [06:04<00:53, 4266.86 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1570000/1801350 [06:03<00:49, 4653.73 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1584000/1801350 [06:03<00:50, 4296.76 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1576000/1801350 [06:03<00:51, 4372.43 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1575000/1801350 [06:04<00:50, 4485.71 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1571000/1801350 [06:03<00:51, 4432.61 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1585000/1801350 [06:03<00:49, 4374.40 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1577000/1801350 [06:03<00:50, 4449.40 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1576000/1801350 [06:04<00:50, 4436.56 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1586000/1801350 [06:04<00:46, 4582.25 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1572000/1801350 [06:04<00:54, 4239.83 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1578000/1801350 [06:04<00:50, 4393.40 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1577000/1801350 [06:04<00:50, 4412.57 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1587000/1801350 [06:04<00:47, 4492.80 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1573000/1801350 [06:04<00:54, 4228.54 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1579000/1801350 [06:04<00:51, 4289.94 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1578000/1801350 [06:05<00:52, 4251.28 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1588000/1801350 [06:04<00:47, 4511.46 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1574000/1801350 [06:04<00:52, 4335.28 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1580000/1801350 [06:04<00:51, 4314.95 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1579000/1801350 [06:05<00:51, 4287.93 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1589000/1801350 [06:04<00:46, 4602.59 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1575000/1801350 [06:04<00:50, 4513.03 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1581000/1801350 [06:04<00:49, 4446.22 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1580000/1801350 [06:05<00:51, 4311.96 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1590000/1801350 [06:04<00:47, 4406.86 examples/s]Grouping texts in chunks of 1024:  87%|████████▋ | 1576000/1801350 [06:04<00:50, 4431.90 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1582000/1801350 [06:05<00:50, 4330.43 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1581000/1801350 [06:05<00:50, 4380.15 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1591000/1801350 [06:05<00:47, 4474.35 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1577000/1801350 [06:05<00:51, 4358.59 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1583000/1801350 [06:05<00:51, 4230.98 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1582000/1801350 [06:05<00:50, 4380.14 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1592000/1801350 [06:05<00:45, 4595.56 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1578000/1801350 [06:05<00:51, 4322.38 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1584000/1801350 [06:05<00:50, 4330.69 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1583000/1801350 [06:06<00:52, 4167.31 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1593000/1801350 [06:05<00:48, 4286.18 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1579000/1801350 [06:05<00:50, 4378.57 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1585000/1801350 [06:05<00:49, 4406.73 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1584000/1801350 [06:06<00:51, 4250.21 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1594000/1801350 [06:05<00:46, 4443.96 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1580000/1801350 [06:05<00:51, 4264.09 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1586000/1801350 [06:05<00:47, 4559.42 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1585000/1801350 [06:06<00:49, 4382.28 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1595000/1801350 [06:06<00:45, 4501.02 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1581000/1801350 [06:06<00:49, 4439.79 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1587000/1801350 [06:06<00:48, 4455.35 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1586000/1801350 [06:06<00:46, 4590.26 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1596000/1801350 [06:06<00:43, 4678.14 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1582000/1801350 [06:06<00:51, 4297.30 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1588000/1801350 [06:06<00:48, 4423.56 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1587000/1801350 [06:07<00:48, 4392.98 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1597000/1801350 [06:06<00:46, 4421.88 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1583000/1801350 [06:06<00:51, 4227.93 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1589000/1801350 [06:06<00:45, 4634.10 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1588000/1801350 [06:07<00:48, 4391.22 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1598000/1801350 [06:06<00:46, 4387.79 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1584000/1801350 [06:06<00:50, 4278.69 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1590000/1801350 [06:06<00:48, 4356.51 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1589000/1801350 [06:07<00:47, 4464.23 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1599000/1801350 [06:06<00:45, 4418.53 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1585000/1801350 [06:07<00:49, 4375.78 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1591000/1801350 [06:07<00:47, 4398.85 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1600000/1801350 [06:07<00:44, 4543.26 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1590000/1801350 [06:07<00:48, 4336.10 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1586000/1801350 [06:07<00:48, 4473.30 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1592000/1801350 [06:07<00:47, 4409.10 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1591000/1801350 [06:07<00:47, 4392.40 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1601000/1801350 [06:07<00:44, 4470.27 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1587000/1801350 [06:07<00:49, 4357.75 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1593000/1801350 [06:07<00:48, 4265.89 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1602000/1801350 [06:07<00:44, 4515.83 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1592000/1801350 [06:08<00:47, 4364.00 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1588000/1801350 [06:07<00:47, 4450.33 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1594000/1801350 [06:07<00:46, 4421.91 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1603000/1801350 [06:07<00:45, 4350.76 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1593000/1801350 [06:08<00:49, 4238.82 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1589000/1801350 [06:07<00:46, 4552.96 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1595000/1801350 [06:08<00:45, 4498.30 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1604000/1801350 [06:08<00:42, 4678.80 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1594000/1801350 [06:08<00:46, 4428.27 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1590000/1801350 [06:08<00:48, 4369.06 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1596000/1801350 [06:08<00:44, 4638.45 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1605000/1801350 [06:08<00:44, 4441.09 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1595000/1801350 [06:08<00:47, 4332.57 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1591000/1801350 [06:08<00:47, 4434.71 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1597000/1801350 [06:08<00:46, 4411.72 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1596000/1801350 [06:09<00:45, 4498.52 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1606000/1801350 [06:08<00:47, 4080.62 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1592000/1801350 [06:08<00:47, 4391.24 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1598000/1801350 [06:08<00:46, 4354.34 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1597000/1801350 [06:09<00:46, 4437.08 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1607000/1801350 [06:08<00:46, 4162.98 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1593000/1801350 [06:08<00:49, 4197.71 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1599000/1801350 [06:08<00:46, 4398.27 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1598000/1801350 [06:09<00:46, 4351.97 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1608000/1801350 [06:09<00:44, 4343.60 examples/s]Grouping texts in chunks of 1024:  88%|████████▊ | 1594000/1801350 [06:09<00:47, 4395.76 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1600000/1801350 [06:09<00:44, 4562.06 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1609000/1801350 [06:09<00:43, 4406.86 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1599000/1801350 [06:09<00:47, 4240.88 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1595000/1801350 [06:09<00:45, 4492.46 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1601000/1801350 [06:09<00:43, 4554.53 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1600000/1801350 [06:10<00:45, 4431.27 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1610000/1801350 [06:09<00:43, 4360.61 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1596000/1801350 [06:09<00:45, 4536.96 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1602000/1801350 [06:09<00:43, 4601.63 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1601000/1801350 [06:10<00:43, 4555.74 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1611000/1801350 [06:09<00:44, 4281.46 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1597000/1801350 [06:09<00:45, 4456.46 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1603000/1801350 [06:09<00:44, 4413.94 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1602000/1801350 [06:10<00:44, 4514.49 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1612000/1801350 [06:09<00:43, 4374.77 examples/s]Grouping texts in chunks of 1024:  89%|████████▊ | 1598000/1801350 [06:09<00:45, 4422.18 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1604000/1801350 [06:10<00:43, 4509.82 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1603000/1801350 [06:10<00:45, 4322.26 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1613000/1801350 [06:10<00:42, 4393.60 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1605000/1801350 [06:10<00:44, 4451.23 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1599000/1801350 [06:10<00:47, 4290.03 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1604000/1801350 [06:10<00:43, 4530.45 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1614000/1801350 [06:10<00:43, 4329.36 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1600000/1801350 [06:10<00:44, 4567.28 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1606000/1801350 [06:10<00:48, 4031.91 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1605000/1801350 [06:11<00:44, 4459.75 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1601000/1801350 [06:10<00:44, 4549.35 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1615000/1801350 [06:10<00:45, 4051.47 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1607000/1801350 [06:10<00:45, 4225.15 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1602000/1801350 [06:10<00:44, 4504.46 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1606000/1801350 [06:11<00:49, 3976.76 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1616000/1801350 [06:10<00:45, 4043.15 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1608000/1801350 [06:10<00:43, 4404.43 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1607000/1801350 [06:11<00:46, 4168.72 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1603000/1801350 [06:11<00:44, 4412.63 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1609000/1801350 [06:11<00:44, 4339.15 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1617000/1801350 [06:11<00:46, 3962.15 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1608000/1801350 [06:11<00:44, 4345.83 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1604000/1801350 [06:11<00:43, 4498.43 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1610000/1801350 [06:11<00:44, 4346.75 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1618000/1801350 [06:11<00:45, 4065.76 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1609000/1801350 [06:12<00:44, 4369.23 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1605000/1801350 [06:11<00:44, 4415.33 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1619000/1801350 [06:11<00:42, 4287.09 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1611000/1801350 [06:11<00:44, 4265.53 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1610000/1801350 [06:12<00:44, 4286.99 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1620000/1801350 [06:11<00:38, 4690.78 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1606000/1801350 [06:11<00:47, 4091.72 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1612000/1801350 [06:11<00:43, 4339.70 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1611000/1801350 [06:12<00:45, 4210.69 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1621000/1801350 [06:12<00:39, 4550.09 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1607000/1801350 [06:12<00:46, 4175.43 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1613000/1801350 [06:12<00:41, 4488.88 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1622000/1801350 [06:12<00:38, 4665.10 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1612000/1801350 [06:12<00:43, 4308.41 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1608000/1801350 [06:12<00:44, 4311.86 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1614000/1801350 [06:12<00:43, 4351.79 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1613000/1801350 [06:13<00:42, 4418.59 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1623000/1801350 [06:12<00:40, 4436.69 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1609000/1801350 [06:12<00:44, 4314.40 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1615000/1801350 [06:12<00:45, 4074.65 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1614000/1801350 [06:13<00:43, 4259.63 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1624000/1801350 [06:12<00:40, 4408.23 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1610000/1801350 [06:12<00:43, 4365.98 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1616000/1801350 [06:12<00:45, 4089.15 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1625000/1801350 [06:12<00:39, 4514.94 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1611000/1801350 [06:12<00:44, 4262.34 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1615000/1801350 [06:13<00:46, 3995.28 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1617000/1801350 [06:13<00:46, 3987.67 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1626000/1801350 [06:13<00:41, 4187.24 examples/s]Grouping texts in chunks of 1024:  89%|████████▉ | 1612000/1801350 [06:13<00:43, 4340.43 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1616000/1801350 [06:13<00:45, 4071.78 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1618000/1801350 [06:13<00:45, 4019.01 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1627000/1801350 [06:13<00:38, 4525.67 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1613000/1801350 [06:13<00:42, 4393.35 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1617000/1801350 [06:14<00:46, 4005.96 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1619000/1801350 [06:13<00:43, 4170.98 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1628000/1801350 [06:13<00:38, 4492.93 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1614000/1801350 [06:13<00:43, 4329.99 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1618000/1801350 [06:14<00:45, 4000.24 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1620000/1801350 [06:13<00:39, 4583.20 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1629000/1801350 [06:13<00:40, 4231.10 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1615000/1801350 [06:13<00:45, 4085.12 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1619000/1801350 [06:14<00:44, 4112.09 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1621000/1801350 [06:14<00:39, 4549.37 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1630000/1801350 [06:14<00:38, 4403.38 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1620000/1801350 [06:14<00:39, 4552.53 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1622000/1801350 [06:14<00:38, 4700.73 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1616000/1801350 [06:14<00:46, 4010.91 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1621000/1801350 [06:14<00:39, 4624.28 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1631000/1801350 [06:14<00:40, 4185.55 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1623000/1801350 [06:14<00:41, 4336.45 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1617000/1801350 [06:14<00:46, 3951.67 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1622000/1801350 [06:15<00:38, 4676.26 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1632000/1801350 [06:14<00:39, 4290.13 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1624000/1801350 [06:14<00:41, 4322.39 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1618000/1801350 [06:14<00:45, 4027.09 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1623000/1801350 [06:15<00:40, 4373.42 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1633000/1801350 [06:14<00:40, 4193.48 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1625000/1801350 [06:14<00:39, 4418.57 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1619000/1801350 [06:14<00:44, 4140.48 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1624000/1801350 [06:15<00:40, 4393.58 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1634000/1801350 [06:15<00:38, 4297.92 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1620000/1801350 [06:15<00:40, 4533.11 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1626000/1801350 [06:15<00:40, 4298.56 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1635000/1801350 [06:15<00:37, 4460.95 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1625000/1801350 [06:15<00:40, 4363.67 examples/s]Grouping texts in chunks of 1024:  90%|████████▉ | 1621000/1801350 [06:15<00:39, 4546.78 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1627000/1801350 [06:15<00:38, 4514.74 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1636000/1801350 [06:15<00:36, 4537.70 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1622000/1801350 [06:15<00:38, 4695.14 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1626000/1801350 [06:16<00:42, 4137.70 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1628000/1801350 [06:15<00:38, 4537.91 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1637000/1801350 [06:15<00:35, 4662.98 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1627000/1801350 [06:16<00:39, 4423.51 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1623000/1801350 [06:15<00:39, 4469.84 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1629000/1801350 [06:15<00:40, 4306.67 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1638000/1801350 [06:15<00:34, 4695.70 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1628000/1801350 [06:16<00:39, 4434.83 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1624000/1801350 [06:16<00:40, 4394.78 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1630000/1801350 [06:16<00:39, 4370.89 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1639000/1801350 [06:16<00:36, 4506.73 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1629000/1801350 [06:16<00:40, 4276.18 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1625000/1801350 [06:16<00:40, 4395.94 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1631000/1801350 [06:16<00:41, 4145.41 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1640000/1801350 [06:16<00:36, 4394.84 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1630000/1801350 [06:17<00:39, 4326.04 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1626000/1801350 [06:16<00:42, 4142.68 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1632000/1801350 [06:16<00:39, 4241.44 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1641000/1801350 [06:16<00:37, 4312.50 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1627000/1801350 [06:16<00:39, 4462.00 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1631000/1801350 [06:17<00:41, 4138.41 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1633000/1801350 [06:16<00:40, 4170.29 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1642000/1801350 [06:16<00:36, 4328.69 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1628000/1801350 [06:16<00:39, 4430.98 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1632000/1801350 [06:17<00:40, 4152.84 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1634000/1801350 [06:17<00:39, 4243.87 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1643000/1801350 [06:17<00:39, 3997.29 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1633000/1801350 [06:17<00:40, 4201.86 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1629000/1801350 [06:17<00:40, 4278.17 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1635000/1801350 [06:17<00:37, 4377.72 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1644000/1801350 [06:17<00:39, 4009.27 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1634000/1801350 [06:17<00:39, 4283.87 examples/s]Grouping texts in chunks of 1024:  90%|█████████ | 1630000/1801350 [06:17<00:39, 4296.51 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1636000/1801350 [06:17<00:37, 4447.88 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1645000/1801350 [06:17<00:37, 4222.70 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1635000/1801350 [06:18<00:38, 4323.79 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1637000/1801350 [06:17<00:35, 4602.81 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1631000/1801350 [06:17<00:40, 4192.81 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1646000/1801350 [06:17<00:35, 4342.79 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1636000/1801350 [06:18<00:37, 4417.51 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1638000/1801350 [06:17<00:35, 4658.82 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1632000/1801350 [06:17<00:39, 4236.70 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1637000/1801350 [06:18<00:35, 4570.40 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1647000/1801350 [06:18<00:36, 4214.22 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1639000/1801350 [06:18<00:36, 4440.53 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1633000/1801350 [06:18<00:40, 4144.47 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1648000/1801350 [06:18<00:35, 4368.68 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1638000/1801350 [06:18<00:36, 4522.75 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1640000/1801350 [06:18<00:36, 4475.57 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1634000/1801350 [06:18<00:39, 4274.24 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1649000/1801350 [06:18<00:34, 4438.03 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1639000/1801350 [06:19<00:37, 4337.52 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1635000/1801350 [06:18<00:37, 4420.06 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1641000/1801350 [06:18<00:37, 4290.91 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1650000/1801350 [06:18<00:35, 4219.20 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1640000/1801350 [06:19<00:37, 4330.17 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1636000/1801350 [06:18<00:36, 4476.74 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1642000/1801350 [06:18<00:36, 4313.81 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1651000/1801350 [06:18<00:36, 4141.96 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1641000/1801350 [06:19<00:38, 4216.97 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1637000/1801350 [06:19<00:36, 4463.02 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1643000/1801350 [06:19<00:38, 4096.34 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1652000/1801350 [06:19<00:34, 4340.15 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1638000/1801350 [06:19<00:35, 4627.18 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1642000/1801350 [06:19<00:37, 4293.77 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1644000/1801350 [06:19<00:38, 4050.19 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1653000/1801350 [06:19<00:32, 4548.84 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1639000/1801350 [06:19<00:37, 4361.36 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1643000/1801350 [06:20<00:39, 3986.20 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1645000/1801350 [06:19<00:36, 4271.54 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1654000/1801350 [06:19<00:34, 4265.05 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1640000/1801350 [06:19<00:36, 4396.56 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1644000/1801350 [06:20<00:38, 4051.67 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1646000/1801350 [06:19<00:36, 4300.69 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1655000/1801350 [06:19<00:34, 4213.23 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1641000/1801350 [06:19<00:37, 4249.96 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1645000/1801350 [06:20<00:36, 4297.92 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1647000/1801350 [06:20<00:36, 4287.20 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1656000/1801350 [06:20<00:33, 4394.22 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1642000/1801350 [06:20<00:37, 4299.29 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1646000/1801350 [06:20<00:36, 4250.03 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1648000/1801350 [06:20<00:35, 4266.61 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1657000/1801350 [06:20<00:34, 4194.52 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1647000/1801350 [06:21<00:36, 4208.71 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1649000/1801350 [06:20<00:34, 4393.21 examples/s]Grouping texts in chunks of 1024:  91%|█████████ | 1643000/1801350 [06:20<00:39, 4007.46 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1658000/1801350 [06:20<00:33, 4290.10 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1648000/1801350 [06:21<00:35, 4321.96 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1644000/1801350 [06:20<00:38, 4093.86 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1650000/1801350 [06:20<00:35, 4241.95 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1659000/1801350 [06:20<00:33, 4286.89 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1645000/1801350 [06:20<00:36, 4320.23 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1649000/1801350 [06:21<00:35, 4281.65 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1651000/1801350 [06:20<00:36, 4124.62 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1660000/1801350 [06:21<00:33, 4207.48 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1650000/1801350 [06:21<00:35, 4209.89 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1646000/1801350 [06:21<00:36, 4217.57 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1652000/1801350 [06:21<00:34, 4369.42 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1661000/1801350 [06:21<00:32, 4291.97 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1653000/1801350 [06:21<00:32, 4542.84 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1647000/1801350 [06:21<00:36, 4283.07 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1651000/1801350 [06:21<00:37, 4024.12 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1662000/1801350 [06:21<00:30, 4545.85 examples/s]Grouping texts in chunks of 1024:  91%|█████████▏| 1648000/1801350 [06:21<00:36, 4242.87 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1652000/1801350 [06:22<00:35, 4262.04 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1654000/1801350 [06:21<00:34, 4254.02 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1663000/1801350 [06:21<00:30, 4610.96 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1653000/1801350 [06:22<00:32, 4498.49 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1649000/1801350 [06:21<00:34, 4374.92 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1655000/1801350 [06:21<00:35, 4106.15 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1664000/1801350 [06:21<00:29, 4662.33 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1650000/1801350 [06:22<00:35, 4257.80 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1654000/1801350 [06:22<00:34, 4249.89 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1656000/1801350 [06:22<00:33, 4304.18 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1665000/1801350 [06:22<00:31, 4351.08 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1655000/1801350 [06:22<00:35, 4156.91 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1651000/1801350 [06:22<00:36, 4100.86 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1657000/1801350 [06:22<00:35, 4069.87 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1666000/1801350 [06:22<00:30, 4421.53 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1652000/1801350 [06:22<00:34, 4340.99 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1656000/1801350 [06:23<00:33, 4303.34 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1658000/1801350 [06:22<00:33, 4276.98 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1667000/1801350 [06:22<00:29, 4576.14 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1653000/1801350 [06:22<00:33, 4480.90 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1659000/1801350 [06:22<00:33, 4301.52 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1668000/1801350 [06:22<00:29, 4540.70 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1657000/1801350 [06:23<00:35, 4060.56 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1654000/1801350 [06:23<00:35, 4203.90 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1658000/1801350 [06:23<00:33, 4255.94 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1669000/1801350 [06:23<00:29, 4526.21 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1660000/1801350 [06:23<00:33, 4248.58 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1670000/1801350 [06:23<00:28, 4586.92 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1655000/1801350 [06:23<00:35, 4171.87 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1661000/1801350 [06:23<00:32, 4339.26 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1659000/1801350 [06:23<00:33, 4191.26 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1662000/1801350 [06:23<00:30, 4583.81 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1656000/1801350 [06:23<00:34, 4207.99 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1671000/1801350 [06:23<00:29, 4371.80 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1660000/1801350 [06:24<00:33, 4203.98 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1672000/1801350 [06:23<00:29, 4443.35 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1661000/1801350 [06:24<00:32, 4306.89 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1657000/1801350 [06:23<00:34, 4128.25 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1663000/1801350 [06:23<00:34, 4014.25 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1662000/1801350 [06:24<00:30, 4631.86 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1673000/1801350 [06:23<00:28, 4503.82 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1658000/1801350 [06:23<00:33, 4317.12 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1664000/1801350 [06:23<00:31, 4317.24 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1663000/1801350 [06:24<00:30, 4551.63 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1674000/1801350 [06:24<00:28, 4447.72 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1659000/1801350 [06:24<00:32, 4332.48 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1665000/1801350 [06:24<00:32, 4140.88 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1664000/1801350 [06:24<00:30, 4532.24 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1675000/1801350 [06:24<00:28, 4443.73 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1660000/1801350 [06:24<00:32, 4335.23 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1666000/1801350 [06:24<00:31, 4259.28 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1676000/1801350 [06:24<00:28, 4418.38 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1665000/1801350 [06:25<00:31, 4295.99 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1661000/1801350 [06:24<00:32, 4253.65 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1667000/1801350 [06:24<00:30, 4408.34 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1677000/1801350 [06:24<00:27, 4508.09 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1662000/1801350 [06:24<00:30, 4528.84 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1666000/1801350 [06:25<00:31, 4332.80 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1668000/1801350 [06:24<00:29, 4463.62 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1663000/1801350 [06:25<00:29, 4637.45 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1667000/1801350 [06:25<00:30, 4463.03 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1678000/1801350 [06:25<00:28, 4352.49 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1669000/1801350 [06:25<00:29, 4543.57 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1664000/1801350 [06:25<00:29, 4619.72 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1679000/1801350 [06:25<00:27, 4524.27 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1668000/1801350 [06:25<00:29, 4468.33 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1670000/1801350 [06:25<00:29, 4430.34 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1669000/1801350 [06:26<00:29, 4557.80 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1680000/1801350 [06:25<00:28, 4327.02 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1665000/1801350 [06:25<00:32, 4228.59 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1671000/1801350 [06:25<00:29, 4421.12 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1670000/1801350 [06:26<00:28, 4554.13 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1681000/1801350 [06:25<00:27, 4387.32 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1672000/1801350 [06:25<00:28, 4482.06 examples/s]Grouping texts in chunks of 1024:  92%|█████████▏| 1666000/1801350 [06:25<00:31, 4281.98 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1667000/1801350 [06:25<00:29, 4523.16 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1671000/1801350 [06:26<00:29, 4397.20 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1682000/1801350 [06:26<00:28, 4259.55 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1673000/1801350 [06:26<00:29, 4392.18 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1672000/1801350 [06:26<00:29, 4393.70 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1668000/1801350 [06:26<00:30, 4433.28 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1683000/1801350 [06:26<00:28, 4203.13 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1674000/1801350 [06:26<00:29, 4322.10 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1669000/1801350 [06:26<00:29, 4551.75 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1673000/1801350 [06:26<00:29, 4306.03 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1675000/1801350 [06:26<00:28, 4402.11 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1684000/1801350 [06:26<00:28, 4180.79 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1670000/1801350 [06:26<00:29, 4491.25 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1674000/1801350 [06:27<00:29, 4366.06 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1676000/1801350 [06:26<00:28, 4331.46 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1685000/1801350 [06:26<00:27, 4247.75 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1671000/1801350 [06:26<00:29, 4395.93 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1675000/1801350 [06:27<00:29, 4333.30 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1677000/1801350 [06:26<00:27, 4566.79 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1686000/1801350 [06:26<00:27, 4179.97 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1672000/1801350 [06:27<00:29, 4422.79 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1676000/1801350 [06:27<00:29, 4306.83 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1687000/1801350 [06:27<00:25, 4437.11 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1678000/1801350 [06:27<00:28, 4287.68 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1677000/1801350 [06:27<00:28, 4406.13 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1673000/1801350 [06:27<00:29, 4316.62 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1679000/1801350 [06:27<00:27, 4499.86 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1688000/1801350 [06:27<00:25, 4459.09 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1674000/1801350 [06:27<00:29, 4294.26 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1678000/1801350 [06:28<00:29, 4208.09 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1689000/1801350 [06:27<00:25, 4445.42 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1680000/1801350 [06:27<00:27, 4342.79 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1675000/1801350 [06:27<00:28, 4438.25 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1679000/1801350 [06:28<00:27, 4403.14 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1690000/1801350 [06:27<00:25, 4370.95 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1681000/1801350 [06:27<00:28, 4233.72 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1676000/1801350 [06:28<00:29, 4306.87 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1680000/1801350 [06:28<00:28, 4318.72 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1691000/1801350 [06:28<00:24, 4512.10 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1682000/1801350 [06:28<00:27, 4288.69 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1677000/1801350 [06:28<00:28, 4361.73 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1692000/1801350 [06:28<00:24, 4533.04 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1681000/1801350 [06:28<00:28, 4265.67 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1683000/1801350 [06:28<00:28, 4095.37 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1678000/1801350 [06:28<00:28, 4318.09 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1682000/1801350 [06:29<00:28, 4171.34 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1693000/1801350 [06:28<00:25, 4199.92 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1684000/1801350 [06:28<00:28, 4173.79 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1679000/1801350 [06:28<00:28, 4357.26 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1683000/1801350 [06:29<00:28, 4108.68 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1694000/1801350 [06:28<00:26, 4121.10 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1685000/1801350 [06:28<00:27, 4215.04 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1680000/1801350 [06:28<00:28, 4258.56 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1684000/1801350 [06:29<00:28, 4148.77 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1695000/1801350 [06:29<00:25, 4172.15 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1686000/1801350 [06:29<00:28, 4090.18 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1681000/1801350 [06:29<00:28, 4286.89 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1696000/1801350 [06:29<00:24, 4305.33 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1687000/1801350 [06:29<00:25, 4434.06 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1685000/1801350 [06:29<00:28, 4132.95 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1682000/1801350 [06:29<00:28, 4213.79 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1688000/1801350 [06:29<00:24, 4574.37 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1686000/1801350 [06:30<00:27, 4162.50 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1697000/1801350 [06:29<00:25, 4142.44 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1683000/1801350 [06:29<00:28, 4176.91 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1687000/1801350 [06:30<00:25, 4431.08 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1689000/1801350 [06:29<00:25, 4434.49 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1698000/1801350 [06:29<00:24, 4200.54 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1688000/1801350 [06:30<00:25, 4529.82 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1690000/1801350 [06:29<00:25, 4355.05 examples/s]Grouping texts in chunks of 1024:  93%|█████████▎| 1684000/1801350 [06:29<00:28, 4074.66 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1699000/1801350 [06:29<00:24, 4162.28 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1689000/1801350 [06:30<00:26, 4307.11 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1691000/1801350 [06:30<00:25, 4388.93 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1685000/1801350 [06:30<00:27, 4157.83 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1700000/1801350 [06:30<00:25, 4015.05 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1692000/1801350 [06:30<00:24, 4518.32 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1690000/1801350 [06:30<00:25, 4298.79 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1686000/1801350 [06:30<00:27, 4193.71 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1701000/1801350 [06:30<00:24, 4051.75 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1691000/1801350 [06:31<00:25, 4382.93 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1687000/1801350 [06:30<00:26, 4355.94 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1693000/1801350 [06:30<00:26, 4137.17 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1702000/1801350 [06:30<00:24, 4114.52 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1692000/1801350 [06:31<00:24, 4516.37 examples/s]Grouping texts in chunks of 1024:  94%|█████████▎| 1688000/1801350 [06:30<00:25, 4478.13 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1694000/1801350 [06:30<00:26, 4054.82 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1703000/1801350 [06:30<00:23, 4158.74 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1689000/1801350 [06:31<00:25, 4369.74 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1693000/1801350 [06:31<00:26, 4072.34 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1695000/1801350 [06:31<00:25, 4197.01 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1704000/1801350 [06:31<00:22, 4236.78 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1690000/1801350 [06:31<00:25, 4303.55 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1696000/1801350 [06:31<00:24, 4285.03 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1694000/1801350 [06:31<00:26, 4049.60 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1705000/1801350 [06:31<00:22, 4206.84 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1691000/1801350 [06:31<00:25, 4355.54 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1695000/1801350 [06:32<00:24, 4281.04 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1697000/1801350 [06:31<00:25, 4111.20 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1706000/1801350 [06:31<00:22, 4300.28 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1692000/1801350 [06:31<00:24, 4442.57 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1696000/1801350 [06:32<00:25, 4130.29 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1698000/1801350 [06:31<00:24, 4204.77 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1707000/1801350 [06:31<00:21, 4367.16 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1693000/1801350 [06:32<00:26, 4122.97 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1697000/1801350 [06:32<00:25, 4076.33 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1699000/1801350 [06:32<00:24, 4116.72 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1708000/1801350 [06:32<00:22, 4235.93 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1694000/1801350 [06:32<00:25, 4149.98 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1698000/1801350 [06:32<00:24, 4175.24 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1709000/1801350 [06:32<00:21, 4338.63 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1700000/1801350 [06:32<00:25, 3969.03 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1695000/1801350 [06:32<00:25, 4159.21 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1710000/1801350 [06:32<00:20, 4472.41 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1699000/1801350 [06:33<00:24, 4116.61 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1701000/1801350 [06:32<00:24, 4037.83 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1696000/1801350 [06:32<00:24, 4265.33 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1711000/1801350 [06:32<00:20, 4467.68 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1700000/1801350 [06:33<00:25, 3907.51 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1702000/1801350 [06:32<00:24, 4093.59 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1697000/1801350 [06:32<00:24, 4176.30 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1712000/1801350 [06:33<00:20, 4461.16 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1703000/1801350 [06:33<00:23, 4162.08 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1701000/1801350 [06:33<00:25, 3963.15 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1713000/1801350 [06:33<00:19, 4430.03 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1698000/1801350 [06:33<00:25, 4079.92 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1702000/1801350 [06:33<00:24, 4139.10 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1704000/1801350 [06:33<00:23, 4142.26 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1714000/1801350 [06:33<00:19, 4564.81 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1699000/1801350 [06:33<00:24, 4177.42 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1703000/1801350 [06:34<00:23, 4151.38 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1705000/1801350 [06:33<00:23, 4187.34 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1715000/1801350 [06:33<00:18, 4633.81 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1700000/1801350 [06:33<00:26, 3880.10 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1706000/1801350 [06:33<00:22, 4328.17 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1704000/1801350 [06:34<00:23, 4127.03 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1716000/1801350 [06:33<00:18, 4531.05 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1701000/1801350 [06:33<00:24, 4060.83 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1707000/1801350 [06:34<00:21, 4340.55 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1705000/1801350 [06:34<00:22, 4192.80 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1717000/1801350 [06:34<00:18, 4464.05 examples/s]Grouping texts in chunks of 1024:  94%|█████████▍| 1702000/1801350 [06:34<00:23, 4142.49 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1708000/1801350 [06:34<00:21, 4350.40 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1706000/1801350 [06:34<00:22, 4276.16 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1718000/1801350 [06:34<00:17, 4696.98 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1703000/1801350 [06:34<00:23, 4169.63 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1709000/1801350 [06:34<00:21, 4392.56 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1707000/1801350 [06:35<00:21, 4371.10 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1719000/1801350 [06:34<00:19, 4328.26 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1704000/1801350 [06:34<00:23, 4231.55 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1710000/1801350 [06:34<00:20, 4358.10 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1708000/1801350 [06:35<00:21, 4255.70 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1720000/1801350 [06:34<00:19, 4229.95 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1711000/1801350 [06:34<00:20, 4506.83 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1709000/1801350 [06:35<00:21, 4367.28 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1705000/1801350 [06:34<00:23, 4102.50 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1721000/1801350 [06:35<00:19, 4187.33 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1712000/1801350 [06:35<00:19, 4486.10 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1706000/1801350 [06:35<00:22, 4257.12 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1710000/1801350 [06:35<00:21, 4345.48 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1722000/1801350 [06:35<00:19, 4156.57 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1713000/1801350 [06:35<00:19, 4459.13 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1707000/1801350 [06:35<00:22, 4286.57 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1711000/1801350 [06:35<00:20, 4323.01 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1723000/1801350 [06:35<00:18, 4213.48 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1714000/1801350 [06:35<00:19, 4575.67 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1712000/1801350 [06:36<00:19, 4468.32 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1708000/1801350 [06:35<00:21, 4310.18 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1715000/1801350 [06:35<00:18, 4625.49 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1724000/1801350 [06:35<00:18, 4230.64 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1709000/1801350 [06:35<00:21, 4342.58 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1713000/1801350 [06:36<00:20, 4376.03 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1725000/1801350 [06:35<00:17, 4399.02 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1716000/1801350 [06:36<00:19, 4382.27 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1714000/1801350 [06:36<00:19, 4574.27 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1710000/1801350 [06:36<00:20, 4369.69 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1726000/1801350 [06:36<00:16, 4462.66 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1717000/1801350 [06:36<00:18, 4492.24 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1715000/1801350 [06:36<00:19, 4540.46 examples/s]Grouping texts in chunks of 1024:  95%|█████████▍| 1711000/1801350 [06:36<00:20, 4428.73 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1727000/1801350 [06:36<00:16, 4642.55 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1718000/1801350 [06:36<00:17, 4657.67 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1716000/1801350 [06:37<00:19, 4393.42 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1712000/1801350 [06:36<00:20, 4330.25 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1728000/1801350 [06:36<00:15, 4648.66 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1719000/1801350 [06:36<00:19, 4330.37 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1717000/1801350 [06:37<00:18, 4445.05 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1713000/1801350 [06:36<00:19, 4451.17 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1729000/1801350 [06:36<00:15, 4628.00 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1718000/1801350 [06:37<00:18, 4621.36 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1720000/1801350 [06:36<00:19, 4262.60 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1714000/1801350 [06:36<00:19, 4531.85 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1730000/1801350 [06:37<00:15, 4581.48 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1715000/1801350 [06:37<00:18, 4590.24 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1721000/1801350 [06:37<00:19, 4164.62 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1719000/1801350 [06:37<00:19, 4225.44 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1731000/1801350 [06:37<00:15, 4634.11 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1716000/1801350 [06:37<00:19, 4421.16 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1722000/1801350 [06:37<00:18, 4225.21 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1720000/1801350 [06:38<00:19, 4243.95 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1732000/1801350 [06:37<00:15, 4369.96 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1717000/1801350 [06:37<00:19, 4326.11 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1723000/1801350 [06:37<00:18, 4209.74 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1721000/1801350 [06:38<00:19, 4136.15 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1733000/1801350 [06:37<00:15, 4410.56 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1718000/1801350 [06:37<00:18, 4585.32 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1724000/1801350 [06:37<00:18, 4113.22 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1734000/1801350 [06:37<00:14, 4614.63 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1722000/1801350 [06:38<00:19, 4124.62 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1719000/1801350 [06:38<00:19, 4306.33 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1725000/1801350 [06:38<00:17, 4331.52 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1735000/1801350 [06:38<00:14, 4666.89 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1723000/1801350 [06:38<00:18, 4135.16 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1726000/1801350 [06:38<00:16, 4574.34 examples/s]Grouping texts in chunks of 1024:  95%|█████████▌| 1720000/1801350 [06:38<00:19, 4266.41 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1736000/1801350 [06:38<00:13, 4809.55 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1724000/1801350 [06:38<00:18, 4255.22 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1727000/1801350 [06:38<00:16, 4622.33 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1737000/1801350 [06:38<00:13, 4719.05 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1721000/1801350 [06:38<00:19, 4061.34 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1725000/1801350 [06:39<00:17, 4315.08 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1728000/1801350 [06:38<00:15, 4701.23 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1738000/1801350 [06:38<00:13, 4526.41 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1726000/1801350 [06:39<00:16, 4496.60 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1722000/1801350 [06:38<00:19, 4142.57 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1729000/1801350 [06:38<00:15, 4548.81 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1739000/1801350 [06:39<00:14, 4416.62 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1727000/1801350 [06:39<00:16, 4505.50 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1723000/1801350 [06:39<00:18, 4216.14 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1730000/1801350 [06:39<00:15, 4493.05 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1740000/1801350 [06:39<00:13, 4544.85 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1728000/1801350 [06:39<00:16, 4521.86 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1724000/1801350 [06:39<00:18, 4188.52 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1731000/1801350 [06:39<00:15, 4494.87 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1741000/1801350 [06:39<00:13, 4359.54 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1729000/1801350 [06:40<00:15, 4569.00 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1725000/1801350 [06:39<00:17, 4340.36 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1732000/1801350 [06:39<00:15, 4373.53 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1730000/1801350 [06:40<00:15, 4563.14 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1742000/1801350 [06:39<00:13, 4354.46 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1726000/1801350 [06:39<00:16, 4488.42 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1733000/1801350 [06:39<00:15, 4524.06 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1731000/1801350 [06:40<00:15, 4534.61 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1727000/1801350 [06:39<00:16, 4584.09 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1743000/1801350 [06:39<00:13, 4322.29 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1734000/1801350 [06:40<00:14, 4642.20 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1728000/1801350 [06:40<00:16, 4523.00 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1744000/1801350 [06:40<00:13, 4362.40 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1732000/1801350 [06:40<00:16, 4288.09 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1735000/1801350 [06:40<00:14, 4602.26 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1729000/1801350 [06:40<00:16, 4499.73 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1733000/1801350 [06:40<00:15, 4406.83 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1745000/1801350 [06:40<00:12, 4342.14 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1736000/1801350 [06:40<00:14, 4642.23 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1730000/1801350 [06:40<00:15, 4670.96 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1734000/1801350 [06:41<00:14, 4559.31 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1746000/1801350 [06:40<00:12, 4486.72 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1737000/1801350 [06:40<00:13, 4803.03 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1735000/1801350 [06:41<00:14, 4641.16 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1731000/1801350 [06:40<00:15, 4477.37 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1747000/1801350 [06:40<00:12, 4454.64 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1738000/1801350 [06:40<00:13, 4528.43 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1736000/1801350 [06:41<00:13, 4714.78 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1748000/1801350 [06:41<00:11, 4619.97 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1732000/1801350 [06:41<00:15, 4407.26 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1739000/1801350 [06:41<00:14, 4445.04 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1737000/1801350 [06:41<00:13, 4747.24 examples/s]Grouping texts in chunks of 1024:  96%|█████████▌| 1733000/1801350 [06:41<00:15, 4479.18 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1749000/1801350 [06:41<00:11, 4438.57 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1740000/1801350 [06:41<00:13, 4560.47 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1738000/1801350 [06:42<00:14, 4441.69 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1734000/1801350 [06:41<00:14, 4523.20 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1750000/1801350 [06:41<00:12, 4109.47 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1741000/1801350 [06:41<00:13, 4336.16 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1739000/1801350 [06:42<00:13, 4477.63 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1735000/1801350 [06:41<00:14, 4594.78 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1751000/1801350 [06:41<00:12, 4039.46 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1742000/1801350 [06:41<00:13, 4388.82 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1736000/1801350 [06:41<00:13, 4736.54 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1740000/1801350 [06:42<00:13, 4437.82 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1752000/1801350 [06:42<00:11, 4246.87 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1737000/1801350 [06:42<00:13, 4794.09 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1743000/1801350 [06:42<00:13, 4246.69 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1741000/1801350 [06:42<00:14, 4288.97 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1753000/1801350 [06:42<00:11, 4214.08 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1744000/1801350 [06:42<00:13, 4384.47 examples/s]Grouping texts in chunks of 1024:  96%|█████████▋| 1738000/1801350 [06:42<00:14, 4500.85 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1742000/1801350 [06:42<00:13, 4307.80 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1754000/1801350 [06:42<00:10, 4416.27 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1745000/1801350 [06:42<00:12, 4345.40 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1739000/1801350 [06:42<00:14, 4377.95 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1743000/1801350 [06:43<00:13, 4311.13 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1755000/1801350 [06:42<00:10, 4386.24 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1746000/1801350 [06:42<00:12, 4375.42 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1740000/1801350 [06:42<00:13, 4414.62 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1744000/1801350 [06:43<00:13, 4302.10 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1756000/1801350 [06:42<00:10, 4378.95 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1747000/1801350 [06:42<00:11, 4537.63 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1741000/1801350 [06:43<00:13, 4379.95 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1745000/1801350 [06:43<00:13, 4246.95 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1757000/1801350 [06:43<00:09, 4477.40 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1748000/1801350 [06:43<00:11, 4525.59 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1742000/1801350 [06:43<00:13, 4314.21 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1746000/1801350 [06:43<00:12, 4293.48 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1758000/1801350 [06:43<00:09, 4449.55 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1749000/1801350 [06:43<00:11, 4490.14 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1743000/1801350 [06:43<00:13, 4233.16 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1747000/1801350 [06:44<00:12, 4416.58 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1759000/1801350 [06:43<00:09, 4534.92 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1750000/1801350 [06:43<00:12, 4052.92 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1744000/1801350 [06:43<00:13, 4308.18 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1748000/1801350 [06:44<00:11, 4451.37 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1760000/1801350 [06:43<00:09, 4444.12 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1751000/1801350 [06:44<00:12, 4021.64 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1745000/1801350 [06:43<00:13, 4333.95 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1749000/1801350 [06:44<00:12, 4275.93 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1761000/1801350 [06:44<00:08, 4527.15 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1752000/1801350 [06:44<00:11, 4165.63 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1746000/1801350 [06:44<00:12, 4393.32 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1762000/1801350 [06:44<00:09, 4307.92 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1750000/1801350 [06:44<00:12, 4023.68 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1753000/1801350 [06:44<00:11, 4289.89 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1747000/1801350 [06:44<00:12, 4398.42 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1763000/1801350 [06:44<00:08, 4475.24 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1751000/1801350 [06:45<00:12, 3995.25 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1754000/1801350 [06:44<00:10, 4308.00 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1748000/1801350 [06:44<00:11, 4460.57 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1764000/1801350 [06:44<00:08, 4406.02 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1752000/1801350 [06:45<00:11, 4202.72 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1755000/1801350 [06:44<00:10, 4379.23 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1749000/1801350 [06:44<00:12, 4350.54 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1765000/1801350 [06:44<00:07, 4589.08 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1753000/1801350 [06:45<00:11, 4163.82 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1756000/1801350 [06:45<00:10, 4274.95 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1766000/1801350 [06:45<00:07, 4553.96 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1750000/1801350 [06:45<00:12, 3992.85 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1754000/1801350 [06:45<00:10, 4341.89 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1757000/1801350 [06:45<00:09, 4520.09 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1767000/1801350 [06:45<00:07, 4589.18 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1751000/1801350 [06:45<00:12, 4042.44 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1755000/1801350 [06:46<00:10, 4242.75 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1758000/1801350 [06:45<00:09, 4436.01 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1768000/1801350 [06:45<00:07, 4252.73 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1752000/1801350 [06:45<00:11, 4144.08 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1756000/1801350 [06:46<00:10, 4288.04 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1759000/1801350 [06:45<00:09, 4526.63 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1769000/1801350 [06:45<00:07, 4295.28 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1753000/1801350 [06:45<00:11, 4199.40 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1757000/1801350 [06:46<00:09, 4551.45 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1760000/1801350 [06:45<00:09, 4480.33 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1754000/1801350 [06:46<00:10, 4404.45 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1770000/1801350 [06:46<00:07, 4338.80 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1758000/1801350 [06:46<00:09, 4432.13 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1761000/1801350 [06:46<00:09, 4474.15 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1771000/1801350 [06:46<00:06, 4455.75 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1755000/1801350 [06:46<00:10, 4277.77 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1759000/1801350 [06:46<00:09, 4445.33 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1762000/1801350 [06:46<00:09, 4321.95 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1772000/1801350 [06:46<00:06, 4504.29 examples/s]Grouping texts in chunks of 1024:  97%|█████████▋| 1756000/1801350 [06:46<00:10, 4346.55 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1760000/1801350 [06:47<00:09, 4487.63 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1763000/1801350 [06:46<00:08, 4457.18 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1773000/1801350 [06:46<00:06, 4530.70 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1757000/1801350 [06:46<00:10, 4424.96 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1761000/1801350 [06:47<00:08, 4487.57 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1764000/1801350 [06:46<00:08, 4452.93 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1774000/1801350 [06:46<00:05, 4781.69 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1758000/1801350 [06:46<00:09, 4481.74 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1762000/1801350 [06:47<00:09, 4209.54 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1765000/1801350 [06:47<00:08, 4533.31 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1775000/1801350 [06:47<00:05, 4638.17 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1759000/1801350 [06:47<00:09, 4484.75 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1763000/1801350 [06:47<00:08, 4466.19 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1766000/1801350 [06:47<00:07, 4602.09 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1776000/1801350 [06:47<00:05, 4695.83 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1760000/1801350 [06:47<00:09, 4395.52 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1764000/1801350 [06:48<00:08, 4382.22 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1767000/1801350 [06:47<00:07, 4418.80 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1777000/1801350 [06:47<00:05, 4215.92 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1761000/1801350 [06:47<00:09, 4464.02 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1765000/1801350 [06:48<00:08, 4421.30 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1768000/1801350 [06:47<00:07, 4269.39 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1778000/1801350 [06:47<00:05, 4305.73 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1766000/1801350 [06:48<00:07, 4636.36 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1762000/1801350 [06:47<00:09, 4243.99 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1769000/1801350 [06:48<00:07, 4315.64 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1779000/1801350 [06:48<00:05, 4209.65 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1763000/1801350 [06:48<00:08, 4379.15 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1767000/1801350 [06:48<00:07, 4394.49 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1770000/1801350 [06:48<00:07, 4429.43 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1780000/1801350 [06:48<00:05, 4211.28 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1764000/1801350 [06:48<00:08, 4434.75 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1768000/1801350 [06:48<00:07, 4288.73 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1771000/1801350 [06:48<00:06, 4389.12 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1765000/1801350 [06:48<00:07, 4612.24 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1781000/1801350 [06:48<00:04, 4164.98 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1769000/1801350 [06:49<00:07, 4297.41 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1772000/1801350 [06:48<00:06, 4523.83 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1766000/1801350 [06:48<00:07, 4551.73 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1782000/1801350 [06:48<00:04, 4251.71 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1770000/1801350 [06:49<00:07, 4325.22 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1773000/1801350 [06:48<00:06, 4432.52 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1783000/1801350 [06:49<00:04, 4511.89 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1767000/1801350 [06:49<00:07, 4419.57 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1774000/1801350 [06:49<00:05, 4637.16 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1784000/1801350 [06:49<00:03, 4553.28 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1768000/1801350 [06:49<00:07, 4200.74 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1775000/1801350 [06:49<00:05, 4699.26 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1771000/1801350 [06:50<00:10, 2989.22 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1785000/1801350 [06:49<00:03, 4354.47 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1769000/1801350 [06:49<00:07, 4316.85 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1776000/1801350 [06:49<00:05, 4666.51 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1772000/1801350 [06:50<00:08, 3284.10 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1786000/1801350 [06:49<00:03, 4300.06 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1770000/1801350 [06:49<00:07, 4344.37 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1777000/1801350 [06:49<00:05, 4171.09 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1773000/1801350 [06:50<00:07, 3658.55 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1787000/1801350 [06:49<00:03, 4401.86 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1771000/1801350 [06:49<00:07, 4299.57 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1778000/1801350 [06:50<00:05, 4237.40 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1774000/1801350 [06:50<00:06, 4010.84 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1772000/1801350 [06:50<00:06, 4498.51 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1788000/1801350 [06:50<00:03, 4308.67 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1779000/1801350 [06:50<00:05, 4254.86 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1775000/1801350 [06:50<00:06, 4074.99 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1789000/1801350 [06:50<00:02, 4420.21 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1773000/1801350 [06:50<00:06, 4383.90 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1780000/1801350 [06:50<00:04, 4280.35 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1776000/1801350 [06:51<00:06, 4223.16 examples/s]Grouping texts in chunks of 1024:  98%|█████████▊| 1774000/1801350 [06:50<00:05, 4731.01 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1790000/1801350 [06:50<00:02, 4248.91 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1781000/1801350 [06:50<00:04, 4122.48 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1777000/1801350 [06:51<00:06, 3958.99 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1775000/1801350 [06:50<00:05, 4576.04 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1791000/1801350 [06:50<00:02, 4188.91 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1776000/1801350 [06:51<00:05, 4716.07 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1782000/1801350 [06:51<00:04, 4141.68 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1778000/1801350 [06:51<00:05, 4068.75 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1783000/1801350 [06:51<00:04, 4538.42 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1779000/1801350 [06:51<00:05, 4057.99 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1777000/1801350 [06:51<00:05, 4102.47 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1784000/1801350 [06:51<00:03, 4501.77 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1792000/1801350 [06:51<00:03, 2890.88 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1780000/1801350 [06:52<00:05, 4145.02 examples/s]Grouping texts in chunks of 1024:  99%|█████████▊| 1778000/1801350 [06:51<00:05, 4205.49 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1785000/1801350 [06:51<00:03, 4311.61 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1793000/1801350 [06:51<00:02, 3334.86 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1781000/1801350 [06:52<00:05, 4049.42 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1779000/1801350 [06:51<00:05, 4182.02 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1794000/1801350 [06:51<00:02, 3644.21 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1786000/1801350 [06:51<00:03, 4217.57 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1782000/1801350 [06:52<00:04, 4177.68 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1780000/1801350 [06:52<00:05, 4152.35 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1787000/1801350 [06:52<00:03, 4435.58 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1795000/1801350 [06:52<00:01, 3708.29 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1783000/1801350 [06:52<00:04, 4427.16 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1781000/1801350 [06:52<00:04, 4118.30 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1788000/1801350 [06:52<00:03, 4314.23 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1796000/1801350 [06:52<00:01, 3804.17 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1784000/1801350 [06:53<00:03, 4407.32 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1782000/1801350 [06:52<00:04, 4227.09 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1789000/1801350 [06:52<00:02, 4380.30 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1797000/1801350 [06:52<00:01, 4087.05 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1785000/1801350 [06:53<00:03, 4237.14 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1783000/1801350 [06:52<00:04, 4504.57 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1798000/1801350 [06:52<00:00, 4135.76 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1790000/1801350 [06:52<00:02, 4196.11 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1784000/1801350 [06:52<00:03, 4531.63 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1786000/1801350 [06:53<00:03, 4180.58 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1791000/1801350 [06:53<00:02, 4246.42 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1799000/1801350 [06:53<00:00, 4151.83 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1787000/1801350 [06:53<00:03, 4365.22 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1785000/1801350 [06:53<00:03, 4353.88 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1800000/1801350 [06:53<00:00, 4382.07 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1788000/1801350 [06:53<00:03, 4242.88 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1786000/1801350 [06:53<00:03, 4217.12 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1801000/1801350 [06:53<00:00, 4494.29 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1789000/1801350 [06:54<00:02, 4357.42 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1787000/1801350 [06:53<00:03, 4334.24 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1792000/1801350 [06:53<00:03, 2923.45 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1790000/1801350 [06:54<00:02, 4119.79 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1793000/1801350 [06:53<00:02, 3283.12 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1788000/1801350 [06:53<00:03, 4237.96 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1791000/1801350 [06:54<00:02, 4470.11 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1794000/1801350 [06:54<00:01, 3785.40 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1789000/1801350 [06:54<00:02, 4583.93 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1795000/1801350 [06:54<00:01, 4048.64 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1792000/1801350 [06:54<00:02, 4517.14 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1790000/1801350 [06:54<00:02, 4626.00 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1793000/1801350 [06:55<00:01, 4937.31 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1791000/1801350 [06:54<00:02, 4885.94 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1796000/1801350 [06:54<00:01, 4305.53 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1794000/1801350 [06:55<00:01, 5350.62 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1797000/1801350 [06:54<00:00, 4881.64 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1795000/1801350 [06:55<00:01, 5143.56 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1798000/1801350 [06:54<00:00, 4990.38 examples/s]Grouping texts in chunks of 1024:  99%|█████████▉| 1792000/1801350 [06:54<00:02, 3647.08 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1799000/1801350 [06:54<00:00, 5231.63 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1796000/1801350 [06:55<00:01, 5202.62 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1793000/1801350 [06:55<00:02, 4075.23 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1800000/1801350 [06:55<00:00, 5583.26 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1797000/1801350 [06:55<00:00, 5332.51 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1794000/1801350 [06:55<00:01, 4591.59 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1801000/1801350 [06:55<00:00, 5449.67 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1798000/1801350 [06:55<00:00, 5509.99 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1795000/1801350 [06:55<00:01, 4626.73 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1799000/1801350 [06:56<00:00, 5531.43 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1796000/1801350 [06:55<00:01, 4879.13 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1800000/1801350 [06:56<00:00, 5802.36 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1797000/1801350 [06:55<00:00, 5655.64 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1801000/1801350 [06:56<00:00, 6396.22 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1798000/1801350 [06:55<00:00, 6292.68 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1799000/1801350 [06:55<00:00, 7025.64 examples/s]Grouping texts in chunks of 1024: 100%|█████████▉| 1801000/1801350 [06:56<00:00, 8919.76 examples/s]                                                                                                    Grouping texts in chunks of 1024:   0%|          | 0/3760 [00:00<?, ? examples/s]Grouping texts in chunks of 1024:  53%|█████▎    | 2000/3760 [00:00<00:00, 16032.23 examples/s]Grouping texts in chunks of 1024: 100%|██████████| 3760/3760 [00:00<00:00, 15425.19 examples/s]                                                                                                                                                                                                   04/09/2023 01:44:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /home/tli104/.cache/huggingface/datasets/text/default-3efe75d0ffff50d9/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-218ece2b00a9e850.arrow
04/09/2023 01:44:53 - INFO - __main__ - Sample 14291 of the training set: {'input_ids': [220, 198, 796, 796, 10407, 37716, 796, 796, 220, 198, 220, 198, 21171, 12777, 265, 3301, 389, 35609, 290, 645, 310, 35735, 46617, 837, 996, 484, 481, 1690, 39353, 287, 262, 4252, 284, 5814, 511, 5920, 764, 31537, 17783, 7808, 739, 17259, 290, 14966, 837, 290, 389, 2566, 35735, 837, 1884, 780, 6490, 389, 39904, 2569, 764, 16749, 265, 3301, 22191, 287, 10101, 881, 2793, 621, 883, 28197, 416, 749, 46617, 837, 290, 46681, 77, 378, 1141, 7374, 764, 1119, 3520, 4075, 379, 10101, 355, 1877, 355, 642, 22074, 327, 357, 6073, 22074, 376, 1267, 837, 981, 10101, 625, 2579, 22074, 327, 357, 9415, 22074, 376, 1267, 389, 4143, 10800, 764, 383, 16586, 1767, 5951, 329, 262, 12777, 265, 3301, 318, 422, 1467, 284, 2310, 22074, 327, 357, 8454, 284, 4317, 22074, 376, 1267, 837, 262, 9016, 286, 597, 28761, 576, 764, 383, 1767, 5951, 286, 12777, 265, 3301, 318, 2793, 621, 326, 286, 584, 46617, 837, 12897, 422, 642, 2488, 13, 31, 362, 784, 1367, 2488, 13, 31, 362, 22074, 327, 357, 6073, 2488, 13, 31, 604, 784, 6740, 2488, 13, 31, 362, 22074, 376, 1267, 625, 257, 1110, 837, 9472, 749, 46617, 423, 1767, 10101, 1088, 1160, 22074, 327, 357, 8257, 22074, 376, 1267, 764, 383, 1877, 1767, 5951, 2482, 287, 257, 13611, 20211, 764, 220, 198, 5481, 11577, 384, 397, 11049, 884, 355, 4273, 2411, 82, 837, 778, 507, 837, 290, 673, 283, 41555, 2648, 262, 12777, 265, 3301, 705, 82, 7022, 20018, 1141, 262, 10087, 705, 46282, 7028, 764, 383, 12777, 265, 3301, 779, 262, 10087, 705, 4356, 8516, 329, 11772, 618, 1695, 837, 393, 3100, 511, 898, 764, 383, 384, 397, 11049, 705, 915, 5733, 5419, 284, 5529, 40631, 660, 40804, 9684, 319, 543, 12777, 265, 3301, 20736, 15974, 2162, 1390, 46716, 837, 1067, 15970, 837, 290, 26120, 764, 5334, 18977, 635, 3473, 286, 37475, 837, 300, 14124, 837, 290, 6512, 705, 82, 9653, 290, 43803, 764, 383, 9653, 290, 1862, 286, 384, 397, 11049, 326, 389, 1622, 453, 1695, 355, 2057, 329, 12777, 265, 3301, 743, 2148, 13205, 19251, 17045, 764, 16749, 265, 3301, 286, 1111, 32487, 4404, 16771, 837, 290, 481, 16180, 290, 4191, 13197, 9913, 48739, 764, 383, 13197, 460, 2728, 2726, 5095, 764, 16749, 265, 3301, 481, 13197, 618, 10448, 837, 290, 481, 407, 1309, 467, 3538, 764, 220, 198, 220, 198, 796, 796, 36551, 596, 796, 796, 220, 198, 220, 198, 16749, 265, 3301, 22919, 845, 6364, 837, 2263, 838, 284, 1160, 812, 284, 3151, 3206, 24841, 764, 337, 803, 8833, 287, 49304, 31647, 2162, 12366, 16133, 290, 3830, 9653, 1752, 790, 1440, 812, 764, 5856, 8028, 1056, 837, 257, 4257, 1838, 465, 4168, 18646, 837, 12073, 465, 1126, 6448, 837, 290, 1582, 2367, 3812, 262, 4048, 764, 679, 6364, 11114, 287, 13332, 1088, 262, 4048, 351, 15175, 2945, 7405, 764, 383, 4048, 481, 2035, 9199, 837, 290, 1249, 262, 4257, 284, 3817, 607, 837, 393, 13703, 284, 607, 4356, 808, 764, 43404, 466, 407, 423, 257, 16360, 2162, 484, 22919, 416, 262, 4257, 16842, 262, 7894, 286, 262, 4048, 290, 12560, 465, 7435, 625, 25144, 764, 383, 19311, 318, 788, 11172, 656, 262, 4048, 837, 881, 588, 262, 31993, 1429, 287, 10087, 764, 220, 198, 16749, 265, 3301, 9653, 423, 257, 2705, 837, 38414, 2488, 12, 31, 588, 7582, 764, 632, 2753, 262, 12366, 1022, 530, 290, 1115, 812, 284, 2148, 9653, 351, 331, 13597, 837, 290, 510, 284, 3598, 1933, 284, 1296, 262, 7582, 764, 632, 788, 2753, 1022, 1105, 290, 1315, 1933, 422, 2243, 1741, 284, 289, 19775, 764, 770, 1724, 20728, 8833, 379, 734, 12, 284, 1936, 2488, 12, 31, 614, 20016, 837, 262, 3105, 395, 287, 597, 28761, 576, 764, 6183, 12777, 265, 3301, 389, 1900, 284, 307, 991, 8186, 2259, 379, 546, 3126, 812, 286, 2479, 2162, 366, 8616, 366, 837, 257, 4257, 12777, 265, 3301, 379, 2520, 1044, 9594, 287, 554, 332, 66, 853, 359, 837, 968, 8936, 837, 2627, 257, 2988, 357, 5457, 329, 262, 717, 640, 1267, 319, 2242, 3269, 3717, 837, 379, 262, 2479, 286, 13374, 764, 220, 198, 383, 1714, 286, 257, 25834, 1359, 8338, 319, 262, 5951, 286, 262, 5935, 837, 351, 23254, 9653, 44681, 284, 4439, 4257, 12777, 265, 3301, 837, 290, 19346, 9653, 9194, 12366, 764, 40433, 25543, 515, 379, 2310, 22074, 327, 357, 4317, 22074, 376, 1267, 423, 281, 4961, 2863, 286, 852, 4257, 393, 4048, 764, 2102, 837, 379, 2534, 22074, 327, 357, 7724, 22074, 376, 1267, 837, 4019, 4064, 389, 1884, 284, 307, 10835, 837, 290, 379, 1160, 22074, 327, 357, 8257, 22074, 376, 1267, 837, 4019, 4064, 389, 1884, 284, 307, 12366, 2162, 379, 1248, 22074, 327, 357, 5598, 22074, 376, 1267, 477, 25834, 17783, 481, 307, 12366, 764, 2773, 2370, 9217, 1714, 12123, 287, 12777, 265, 3301, 318, 5295, 416, 1111, 8513, 290, 6142, 5087, 764, 220, 198, 16749, 265, 3301, 2192, 423, 262, 3105, 395, 3349, 3965, 286, 597, 28761, 576, 837, 8282, 284, 1663, 4025, 329, 262, 717, 3439, 812, 286, 511, 3160, 764, 383, 2811, 30458, 318, 546, 3126, 812, 837, 475, 484, 460, 2107, 284, 307, 880, 625, 1802, 812, 1468, 764, 2773, 6154, 1975, 326, 25798, 12777, 265, 3301, 714, 2107, 355, 890, 355, 939, 812, 764, 220, 198, 220, 198, 796, 796, 23702, 796, 796, 220, 198, 220, 198, 220, 198, 796, 796, 796, 27484, 290, 7432, 796, 796, 796, 220, 198, 220, 198, 16749, 265, 3301, 547, 1752, 10095, 319, 968, 8936, 705, 82, 1388, 2258, 290, 2520, 12010, 837, 810, 850, 69, 793, 346, 3793, 423, 587, 1043, 287, 6450, 288, 4015, 837, 30923, 837, 290, 337, 10235, 10145, 285, 1638, 641, 764, 370, 46647, 503, 422, 262, 1388, 14807, 878, 3427, 9443, 837, 484, 547, 890, 19733, 284, 3933, 18479, 14807, 1479, 286, 23426, 764, 383, 14807, 389, 2408, 284, 651, 284, 837, 290, 389, 7633, 1417, 416, 1178, 5044, 4693, 837, 12739, 326, 617, 4695, 13717, 422, 777, 14807, 743, 423, 4073, 12777, 265, 3301, 284, 10921, 422, 262, 22779, 764, 2102, 837, 1279, 2954, 29, 357, 12280, 2516, 666, 13623, 1267, 550, 2904, 1716, 4920, 319, 1811, 286, 262, 14807, 837, 290, 12777, 265], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [220, 198, 796, 796, 10407, 37716, 796, 796, 220, 198, 220, 198, 21171, 12777, 265, 3301, 389, 35609, 290, 645, 310, 35735, 46617, 837, 996, 484, 481, 1690, 39353, 287, 262, 4252, 284, 5814, 511, 5920, 764, 31537, 17783, 7808, 739, 17259, 290, 14966, 837, 290, 389, 2566, 35735, 837, 1884, 780, 6490, 389, 39904, 2569, 764, 16749, 265, 3301, 22191, 287, 10101, 881, 2793, 621, 883, 28197, 416, 749, 46617, 837, 290, 46681, 77, 378, 1141, 7374, 764, 1119, 3520, 4075, 379, 10101, 355, 1877, 355, 642, 22074, 327, 357, 6073, 22074, 376, 1267, 837, 981, 10101, 625, 2579, 22074, 327, 357, 9415, 22074, 376, 1267, 389, 4143, 10800, 764, 383, 16586, 1767, 5951, 329, 262, 12777, 265, 3301, 318, 422, 1467, 284, 2310, 22074, 327, 357, 8454, 284, 4317, 22074, 376, 1267, 837, 262, 9016, 286, 597, 28761, 576, 764, 383, 1767, 5951, 286, 12777, 265, 3301, 318, 2793, 621, 326, 286, 584, 46617, 837, 12897, 422, 642, 2488, 13, 31, 362, 784, 1367, 2488, 13, 31, 362, 22074, 327, 357, 6073, 2488, 13, 31, 604, 784, 6740, 2488, 13, 31, 362, 22074, 376, 1267, 625, 257, 1110, 837, 9472, 749, 46617, 423, 1767, 10101, 1088, 1160, 22074, 327, 357, 8257, 22074, 376, 1267, 764, 383, 1877, 1767, 5951, 2482, 287, 257, 13611, 20211, 764, 220, 198, 5481, 11577, 384, 397, 11049, 884, 355, 4273, 2411, 82, 837, 778, 507, 837, 290, 673, 283, 41555, 2648, 262, 12777, 265, 3301, 705, 82, 7022, 20018, 1141, 262, 10087, 705, 46282, 7028, 764, 383, 12777, 265, 3301, 779, 262, 10087, 705, 4356, 8516, 329, 11772, 618, 1695, 837, 393, 3100, 511, 898, 764, 383, 384, 397, 11049, 705, 915, 5733, 5419, 284, 5529, 40631, 660, 40804, 9684, 319, 543, 12777, 265, 3301, 20736, 15974, 2162, 1390, 46716, 837, 1067, 15970, 837, 290, 26120, 764, 5334, 18977, 635, 3473, 286, 37475, 837, 300, 14124, 837, 290, 6512, 705, 82, 9653, 290, 43803, 764, 383, 9653, 290, 1862, 286, 384, 397, 11049, 326, 389, 1622, 453, 1695, 355, 2057, 329, 12777, 265, 3301, 743, 2148, 13205, 19251, 17045, 764, 16749, 265, 3301, 286, 1111, 32487, 4404, 16771, 837, 290, 481, 16180, 290, 4191, 13197, 9913, 48739, 764, 383, 13197, 460, 2728, 2726, 5095, 764, 16749, 265, 3301, 481, 13197, 618, 10448, 837, 290, 481, 407, 1309, 467, 3538, 764, 220, 198, 220, 198, 796, 796, 36551, 596, 796, 796, 220, 198, 220, 198, 16749, 265, 3301, 22919, 845, 6364, 837, 2263, 838, 284, 1160, 812, 284, 3151, 3206, 24841, 764, 337, 803, 8833, 287, 49304, 31647, 2162, 12366, 16133, 290, 3830, 9653, 1752, 790, 1440, 812, 764, 5856, 8028, 1056, 837, 257, 4257, 1838, 465, 4168, 18646, 837, 12073, 465, 1126, 6448, 837, 290, 1582, 2367, 3812, 262, 4048, 764, 679, 6364, 11114, 287, 13332, 1088, 262, 4048, 351, 15175, 2945, 7405, 764, 383, 4048, 481, 2035, 9199, 837, 290, 1249, 262, 4257, 284, 3817, 607, 837, 393, 13703, 284, 607, 4356, 808, 764, 43404, 466, 407, 423, 257, 16360, 2162, 484, 22919, 416, 262, 4257, 16842, 262, 7894, 286, 262, 4048, 290, 12560, 465, 7435, 625, 25144, 764, 383, 19311, 318, 788, 11172, 656, 262, 4048, 837, 881, 588, 262, 31993, 1429, 287, 10087, 764, 220, 198, 16749, 265, 3301, 9653, 423, 257, 2705, 837, 38414, 2488, 12, 31, 588, 7582, 764, 632, 2753, 262, 12366, 1022, 530, 290, 1115, 812, 284, 2148, 9653, 351, 331, 13597, 837, 290, 510, 284, 3598, 1933, 284, 1296, 262, 7582, 764, 632, 788, 2753, 1022, 1105, 290, 1315, 1933, 422, 2243, 1741, 284, 289, 19775, 764, 770, 1724, 20728, 8833, 379, 734, 12, 284, 1936, 2488, 12, 31, 614, 20016, 837, 262, 3105, 395, 287, 597, 28761, 576, 764, 6183, 12777, 265, 3301, 389, 1900, 284, 307, 991, 8186, 2259, 379, 546, 3126, 812, 286, 2479, 2162, 366, 8616, 366, 837, 257, 4257, 12777, 265, 3301, 379, 2520, 1044, 9594, 287, 554, 332, 66, 853, 359, 837, 968, 8936, 837, 2627, 257, 2988, 357, 5457, 329, 262, 717, 640, 1267, 319, 2242, 3269, 3717, 837, 379, 262, 2479, 286, 13374, 764, 220, 198, 383, 1714, 286, 257, 25834, 1359, 8338, 319, 262, 5951, 286, 262, 5935, 837, 351, 23254, 9653, 44681, 284, 4439, 4257, 12777, 265, 3301, 837, 290, 19346, 9653, 9194, 12366, 764, 40433, 25543, 515, 379, 2310, 22074, 327, 357, 4317, 22074, 376, 1267, 423, 281, 4961, 2863, 286, 852, 4257, 393, 4048, 764, 2102, 837, 379, 2534, 22074, 327, 357, 7724, 22074, 376, 1267, 837, 4019, 4064, 389, 1884, 284, 307, 10835, 837, 290, 379, 1160, 22074, 327, 357, 8257, 22074, 376, 1267, 837, 4019, 4064, 389, 1884, 284, 307, 12366, 2162, 379, 1248, 22074, 327, 357, 5598, 22074, 376, 1267, 477, 25834, 17783, 481, 307, 12366, 764, 2773, 2370, 9217, 1714, 12123, 287, 12777, 265, 3301, 318, 5295, 416, 1111, 8513, 290, 6142, 5087, 764, 220, 198, 16749, 265, 3301, 2192, 423, 262, 3105, 395, 3349, 3965, 286, 597, 28761, 576, 837, 8282, 284, 1663, 4025, 329, 262, 717, 3439, 812, 286, 511, 3160, 764, 383, 2811, 30458, 318, 546, 3126, 812, 837, 475, 484, 460, 2107, 284, 307, 880, 625, 1802, 812, 1468, 764, 2773, 6154, 1975, 326, 25798, 12777, 265, 3301, 714, 2107, 355, 890, 355, 939, 812, 764, 220, 198, 220, 198, 796, 796, 23702, 796, 796, 220, 198, 220, 198, 220, 198, 796, 796, 796, 27484, 290, 7432, 796, 796, 796, 220, 198, 220, 198, 16749, 265, 3301, 547, 1752, 10095, 319, 968, 8936, 705, 82, 1388, 2258, 290, 2520, 12010, 837, 810, 850, 69, 793, 346, 3793, 423, 587, 1043, 287, 6450, 288, 4015, 837, 30923, 837, 290, 337, 10235, 10145, 285, 1638, 641, 764, 370, 46647, 503, 422, 262, 1388, 14807, 878, 3427, 9443, 837, 484, 547, 890, 19733, 284, 3933, 18479, 14807, 1479, 286, 23426, 764, 383, 14807, 389, 2408, 284, 651, 284, 837, 290, 389, 7633, 1417, 416, 1178, 5044, 4693, 837, 12739, 326, 617, 4695, 13717, 422, 777, 14807, 743, 423, 4073, 12777, 265, 3301, 284, 10921, 422, 262, 22779, 764, 2102, 837, 1279, 2954, 29, 357, 12280, 2516, 666, 13623, 1267, 550, 2904, 1716, 4920, 319, 1811, 286, 262, 14807, 837, 290, 12777, 265]}.
04/09/2023 01:44:53 - INFO - __main__ - Sample 103786 of the training set: {'input_ids': [220, 198, 796, 796, 796, 14056, 796, 796, 796, 220, 198, 220, 198, 554, 465, 2457, 5668, 1492, 837, 14056, 290, 14056, 15538, 1058, 1052, 11985, 323, 287, 13005, 48909, 357, 6244, 1267, 837, 6484, 21079, 262, 734, 4096, 3815, 286, 3872, 355, 9922, 290, 44053, 837, 290, 8404, 284, 2209, 262, 41593, 1022, 262, 3512, 329, 3872, 290, 262, 4719, 326, 597, 884, 1517, 7160, 764, 12091, 440, 705, 8642, 4597, 2630, 287, 257, 8283, 909, 270, 2838, 286, 6484, 326, 262, 1492, 318, 281, 12452, 286, 883, 508, 366, 10505, 263, 379, 597, 23236, 3872, 355, 35214, 306, 24354, 780, 340, 318, 837, 16857, 837, 26987, 416, 1176, 837, 1398, 10690, 290, 12959, 764, 366, 220, 198, 383, 5057, 284, 40258, 318, 1598, 837, 749, 6189, 287, 262, 12695, 286, 257, 9779, 11794, 605, 2446, 355, 257, 2891, 286, 7468, 290, 19976, 764, 4900, 636, 286, 6484, 705, 82, 6778, 373, 284, 1368, 883, 339, 2936, 6699, 262, 1988, 286, 3872, 837, 262, 1492, 1275, 3508, 326, 837, 284, 1833, 340, 2391, 287, 326, 2565, 837, 561, 307, 284, 2051, 636, 286, 663, 4007, 2162, 2138, 837, 355, 23632, 14372, 2630, 837, 340, 318, 366, 6484, 705, 14580, 319, 262, 6573, 1575, 286, 262, 9028, 410, 5119, 329, 18905, 278, 351, 262, 3721, 286, 3872, 764, 366, 220, 198, 220, 198, 796, 796, 14843, 796, 796, 220, 198, 220, 198, 6484, 750, 407, 18077, 597, 17895, 17580, 4583, 2162, 5600, 837, 339, 373, 13678, 286, 597, 884, 2230, 764, 679, 2627, 1900, 329, 465, 23637, 605, 5635, 837, 3584, 339, 373, 13678, 286, 606, 1165, 764, 12246, 6127, 2630, 326, 6484, 550, 1239, 587, 366, 12617, 416, 262, 3359, 286, 5019, 23637, 605, 1190, 933, 408, 837, 1551, 286, 477, 287, 6573, 8876, 366, 1058, 220, 198, 1550, 262, 10388, 837, 530, 286, 262, 749, 12411, 3033, 286, 465, 17580, 19360, 373, 281, 7379, 42610, 30696, 319, 257, 2168, 286, 2173, 326, 743, 1283, 3489, 475, 543, 389, 19032, 477, 2488, 12, 31, 1165, 2488, 12, 31, 6777, 24007, 1058, 326, 6573, 393, 15028, 1807, 318, 636, 286, 1692, 1204, 2162, 326, 287, 3597, 546, 340, 837, 24858, 389, 3597, 546, 1223, 286, 8768, 6817, 2162, 326, 340, 318, 407, 2562, 284, 910, 1997, 2861, 2282, 546, 262, 2426, 2162, 326, 644, 6573, 24858, 3551, 318, 3280, 540, 284, 262, 22072, 286, 1692, 2106, 837, 15119, 837, 290, 1919, 9674, 2162, 290, 326, 5019, 1190, 933, 408, 318, 5600, 407, 262, 5981, 3953, 286, 1988, 764, 366, 220, 198, 554, 8235, 5780, 11806, 271, 531, 326, 6484, 550, 366, 257, 922, 1624, 284, 307, 262, 3756, 3517, 23723, 286, 465, 1110, 837, 366, 475, 326, 837, 3584, 339, 550, 257, 366, 14081, 4151, 329, 262, 4318, 2683, 837, 366, 339, 550, 4844, 286, 262, 7429, 764, 12246, 5658, 5174, 6484, 705, 82, 10156, 284, 14458, 355, 281, 43247, 30186, 11965, 546, 6370, 284, 2251, 257, 8489, 329, 6573, 8876, 837, 11777, 36877, 287, 25092, 290, 262, 44943, 286, 26099, 357, 12863, 1267, 290, 48266, 290, 19652, 408, 414, 357, 9656, 1267, 837, 287, 543, 339, 7189, 326, 6573, 10946, 460, 1239, 4079, 262, 42292, 286, 1204, 837, 3573, 1813, 262, 7702, 22801, 1042, 286, 3660, 14515, 764, 220, 198, 18252, 284, 307, 3511, 837, 284, 307, 16425, 290, 284, 719, 351, 11540, 837, 2138, 621, 369, 15464, 284, 597, 7097, 6573, 1080, 837, 318, 15242, 262, 7531, 32702, 286, 6484, 705, 82, 670, 837, 1864, 284, 35331, 16156, 609, 1324, 695, 764, 366, 1002, 612, 705, 82, 530, 7505, 287, 477, 616, 670, 340, 705, 82, 546, 26275, 290, 2116, 2488, 12, 31, 5408, 837, 366, 6484, 531, 287, 6244, 764, 366, 632, 705, 82, 262, 2126, 326, 617, 1243, 389, 287, 617, 1103, 2565, 1107, 345, 837, 393, 4911, 644, 345, 290, 1854, 3588, 705, 83, 2644, 383, 2187, 1517, 468, 587, 546, 24993, 503, 262, 9495, 286, 8434, 14564, 764, 366, 679, 3888, 6573, 8876, 1497, 422, 262, 29576, 666, 1808, 837, 366, 1867, 318, 616, 7077, 5633, 366, 837, 290, 736, 284, 262, 2071, 326, 33343, 284, 262, 25059, 1058, 366, 1374, 815, 356, 2107, 5633, 366, 220, 198, 220, 198, 796, 796, 40865, 796, 796, 220, 198, 220, 198, 41344, 9473, 220, 198, 220, 198, 220, 198, 796, 10836, 16712, 796, 220, 198, 220, 198, 10836, 16712, 357, 23618, 1058, 1279, 2954, 29, 1279, 2954, 29, 1279, 2954, 29, 2264, 157, 119, 239, 66, 308, 544, 16049, 157, 119, 229, 83, 17871, 1267, 318, 262, 6056, 11920, 286, 10836, 764, 4062, 276, 287, 25190, 739, 262, 1438, 10836, 7511, 25186, 837, 262, 18091, 373, 4920, 355, 257, 1181, 2488, 12, 31, 6898, 13953, 287, 3035, 11104, 764, 10836, 16712, 318, 48583, 287, 5882, 347, 2013, 5665, 837, 367, 5733, 72, 837, 351, 38459, 379, 1400, 72, 40750, 4037, 12690, 290, 11818, 6295, 399, 5183, 4037, 12690, 764, 383, 18091, 17607, 284, 6740, 23982, 287, 1596, 2678, 837, 23494, 1279, 2954, 29, 2594, 764, 220, 198, 3574, 663, 30839, 1566, 262, 1903, 6303, 82, 837, 10836, 16712, 373, 257, 4159, 11920, 1626, 262, 22548, 2831, 355, 340, 373, 42629, 416, 257, 4996, 286, 5087, 1390, 262, 21790, 2488, 12, 31, 3034, 290, 1964, 3074, 286, 262, 1499, 764, 2080, 262, 1230, 705, 82, 3487, 1634, 286, 2316, 351, 262, 1578, 1829, 837, 262, 18091, 373, 1498, 284, 4292, 837, 2987, 663, 3186, 290, 2594, 837, 290, 3660, 1096, 663, 41310, 11026, 764, 554, 8235, 837, 262, 23618, 1230, 3181, 1978, 1160, 2139, 2706, 284, 1296, 10836, 16712, 10501, 837, 351, 262, 18091, 2346, 355, 262, 7372, 12239, 764, 554, 3050, 837, 262, 12017, 373, 27596, 1522, 656, 257, 3614, 12247, 1664, 290, 25121, 10836, 16712, 5834, 15302, 764, 317, 3598, 2488, 12, 31, 5852, 4542, 3096, 837, 1866, 286, 543, 389, 9899, 416, 262, 23618, 5537, 4139, 837, 31806, 262, 1664, 764, 220, 198, 1081, 11849, 4839, 19300, 663, 4755, 3842, 837, 10836, 16712, 5341, 257, 8780, 2597, 287, 262, 3034, 2478, 286, 262, 1499, 764, 632, 12216, 1802, 4064, 286, 10836, 3701, 4809, 5834, 784, 257, 7915, 18091, 287, 8372, 10836, 837, 4317, 4064, 286, 262, 1877, 2488], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [220, 198, 796, 796, 796, 14056, 796, 796, 796, 220, 198, 220, 198, 554, 465, 2457, 5668, 1492, 837, 14056, 290, 14056, 15538, 1058, 1052, 11985, 323, 287, 13005, 48909, 357, 6244, 1267, 837, 6484, 21079, 262, 734, 4096, 3815, 286, 3872, 355, 9922, 290, 44053, 837, 290, 8404, 284, 2209, 262, 41593, 1022, 262, 3512, 329, 3872, 290, 262, 4719, 326, 597, 884, 1517, 7160, 764, 12091, 440, 705, 8642, 4597, 2630, 287, 257, 8283, 909, 270, 2838, 286, 6484, 326, 262, 1492, 318, 281, 12452, 286, 883, 508, 366, 10505, 263, 379, 597, 23236, 3872, 355, 35214, 306, 24354, 780, 340, 318, 837, 16857, 837, 26987, 416, 1176, 837, 1398, 10690, 290, 12959, 764, 366, 220, 198, 383, 5057, 284, 40258, 318, 1598, 837, 749, 6189, 287, 262, 12695, 286, 257, 9779, 11794, 605, 2446, 355, 257, 2891, 286, 7468, 290, 19976, 764, 4900, 636, 286, 6484, 705, 82, 6778, 373, 284, 1368, 883, 339, 2936, 6699, 262, 1988, 286, 3872, 837, 262, 1492, 1275, 3508, 326, 837, 284, 1833, 340, 2391, 287, 326, 2565, 837, 561, 307, 284, 2051, 636, 286, 663, 4007, 2162, 2138, 837, 355, 23632, 14372, 2630, 837, 340, 318, 366, 6484, 705, 14580, 319, 262, 6573, 1575, 286, 262, 9028, 410, 5119, 329, 18905, 278, 351, 262, 3721, 286, 3872, 764, 366, 220, 198, 220, 198, 796, 796, 14843, 796, 796, 220, 198, 220, 198, 6484, 750, 407, 18077, 597, 17895, 17580, 4583, 2162, 5600, 837, 339, 373, 13678, 286, 597, 884, 2230, 764, 679, 2627, 1900, 329, 465, 23637, 605, 5635, 837, 3584, 339, 373, 13678, 286, 606, 1165, 764, 12246, 6127, 2630, 326, 6484, 550, 1239, 587, 366, 12617, 416, 262, 3359, 286, 5019, 23637, 605, 1190, 933, 408, 837, 1551, 286, 477, 287, 6573, 8876, 366, 1058, 220, 198, 1550, 262, 10388, 837, 530, 286, 262, 749, 12411, 3033, 286, 465, 17580, 19360, 373, 281, 7379, 42610, 30696, 319, 257, 2168, 286, 2173, 326, 743, 1283, 3489, 475, 543, 389, 19032, 477, 2488, 12, 31, 1165, 2488, 12, 31, 6777, 24007, 1058, 326, 6573, 393, 15028, 1807, 318, 636, 286, 1692, 1204, 2162, 326, 287, 3597, 546, 340, 837, 24858, 389, 3597, 546, 1223, 286, 8768, 6817, 2162, 326, 340, 318, 407, 2562, 284, 910, 1997, 2861, 2282, 546, 262, 2426, 2162, 326, 644, 6573, 24858, 3551, 318, 3280, 540, 284, 262, 22072, 286, 1692, 2106, 837, 15119, 837, 290, 1919, 9674, 2162, 290, 326, 5019, 1190, 933, 408, 318, 5600, 407, 262, 5981, 3953, 286, 1988, 764, 366, 220, 198, 554, 8235, 5780, 11806, 271, 531, 326, 6484, 550, 366, 257, 922, 1624, 284, 307, 262, 3756, 3517, 23723, 286, 465, 1110, 837, 366, 475, 326, 837, 3584, 339, 550, 257, 366, 14081, 4151, 329, 262, 4318, 2683, 837, 366, 339, 550, 4844, 286, 262, 7429, 764, 12246, 5658, 5174, 6484, 705, 82, 10156, 284, 14458, 355, 281, 43247, 30186, 11965, 546, 6370, 284, 2251, 257, 8489, 329, 6573, 8876, 837, 11777, 36877, 287, 25092, 290, 262, 44943, 286, 26099, 357, 12863, 1267, 290, 48266, 290, 19652, 408, 414, 357, 9656, 1267, 837, 287, 543, 339, 7189, 326, 6573, 10946, 460, 1239, 4079, 262, 42292, 286, 1204, 837, 3573, 1813, 262, 7702, 22801, 1042, 286, 3660, 14515, 764, 220, 198, 18252, 284, 307, 3511, 837, 284, 307, 16425, 290, 284, 719, 351, 11540, 837, 2138, 621, 369, 15464, 284, 597, 7097, 6573, 1080, 837, 318, 15242, 262, 7531, 32702, 286, 6484, 705, 82, 670, 837, 1864, 284, 35331, 16156, 609, 1324, 695, 764, 366, 1002, 612, 705, 82, 530, 7505, 287, 477, 616, 670, 340, 705, 82, 546, 26275, 290, 2116, 2488, 12, 31, 5408, 837, 366, 6484, 531, 287, 6244, 764, 366, 632, 705, 82, 262, 2126, 326, 617, 1243, 389, 287, 617, 1103, 2565, 1107, 345, 837, 393, 4911, 644, 345, 290, 1854, 3588, 705, 83, 2644, 383, 2187, 1517, 468, 587, 546, 24993, 503, 262, 9495, 286, 8434, 14564, 764, 366, 679, 3888, 6573, 8876, 1497, 422, 262, 29576, 666, 1808, 837, 366, 1867, 318, 616, 7077, 5633, 366, 837, 290, 736, 284, 262, 2071, 326, 33343, 284, 262, 25059, 1058, 366, 1374, 815, 356, 2107, 5633, 366, 220, 198, 220, 198, 796, 796, 40865, 796, 796, 220, 198, 220, 198, 41344, 9473, 220, 198, 220, 198, 220, 198, 796, 10836, 16712, 796, 220, 198, 220, 198, 10836, 16712, 357, 23618, 1058, 1279, 2954, 29, 1279, 2954, 29, 1279, 2954, 29, 2264, 157, 119, 239, 66, 308, 544, 16049, 157, 119, 229, 83, 17871, 1267, 318, 262, 6056, 11920, 286, 10836, 764, 4062, 276, 287, 25190, 739, 262, 1438, 10836, 7511, 25186, 837, 262, 18091, 373, 4920, 355, 257, 1181, 2488, 12, 31, 6898, 13953, 287, 3035, 11104, 764, 10836, 16712, 318, 48583, 287, 5882, 347, 2013, 5665, 837, 367, 5733, 72, 837, 351, 38459, 379, 1400, 72, 40750, 4037, 12690, 290, 11818, 6295, 399, 5183, 4037, 12690, 764, 383, 18091, 17607, 284, 6740, 23982, 287, 1596, 2678, 837, 23494, 1279, 2954, 29, 2594, 764, 220, 198, 3574, 663, 30839, 1566, 262, 1903, 6303, 82, 837, 10836, 16712, 373, 257, 4159, 11920, 1626, 262, 22548, 2831, 355, 340, 373, 42629, 416, 257, 4996, 286, 5087, 1390, 262, 21790, 2488, 12, 31, 3034, 290, 1964, 3074, 286, 262, 1499, 764, 2080, 262, 1230, 705, 82, 3487, 1634, 286, 2316, 351, 262, 1578, 1829, 837, 262, 18091, 373, 1498, 284, 4292, 837, 2987, 663, 3186, 290, 2594, 837, 290, 3660, 1096, 663, 41310, 11026, 764, 554, 8235, 837, 262, 23618, 1230, 3181, 1978, 1160, 2139, 2706, 284, 1296, 10836, 16712, 10501, 837, 351, 262, 18091, 2346, 355, 262, 7372, 12239, 764, 554, 3050, 837, 262, 12017, 373, 27596, 1522, 656, 257, 3614, 12247, 1664, 290, 25121, 10836, 16712, 5834, 15302, 764, 317, 3598, 2488, 12, 31, 5852, 4542, 3096, 837, 1866, 286, 543, 389, 9899, 416, 262, 23618, 5537, 4139, 837, 31806, 262, 1664, 764, 220, 198, 1081, 11849, 4839, 19300, 663, 4755, 3842, 837, 10836, 16712, 5341, 257, 8780, 2597, 287, 262, 3034, 2478, 286, 262, 1499, 764, 632, 12216, 1802, 4064, 286, 10836, 3701, 4809, 5834, 784, 257, 7915, 18091, 287, 8372, 10836, 837, 4317, 4064, 286, 262, 1877, 2488]}.
04/09/2023 01:44:53 - INFO - __main__ - Sample 37331 of the training set: {'input_ids': [25190, 764, 1119, 550, 257, 3367, 837, 3700, 16653, 65, 1039, 764, 220, 198, 554, 3269, 24648, 837, 16653, 65, 1039, 2627, 11561, 286, 262, 718, 400, 3701, 7458, 379, 4100, 35, 359, 3701, 5221, 7308, 837, 1279, 2954, 29, 290, 373, 13722, 284, 24393, 38868, 2276, 287, 23859, 764, 770, 373, 3940, 416, 1194, 4205, 286, 7077, 379, 262, 12651, 355, 3437, 286, 8549, 14691, 764, 554, 2901, 20033, 837, 339, 373, 8686, 284, 262, 16798, 18733, 286, 9983, 355, 10636, 3437, 329, 4560, 837, 290, 788, 837, 287, 2795, 19342, 837, 355, 10636, 3437, 329, 262, 2351, 12842, 9455, 4482, 764, 554, 17575, 837, 16653, 65, 1039, 373, 3706, 2422, 10199, 2634, 287, 3794, 764, 679, 3377, 2534, 1933, 612, 319, 428, 10754, 837, 543, 4444, 287, 2795, 19322, 764, 679, 9880, 422, 262, 1578, 1829, 3701, 5221, 357, 45353, 1267, 319, 3261, 2932, 19322, 764, 220, 198, 220, 198, 796, 796, 11450, 1204, 290, 1918, 796, 796, 220, 198, 220, 198, 2293, 465, 10737, 422, 262, 3701, 5221, 837, 16653, 65, 1039, 3111, 329, 10390, 19013, 25186, 357, 412, 37048, 1267, 837, 281, 1633, 17536, 1664, 1912, 287, 14939, 837, 6835, 837, 290, 783, 1444, 3433, 41, 1039, 764, 679, 7482, 284, 9117, 262, 1664, 705, 82, 4560, 284, 2031, 837, 475, 373, 23993, 764, 679, 9880, 422, 262, 1664, 287, 15963, 837, 290, 4504, 284, 8437, 837, 4744, 837, 810, 339, 550, 3377, 636, 286, 465, 9963, 764, 383, 6341, 1674, 20225, 319, 412, 37048, 287, 8069, 837, 290, 11088, 3309, 75, 403, 2627, 1893, 764, 3309, 75, 403, 41546, 16653, 65, 1039, 736, 284, 412, 37048, 326, 614, 764, 16653, 65, 1039, 14131, 3309, 75, 403, 355, 1893, 319, 2310, 3035, 15408, 837, 290, 6150, 287, 262, 2597, 1566, 12113, 764, 679, 4983, 329, 257, 614, 355, 257, 17028, 878, 465, 1218, 290, 2457, 10737, 422, 412, 37048, 287, 12923, 764, 220, 198, 14488, 12996, 2826, 16653, 65, 1039, 287, 262, 2646, 383, 25976, 393, 262, 5268, 357, 21709, 1267, 764, 23302, 290, 12197, 357, 26352, 1267, 18904, 262, 2159, 1810, 2873, 2995, 7411, 16653, 65, 1039, 837, 351, 5199, 8121, 20495, 355, 16653, 65, 1039, 290, 45566, 13612, 355, 465, 717, 3656, 22162, 764, 16653, 65, 1039, 373, 635, 262, 2746, 329, 3159, 16002, 1632, 13167, 15503, 705, 82, 19812, 2095, 366, 8386, 5689, 31868, 366, 287, 262, 2646, 30775, 440, 705, 44758, 3334, 837, 290, 329, 257, 4506, 2278, 287, 3945, 24977, 373, 23488, 284, 307, 262, 2646, 705, 82, 6276, 20685, 1566, 465, 9014, 379, 262, 938, 5664, 416, 21636, 1757, 367, 13, 1279, 2954, 29, 764, 2039, 5708, 16013, 1058, 383, 6065, 837, 262, 12633, 837, 262, 28976, 14476, 837, 257, 7169, 925, 2488, 12, 31, 329, 2488, 12, 31, 5581, 3807, 837, 6454, 19812, 1143, 837, 1297, 262, 1621, 286, 16653, 65, 1039, 5462, 764, 9925, 35829, 2826, 16653, 65, 1039, 290, 6502, 7491, 1525, 2826, 22162, 764, 220, 198, 554, 584, 19812, 10993, 874, 837, 20320, 1279, 2954, 29, 373, 16653, 65, 1039, 287, 262, 2646, 3596, 1881, 837, 3271, 41396, 2826, 683, 287, 262, 8735, 3195, 3807, 42922, 837, 290, 12930, 18193, 2826, 262, 636, 287, 262, 7823, 705, 82, 5075, 3195, 2205, 463, 20058, 42922, 837, 329, 543, 16653, 65, 1039, 373, 635, 12299, 319, 4676, 764, 1052, 2720, 351, 16653, 65, 1039, 635, 4120, 287, 262, 14489, 3807, 28976, 26965, 837, 355, 880, 355, 373, 287, 262, 8069, 82, 3517, 11648, 2168, 383, 2159, 379, 1810, 837, 290, 262, 366, 6065, 5338, 347, 2909, 262, 12258, 366, 4471, 286, 262, 40131, 27862, 705, 1810, 18152, 357, 8735, 1267, 764, 16653, 65, 1039, 11638, 5688, 287, 262, 4751, 1492, 18104, 1058, 317, 9190, 837, 2399, 6295, 290, 262, 1869, 5338, 23306, 262, 1810, 416, 5811, 28132, 286, 262, 4842, 17588, 764, 220, 198, 383, 1578, 1829, 1230, 22893, 284, 2869, 287, 15408, 706, 16653, 65, 1039, 302, 2488, 12, 31, 17814, 262, 13471, 287, 257, 15032, 347, 2488, 12, 31, 2808, 379, 281, 1633, 905, 287, 3936, 837, 1844, 351, 257, 28520, 6279, 764, 679, 531, 326, 339, 550, 407, 4001, 329, 262, 302, 2488, 12, 31, 28547, 284, 423, 587, 281, 13277, 284, 262, 4960, 764, 554, 8735, 837, 339, 26443, 262, 2026, 400, 11162, 17127, 286, 262, 2039, 5708, 16013, 379, 262, 40131, 29426, 837, 543, 7482, 284, 1944, 262, 13471, 287, 4732, 351, 262, 8166, 340, 4073, 837, 355, 257, 366, 12270, 1263, 13277, 366, 837, 2233, 284, 663, 2962, 319, 262, 4960, 18499, 2138, 621, 262, 24557, 286, 262, 4960, 1230, 764, 679, 373, 28948, 276, 656, 262, 2351, 25186, 4789, 286, 18864, 287, 8235, 764, 220, 198, 16653, 65, 1039, 705, 82, 31845, 3362, 370, 13, 16653, 65, 1039, 8363, 18303, 422, 262, 1578, 1829, 3701, 5221, 8581, 287, 11104, 837, 290, 287, 3035, 4793, 2627, 11561, 286, 262, 5014, 18, 67, 14476, 27242, 837, 7348, 262, 347, 2488, 12, 31, 362, 7710, 379, 13183, 8463, 43827, 837, 11565, 764, 383, 40733, 373, 530, 286, 262, 734, 13919, 8244, 12212, 326, 550, 7042, 636, 286, 262, 2026, 24, 400, 49355, 4912, 618, 16653, 65, 1039, 22419, 340, 764, 3362, 16653, 65, 1039, 8363, 373, 13722, 284, 24393, 38868, 2276, 287, 1946, 837, 290, 2627, 15110, 5890, 329, 19229, 16205, 379, 262, 8060, 16205, 44437, 286, 262, 1578, 1829, 24999, 9455, 379, 3242, 15318, 3701, 5221, 7308, 287, 18329, 764, 1081, 884, 837, 339, 373, 4497, 329, 2253, 705, 82, 10039, 4523, 3386, 764, 1550, 642, 2795, 1853, 837, 339, 9672, 3141, 286, 262, 2026, 24, 400, 14476, 13405, 764, 220, 198, 16653, 65, 1039, 3724, 287, 465, 14939, 837, 6835, 837, 1363, 319, 352, 3389, 4343, 837, 379, 262, 2479, 286, 10190, 764, 679, 550, 6989, 1402, 29483, 290, 2612, 5287, 1141, 465, 2457, 812, 290, 550, 587, 287, 10496, 501, 1337, 764, 679, 373, 11803, 416, 465, 4141, 2488, 12, 31, 4642, 3656, 837, 23174, 837, 290, 734, 11989, 422, 465, 717, 4845, 837, 3362, 6711, 290, 13005, 355, 880, 355, 465, 3367, 837, 3700, 837, 422, 465, 1218, 4845, 764, 16653, 65, 1039, 550, 1965, 329, 645, 14825, 4249, 1182, 6440, 355, 339, 15240], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [25190, 764, 1119, 550, 257, 3367, 837, 3700, 16653, 65, 1039, 764, 220, 198, 554, 3269, 24648, 837, 16653, 65, 1039, 2627, 11561, 286, 262, 718, 400, 3701, 7458, 379, 4100, 35, 359, 3701, 5221, 7308, 837, 1279, 2954, 29, 290, 373, 13722, 284, 24393, 38868, 2276, 287, 23859, 764, 770, 373, 3940, 416, 1194, 4205, 286, 7077, 379, 262, 12651, 355, 3437, 286, 8549, 14691, 764, 554, 2901, 20033, 837, 339, 373, 8686, 284, 262, 16798, 18733, 286, 9983, 355, 10636, 3437, 329, 4560, 837, 290, 788, 837, 287, 2795, 19342, 837, 355, 10636, 3437, 329, 262, 2351, 12842, 9455, 4482, 764, 554, 17575, 837, 16653, 65, 1039, 373, 3706, 2422, 10199, 2634, 287, 3794, 764, 679, 3377, 2534, 1933, 612, 319, 428, 10754, 837, 543, 4444, 287, 2795, 19322, 764, 679, 9880, 422, 262, 1578, 1829, 3701, 5221, 357, 45353, 1267, 319, 3261, 2932, 19322, 764, 220, 198, 220, 198, 796, 796, 11450, 1204, 290, 1918, 796, 796, 220, 198, 220, 198, 2293, 465, 10737, 422, 262, 3701, 5221, 837, 16653, 65, 1039, 3111, 329, 10390, 19013, 25186, 357, 412, 37048, 1267, 837, 281, 1633, 17536, 1664, 1912, 287, 14939, 837, 6835, 837, 290, 783, 1444, 3433, 41, 1039, 764, 679, 7482, 284, 9117, 262, 1664, 705, 82, 4560, 284, 2031, 837, 475, 373, 23993, 764, 679, 9880, 422, 262, 1664, 287, 15963, 837, 290, 4504, 284, 8437, 837, 4744, 837, 810, 339, 550, 3377, 636, 286, 465, 9963, 764, 383, 6341, 1674, 20225, 319, 412, 37048, 287, 8069, 837, 290, 11088, 3309, 75, 403, 2627, 1893, 764, 3309, 75, 403, 41546, 16653, 65, 1039, 736, 284, 412, 37048, 326, 614, 764, 16653, 65, 1039, 14131, 3309, 75, 403, 355, 1893, 319, 2310, 3035, 15408, 837, 290, 6150, 287, 262, 2597, 1566, 12113, 764, 679, 4983, 329, 257, 614, 355, 257, 17028, 878, 465, 1218, 290, 2457, 10737, 422, 412, 37048, 287, 12923, 764, 220, 198, 14488, 12996, 2826, 16653, 65, 1039, 287, 262, 2646, 383, 25976, 393, 262, 5268, 357, 21709, 1267, 764, 23302, 290, 12197, 357, 26352, 1267, 18904, 262, 2159, 1810, 2873, 2995, 7411, 16653, 65, 1039, 837, 351, 5199, 8121, 20495, 355, 16653, 65, 1039, 290, 45566, 13612, 355, 465, 717, 3656, 22162, 764, 16653, 65, 1039, 373, 635, 262, 2746, 329, 3159, 16002, 1632, 13167, 15503, 705, 82, 19812, 2095, 366, 8386, 5689, 31868, 366, 287, 262, 2646, 30775, 440, 705, 44758, 3334, 837, 290, 329, 257, 4506, 2278, 287, 3945, 24977, 373, 23488, 284, 307, 262, 2646, 705, 82, 6276, 20685, 1566, 465, 9014, 379, 262, 938, 5664, 416, 21636, 1757, 367, 13, 1279, 2954, 29, 764, 2039, 5708, 16013, 1058, 383, 6065, 837, 262, 12633, 837, 262, 28976, 14476, 837, 257, 7169, 925, 2488, 12, 31, 329, 2488, 12, 31, 5581, 3807, 837, 6454, 19812, 1143, 837, 1297, 262, 1621, 286, 16653, 65, 1039, 5462, 764, 9925, 35829, 2826, 16653, 65, 1039, 290, 6502, 7491, 1525, 2826, 22162, 764, 220, 198, 554, 584, 19812, 10993, 874, 837, 20320, 1279, 2954, 29, 373, 16653, 65, 1039, 287, 262, 2646, 3596, 1881, 837, 3271, 41396, 2826, 683, 287, 262, 8735, 3195, 3807, 42922, 837, 290, 12930, 18193, 2826, 262, 636, 287, 262, 7823, 705, 82, 5075, 3195, 2205, 463, 20058, 42922, 837, 329, 543, 16653, 65, 1039, 373, 635, 12299, 319, 4676, 764, 1052, 2720, 351, 16653, 65, 1039, 635, 4120, 287, 262, 14489, 3807, 28976, 26965, 837, 355, 880, 355, 373, 287, 262, 8069, 82, 3517, 11648, 2168, 383, 2159, 379, 1810, 837, 290, 262, 366, 6065, 5338, 347, 2909, 262, 12258, 366, 4471, 286, 262, 40131, 27862, 705, 1810, 18152, 357, 8735, 1267, 764, 16653, 65, 1039, 11638, 5688, 287, 262, 4751, 1492, 18104, 1058, 317, 9190, 837, 2399, 6295, 290, 262, 1869, 5338, 23306, 262, 1810, 416, 5811, 28132, 286, 262, 4842, 17588, 764, 220, 198, 383, 1578, 1829, 1230, 22893, 284, 2869, 287, 15408, 706, 16653, 65, 1039, 302, 2488, 12, 31, 17814, 262, 13471, 287, 257, 15032, 347, 2488, 12, 31, 2808, 379, 281, 1633, 905, 287, 3936, 837, 1844, 351, 257, 28520, 6279, 764, 679, 531, 326, 339, 550, 407, 4001, 329, 262, 302, 2488, 12, 31, 28547, 284, 423, 587, 281, 13277, 284, 262, 4960, 764, 554, 8735, 837, 339, 26443, 262, 2026, 400, 11162, 17127, 286, 262, 2039, 5708, 16013, 379, 262, 40131, 29426, 837, 543, 7482, 284, 1944, 262, 13471, 287, 4732, 351, 262, 8166, 340, 4073, 837, 355, 257, 366, 12270, 1263, 13277, 366, 837, 2233, 284, 663, 2962, 319, 262, 4960, 18499, 2138, 621, 262, 24557, 286, 262, 4960, 1230, 764, 679, 373, 28948, 276, 656, 262, 2351, 25186, 4789, 286, 18864, 287, 8235, 764, 220, 198, 16653, 65, 1039, 705, 82, 31845, 3362, 370, 13, 16653, 65, 1039, 8363, 18303, 422, 262, 1578, 1829, 3701, 5221, 8581, 287, 11104, 837, 290, 287, 3035, 4793, 2627, 11561, 286, 262, 5014, 18, 67, 14476, 27242, 837, 7348, 262, 347, 2488, 12, 31, 362, 7710, 379, 13183, 8463, 43827, 837, 11565, 764, 383, 40733, 373, 530, 286, 262, 734, 13919, 8244, 12212, 326, 550, 7042, 636, 286, 262, 2026, 24, 400, 49355, 4912, 618, 16653, 65, 1039, 22419, 340, 764, 3362, 16653, 65, 1039, 8363, 373, 13722, 284, 24393, 38868, 2276, 287, 1946, 837, 290, 2627, 15110, 5890, 329, 19229, 16205, 379, 262, 8060, 16205, 44437, 286, 262, 1578, 1829, 24999, 9455, 379, 3242, 15318, 3701, 5221, 7308, 287, 18329, 764, 1081, 884, 837, 339, 373, 4497, 329, 2253, 705, 82, 10039, 4523, 3386, 764, 1550, 642, 2795, 1853, 837, 339, 9672, 3141, 286, 262, 2026, 24, 400, 14476, 13405, 764, 220, 198, 16653, 65, 1039, 3724, 287, 465, 14939, 837, 6835, 837, 1363, 319, 352, 3389, 4343, 837, 379, 262, 2479, 286, 10190, 764, 679, 550, 6989, 1402, 29483, 290, 2612, 5287, 1141, 465, 2457, 812, 290, 550, 587, 287, 10496, 501, 1337, 764, 679, 373, 11803, 416, 465, 4141, 2488, 12, 31, 4642, 3656, 837, 23174, 837, 290, 734, 11989, 422, 465, 717, 4845, 837, 3362, 6711, 290, 13005, 355, 880, 355, 465, 3367, 837, 3700, 837, 422, 465, 1218, 4845, 764, 16653, 65, 1039, 550, 1965, 329, 645, 14825, 4249, 1182, 6440, 355, 339, 15240]}.
                                                                                                                                                                                                        04/09/2023 01:44:57 - INFO - __main__ - ***** Running training *****
04/09/2023 01:44:57 - INFO - __main__ -   Num examples = 115366
04/09/2023 01:44:57 - INFO - __main__ -   Num Epochs = 1
04/09/2023 01:44:57 - INFO - __main__ -   Instantaneous batch size per device = 1
04/09/2023 01:44:57 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 256
04/09/2023 01:44:57 - INFO - __main__ -   Gradient Accumulation steps = 64
04/09/2023 01:44:57 - INFO - __main__ -   Total optimization steps = 451
  0%|          | 0/451 [00:00<?, ?it/s]04/09/2023 01:45:02 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:45:16 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:45:16 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:45:16 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:45:16 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:45:16 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:45:17 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:45:33 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:45:33 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:45:33 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:45:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:45:33 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:45:33 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:45:43 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:45:43 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:45:43 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:45:43 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:45:43 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:45:43 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:45:56 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:45:56 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:45:56 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:45:56 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:45:56 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:45:56 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:46:06 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:46:06 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:46:06 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:46:06 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:46:06 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:46:07 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:46:19 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:46:19 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:46:19 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:46:19 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:46:19 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:46:19 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:46:33 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:46:33 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:46:33 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:46:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:46:33 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:46:33 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:46:45 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:46:45 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:46:45 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:46:45 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:46:45 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:46:45 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:47:01 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:47:01 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:47:01 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:47:01 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:47:01 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:47:01 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:47:14 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:47:14 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:47:14 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:47:14 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:47:14 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:47:15 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:47:27 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:47:27 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:47:27 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:47:27 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:47:27 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:47:28 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:47:40 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:47:40 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:47:40 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:47:40 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:47:40 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:47:40 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:47:56 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:47:56 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:47:56 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:47:56 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:47:56 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:47:56 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:48:09 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:48:09 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:48:09 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:48:09 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:48:09 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:48:10 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:48:21 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:48:21 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:48:21 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:48:21 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:48:21 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:48:21 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:48:33 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:48:33 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:48:33 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:48:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:48:33 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:48:34 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:48:46 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:48:46 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:48:46 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:48:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:48:46 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:48:46 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:48:57 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:48:57 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:48:57 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:48:57 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:48:57 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:48:58 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:49:09 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:49:09 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:49:09 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:49:09 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:49:09 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:49:09 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:49:20 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:49:20 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:49:20 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:49:20 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:49:20 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:49:20 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:49:31 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:49:31 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:49:31 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:49:31 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:49:31 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:49:31 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:49:41 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:49:41 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:49:41 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:49:41 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:49:41 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:49:42 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:49:52 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:49:52 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:49:52 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:49:52 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:49:52 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:49:53 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:50:05 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:50:05 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:50:05 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:50:05 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:50:05 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:50:06 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:50:19 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:50:19 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:50:19 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:50:19 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:50:19 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:50:20 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:50:31 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:50:31 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:50:31 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:50:31 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:50:31 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:50:31 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:50:42 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:50:42 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:50:42 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:50:42 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:50:42 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:50:42 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:50:55 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:50:55 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:50:55 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:50:55 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:50:55 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:50:56 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:51:09 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:51:09 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:51:09 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:51:09 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:51:09 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:51:09 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:51:21 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:51:21 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:51:21 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:51:21 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:51:21 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:51:22 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:51:35 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:51:35 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:51:35 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:51:35 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:51:35 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:51:35 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:51:46 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:51:46 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:51:46 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:51:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:51:46 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:51:46 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:51:57 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:51:57 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:51:57 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:51:57 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:51:57 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:51:58 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:52:10 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:52:10 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:52:10 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:52:10 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:52:10 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:52:10 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:52:20 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:52:20 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:52:20 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:52:20 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:52:20 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:52:21 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:52:31 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:52:31 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:52:31 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:52:31 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:52:31 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:52:31 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:52:42 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:52:42 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:52:42 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:52:42 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:52:42 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:52:42 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:52:56 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:52:56 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:52:56 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:52:56 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:52:56 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:52:56 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:53:07 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:53:07 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:53:07 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:53:07 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:53:07 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:53:08 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:53:20 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:53:20 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:53:20 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:53:20 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:53:20 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:53:21 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:53:31 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:53:31 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:53:31 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:53:31 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:53:31 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:53:32 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:53:46 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:53:46 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:53:46 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:53:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:53:46 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:53:46 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:53:58 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:53:58 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:53:58 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:53:58 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:53:58 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:53:59 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:54:09 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:54:09 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:54:09 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:54:09 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:54:09 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:54:09 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:54:21 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:54:21 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:54:21 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:54:21 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:54:21 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:54:21 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:54:35 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:54:35 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:54:35 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:54:35 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:54:35 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:54:36 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:54:46 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:54:46 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:54:46 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:54:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:54:46 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:54:46 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:01 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:01 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:01 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:01 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:01 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:02 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:13 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:13 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:13 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:13 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:13 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:14 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:25 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:25 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:25 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:25 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:25 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:25 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:36 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:36 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:36 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:36 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:36 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:36 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:46 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:46 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:46 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:46 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:46 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:47 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:55:57 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:55:57 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:55:57 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:55:57 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:55:57 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:55:57 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:06 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:06 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:06 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:06 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:06 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:07 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:16 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:16 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:16 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:16 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:16 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:17 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:26 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:26 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:26 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:26 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:26 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:26 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:36 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:36 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:36 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:36 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:36 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:36 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:45 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:45 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:45 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:45 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:45 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:46 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:56:55 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:56:55 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:56:55 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:56:55 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:56:55 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:56:56 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:57:04 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:57:04 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:57:04 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:57:04 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:57:04 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:57:05 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:57:14 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:57:14 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:57:14 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:57:14 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:57:14 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:57:15 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:57:24 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:57:24 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:57:24 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:57:24 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:57:24 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
04/09/2023 01:57:24 - INFO - accelerate.accelerator - Saving current state to /scratch4/cs601/tli104/gpt2/checkpoints/step_0
04/09/2023 01:57:33 - INFO - accelerate.checkpointing - Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/pytorch_model.bin
04/09/2023 01:57:33 - INFO - accelerate.checkpointing - Optimizer state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/optimizer.bin
04/09/2023 01:57:33 - INFO - accelerate.checkpointing - Scheduler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scheduler.bin
04/09/2023 01:57:33 - INFO - accelerate.checkpointing - Gradient scaler state saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/scaler.pt
04/09/2023 01:57:33 - INFO - accelerate.checkpointing - Random states saved in /scratch4/cs601/tli104/gpt2/checkpoints/step_0/random_states_0.pkl
  0%|          | 1/451 [12:36<94:36:31, 756.87s/it]04/09/2023 01:57:34 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.
04/09/2023 01:57:34 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.
04/09/2023 01:57:34 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.
04/09/2023 01:57:34 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.
  0%|          | 2/451 [13:07<41:05:45, 329.50s/it]  1%|          | 3/451 [13:37<24:00:00, 192.86s/it]  1%|          | 4/451 [14:07<15:58:45, 128.69s/it]  1%|          | 5/451 [14:38<11:33:04, 93.24s/it]   1%|▏         | 6/451 [15:08<8:52:45, 71.83s/it]   2%|▏         | 7/451 [15:38<7:11:13, 58.27s/it]  2%|▏         | 8/451 [16:09<6:05:02, 49.44s/it]  2%|▏         | 9/451 [16:39<5:19:54, 43.43s/it]  2%|▏         | 10/451 [17:09<4:49:16, 39.36s/it]  2%|▏         | 11/451 [17:40<4:28:10, 36.57s/it]  3%|▎         | 12/451 [18:10<4:13:27, 34.64s/it]  3%|▎         | 13/451 [18:40<4:03:11, 33.31s/it]  3%|▎         | 14/451 [19:10<3:56:03, 32.41s/it]  3%|▎         | 15/451 [19:41<3:50:42, 31.75s/it]  4%|▎         | 16/451 [20:11<3:46:58, 31.31s/it]  4%|▍         | 17/451 [20:41<3:44:19, 31.01s/it]  4%|▍         | 18/451 [21:11<3:42:12, 30.79s/it]  4%|▍         | 19/451 [21:42<3:40:28, 30.62s/it]  4%|▍         | 20/451 [22:12<3:39:07, 30.50s/it]  5%|▍         | 21/451 [22:42<3:38:07, 30.44s/it]  5%|▍         | 22/451 [23:12<3:37:13, 30.38s/it]  5%|▌         | 23/451 [23:43<3:36:36, 30.36s/it]  5%|▌         | 24/451 [24:13<3:36:07, 30.37s/it]  6%|▌         | 25/451 [24:43<3:35:28, 30.35s/it]  6%|▌         | 26/451 [25:14<3:34:58, 30.35s/it]  6%|▌         | 27/451 [25:44<3:33:58, 30.28s/it]  6%|▌         | 28/451 [26:14<3:33:17, 30.25s/it]  6%|▋         | 29/451 [26:44<3:33:04, 30.29s/it]  7%|▋         | 30/451 [27:15<3:32:23, 30.27s/it]  7%|▋         | 31/451 [27:45<3:31:37, 30.23s/it]  7%|▋         | 32/451 [28:15<3:31:21, 30.27s/it]  7%|▋         | 33/451 [28:45<3:30:56, 30.28s/it]  8%|▊         | 34/451 [29:16<3:30:40, 30.31s/it]  8%|▊         | 35/451 [29:46<3:30:04, 30.30s/it]  8%|▊         | 36/451 [30:16<3:29:25, 30.28s/it]  8%|▊         | 37/451 [30:47<3:29:04, 30.30s/it]  8%|▊         | 38/451 [31:17<3:28:20, 30.27s/it]  9%|▊         | 39/451 [31:47<3:27:41, 30.25s/it]  9%|▉         | 40/451 [32:17<3:26:51, 30.20s/it]  9%|▉         | 41/451 [32:48<3:26:46, 30.26s/it]  9%|▉         | 42/451 [33:18<3:26:04, 30.23s/it] 10%|▉         | 43/451 [33:48<3:25:34, 30.23s/it] 10%|▉         | 44/451 [34:18<3:25:18, 30.27s/it] 10%|▉         | 45/451 [34:49<3:24:52, 30.28s/it] 10%|█         | 46/451 [35:19<3:24:23, 30.28s/it] 10%|█         | 47/451 [35:49<3:23:42, 30.25s/it] 11%|█         | 48/451 [36:20<3:23:25, 30.29s/it] 11%|█         | 49/451 [36:50<3:22:44, 30.26s/it] 11%|█         | 50/451 [37:20<3:22:16, 30.27s/it] 11%|█▏        | 51/451 [37:50<3:21:37, 30.24s/it] 12%|█▏        | 52/451 [38:20<3:21:09, 30.25s/it] 12%|█▏        | 53/451 [38:51<3:20:36, 30.24s/it] 12%|█▏        | 54/451 [39:21<3:20:06, 30.24s/it] 12%|█▏        | 55/451 [39:51<3:19:34, 30.24s/it] 12%|█▏        | 56/451 [40:21<3:19:05, 30.24s/it] 13%|█▎        | 57/451 [40:52<3:18:46, 30.27s/it] 13%|█▎        | 58/451 [41:22<3:18:17, 30.27s/it] 13%|█▎        | 59/451 [41:52<3:17:40, 30.26s/it] 13%|█▎        | 60/451 [42:22<3:17:09, 30.25s/it] 14%|█▎        | 61/451 [42:53<3:16:45, 30.27s/it] 14%|█▎        | 62/451 [43:23<3:16:17, 30.28s/it] 14%|█▍        | 63/451 [43:53<3:15:32, 30.24s/it] 14%|█▍        | 64/451 [44:23<3:15:06, 30.25s/it] 14%|█▍        | 65/451 [44:54<3:14:51, 30.29s/it] 15%|█▍        | 66/451 [45:24<3:14:05, 30.25s/it] 15%|█▍        | 67/451 [45:54<3:13:33, 30.24s/it] 15%|█▌        | 68/451 [46:24<3:12:51, 30.21s/it] 15%|█▌        | 69/451 [46:55<3:12:46, 30.28s/it] 16%|█▌        | 70/451 [47:25<3:12:10, 30.26s/it] 16%|█▌        | 71/451 [47:55<3:11:34, 30.25s/it] 16%|█▌        | 72/451 [48:26<3:11:14, 30.28s/it] 16%|█▌        | 73/451 [48:56<3:10:56, 30.31s/it] 16%|█▋        | 74/451 [49:26<3:10:10, 30.27s/it] 17%|█▋        | 75/451 [49:56<3:09:31, 30.24s/it] 17%|█▋        | 76/451 [50:26<3:08:50, 30.21s/it] 17%|█▋        | 77/451 [50:57<3:08:31, 30.24s/it] 17%|█▋        | 78/451 [51:27<3:07:48, 30.21s/it] 18%|█▊        | 79/451 [51:57<3:07:21, 30.22s/it] 18%|█▊        | 80/451 [52:27<3:06:52, 30.22s/it] 18%|█▊        | 81/451 [52:58<3:06:27, 30.24s/it] 18%|█▊        | 82/451 [53:28<3:06:05, 30.26s/it] 18%|█▊        | 83/451 [53:58<3:05:13, 30.20s/it] 19%|█▊        | 84/451 [54:28<3:04:42, 30.20s/it] 19%|█▉        | 85/451 [54:59<3:04:19, 30.22s/it] 19%|█▉        | 86/451 [55:29<3:03:47, 30.21s/it] 19%|█▉        | 87/451 [55:59<3:03:27, 30.24s/it] 20%|█▉        | 88/451 [56:29<3:03:02, 30.26s/it] 20%|█▉        | 89/451 [57:00<3:02:31, 30.25s/it] 20%|█▉        | 90/451 [57:30<3:02:07, 30.27s/it] 20%|██        | 91/451 [58:00<3:01:34, 30.26s/it] 20%|██        | 92/451 [58:30<3:01:12, 30.29s/it] 21%|██        | 93/451 [59:01<3:00:30, 30.25s/it] 21%|██        | 94/451 [59:31<2:59:55, 30.24s/it] 21%|██        | 95/451 [1:00:01<2:59:35, 30.27s/it] 21%|██▏       | 96/451 [1:00:31<2:58:57, 30.25s/it] 22%|██▏       | 97/451 [1:01:02<2:58:37, 30.28s/it] 22%|██▏       | 98/451 [1:01:32<2:58:15, 30.30s/it] 22%|██▏       | 99/451 [1:02:02<2:57:34, 30.27s/it] 22%|██▏       | 100/451 [1:02:32<2:56:56, 30.25s/it] 22%|██▏       | 101/451 [1:03:03<2:56:25, 30.24s/it] 23%|██▎       | 102/451 [1:03:33<2:55:58, 30.25s/it] 23%|██▎       | 103/451 [1:04:03<2:55:14, 30.21s/it] 23%|██▎       | 104/451 [1:04:33<2:54:50, 30.23s/it] 23%|██▎       | 105/451 [1:05:04<2:54:36, 30.28s/it] 24%|██▎       | 106/451 [1:05:34<2:54:00, 30.26s/it] 24%|██▎       | 107/451 [1:06:04<2:53:36, 30.28s/it] 24%|██▍       | 108/451 [1:06:35<2:53:01, 30.27s/it] 24%|██▍       | 109/451 [1:07:05<2:52:33, 30.27s/it] 24%|██▍       | 110/451 [1:07:35<2:52:04, 30.28s/it] 25%|██▍       | 111/451 [1:08:05<2:51:37, 30.29s/it] 25%|██▍       | 112/451 [1:08:36<2:51:06, 30.28s/it] 25%|██▌       | 113/451 [1:09:06<2:50:35, 30.28s/it] 25%|██▌       | 114/451 [1:09:36<2:50:00, 30.27s/it] 25%|██▌       | 115/451 [1:10:06<2:49:15, 30.22s/it] 26%|██▌       | 116/451 [1:10:37<2:48:45, 30.22s/it] 26%|██▌       | 117/451 [1:11:07<2:48:19, 30.24s/it] 26%|██▌       | 118/451 [1:11:37<2:47:53, 30.25s/it] 26%|██▋       | 119/451 [1:12:07<2:47:20, 30.24s/it] 27%|██▋       | 120/451 [1:12:38<2:47:04, 30.29s/it] 27%|██▋       | 121/451 [1:13:08<2:46:35, 30.29s/it] 27%|██▋       | 122/451 [1:13:38<2:46:12, 30.31s/it] 27%|██▋       | 123/451 [1:14:09<2:45:39, 30.30s/it] 27%|██▋       | 124/451 [1:14:39<2:44:56, 30.26s/it] 28%|██▊       | 125/451 [1:15:09<2:44:18, 30.24s/it] 28%|██▊       | 126/451 [1:15:39<2:43:49, 30.24s/it] 28%|██▊       | 127/451 [1:16:10<2:43:25, 30.26s/it] 28%|██▊       | 128/451 [1:16:40<2:42:50, 30.25s/it] 29%|██▊       | 129/451 [1:17:10<2:42:27, 30.27s/it] 29%|██▉       | 130/451 [1:17:40<2:41:44, 30.23s/it] 29%|██▉       | 131/451 [1:18:10<2:41:12, 30.23s/it] 29%|██▉       | 132/451 [1:18:41<2:40:49, 30.25s/it] 29%|██▉       | 133/451 [1:19:11<2:40:26, 30.27s/it] 30%|██▉       | 134/451 [1:19:41<2:39:51, 30.26s/it] 30%|██▉       | 135/451 [1:20:12<2:39:21, 30.26s/it] 30%|███       | 136/451 [1:20:42<2:38:45, 30.24s/it] 30%|███       | 137/451 [1:21:12<2:38:29, 30.29s/it] 31%|███       | 138/451 [1:21:42<2:37:49, 30.25s/it] 31%|███       | 139/451 [1:22:13<2:37:24, 30.27s/it] 31%|███       | 140/451 [1:22:43<2:37:04, 30.30s/it] 31%|███▏      | 141/451 [1:23:13<2:36:18, 30.25s/it] 31%|███▏      | 142/451 [1:23:43<2:35:50, 30.26s/it] 32%|███▏      | 143/451 [1:24:14<2:35:31, 30.30s/it] 32%|███▏      | 144/451 [1:24:44<2:35:01, 30.30s/it] 32%|███▏      | 145/451 [1:25:14<2:34:31, 30.30s/it] 32%|███▏      | 146/451 [1:25:45<2:33:48, 30.26s/it] 33%|███▎      | 147/451 [1:26:15<2:33:05, 30.22s/it] 33%|███▎      | 148/451 [1:26:45<2:32:46, 30.25s/it] 33%|███▎      | 149/451 [1:27:15<2:32:14, 30.25s/it] 33%|███▎      | 150/451 [1:27:46<2:31:41, 30.24s/it] 33%|███▎      | 151/451 [1:28:16<2:31:08, 30.23s/it] 34%|███▎      | 152/451 [1:28:46<2:30:45, 30.25s/it] 34%|███▍      | 153/451 [1:29:16<2:30:18, 30.26s/it] 34%|███▍      | 154/451 [1:29:47<2:29:51, 30.27s/it] 34%|███▍      | 155/451 [1:30:17<2:29:08, 30.23s/it] 35%|███▍      | 156/451 [1:30:47<2:28:54, 30.29s/it] 35%|███▍      | 157/451 [1:31:17<2:28:26, 30.29s/it] 35%|███▌      | 158/451 [1:31:48<2:27:49, 30.27s/it] 35%|███▌      | 159/451 [1:32:18<2:27:22, 30.28s/it] 35%|███▌      | 160/451 [1:32:48<2:27:00, 30.31s/it] 36%|███▌      | 161/451 [1:33:19<2:26:20, 30.28s/it] 36%|███▌      | 162/451 [1:33:49<2:25:38, 30.24s/it] 36%|███▌      | 163/451 [1:34:19<2:25:14, 30.26s/it] 36%|███▋      | 164/451 [1:34:49<2:24:35, 30.23s/it] 37%|███▋      | 165/451 [1:35:19<2:24:09, 30.24s/it] 37%|███▋      | 166/451 [1:35:50<2:23:39, 30.24s/it] 37%|███▋      | 167/451 [1:36:20<2:23:15, 30.26s/it] 37%|███▋      | 168/451 [1:36:50<2:22:44, 30.26s/it] 37%|███▋      | 169/451 [1:37:21<2:22:22, 30.29s/it] 38%|███▊      | 170/451 [1:37:51<2:21:51, 30.29s/it] 38%|███▊      | 171/451 [1:38:21<2:21:17, 30.28s/it] 38%|███▊      | 172/451 [1:38:51<2:20:40, 30.25s/it] 38%|███▊      | 173/451 [1:39:22<2:20:13, 30.27s/it] 39%|███▊      | 174/451 [1:39:52<2:19:33, 30.23s/it] 39%|███▉      | 175/451 [1:40:22<2:18:54, 30.20s/it] 39%|███▉      | 176/451 [1:40:52<2:18:36, 30.24s/it] 39%|███▉      | 177/451 [1:41:22<2:18:00, 30.22s/it] 39%|███▉      | 178/451 [1:41:53<2:17:39, 30.25s/it] 40%|███▉      | 179/451 [1:42:23<2:17:09, 30.25s/it] 40%|███▉      | 180/451 [1:42:53<2:16:39, 30.26s/it] 40%|████      | 181/451 [1:43:24<2:16:12, 30.27s/it] 40%|████      | 182/451 [1:43:54<2:15:36, 30.25s/it] 41%|████      | 183/451 [1:44:24<2:15:08, 30.25s/it] 41%|████      | 184/451 [1:44:54<2:14:29, 30.22s/it] 41%|████      | 185/451 [1:45:24<2:13:49, 30.18s/it] 41%|████      | 186/451 [1:45:55<2:13:27, 30.22s/it] 41%|████▏     | 187/451 [1:46:25<2:13:05, 30.25s/it] 42%|████▏     | 188/451 [1:46:55<2:12:40, 30.27s/it] 42%|████▏     | 189/451 [1:47:25<2:12:06, 30.25s/it] 42%|████▏     | 190/451 [1:47:56<2:11:45, 30.29s/it] 42%|████▏     | 191/451 [1:48:26<2:11:08, 30.26s/it] 43%|████▎     | 192/451 [1:48:56<2:10:37, 30.26s/it] 43%|████▎     | 193/451 [1:49:26<2:10:02, 30.24s/it] 43%|████▎     | 194/451 [1:49:57<2:09:28, 30.23s/it] 43%|████▎     | 195/451 [1:50:27<2:09:12, 30.28s/it] 43%|████▎     | 196/451 [1:50:57<2:08:36, 30.26s/it] 44%|████▎     | 197/451 [1:51:28<2:08:06, 30.26s/it] 44%|████▍     | 198/451 [1:51:58<2:07:34, 30.25s/it] 44%|████▍     | 199/451 [1:52:28<2:07:05, 30.26s/it] 44%|████▍     | 200/451 [1:52:58<2:06:28, 30.23s/it] 45%|████▍     | 201/451 [1:53:28<2:05:55, 30.22s/it] 45%|████▍     | 202/451 [1:53:59<2:05:32, 30.25s/it] 45%|████▌     | 203/451 [1:54:29<2:04:56, 30.23s/it] 45%|████▌     | 204/451 [1:54:59<2:04:29, 30.24s/it] 45%|████▌     | 205/451 [1:55:30<2:04:03, 30.26s/it] 46%|████▌     | 206/451 [1:56:00<2:03:36, 30.27s/it] 46%|████▌     | 207/451 [1:56:30<2:02:55, 30.23s/it] 46%|████▌     | 208/451 [1:57:00<2:02:31, 30.25s/it] 46%|████▋     | 209/451 [1:57:30<2:02:01, 30.25s/it] 47%|████▋     | 210/451 [1:58:01<2:01:31, 30.26s/it] 47%|████▋     | 211/451 [1:58:31<2:01:06, 30.28s/it] 47%|████▋     | 212/451 [1:59:01<2:00:37, 30.28s/it] 47%|████▋     | 213/451 [1:59:32<2:00:10, 30.30s/it] 47%|████▋     | 214/451 [2:00:02<1:59:28, 30.25s/it] 48%|████▊     | 215/451 [2:00:32<1:58:54, 30.23s/it] 48%|████▊     | 216/451 [2:01:02<1:58:30, 30.26s/it] 48%|████▊     | 217/451 [2:01:33<1:57:58, 30.25s/it] 48%|████▊     | 218/451 [2:02:03<1:57:29, 30.26s/it] 49%|████▊     | 219/451 [2:02:33<1:56:59, 30.26s/it] 49%|████▉     | 220/451 [2:03:03<1:56:28, 30.25s/it] 49%|████▉     | 221/451 [2:03:34<1:55:56, 30.24s/it] 49%|████▉     | 222/451 [2:04:04<1:55:27, 30.25s/it] 49%|████▉     | 223/451 [2:04:34<1:55:06, 30.29s/it] 50%|████▉     | 224/451 [2:05:04<1:54:33, 30.28s/it] 50%|████▉     | 225/451 [2:05:35<1:54:01, 30.27s/it] 50%|█████     | 226/451 [2:06:05<1:53:27, 30.26s/it] 50%|█████     | 227/451 [2:06:35<1:52:58, 30.26s/it] 51%|█████     | 228/451 [2:07:06<1:52:30, 30.27s/it] 51%|█████     | 229/451 [2:07:36<1:51:58, 30.27s/it] 51%|█████     | 230/451 [2:08:06<1:51:27, 30.26s/it] 51%|█████     | 231/451 [2:08:36<1:50:59, 30.27s/it] 51%|█████▏    | 232/451 [2:09:07<1:50:23, 30.24s/it] 52%|█████▏    | 233/451 [2:09:37<1:49:53, 30.25s/it] 52%|█████▏    | 234/451 [2:10:07<1:49:23, 30.25s/it] 52%|█████▏    | 235/451 [2:10:37<1:48:44, 30.21s/it] 52%|█████▏    | 236/451 [2:11:07<1:48:11, 30.19s/it] 53%|█████▎    | 237/451 [2:11:37<1:47:39, 30.19s/it] 53%|█████▎    | 238/451 [2:12:08<1:47:12, 30.20s/it] 53%|█████▎    | 239/451 [2:12:38<1:46:48, 30.23s/it] 53%|█████▎    | 240/451 [2:13:08<1:46:19, 30.23s/it] 53%|█████▎    | 241/451 [2:13:38<1:45:51, 30.25s/it] 54%|█████▎    | 242/451 [2:14:09<1:45:20, 30.24s/it] 54%|█████▍    | 243/451 [2:14:39<1:44:41, 30.20s/it] 54%|█████▍    | 244/451 [2:15:09<1:44:12, 30.21s/it] 54%|█████▍    | 245/451 [2:15:39<1:43:48, 30.23s/it] 55%|█████▍    | 246/451 [2:16:10<1:43:16, 30.23s/it] 55%|█████▍    | 247/451 [2:16:40<1:42:49, 30.24s/it] 55%|█████▍    | 248/451 [2:17:10<1:42:20, 30.25s/it] 55%|█████▌    | 249/451 [2:17:40<1:41:55, 30.27s/it] 55%|█████▌    | 250/451 [2:18:11<1:41:13, 30.22s/it] 56%|█████▌    | 251/451 [2:18:41<1:40:46, 30.23s/it] 56%|█████▌    | 252/451 [2:19:11<1:40:16, 30.23s/it] 56%|█████▌    | 253/451 [2:19:41<1:39:48, 30.25s/it] 56%|█████▋    | 254/451 [2:20:11<1:39:14, 30.23s/it] 57%|█████▋    | 255/451 [2:20:42<1:38:41, 30.21s/it] 57%|█████▋    | 256/451 [2:21:12<1:38:09, 30.20s/it] 57%|█████▋    | 257/451 [2:21:42<1:37:39, 30.20s/it] 57%|█████▋    | 258/451 [2:22:12<1:37:11, 30.21s/it] 57%|█████▋    | 259/451 [2:22:43<1:36:42, 30.22s/it] 58%|█████▊    | 260/451 [2:23:13<1:36:11, 30.22s/it] 58%|█████▊    | 261/451 [2:23:43<1:35:39, 30.21s/it] 58%|█████▊    | 262/451 [2:24:13<1:35:10, 30.22s/it] 58%|█████▊    | 263/451 [2:24:43<1:34:40, 30.22s/it] 59%|█████▊    | 264/451 [2:25:14<1:34:14, 30.24s/it] 59%|█████▉    | 265/451 [2:25:44<1:33:39, 30.21s/it] 59%|█████▉    | 266/451 [2:26:14<1:33:14, 30.24s/it] 59%|█████▉    | 267/451 [2:26:44<1:32:47, 30.26s/it] 59%|█████▉    | 268/451 [2:27:15<1:32:18, 30.27s/it] 60%|█████▉    | 269/451 [2:27:45<1:31:47, 30.26s/it] 60%|█████▉    | 270/451 [2:28:15<1:31:19, 30.27s/it] 60%|██████    | 271/451 [2:28:46<1:30:55, 30.31s/it] 60%|██████    | 272/451 [2:29:16<1:30:19, 30.27s/it] 61%|██████    | 273/451 [2:29:46<1:29:40, 30.22s/it] 61%|██████    | 274/451 [2:30:16<1:29:07, 30.21s/it] 61%|██████    | 275/451 [2:30:46<1:28:38, 30.22s/it] 61%|██████    | 276/451 [2:31:17<1:28:10, 30.23s/it] 61%|██████▏   | 277/451 [2:31:47<1:27:41, 30.24s/it] 62%|██████▏   | 278/451 [2:32:17<1:27:07, 30.22s/it] 62%|██████▏   | 279/451 [2:32:47<1:26:42, 30.25s/it] 62%|██████▏   | 280/451 [2:33:17<1:26:05, 30.21s/it] 62%|██████▏   | 281/451 [2:33:48<1:25:40, 30.24s/it] 63%|██████▎   | 282/451 [2:34:18<1:25:06, 30.21s/it] 63%|██████▎   | 283/451 [2:34:48<1:24:32, 30.19s/it] 63%|██████▎   | 284/451 [2:35:18<1:24:01, 30.19s/it] 63%|██████▎   | 285/451 [2:35:48<1:23:31, 30.19s/it] 63%|██████▎   | 286/451 [2:36:19<1:23:02, 30.20s/it] 64%|██████▎   | 287/451 [2:36:49<1:22:30, 30.19s/it] 64%|██████▍   | 288/451 [2:37:19<1:21:59, 30.18s/it] 64%|██████▍   | 289/451 [2:37:49<1:21:26, 30.16s/it] 64%|██████▍   | 290/451 [2:38:19<1:21:01, 30.20s/it] 65%|██████▍   | 291/451 [2:38:50<1:20:30, 30.19s/it] 65%|██████▍   | 292/451 [2:39:20<1:20:02, 30.20s/it] 65%|██████▍   | 293/451 [2:39:50<1:19:34, 30.22s/it] 65%|██████▌   | 294/451 [2:40:20<1:19:08, 30.25s/it] 65%|██████▌   | 295/451 [2:40:51<1:18:34, 30.22s/it] 66%|██████▌   | 296/451 [2:41:21<1:18:04, 30.22s/it] 66%|██████▌   | 297/451 [2:41:51<1:17:35, 30.23s/it] 66%|██████▌   | 298/451 [2:42:21<1:17:05, 30.23s/it] 66%|██████▋   | 299/451 [2:42:51<1:16:34, 30.23s/it] 67%|██████▋   | 300/451 [2:43:22<1:16:06, 30.24s/it] 67%|██████▋   | 301/451 [2:43:52<1:15:37, 30.25s/it] 67%|██████▋   | 302/451 [2:44:22<1:15:06, 30.24s/it] 67%|██████▋   | 303/451 [2:44:52<1:14:36, 30.25s/it] 67%|██████▋   | 304/451 [2:45:23<1:14:03, 30.23s/it] 68%|██████▊   | 305/451 [2:45:53<1:13:30, 30.21s/it] 68%|██████▊   | 306/451 [2:46:23<1:13:03, 30.23s/it] 68%|██████▊   | 307/451 [2:46:53<1:12:33, 30.24s/it] 68%|██████▊   | 308/451 [2:47:24<1:12:03, 30.24s/it] 69%|██████▊   | 309/451 [2:47:54<1:11:33, 30.24s/it] 69%|██████▊   | 310/451 [2:48:24<1:11:04, 30.25s/it] 69%|██████▉   | 311/451 [2:48:54<1:10:34, 30.25s/it] 69%|██████▉   | 312/451 [2:49:25<1:10:08, 30.28s/it] 69%|██████▉   | 313/451 [2:49:55<1:09:40, 30.29s/it] 70%|██████▉   | 314/451 [2:50:25<1:09:06, 30.27s/it] 70%|██████▉   | 315/451 [2:50:55<1:08:35, 30.26s/it] 70%|███████   | 316/451 [2:51:26<1:08:04, 30.26s/it] 70%|███████   | 317/451 [2:51:56<1:07:35, 30.26s/it] 71%|███████   | 318/451 [2:52:26<1:07:04, 30.26s/it] 71%|███████   | 319/451 [2:52:57<1:06:37, 30.28s/it] 71%|███████   | 320/451 [2:53:27<1:06:05, 30.27s/it] 71%|███████   | 321/451 [2:53:57<1:05:36, 30.28s/it] 71%|███████▏  | 322/451 [2:54:27<1:05:02, 30.25s/it] 72%|███████▏  | 323/451 [2:54:58<1:04:29, 30.23s/it] 72%|███████▏  | 324/451 [2:55:28<1:03:58, 30.23s/it] 72%|███████▏  | 325/451 [2:55:58<1:03:27, 30.21s/it] 72%|███████▏  | 326/451 [2:56:28<1:02:56, 30.21s/it] 73%|███████▎  | 327/451 [2:56:58<1:02:28, 30.23s/it] 73%|███████▎  | 328/451 [2:57:29<1:01:57, 30.22s/it] 73%|███████▎  | 329/451 [2:57:59<1:01:28, 30.23s/it] 73%|███████▎  | 330/451 [2:58:29<1:00:57, 30.23s/it] 73%|███████▎  | 331/451 [2:58:59<1:00:28, 30.24s/it] 74%|███████▎  | 332/451 [2:59:30<59:56, 30.22s/it]   74%|███████▍  | 333/451 [3:00:00<59:30, 30.26s/it] 74%|███████▍  | 334/451 [3:00:30<59:02, 30.28s/it] 74%|███████▍  | 335/451 [3:01:01<58:34, 30.30s/it] 75%|███████▍  | 336/451 [3:01:31<58:03, 30.29s/it] 75%|███████▍  | 337/451 [3:02:01<57:31, 30.28s/it] 75%|███████▍  | 338/451 [3:02:31<57:01, 30.28s/it] 75%|███████▌  | 339/451 [3:03:02<56:29, 30.26s/it] 75%|███████▌  | 340/451 [3:03:32<55:57, 30.24s/it] 76%|███████▌  | 341/451 [3:04:02<55:26, 30.24s/it] 76%|███████▌  | 342/451 [3:04:32<54:58, 30.27s/it] 76%|███████▌  | 343/451 [3:05:03<54:27, 30.26s/it] 76%|███████▋  | 344/451 [3:05:33<53:57, 30.25s/it] 76%|███████▋  | 345/451 [3:06:03<53:29, 30.28s/it] 77%|███████▋  | 346/451 [3:06:33<52:56, 30.25s/it] 77%|███████▋  | 347/451 [3:07:04<52:27, 30.27s/it] 77%|███████▋  | 348/451 [3:07:34<51:56, 30.26s/it] 77%|███████▋  | 349/451 [3:08:04<51:26, 30.26s/it] 78%|███████▊  | 350/451 [3:08:34<50:52, 30.23s/it] 78%|███████▊  | 351/451 [3:09:05<50:26, 30.26s/it] 78%|███████▊  | 352/451 [3:09:35<49:53, 30.24s/it] 78%|███████▊  | 353/451 [3:10:05<49:20, 30.21s/it] 78%|███████▊  | 354/451 [3:10:35<48:48, 30.19s/it] 79%|███████▊  | 355/451 [3:11:05<48:21, 30.22s/it] 79%|███████▉  | 356/451 [3:11:36<47:54, 30.26s/it] 79%|███████▉  | 357/451 [3:12:06<47:21, 30.22s/it] 79%|███████▉  | 358/451 [3:12:36<46:51, 30.23s/it] 80%|███████▉  | 359/451 [3:13:06<46:20, 30.23s/it] 80%|███████▉  | 360/451 [3:13:36<45:47, 30.20s/it] 80%|████████  | 361/451 [3:14:07<45:18, 30.20s/it] 80%|████████  | 362/451 [3:14:37<44:50, 30.23s/it] 80%|████████  | 363/451 [3:15:07<44:21, 30.24s/it] 81%|████████  | 364/451 [3:15:37<43:49, 30.23s/it] 81%|████████  | 365/451 [3:16:08<43:18, 30.22s/it] 81%|████████  | 366/451 [3:16:38<42:47, 30.21s/it] 81%|████████▏ | 367/451 [3:17:08<42:19, 30.23s/it] 82%|████████▏ | 368/451 [3:17:38<41:51, 30.26s/it] 82%|████████▏ | 369/451 [3:18:09<41:20, 30.25s/it] 82%|████████▏ | 370/451 [3:18:39<40:51, 30.27s/it] 82%|████████▏ | 371/451 [3:19:09<40:21, 30.26s/it] 82%|████████▏ | 372/451 [3:19:40<39:51, 30.27s/it] 83%|████████▎ | 373/451 [3:20:10<39:20, 30.26s/it] 83%|████████▎ | 374/451 [3:20:40<38:51, 30.28s/it] 83%|████████▎ | 375/451 [3:21:10<38:20, 30.26s/it] 83%|████████▎ | 376/451 [3:21:41<37:48, 30.25s/it] 84%|████████▎ | 377/451 [3:22:11<37:16, 30.23s/it] 84%|████████▍ | 378/451 [3:22:41<36:45, 30.21s/it] 84%|████████▍ | 379/451 [3:23:11<36:15, 30.22s/it] 84%|████████▍ | 380/451 [3:23:41<35:43, 30.19s/it] 84%|████████▍ | 381/451 [3:24:12<35:15, 30.22s/it] 85%|████████▍ | 382/451 [3:24:42<34:45, 30.23s/it] 85%|████████▍ | 383/451 [3:25:12<34:16, 30.25s/it] 85%|████████▌ | 384/451 [3:25:42<33:47, 30.26s/it] 85%|████████▌ | 385/451 [3:26:13<33:17, 30.27s/it] 86%|████████▌ | 386/451 [3:26:43<32:47, 30.27s/it] 86%|████████▌ | 387/451 [3:27:13<32:17, 30.28s/it] 86%|████████▌ | 388/451 [3:27:43<31:45, 30.25s/it] 86%|████████▋ | 389/451 [3:28:14<31:14, 30.24s/it] 86%|████████▋ | 390/451 [3:28:44<30:44, 30.23s/it] 87%|████████▋ | 391/451 [3:29:14<30:14, 30.25s/it] 87%|████████▋ | 392/451 [3:29:44<29:45, 30.26s/it] 87%|████████▋ | 393/451 [3:30:15<29:14, 30.26s/it] 87%|████████▋ | 394/451 [3:30:45<28:44, 30.25s/it] 88%|████████▊ | 395/451 [3:31:15<28:14, 30.26s/it] 88%|████████▊ | 396/451 [3:31:45<27:43, 30.25s/it] 88%|████████▊ | 397/451 [3:32:16<27:12, 30.23s/it] 88%|████████▊ | 398/451 [3:32:46<26:43, 30.26s/it] 88%|████████▊ | 399/451 [3:33:16<26:13, 30.26s/it] 89%|████████▊ | 400/451 [3:33:46<25:43, 30.26s/it] 89%|████████▉ | 401/451 [3:34:17<25:12, 30.25s/it] 89%|████████▉ | 402/451 [3:34:47<24:42, 30.26s/it] 89%|████████▉ | 403/451 [3:35:17<24:11, 30.25s/it] 90%|████████▉ | 404/451 [3:35:48<23:43, 30.28s/it] 90%|████████▉ | 405/451 [3:36:18<23:12, 30.27s/it] 90%|█████████ | 406/451 [3:36:48<22:41, 30.26s/it] 90%|█████████ | 407/451 [3:37:18<22:10, 30.24s/it] 90%|█████████ | 408/451 [3:37:48<21:40, 30.24s/it] 91%|█████████ | 409/451 [3:38:19<21:09, 30.23s/it] 91%|█████████ | 410/451 [3:38:49<20:39, 30.23s/it] 91%|█████████ | 411/451 [3:39:19<20:09, 30.24s/it] 91%|█████████▏| 412/451 [3:39:49<19:39, 30.25s/it] 92%|█████████▏| 413/451 [3:40:20<19:09, 30.26s/it] 92%|█████████▏| 414/451 [3:40:50<18:40, 30.28s/it] 92%|█████████▏| 415/451 [3:41:20<18:09, 30.27s/it] 92%|█████████▏| 416/451 [3:41:50<17:38, 30.25s/it] 92%|█████████▏| 417/451 [3:42:21<17:08, 30.24s/it] 93%|█████████▎| 418/451 [3:42:51<16:37, 30.23s/it] 93%|█████████▎| 419/451 [3:43:21<16:07, 30.25s/it] 93%|█████████▎| 420/451 [3:43:51<15:37, 30.23s/it] 93%|█████████▎| 421/451 [3:44:22<15:07, 30.25s/it] 94%|█████████▎| 422/451 [3:44:52<14:37, 30.24s/it] 94%|█████████▍| 423/451 [3:45:22<14:06, 30.22s/it] 94%|█████████▍| 424/451 [3:45:52<13:35, 30.22s/it] 94%|█████████▍| 425/451 [3:46:22<13:04, 30.17s/it] 94%|█████████▍| 426/451 [3:46:52<12:34, 30.17s/it] 95%|█████████▍| 427/451 [3:47:23<12:03, 30.14s/it] 95%|█████████▍| 428/451 [3:47:53<11:33, 30.15s/it] 95%|█████████▌| 429/451 [3:48:23<11:03, 30.14s/it] 95%|█████████▌| 430/451 [3:48:53<10:32, 30.14s/it] 96%|█████████▌| 431/451 [3:49:23<10:02, 30.14s/it] 96%|█████████▌| 432/451 [3:49:53<09:32, 30.11s/it] 96%|█████████▌| 433/451 [3:50:23<09:01, 30.10s/it] 96%|█████████▌| 434/451 [3:50:53<08:32, 30.12s/it] 96%|█████████▋| 435/451 [3:51:23<08:01, 30.09s/it] 97%|█████████▋| 436/451 [3:51:54<07:31, 30.09s/it] 97%|█████████▋| 437/451 [3:52:24<07:01, 30.10s/it] 97%|█████████▋| 438/451 [3:52:54<06:30, 30.07s/it] 97%|█████████▋| 439/451 [3:53:24<06:01, 30.09s/it] 98%|█████████▊| 440/451 [3:53:54<05:30, 30.09s/it] 98%|█████████▊| 441/451 [3:54:24<05:00, 30.09s/it] 98%|█████████▊| 442/451 [3:54:54<04:31, 30.11s/it] 98%|█████████▊| 443/451 [3:55:24<04:00, 30.08s/it] 98%|█████████▊| 444/451 [3:55:54<03:30, 30.07s/it] 99%|█████████▊| 445/451 [3:56:24<03:00, 30.03s/it] 99%|█████████▉| 446/451 [3:56:54<02:30, 30.03s/it] 99%|█████████▉| 447/451 [3:57:24<02:00, 30.02s/it] 99%|█████████▉| 448/451 [3:57:54<01:30, 30.02s/it]100%|█████████▉| 449/451 [3:58:24<01:00, 30.04s/it]100%|█████████▉| 450/451 [3:58:54<00:30, 30.04s/it]100%|██████████| 451/451 [3:59:14<00:00, 27.01s/it]04/09/2023 05:44:30 - INFO - __main__ - epoch 0: perplexity: 11.353922556580205 eval_loss: 2.429563283920288
Configuration saved in /scratch4/cs601/tli104/gpt2/checkpoints/config.json
Configuration saved in /scratch4/cs601/tli104/gpt2/checkpoints/generation_config.json
Model weights saved in /scratch4/cs601/tli104/gpt2/checkpoints/pytorch_model.bin
tokenizer config file saved in /scratch4/cs601/tli104/gpt2/checkpoints/tokenizer_config.json
Special tokens file saved in /scratch4/cs601/tli104/gpt2/checkpoints/special_tokens_map.json
100%|██████████| 451/451 [3:59:39<00:00, 31.88s/it]
