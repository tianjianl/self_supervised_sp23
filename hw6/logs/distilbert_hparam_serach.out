Could not find conda environment: toy_classification_env
You can list all discoverable environments with `conda info --envs`.

Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: torch in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.13.1)
Requirement already satisfied: scikit-learn==0.24.2 in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.24.2)
Requirement already satisfied: tqdm==4.64.1 in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (4.64.1)
Requirement already satisfied: transformers==4.26.1 in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.26.1)
Requirement already satisfied: datasets==2.10.0 in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (2.10.0)
Requirement already satisfied: evaluate==0.4.0 in /home/tli104/.local/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.4.0)
Requirement already satisfied: typing-extensions in /home/tli104/.local/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (4.5.0)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == "Linux" in /home/tli104/.local/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == "Linux" in /home/tli104/.local/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (8.5.0.96)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == "Linux" in /home/tli104/.local/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.10.3.66)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == "Linux" in /home/tli104/.local/lib/python3.8/site-packages (from torch->-r requirements.txt (line 1)) (11.7.99)
Requirement already satisfied: threadpoolctl>=2.0.0 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (2.1.0)
Requirement already satisfied: scipy>=0.19.1 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (1.5.0)
Requirement already satisfied: joblib>=0.11 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (0.16.0)
Requirement already satisfied: numpy>=1.13.3 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from scikit-learn==0.24.2->-r requirements.txt (line 2)) (1.18.5)
Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/tli104/.local/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (0.13.1)
Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/tli104/.local/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (0.13.2)
Requirement already satisfied: regex!=2019.12.17 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (2020.6.8)
Requirement already satisfied: pyyaml>=5.1 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (5.3.1)
Requirement already satisfied: requests in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (2.24.0)
Requirement already satisfied: packaging>=20.0 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (20.4)
Requirement already satisfied: filelock in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from transformers==4.26.1->-r requirements.txt (line 4)) (3.0.12)
Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (0.3.6)
Requirement already satisfied: multiprocess in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (0.70.14)
Requirement already satisfied: responses<0.19 in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (0.18.0)
Requirement already satisfied: xxhash in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (3.2.0)
Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (2023.3.0)
Requirement already satisfied: pyarrow>=6.0.0 in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (11.0.0)
Requirement already satisfied: aiohttp in /home/tli104/.local/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (3.8.4)
Requirement already satisfied: pandas in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from datasets==2.10.0->-r requirements.txt (line 5)) (1.0.5)
Requirement already satisfied: setuptools in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == "Linux"->torch->-r requirements.txt (line 1)) (49.2.0.post20200714)
Requirement already satisfied: wheel in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from nvidia-cuda-runtime-cu11==11.7.99; platform_system == "Linux"->torch->-r requirements.txt (line 1)) (0.34.2)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (1.25.9)
Requirement already satisfied: certifi>=2017.4.17 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (2020.6.20)
Requirement already satisfied: chardet<4,>=3.0.2 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (3.0.4)
Requirement already satisfied: idna<3,>=2.5 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from requests->transformers==4.26.1->-r requirements.txt (line 4)) (2.10)
Requirement already satisfied: six in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.26.1->-r requirements.txt (line 4)) (1.15.0)
Requirement already satisfied: pyparsing>=2.0.2 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from packaging>=20.0->transformers==4.26.1->-r requirements.txt (line 4)) (2.4.7)
Requirement already satisfied: frozenlist>=1.1.1 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (1.3.3)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (4.0.2)
Requirement already satisfied: attrs>=17.3.0 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (19.3.0)
Requirement already satisfied: aiosignal>=1.1.2 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (1.3.1)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (6.0.4)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (3.1.0)
Requirement already satisfied: yarl<2.0,>=1.0 in /home/tli104/.local/lib/python3.8/site-packages (from aiohttp->datasets==2.10.0->-r requirements.txt (line 5)) (1.8.2)
Requirement already satisfied: pytz>=2017.2 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from pandas->datasets==2.10.0->-r requirements.txt (line 5)) (2020.1)
Requirement already satisfied: python-dateutil>=2.6.1 in /data/apps/linux-centos8-cascadelake/gcc-9.3.0/anaconda3-2020.07-i7qavhiohb2uwqs4eqjeefzx3kp5jqdu/lib/python3.8/site-packages (from pandas->datasets==2.10.0->-r requirements.txt (line 5)) (2.8.1)
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0001, model='distilbert-base-uncased', num_epochs=9, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 856.68it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.642875}
 - Average validation metrics: accuracy={'accuracy': 0.6669724770642201}
 - Average test metrics: accuracy={'accuracy': 0.6783461807988788}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.73575}
 - Average validation metrics: accuracy={'accuracy': 0.6730886850152905}
 - Average test metrics: accuracy={'accuracy': 0.6664330763840224}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.842625}
 - Average validation metrics: accuracy={'accuracy': 0.6889908256880733}
 - Average test metrics: accuracy={'accuracy': 0.6923615977575333}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.9045}
 - Average validation metrics: accuracy={'accuracy': 0.6400611620795107}
 - Average test metrics: accuracy={'accuracy': 0.6545199719691661}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.937625}
 - Average validation metrics: accuracy={'accuracy': 0.6987767584097859}
 - Average test metrics: accuracy={'accuracy': 0.6965662228451296}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.96375}
 - Average validation metrics: accuracy={'accuracy': 0.6984709480122324}
 - Average test metrics: accuracy={'accuracy': 0.6951646811492642}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.977125}
 - Average validation metrics: accuracy={'accuracy': 0.717737003058104}
 - Average test metrics: accuracy={'accuracy': 0.7105816398037842}
Epoch 8 training:
 ===> Epoch 8
 - Average training metrics: accuracy={'accuracy': 0.988625}
 - Average validation metrics: accuracy={'accuracy': 0.7131498470948012}
 - Average test metrics: accuracy={'accuracy': 0.708479327259986}
Epoch 9 training:
 ===> Epoch 9
 - Average training metrics: accuracy={'accuracy': 0.9935}
 - Average validation metrics: accuracy={'accuracy': 0.7061162079510703}
 - Average test metrics: accuracy={'accuracy': 0.7077785564120532}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Mon Mar 13 23:40:41 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   60C    P0   286W / 300W |  47367MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   56C    P0   274W / 300W |  40219MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   28C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   28C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      32807      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    7    0      27276      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    8    0      33993      C   ...sification_env/bin/python     8015MiB |
|    1    9    0      35296      C   ...sification_env/bin/python     5927MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     6389MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     6587MiB |
|    1   12    0      35552      C   ...sification_env/bin/python     5923MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.7061162079510703}
 - Average TEST metrics: accuracy={'accuracy': 0.7077785564120532}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0005, model='distilbert-base-uncased', num_epochs=9, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 848.02it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.61975}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.623375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 8 training:
 ===> Epoch 8
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
Epoch 9 training:
 ===> Epoch 9
 - Average training metrics: accuracy={'accuracy': 0.62375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6194814295725298}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 00:06:01 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   53C    P0   232W / 300W |  36755MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   60C    P0   261W / 300W |  49613MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   40C    P0   138W / 300W |  14710MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   27C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      35700      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    7    0      27276      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    9    0      35296      C   ...sification_env/bin/python     8015MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8489MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8783MiB |
|    1   12    0      35552      C   ...sification_env/bin/python     8023MiB |
|    1   13    0      37702      C   ...sification_env/bin/python     8925MiB |
|    2    7    0      37236      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    2    8    0      37318      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6194814295725298}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.001, model='distilbert-base-uncased', num_epochs=9, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 839.11it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.61625}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 8 training:
 ===> Epoch 8
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
Epoch 9 training:
 ===> Epoch 9
 - Average training metrics: accuracy={'accuracy': 0.622875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6243868255080589}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 00:31:06 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   61C    P0   290W / 300W |  44535MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   49C    P0   179W / 300W |  24880MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   28C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   28C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      37925      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    7    0      27276      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6243868255080589}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0001, model='distilbert-base-uncased', num_epochs=7, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 846.31it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.6285}
 - Average validation metrics: accuracy={'accuracy': 0.6574923547400612}
 - Average test metrics: accuracy={'accuracy': 0.6587245970567625}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.70675}
 - Average validation metrics: accuracy={'accuracy': 0.6486238532110091}
 - Average test metrics: accuracy={'accuracy': 0.6398037841625789}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.82375}
 - Average validation metrics: accuracy={'accuracy': 0.6657492354740061}
 - Average test metrics: accuracy={'accuracy': 0.6769446391030133}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.899875}
 - Average validation metrics: accuracy={'accuracy': 0.6287461773700306}
 - Average test metrics: accuracy={'accuracy': 0.6131744919411353}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.93775}
 - Average validation metrics: accuracy={'accuracy': 0.6889908256880733}
 - Average test metrics: accuracy={'accuracy': 0.693062368605466}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.96225}
 - Average validation metrics: accuracy={'accuracy': 0.6837920489296636}
 - Average test metrics: accuracy={'accuracy': 0.6846531184302733}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.977375}
 - Average validation metrics: accuracy={'accuracy': 0.6954128440366972}
 - Average test metrics: accuracy={'accuracy': 0.6867554309740714}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 00:50:54 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   58C    P0   237W / 300W |  34833MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   49C    P0   170W / 300W |  24880MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   28C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   28C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      40303      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    7    0      27276      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6954128440366972}
 - Average TEST metrics: accuracy={'accuracy': 0.6867554309740714}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0005, model='distilbert-base-uncased', num_epochs=7, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 841.30it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.618625}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.625375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.625375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.625375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.625875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.625375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.625375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6103714085494043}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 01:10:42 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   56C    P0   231W / 300W |  33423MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   62C    P0   306W / 300W |  49529MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   28C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   27C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      42398      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    7    0      27276      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
|    1    8    0      42642      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1    9    0      44215      C   ...jeefzx3kp5jqdu/bin/python     8023MiB |
|    1   12    0      44711      C   ...sification_env/bin/python     9271MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6103714085494043}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.001, model='distilbert-base-uncased', num_epochs=7, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 850.77it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.62}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 6 training:
 ===> Epoch 6
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
Epoch 7 training:
 ===> Epoch 7
 - Average training metrics: accuracy={'accuracy': 0.6265}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6040644709180099}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 01:30:19 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   55C    P0   221W / 300W |  27516MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   58C    P0   229W / 300W |  34832MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   29C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   29C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      45129      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
|    1    9    0      44215      C   ...jeefzx3kp5jqdu/bin/python     8023MiB |
|    1   12    0      46888      C   ...sification_env/bin/python     9271MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6040644709180099}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0001, model='distilbert-base-uncased', num_epochs=5, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 842.99it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.623625}
 - Average validation metrics: accuracy={'accuracy': 0.6296636085626911}
 - Average test metrics: accuracy={'accuracy': 0.6124737210932025}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.695625}
 - Average validation metrics: accuracy={'accuracy': 0.6831804281345566}
 - Average test metrics: accuracy={'accuracy': 0.6839523475823406}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.8085}
 - Average validation metrics: accuracy={'accuracy': 0.6960244648318042}
 - Average test metrics: accuracy={'accuracy': 0.6916608269096005}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.895625}
 - Average validation metrics: accuracy={'accuracy': 0.689908256880734}
 - Average test metrics: accuracy={'accuracy': 0.6818500350385424}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.94575}
 - Average validation metrics: accuracy={'accuracy': 0.7070336391437309}
 - Average test metrics: accuracy={'accuracy': 0.7042747021723896}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 01:44:38 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   58C    P0   197W / 300W |  27660MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   54C    P0   177W / 300W |  25702MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   29C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   29C    P0    44W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      47018      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
|    1    9    0      44215      C   ...jeefzx3kp5jqdu/bin/python     8167MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.7070336391437309}
 - Average TEST metrics: accuracy={'accuracy': 0.7042747021723896}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.0005, model='distilbert-base-uncased', num_epochs=5, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 857.03it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.614125}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6215837421163279}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.6235}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6215837421163279}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.623375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6215837421163279}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.623375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6215837421163279}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.623375}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6215837421163279}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 01:58:47 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   55C    P0   212W / 300W |  31352MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   53C    P0   165W / 300W |  25702MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   29C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   29C    P0    43W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      48344      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
|    1    9    0      44215      C   ...jeefzx3kp5jqdu/bin/python     8167MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6215837421163279}
Found cached dataset boolq (/home/tli104/.cache/huggingface/datasets/boolq/default/0.1.0/bf0dd57da941c50de94ae3ce3cef7fea48c08f337a4b7aac484e9dddc5aa24e5)
Specified arguments: Namespace(batch_size=64, device='cuda', experiment='full', lr=0.001, model='distilbert-base-uncased', num_epochs=5, small_subset=False)
Loading the dataset ...
  0%|          | 0/2 [00:00<?, ?it/s]100%|██████████| 2/2 [00:00<00:00, 855.11it/s]
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Slicing the data...
Size of the loaded dataset:
 - train: 8000
 - dev: 3270
 - test: 1427
Loading the tokenizer...
Loding the data into DS...
 >>>>>>>> Initializing the data loaders ... 
Loading the model ...
Moving model to device ...cuda
 >>>>>>>>  Starting training ... 
 >>>>>>>>  Initializing optimizer
Epoch 1 training:
 ===> Epoch 1
 - Average training metrics: accuracy={'accuracy': 0.619}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6187806587245971}
Epoch 2 training:
 ===> Epoch 2
 - Average training metrics: accuracy={'accuracy': 0.62025}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6187806587245971}
Epoch 3 training:
 ===> Epoch 3
 - Average training metrics: accuracy={'accuracy': 0.623875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6187806587245971}
Epoch 4 training:
 ===> Epoch 4
 - Average training metrics: accuracy={'accuracy': 0.623875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6187806587245971}
Epoch 5 training:
 ===> Epoch 5
 - Average training metrics: accuracy={'accuracy': 0.623875}
 - Average validation metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average test metrics: accuracy={'accuracy': 0.6187806587245971}
torch.cuda.memory_allocated: 0.502843GB
torch.cuda.memory_reserved: 6.277344GB
torch.cuda.max_memory_reserved: 6.277344GB
Tue Mar 14 02:12:57 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.56       Driver Version: 460.56       CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Graphics Device     On   | 00000000:17:00.0 Off |                   On |
| N/A   52C    P0   153W / 300W |  22904MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   1  Graphics Device     On   | 00000000:31:00.0 Off |                   On |
| N/A   56C    P0   192W / 300W |  25702MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   2  Graphics Device     On   | 00000000:B1:00.0 Off |                   On |
| N/A   30C    P0    41W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+
|   3  Graphics Device     On   | 00000000:CA:00.0 Off |                   On |
| N/A   29C    P0    44W / 300W |     13MiB / 81251MiB |     N/A      Default |
|                               |                      |              Enabled |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| MIG devices:                                                                |
+------------------+----------------------+-----------+-----------------------+
| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |
|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|
|                  |                      |        ECC|                       |
|==================+======================+===========+=======================|
|  0   13   0   0  |   7350MiB /  9728MiB | 14      0 |  1   0    0    0    0 |
|                  |      4MiB / 16383MiB |           |                       |
+------------------+----------------------+-----------+-----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   13    0      49387      C   ...jeefzx3kp5jqdu/bin/python     7345MiB |
|    1   10    0      35327      C   ...jeefzx3kp5jqdu/bin/python     8633MiB |
|    1   11    0      35329      C   ...jeefzx3kp5jqdu/bin/python     8879MiB |
|    1    9    0      44215      C   ...jeefzx3kp5jqdu/bin/python     8167MiB |
+-----------------------------------------------------------------------------+

 - Average DEV metrics: accuracy={'accuracy': 0.6217125382262997}
 - Average TEST metrics: accuracy={'accuracy': 0.6187806587245971}
